2023-10-25 12:25:29.875 | INFO     | __main__:<module>:353 - Using evaluation function v2 to print results
2023-10-25 12:25:31.448 | INFO     | __main__:main:115 - model build
2023-10-25 12:26:30.615 | INFO     | __main__:train:314 - Epoch: [0][0/1251]	 loss 10.74018	 cls_loss: 7.0042 cluster_loss: 6.8014 sup_con_loss: 0.6057 contrastive_loss: 5.6244 nll_loss: 0.0000 
2023-10-25 12:30:17.173 | INFO     | __main__:train:314 - Epoch: [0][100/1251]	 loss 5.53738	 cls_loss: 1.0246 cluster_loss: 2.3961 sup_con_loss: 0.4910 contrastive_loss: 5.3053 nll_loss: 0.0010 
2023-10-25 12:34:02.772 | INFO     | __main__:train:314 - Epoch: [0][200/1251]	 loss 5.47585	 cls_loss: 0.9974 cluster_loss: 2.1837 sup_con_loss: 0.7595 contrastive_loss: 5.2922 nll_loss: 0.0016 
2023-10-25 12:37:53.129 | INFO     | __main__:train:314 - Epoch: [0][300/1251]	 loss 5.38269	 cls_loss: 0.8008 cluster_loss: 2.2055 sup_con_loss: 0.6426 contrastive_loss: 5.2944 nll_loss: 0.0025 
2023-10-25 12:41:37.578 | INFO     | __main__:train:314 - Epoch: [0][400/1251]	 loss 5.32819	 cls_loss: 1.0678 cluster_loss: 2.1132 sup_con_loss: 0.4085 contrastive_loss: 5.2861 nll_loss: 0.0020 
2023-10-25 12:45:23.985 | INFO     | __main__:train:314 - Epoch: [0][500/1251]	 loss 5.40547	 cls_loss: 0.8471 cluster_loss: 2.2227 sup_con_loss: 0.6511 contrastive_loss: 5.2833 nll_loss: 0.0022 
2023-10-25 12:49:09.622 | INFO     | __main__:train:314 - Epoch: [0][600/1251]	 loss 5.34409	 cls_loss: 0.8343 cluster_loss: 2.2125 sup_con_loss: 0.5032 contrastive_loss: 5.2852 nll_loss: 0.0025 
2023-10-25 12:52:56.024 | INFO     | __main__:train:314 - Epoch: [0][700/1251]	 loss 5.24651	 cls_loss: 0.8493 cluster_loss: 2.0681 sup_con_loss: 0.4917 contrastive_loss: 5.2777 nll_loss: 0.0024 
2023-10-25 12:56:46.128 | INFO     | __main__:train:314 - Epoch: [0][800/1251]	 loss 5.18670	 cls_loss: 0.7807 cluster_loss: 1.9839 sup_con_loss: 0.5478 contrastive_loss: 5.2762 nll_loss: 0.0027 
2023-10-25 13:00:34.305 | INFO     | __main__:train:314 - Epoch: [0][900/1251]	 loss 5.31492	 cls_loss: 0.9842 cluster_loss: 2.0949 sup_con_loss: 0.4912 contrastive_loss: 5.2831 nll_loss: 0.0028 
2023-10-25 13:04:38.553 | INFO     | __main__:train:314 - Epoch: [0][1000/1251]	 loss 5.13651	 cls_loss: 0.8607 cluster_loss: 1.9581 sup_con_loss: 0.3690 contrastive_loss: 5.2764 nll_loss: 0.0036 
2023-10-25 13:08:25.068 | INFO     | __main__:train:314 - Epoch: [0][1100/1251]	 loss 5.16788	 cls_loss: 0.8484 cluster_loss: 2.0196 sup_con_loss: 0.3583 contrastive_loss: 5.2768 nll_loss: 0.0029 
2023-10-25 13:12:12.818 | INFO     | __main__:train:314 - Epoch: [0][1200/1251]	 loss 5.08693	 cls_loss: 0.7938 cluster_loss: 1.9385 sup_con_loss: 0.3294 contrastive_loss: 5.2776 nll_loss: 0.0034 
2023-10-25 13:14:05.171 | INFO     | __main__:train:319 - Train Epoch: 0 Avg Loss: 5.3893 
2023-10-25 13:14:05.178 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-25 13:39:05.822 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 0, Train ACC Unlabelled_v2: All 0.4477 | Old 0.7412 | New 0.3003
2023-10-25 13:39:06.810 | INFO     | __main__:main:205 - Train Accuracies: All 0.4477 | Old 0.7412 | New 0.3003
2023-10-25 13:39:08.233 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-25 13:39:37.691 | INFO     | __main__:train:314 - Epoch: [1][0/1251]	 loss 5.16262	 cls_loss: 0.8616 cluster_loss: 1.9610 sup_con_loss: 0.4468 contrastive_loss: 5.2729 nll_loss: 0.0026 
2023-10-25 13:43:22.172 | INFO     | __main__:train:314 - Epoch: [1][100/1251]	 loss 5.17287	 cls_loss: 0.9590 cluster_loss: 1.9776 sup_con_loss: 0.3282 contrastive_loss: 5.2823 nll_loss: 0.0035 
2023-10-25 13:47:07.104 | INFO     | __main__:train:314 - Epoch: [1][200/1251]	 loss 5.03497	 cls_loss: 0.6972 cluster_loss: 1.8782 sup_con_loss: 0.3963 contrastive_loss: 5.2738 nll_loss: 0.0035 
2023-10-25 13:50:56.565 | INFO     | __main__:train:314 - Epoch: [1][300/1251]	 loss 5.15234	 cls_loss: 0.8930 cluster_loss: 1.9098 sup_con_loss: 0.4820 contrastive_loss: 5.2730 nll_loss: 0.0022 
2023-10-25 13:54:42.464 | INFO     | __main__:train:314 - Epoch: [1][400/1251]	 loss 5.06690	 cls_loss: 0.7303 cluster_loss: 1.8626 sup_con_loss: 0.4795 contrastive_loss: 5.2772 nll_loss: 0.0026 
2023-10-25 13:58:25.919 | INFO     | __main__:train:314 - Epoch: [1][500/1251]	 loss 5.12779	 cls_loss: 0.7065 cluster_loss: 1.9448 sup_con_loss: 0.5305 contrastive_loss: 5.2738 nll_loss: 0.0027 
2023-10-25 14:02:10.399 | INFO     | __main__:train:314 - Epoch: [1][600/1251]	 loss 5.08058	 cls_loss: 0.7768 cluster_loss: 1.9447 sup_con_loss: 0.3252 contrastive_loss: 5.2745 nll_loss: 0.0024 
2023-10-25 14:05:53.737 | INFO     | __main__:train:314 - Epoch: [1][700/1251]	 loss 5.12171	 cls_loss: 0.6197 cluster_loss: 1.9508 sup_con_loss: 0.5786 contrastive_loss: 5.2795 nll_loss: 0.0026 
2023-10-25 14:09:39.629 | INFO     | __main__:train:314 - Epoch: [1][800/1251]	 loss 5.03727	 cls_loss: 0.7483 cluster_loss: 1.8432 sup_con_loss: 0.4150 contrastive_loss: 5.2748 nll_loss: 0.0034 
2023-10-25 14:13:24.535 | INFO     | __main__:train:314 - Epoch: [1][900/1251]	 loss 4.92762	 cls_loss: 0.5622 cluster_loss: 1.8398 sup_con_loss: 0.2987 contrastive_loss: 5.2727 nll_loss: 0.0032 
2023-10-25 14:17:11.627 | INFO     | __main__:train:314 - Epoch: [1][1000/1251]	 loss 5.21832	 cls_loss: 0.7445 cluster_loss: 2.0048 sup_con_loss: 0.6219 contrastive_loss: 5.2838 nll_loss: 0.0025 
2023-10-25 14:20:57.966 | INFO     | __main__:train:314 - Epoch: [1][1100/1251]	 loss 5.00725	 cls_loss: 0.5742 cluster_loss: 1.9137 sup_con_loss: 0.3652 contrastive_loss: 5.2793 nll_loss: 0.0030 
2023-10-25 14:24:44.662 | INFO     | __main__:train:314 - Epoch: [1][1200/1251]	 loss 5.22184	 cls_loss: 0.8245 cluster_loss: 1.9629 sup_con_loss: 0.6382 contrastive_loss: 5.2774 nll_loss: 0.0037 
2023-10-25 14:26:36.064 | INFO     | __main__:train:319 - Train Epoch: 1 Avg Loss: 5.1106 
2023-10-25 14:26:36.070 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-25 14:49:13.503 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 1, Train ACC Unlabelled_v2: All 0.4667 | Old 0.7641 | New 0.3172
2023-10-25 14:49:13.766 | INFO     | __main__:main:205 - Train Accuracies: All 0.4667 | Old 0.7641 | New 0.3172
2023-10-25 14:49:15.405 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-25 14:49:34.969 | INFO     | __main__:train:314 - Epoch: [2][0/1251]	 loss 5.21278	 cls_loss: 0.7156 cluster_loss: 1.9871 sup_con_loss: 0.6844 contrastive_loss: 5.2773 nll_loss: 0.0009 
2023-10-25 14:53:19.231 | INFO     | __main__:train:314 - Epoch: [2][100/1251]	 loss 5.08438	 cls_loss: 0.7521 cluster_loss: 1.8551 sup_con_loss: 0.5247 contrastive_loss: 5.2729 nll_loss: 0.0043 
2023-10-25 14:57:04.865 | INFO     | __main__:train:314 - Epoch: [2][200/1251]	 loss 5.08008	 cls_loss: 0.6814 cluster_loss: 1.9123 sup_con_loss: 0.4731 contrastive_loss: 5.2789 nll_loss: 0.0017 
2023-10-25 15:00:56.526 | INFO     | __main__:train:314 - Epoch: [2][300/1251]	 loss 5.08251	 cls_loss: 0.6393 cluster_loss: 1.9180 sup_con_loss: 0.5248 contrastive_loss: 5.2717 nll_loss: 0.0018 
2023-10-25 15:04:41.279 | INFO     | __main__:train:314 - Epoch: [2][400/1251]	 loss 5.12275	 cls_loss: 0.9394 cluster_loss: 1.9165 sup_con_loss: 0.3286 contrastive_loss: 5.2772 nll_loss: 0.0031 
2023-10-25 15:08:27.447 | INFO     | __main__:train:314 - Epoch: [2][500/1251]	 loss 5.04899	 cls_loss: 0.6409 cluster_loss: 1.9592 sup_con_loss: 0.3303 contrastive_loss: 5.2802 nll_loss: 0.0035 
2023-10-25 15:12:13.195 | INFO     | __main__:train:314 - Epoch: [2][600/1251]	 loss 5.07239	 cls_loss: 0.8082 cluster_loss: 1.8781 sup_con_loss: 0.3878 contrastive_loss: 5.2777 nll_loss: 0.0026 
2023-10-25 15:15:59.101 | INFO     | __main__:train:314 - Epoch: [2][700/1251]	 loss 5.00334	 cls_loss: 0.6868 cluster_loss: 1.8451 sup_con_loss: 0.3739 contrastive_loss: 5.2748 nll_loss: 0.0042 
2023-10-25 15:19:42.992 | INFO     | __main__:train:314 - Epoch: [2][800/1251]	 loss 5.00263	 cls_loss: 0.5642 cluster_loss: 1.8521 sup_con_loss: 0.4883 contrastive_loss: 5.2746 nll_loss: 0.0019 
2023-10-25 15:23:32.430 | INFO     | __main__:train:314 - Epoch: [2][900/1251]	 loss 5.09804	 cls_loss: 0.6467 cluster_loss: 1.8694 sup_con_loss: 0.6303 contrastive_loss: 5.2821 nll_loss: 0.0026 
2023-10-25 15:27:21.365 | INFO     | __main__:train:314 - Epoch: [2][1000/1251]	 loss 5.02025	 cls_loss: 0.6515 cluster_loss: 1.8465 sup_con_loss: 0.4548 contrastive_loss: 5.2759 nll_loss: 0.0035 
2023-10-25 15:31:54.364 | INFO     | __main__:train:314 - Epoch: [2][1100/1251]	 loss 4.98516	 cls_loss: 0.6522 cluster_loss: 1.8213 sup_con_loss: 0.4022 contrastive_loss: 5.2748 nll_loss: 0.0037 
2023-10-25 15:36:03.830 | INFO     | __main__:train:314 - Epoch: [2][1200/1251]	 loss 5.01089	 cls_loss: 0.7665 cluster_loss: 1.8593 sup_con_loss: 0.2944 contrastive_loss: 5.2737 nll_loss: 0.0031 
2023-10-25 15:37:58.255 | INFO     | __main__:train:319 - Train Epoch: 2 Avg Loss: 5.0601 
2023-10-25 15:37:58.325 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-25 16:06:39.105 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 2, Train ACC Unlabelled_v2: All 0.4712 | Old 0.7653 | New 0.3234
2023-10-25 16:06:39.406 | INFO     | __main__:main:205 - Train Accuracies: All 0.4712 | Old 0.7653 | New 0.3234
2023-10-25 16:06:40.933 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-25 16:06:57.913 | INFO     | __main__:train:314 - Epoch: [3][0/1251]	 loss 4.97496	 cls_loss: 0.6121 cluster_loss: 1.7250 sup_con_loss: 0.6102 contrastive_loss: 5.2654 nll_loss: 0.0034 
2023-10-25 16:10:42.469 | INFO     | __main__:train:314 - Epoch: [3][100/1251]	 loss 5.01853	 cls_loss: 0.7853 cluster_loss: 1.7616 sup_con_loss: 0.4783 contrastive_loss: 5.2735 nll_loss: 0.0035 
2023-10-25 16:14:26.760 | INFO     | __main__:train:314 - Epoch: [3][200/1251]	 loss 5.08661	 cls_loss: 0.6395 cluster_loss: 1.8487 sup_con_loss: 0.6434 contrastive_loss: 5.2790 nll_loss: 0.0046 
2023-10-25 16:18:16.484 | INFO     | __main__:train:314 - Epoch: [3][300/1251]	 loss 5.10220	 cls_loss: 0.7456 cluster_loss: 1.8959 sup_con_loss: 0.4941 contrastive_loss: 5.2801 nll_loss: 0.0039 
2023-10-25 16:22:18.858 | INFO     | __main__:train:314 - Epoch: [3][400/1251]	 loss 4.84292	 cls_loss: 0.5112 cluster_loss: 1.7486 sup_con_loss: 0.2758 contrastive_loss: 5.2739 nll_loss: 0.0029 
2023-10-25 16:26:09.065 | INFO     | __main__:train:314 - Epoch: [3][500/1251]	 loss 5.00341	 cls_loss: 0.5946 cluster_loss: 1.8962 sup_con_loss: 0.3632 contrastive_loss: 5.2801 nll_loss: 0.0036 
2023-10-25 16:31:09.439 | INFO     | __main__:train:314 - Epoch: [3][600/1251]	 loss 5.05298	 cls_loss: 0.6177 cluster_loss: 1.8856 sup_con_loss: 0.5010 contrastive_loss: 5.2817 nll_loss: 0.0027 
2023-10-25 16:34:55.156 | INFO     | __main__:train:314 - Epoch: [3][700/1251]	 loss 4.86940	 cls_loss: 0.5396 cluster_loss: 1.7322 sup_con_loss: 0.3591 contrastive_loss: 5.2693 nll_loss: 0.0039 
2023-10-25 16:38:43.261 | INFO     | __main__:train:314 - Epoch: [3][800/1251]	 loss 5.07545	 cls_loss: 0.7299 cluster_loss: 1.8523 sup_con_loss: 0.5232 contrastive_loss: 5.2791 nll_loss: 0.0015 
2023-10-25 16:42:29.260 | INFO     | __main__:train:314 - Epoch: [3][900/1251]	 loss 4.93534	 cls_loss: 0.6809 cluster_loss: 1.7760 sup_con_loss: 0.3298 contrastive_loss: 5.2699 nll_loss: 0.0017 
2023-10-25 16:46:16.973 | INFO     | __main__:train:314 - Epoch: [3][1000/1251]	 loss 5.02398	 cls_loss: 0.5901 cluster_loss: 1.8279 sup_con_loss: 0.5728 contrastive_loss: 5.2722 nll_loss: 0.0019 
2023-10-25 16:50:09.099 | INFO     | __main__:train:314 - Epoch: [3][1100/1251]	 loss 5.05954	 cls_loss: 0.7722 cluster_loss: 1.8157 sup_con_loss: 0.5088 contrastive_loss: 5.2733 nll_loss: 0.0034 
2023-10-25 16:54:06.075 | INFO     | __main__:train:314 - Epoch: [3][1200/1251]	 loss 5.02047	 cls_loss: 0.6379 cluster_loss: 1.8529 sup_con_loss: 0.4457 contrastive_loss: 5.2815 nll_loss: 0.0039 
2023-10-25 16:55:59.678 | INFO     | __main__:train:319 - Train Epoch: 3 Avg Loss: 5.0152 
2023-10-25 16:55:59.711 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-25 17:26:13.605 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 3, Train ACC Unlabelled_v2: All 0.4825 | Old 0.7663 | New 0.3398
2023-10-25 17:26:14.000 | INFO     | __main__:main:205 - Train Accuracies: All 0.4825 | Old 0.7663 | New 0.3398
2023-10-25 17:26:16.814 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-25 17:26:35.648 | INFO     | __main__:train:314 - Epoch: [4][0/1251]	 loss 5.10069	 cls_loss: 0.7338 cluster_loss: 1.8301 sup_con_loss: 0.6366 contrastive_loss: 5.2752 nll_loss: 0.0027 
2023-10-25 17:30:23.311 | INFO     | __main__:train:314 - Epoch: [4][100/1251]	 loss 5.00662	 cls_loss: 0.5943 cluster_loss: 1.8047 sup_con_loss: 0.5499 contrastive_loss: 5.2764 nll_loss: 0.0034 
2023-10-25 17:34:10.300 | INFO     | __main__:train:314 - Epoch: [4][200/1251]	 loss 4.98479	 cls_loss: 0.7365 cluster_loss: 1.7552 sup_con_loss: 0.4546 contrastive_loss: 5.2680 nll_loss: 0.0028 
2023-10-25 17:37:55.483 | INFO     | __main__:train:314 - Epoch: [4][300/1251]	 loss 5.08991	 cls_loss: 0.7608 cluster_loss: 1.8141 sup_con_loss: 0.6025 contrastive_loss: 5.2775 nll_loss: 0.0032 
2023-10-25 17:42:32.657 | INFO     | __main__:train:314 - Epoch: [4][400/1251]	 loss 5.03050	 cls_loss: 0.8012 cluster_loss: 1.8302 sup_con_loss: 0.3807 contrastive_loss: 5.2688 nll_loss: 0.0025 
2023-10-25 17:46:40.263 | INFO     | __main__:train:314 - Epoch: [4][500/1251]	 loss 5.04175	 cls_loss: 0.6567 cluster_loss: 1.7656 sup_con_loss: 0.6692 contrastive_loss: 5.2731 nll_loss: 0.0025 
2023-10-25 17:50:49.037 | INFO     | __main__:train:314 - Epoch: [4][600/1251]	 loss 4.83813	 cls_loss: 0.4679 cluster_loss: 1.7902 sup_con_loss: 0.2149 contrastive_loss: 5.2814 nll_loss: 0.0026 
2023-10-25 17:54:35.344 | INFO     | __main__:train:314 - Epoch: [4][700/1251]	 loss 4.89284	 cls_loss: 0.4936 cluster_loss: 1.7679 sup_con_loss: 0.4015 contrastive_loss: 5.2706 nll_loss: 0.0045 
2023-10-25 17:58:29.559 | INFO     | __main__:train:314 - Epoch: [4][800/1251]	 loss 4.97238	 cls_loss: 0.7025 cluster_loss: 1.6971 sup_con_loss: 0.5576 contrastive_loss: 5.2693 nll_loss: 0.0032 
2023-10-25 18:02:28.035 | INFO     | __main__:train:314 - Epoch: [4][900/1251]	 loss 4.93526	 cls_loss: 0.5838 cluster_loss: 1.6956 sup_con_loss: 0.5798 contrastive_loss: 5.2664 nll_loss: 0.0027 
2023-10-25 18:06:18.598 | INFO     | __main__:train:314 - Epoch: [4][1000/1251]	 loss 4.95054	 cls_loss: 0.6440 cluster_loss: 1.7812 sup_con_loss: 0.3855 contrastive_loss: 5.2757 nll_loss: 0.0032 
2023-10-25 18:10:08.056 | INFO     | __main__:train:314 - Epoch: [4][1100/1251]	 loss 4.92529	 cls_loss: 0.5772 cluster_loss: 1.7740 sup_con_loss: 0.3885 contrastive_loss: 5.2779 nll_loss: 0.0036 
2023-10-25 18:13:54.538 | INFO     | __main__:train:314 - Epoch: [4][1200/1251]	 loss 4.99548	 cls_loss: 0.7287 cluster_loss: 1.7886 sup_con_loss: 0.4197 contrastive_loss: 5.2730 nll_loss: 0.0035 
2023-10-25 18:15:47.066 | INFO     | __main__:train:319 - Train Epoch: 4 Avg Loss: 4.9895 
2023-10-25 18:15:47.094 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-25 19:01:32.704 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 4, Train ACC Unlabelled_v2: All 0.4983 | Old 0.7693 | New 0.3622
2023-10-25 19:01:34.214 | INFO     | __main__:main:205 - Train Accuracies: All 0.4983 | Old 0.7693 | New 0.3622
2023-10-25 19:01:37.242 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-25 19:02:25.734 | INFO     | __main__:train:314 - Epoch: [5][0/1251]	 loss 5.02639	 cls_loss: 0.7092 cluster_loss: 1.8801 sup_con_loss: 0.3457 contrastive_loss: 5.2798 nll_loss: 0.0032 
2023-10-25 19:07:07.902 | INFO     | __main__:train:314 - Epoch: [5][100/1251]	 loss 5.01508	 cls_loss: 0.7467 cluster_loss: 1.7494 sup_con_loss: 0.5260 contrastive_loss: 5.2754 nll_loss: 0.0036 
2023-10-25 19:12:48.640 | INFO     | __main__:train:314 - Epoch: [5][200/1251]	 loss 4.98268	 cls_loss: 0.5820 cluster_loss: 1.7881 sup_con_loss: 0.5394 contrastive_loss: 5.2719 nll_loss: 0.0012 
2023-10-25 19:16:46.780 | INFO     | __main__:train:314 - Epoch: [5][300/1251]	 loss 4.90716	 cls_loss: 0.6004 cluster_loss: 1.7806 sup_con_loss: 0.2997 contrastive_loss: 5.2805 nll_loss: 0.0024 
2023-10-25 19:21:47.095 | INFO     | __main__:train:314 - Epoch: [5][400/1251]	 loss 4.99100	 cls_loss: 0.7329 cluster_loss: 1.8384 sup_con_loss: 0.3070 contrastive_loss: 5.2776 nll_loss: 0.0017 
2023-10-25 19:27:49.893 | INFO     | __main__:train:314 - Epoch: [5][500/1251]	 loss 4.85752	 cls_loss: 0.5454 cluster_loss: 1.7193 sup_con_loss: 0.3417 contrastive_loss: 5.2681 nll_loss: 0.0052 
2023-10-25 19:37:02.599 | INFO     | __main__:train:314 - Epoch: [5][600/1251]	 loss 4.83873	 cls_loss: 0.5316 cluster_loss: 1.6755 sup_con_loss: 0.3845 contrastive_loss: 5.2677 nll_loss: 0.0050 
2023-10-25 19:43:38.472 | INFO     | __main__:train:314 - Epoch: [5][700/1251]	 loss 5.06382	 cls_loss: 0.6633 cluster_loss: 1.8038 sup_con_loss: 0.6504 contrastive_loss: 5.2754 nll_loss: 0.0025 
2023-10-25 19:49:00.212 | INFO     | __main__:train:314 - Epoch: [5][800/1251]	 loss 4.93458	 cls_loss: 0.6506 cluster_loss: 1.7680 sup_con_loss: 0.3657 contrastive_loss: 5.2735 nll_loss: 0.0019 
2023-10-25 19:55:56.710 | INFO     | __main__:train:314 - Epoch: [5][900/1251]	 loss 4.97987	 cls_loss: 0.6767 cluster_loss: 1.6713 sup_con_loss: 0.6604 contrastive_loss: 5.2670 nll_loss: 0.0020 
2023-10-25 20:01:11.784 | INFO     | __main__:train:314 - Epoch: [5][1000/1251]	 loss 4.87945	 cls_loss: 0.5589 cluster_loss: 1.7063 sup_con_loss: 0.4234 contrastive_loss: 5.2682 nll_loss: 0.0022 
2023-10-25 20:04:59.108 | INFO     | __main__:train:314 - Epoch: [5][1100/1251]	 loss 4.85796	 cls_loss: 0.6057 cluster_loss: 1.7319 sup_con_loss: 0.2589 contrastive_loss: 5.2733 nll_loss: 0.0020 
2023-10-25 20:08:47.875 | INFO     | __main__:train:314 - Epoch: [5][1200/1251]	 loss 5.04909	 cls_loss: 0.7170 cluster_loss: 1.7591 sup_con_loss: 0.6399 contrastive_loss: 5.2749 nll_loss: 0.0021 
2023-10-25 20:10:43.487 | INFO     | __main__:train:319 - Train Epoch: 5 Avg Loss: 4.9609 
2023-10-25 20:10:43.501 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-25 20:37:07.356 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 5, Train ACC Unlabelled_v2: All 0.5066 | Old 0.7740 | New 0.3721
2023-10-25 20:37:07.621 | INFO     | __main__:main:205 - Train Accuracies: All 0.5066 | Old 0.7740 | New 0.3721
2023-10-25 20:37:09.106 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-25 20:37:25.941 | INFO     | __main__:train:314 - Epoch: [6][0/1251]	 loss 4.82930	 cls_loss: 0.5265 cluster_loss: 1.6781 sup_con_loss: 0.3640 contrastive_loss: 5.2667 nll_loss: 0.0035 
2023-10-25 20:41:13.346 | INFO     | __main__:train:314 - Epoch: [6][100/1251]	 loss 4.98211	 cls_loss: 0.7321 cluster_loss: 1.6833 sup_con_loss: 0.5689 contrastive_loss: 5.2749 nll_loss: 0.0040 
2023-10-25 20:45:12.803 | INFO     | __main__:train:314 - Epoch: [6][200/1251]	 loss 4.84496	 cls_loss: 0.6139 cluster_loss: 1.6517 sup_con_loss: 0.3716 contrastive_loss: 5.2669 nll_loss: 0.0029 
2023-10-25 20:48:58.984 | INFO     | __main__:train:314 - Epoch: [6][300/1251]	 loss 4.93182	 cls_loss: 0.5691 cluster_loss: 1.7639 sup_con_loss: 0.4351 contrastive_loss: 5.2762 nll_loss: 0.0043 
2023-10-25 20:52:52.016 | INFO     | __main__:train:314 - Epoch: [6][400/1251]	 loss 4.87851	 cls_loss: 0.5898 cluster_loss: 1.7379 sup_con_loss: 0.3146 contrastive_loss: 5.2763 nll_loss: 0.0027 
2023-10-25 20:56:38.731 | INFO     | __main__:train:314 - Epoch: [6][500/1251]	 loss 4.97023	 cls_loss: 0.5772 cluster_loss: 1.7907 sup_con_loss: 0.4958 contrastive_loss: 5.2742 nll_loss: 0.0025 
2023-10-25 21:00:25.246 | INFO     | __main__:train:314 - Epoch: [6][600/1251]	 loss 4.86914	 cls_loss: 0.5993 cluster_loss: 1.7018 sup_con_loss: 0.3582 contrastive_loss: 5.2691 nll_loss: 0.0029 
2023-10-25 21:04:42.461 | INFO     | __main__:train:314 - Epoch: [6][700/1251]	 loss 4.98469	 cls_loss: 0.6429 cluster_loss: 1.7601 sup_con_loss: 0.5192 contrastive_loss: 5.2775 nll_loss: 0.0035 
2023-10-25 21:11:16.641 | INFO     | __main__:train:314 - Epoch: [6][800/1251]	 loss 4.81563	 cls_loss: 0.5065 cluster_loss: 1.7125 sup_con_loss: 0.2702 contrastive_loss: 5.2716 nll_loss: 0.0041 
2023-10-25 21:16:40.039 | INFO     | __main__:train:314 - Epoch: [6][900/1251]	 loss 4.85230	 cls_loss: 0.6527 cluster_loss: 1.6220 sup_con_loss: 0.4054 contrastive_loss: 5.2676 nll_loss: 0.0038 
2023-10-25 21:22:54.370 | INFO     | __main__:train:314 - Epoch: [6][1000/1251]	 loss 5.02260	 cls_loss: 0.8044 cluster_loss: 1.8071 sup_con_loss: 0.3912 contrastive_loss: 5.2738 nll_loss: 0.0015 
2023-10-25 21:29:08.251 | INFO     | __main__:train:314 - Epoch: [6][1100/1251]	 loss 4.89199	 cls_loss: 0.6158 cluster_loss: 1.7156 sup_con_loss: 0.3751 contrastive_loss: 5.2722 nll_loss: 0.0031 
2023-10-25 21:35:53.556 | INFO     | __main__:train:314 - Epoch: [6][1200/1251]	 loss 4.86605	 cls_loss: 0.5796 cluster_loss: 1.7182 sup_con_loss: 0.3303 contrastive_loss: 5.2730 nll_loss: 0.0033 
2023-10-25 21:41:49.462 | INFO     | __main__:train:319 - Train Epoch: 6 Avg Loss: 4.9356 
2023-10-25 21:41:49.588 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-25 22:30:22.507 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 6, Train ACC Unlabelled_v2: All 0.5182 | Old 0.7744 | New 0.3894
2023-10-25 22:30:24.350 | INFO     | __main__:main:205 - Train Accuracies: All 0.5182 | Old 0.7744 | New 0.3894
2023-10-25 22:30:33.944 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-25 22:32:13.641 | INFO     | __main__:train:314 - Epoch: [7][0/1251]	 loss 4.88765	 cls_loss: 0.6095 cluster_loss: 1.6750 sup_con_loss: 0.4431 contrastive_loss: 5.2709 nll_loss: 0.0044 
2023-10-25 22:36:55.122 | INFO     | __main__:train:314 - Epoch: [7][100/1251]	 loss 4.80704	 cls_loss: 0.4839 cluster_loss: 1.6688 sup_con_loss: 0.3545 contrastive_loss: 5.2709 nll_loss: 0.0028 
2023-10-25 22:41:19.661 | INFO     | __main__:train:314 - Epoch: [7][200/1251]	 loss 4.96620	 cls_loss: 0.7379 cluster_loss: 1.6617 sup_con_loss: 0.5731 contrastive_loss: 5.2698 nll_loss: 0.0019 
2023-10-25 22:46:25.201 | INFO     | __main__:train:314 - Epoch: [7][300/1251]	 loss 4.88547	 cls_loss: 0.5632 cluster_loss: 1.6400 sup_con_loss: 0.5507 contrastive_loss: 5.2697 nll_loss: 0.0043 
2023-10-25 22:50:45.780 | INFO     | __main__:train:314 - Epoch: [7][400/1251]	 loss 4.86481	 cls_loss: 0.5952 cluster_loss: 1.6751 sup_con_loss: 0.3887 contrastive_loss: 5.2731 nll_loss: 0.0041 
2023-10-25 22:55:15.431 | INFO     | __main__:train:314 - Epoch: [7][500/1251]	 loss 4.99546	 cls_loss: 0.6488 cluster_loss: 1.7309 sup_con_loss: 0.6093 contrastive_loss: 5.2723 nll_loss: 0.0031 
2023-10-25 22:59:12.204 | INFO     | __main__:train:314 - Epoch: [7][600/1251]	 loss 4.83691	 cls_loss: 0.5356 cluster_loss: 1.6829 sup_con_loss: 0.3610 contrastive_loss: 5.2718 nll_loss: 0.0025 
2023-10-25 23:02:56.192 | INFO     | __main__:train:314 - Epoch: [7][700/1251]	 loss 4.83175	 cls_loss: 0.5888 cluster_loss: 1.6326 sup_con_loss: 0.3735 contrastive_loss: 5.2790 nll_loss: 0.0024 
2023-10-25 23:06:40.859 | INFO     | __main__:train:314 - Epoch: [7][800/1251]	 loss 5.06617	 cls_loss: 0.8240 cluster_loss: 1.7729 sup_con_loss: 0.5427 contrastive_loss: 5.2807 nll_loss: 0.0030 
2023-10-25 23:10:30.064 | INFO     | __main__:train:314 - Epoch: [7][900/1251]	 loss 4.88470	 cls_loss: 0.6381 cluster_loss: 1.6983 sup_con_loss: 0.3587 contrastive_loss: 5.2759 nll_loss: 0.0026 
2023-10-25 23:14:14.848 | INFO     | __main__:train:314 - Epoch: [7][1000/1251]	 loss 4.91665	 cls_loss: 0.6833 cluster_loss: 1.6509 sup_con_loss: 0.5046 contrastive_loss: 5.2680 nll_loss: 0.0036 
2023-10-25 23:18:16.511 | INFO     | __main__:train:314 - Epoch: [7][1100/1251]	 loss 4.98436	 cls_loss: 0.6861 cluster_loss: 1.7068 sup_con_loss: 0.5877 contrastive_loss: 5.2712 nll_loss: 0.0028 
2023-10-25 23:22:02.295 | INFO     | __main__:train:314 - Epoch: [7][1200/1251]	 loss 4.83971	 cls_loss: 0.6203 cluster_loss: 1.6476 sup_con_loss: 0.3535 contrastive_loss: 5.2699 nll_loss: 0.0025 
2023-10-25 23:23:53.455 | INFO     | __main__:train:319 - Train Epoch: 7 Avg Loss: 4.9116 
2023-10-25 23:23:53.463 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 00:00:35.237 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 7, Train ACC Unlabelled_v2: All 0.5349 | Old 0.7779 | New 0.4128
2023-10-26 00:00:35.846 | INFO     | __main__:main:205 - Train Accuracies: All 0.5349 | Old 0.7779 | New 0.4128
2023-10-26 00:00:39.463 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 00:01:08.271 | INFO     | __main__:train:314 - Epoch: [8][0/1251]	 loss 4.93501	 cls_loss: 0.6377 cluster_loss: 1.6934 sup_con_loss: 0.5115 contrastive_loss: 5.2712 nll_loss: 0.0058 
2023-10-26 00:04:55.416 | INFO     | __main__:train:314 - Epoch: [8][100/1251]	 loss 4.90148	 cls_loss: 0.7101 cluster_loss: 1.6452 sup_con_loss: 0.4398 contrastive_loss: 5.2727 nll_loss: 0.0023 
2023-10-26 00:08:57.540 | INFO     | __main__:train:314 - Epoch: [8][200/1251]	 loss 4.87921	 cls_loss: 0.5567 cluster_loss: 1.6614 sup_con_loss: 0.4896 contrastive_loss: 5.2770 nll_loss: 0.0030 
2023-10-26 00:13:27.685 | INFO     | __main__:train:314 - Epoch: [8][300/1251]	 loss 4.84473	 cls_loss: 0.6530 cluster_loss: 1.6014 sup_con_loss: 0.4258 contrastive_loss: 5.2665 nll_loss: 0.0030 
2023-10-26 00:17:33.107 | INFO     | __main__:train:314 - Epoch: [8][400/1251]	 loss 4.90971	 cls_loss: 0.5856 cluster_loss: 1.7223 sup_con_loss: 0.4355 contrastive_loss: 5.2776 nll_loss: 0.0024 
2023-10-26 00:21:22.204 | INFO     | __main__:train:314 - Epoch: [8][500/1251]	 loss 4.82812	 cls_loss: 0.5586 cluster_loss: 1.5905 sup_con_loss: 0.4874 contrastive_loss: 5.2705 nll_loss: 0.0024 
2023-10-26 00:25:11.704 | INFO     | __main__:train:314 - Epoch: [8][600/1251]	 loss 4.82468	 cls_loss: 0.6371 cluster_loss: 1.6208 sup_con_loss: 0.3412 contrastive_loss: 5.2702 nll_loss: 0.0031 
2023-10-26 00:29:06.486 | INFO     | __main__:train:314 - Epoch: [8][700/1251]	 loss 4.89960	 cls_loss: 0.5679 cluster_loss: 1.7198 sup_con_loss: 0.4370 contrastive_loss: 5.2740 nll_loss: 0.0019 
2023-10-26 00:32:55.335 | INFO     | __main__:train:314 - Epoch: [8][800/1251]	 loss 4.83839	 cls_loss: 0.5458 cluster_loss: 1.6475 sup_con_loss: 0.4127 contrastive_loss: 5.2751 nll_loss: 0.0033 
2023-10-26 00:36:48.917 | INFO     | __main__:train:314 - Epoch: [8][900/1251]	 loss 4.78121	 cls_loss: 0.4544 cluster_loss: 1.6640 sup_con_loss: 0.3175 contrastive_loss: 5.2733 nll_loss: 0.0018 
2023-10-26 00:40:32.323 | INFO     | __main__:train:314 - Epoch: [8][1000/1251]	 loss 4.84487	 cls_loss: 0.5684 cluster_loss: 1.6548 sup_con_loss: 0.4021 contrastive_loss: 5.2692 nll_loss: 0.0046 
2023-10-26 00:44:17.497 | INFO     | __main__:train:314 - Epoch: [8][1100/1251]	 loss 4.82101	 cls_loss: 0.5367 cluster_loss: 1.6141 sup_con_loss: 0.4460 contrastive_loss: 5.2702 nll_loss: 0.0023 
2023-10-26 00:48:03.886 | INFO     | __main__:train:314 - Epoch: [8][1200/1251]	 loss 4.84774	 cls_loss: 0.5916 cluster_loss: 1.6117 sup_con_loss: 0.4667 contrastive_loss: 5.2726 nll_loss: 0.0025 
2023-10-26 00:49:59.589 | INFO     | __main__:train:319 - Train Epoch: 8 Avg Loss: 4.8869 
2023-10-26 00:49:59.596 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 01:11:35.249 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 8, Train ACC Unlabelled_v2: All 0.5459 | Old 0.7825 | New 0.4270
2023-10-26 01:11:35.478 | INFO     | __main__:main:205 - Train Accuracies: All 0.5459 | Old 0.7825 | New 0.4270
2023-10-26 01:11:39.117 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 01:11:54.297 | INFO     | __main__:train:314 - Epoch: [9][0/1251]	 loss 4.89757	 cls_loss: 0.5586 cluster_loss: 1.6559 sup_con_loss: 0.5631 contrastive_loss: 5.2722 nll_loss: 0.0017 
2023-10-26 01:15:38.459 | INFO     | __main__:train:314 - Epoch: [9][100/1251]	 loss 4.93997	 cls_loss: 0.6104 cluster_loss: 1.7058 sup_con_loss: 0.5212 contrastive_loss: 5.2802 nll_loss: 0.0030 
2023-10-26 01:19:20.662 | INFO     | __main__:train:314 - Epoch: [9][200/1251]	 loss 4.86324	 cls_loss: 0.5739 cluster_loss: 1.6723 sup_con_loss: 0.4055 contrastive_loss: 5.2787 nll_loss: 0.0023 
2023-10-26 01:23:07.879 | INFO     | __main__:train:314 - Epoch: [9][300/1251]	 loss 4.84176	 cls_loss: 0.5793 cluster_loss: 1.5964 sup_con_loss: 0.4950 contrastive_loss: 5.2689 nll_loss: 0.0033 
2023-10-26 01:26:52.663 | INFO     | __main__:train:314 - Epoch: [9][400/1251]	 loss 4.93059	 cls_loss: 0.6219 cluster_loss: 1.7211 sup_con_loss: 0.4552 contrastive_loss: 5.2804 nll_loss: 0.0026 
2023-10-26 01:30:36.080 | INFO     | __main__:train:314 - Epoch: [9][500/1251]	 loss 4.82669	 cls_loss: 0.6694 cluster_loss: 1.5878 sup_con_loss: 0.3791 contrastive_loss: 5.2693 nll_loss: 0.0026 
2023-10-26 01:34:20.664 | INFO     | __main__:train:314 - Epoch: [9][600/1251]	 loss 4.85502	 cls_loss: 0.6397 cluster_loss: 1.6405 sup_con_loss: 0.3867 contrastive_loss: 5.2725 nll_loss: 0.0023 
2023-10-26 01:38:06.391 | INFO     | __main__:train:314 - Epoch: [9][700/1251]	 loss 4.79495	 cls_loss: 0.5174 cluster_loss: 1.6137 sup_con_loss: 0.3929 contrastive_loss: 5.2685 nll_loss: 0.0029 
2023-10-26 01:41:49.126 | INFO     | __main__:train:314 - Epoch: [9][800/1251]	 loss 4.78018	 cls_loss: 0.5610 cluster_loss: 1.6096 sup_con_loss: 0.3108 contrastive_loss: 5.2704 nll_loss: 0.0030 
2023-10-26 01:45:49.294 | INFO     | __main__:train:314 - Epoch: [9][900/1251]	 loss 4.93402	 cls_loss: 0.5065 cluster_loss: 1.7279 sup_con_loss: 0.5704 contrastive_loss: 5.2798 nll_loss: 0.0021 
2023-10-26 01:49:33.552 | INFO     | __main__:train:314 - Epoch: [9][1000/1251]	 loss 4.83523	 cls_loss: 0.5402 cluster_loss: 1.6324 sup_con_loss: 0.4357 contrastive_loss: 5.2755 nll_loss: 0.0035 
2023-10-26 01:53:27.967 | INFO     | __main__:train:314 - Epoch: [9][1100/1251]	 loss 4.94905	 cls_loss: 0.7037 cluster_loss: 1.6756 sup_con_loss: 0.5341 contrastive_loss: 5.2694 nll_loss: 0.0016 
2023-10-26 01:57:15.987 | INFO     | __main__:train:314 - Epoch: [9][1200/1251]	 loss 4.87962	 cls_loss: 0.6687 cluster_loss: 1.6400 sup_con_loss: 0.4261 contrastive_loss: 5.2729 nll_loss: 0.0031 
2023-10-26 01:59:07.790 | INFO     | __main__:train:319 - Train Epoch: 9 Avg Loss: 4.8646 
2023-10-26 01:59:07.820 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 02:20:36.209 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 9, Train ACC Unlabelled_v2: All 0.5545 | Old 0.7797 | New 0.4413
2023-10-26 02:20:36.791 | INFO     | __main__:main:205 - Train Accuracies: All 0.5545 | Old 0.7797 | New 0.4413
2023-10-26 02:20:39.817 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 02:20:54.057 | INFO     | __main__:train:314 - Epoch: [10][0/1251]	 loss 4.87157	 cls_loss: 0.5749 cluster_loss: 1.6509 sup_con_loss: 0.4709 contrastive_loss: 5.2776 nll_loss: 0.0020 
2023-10-26 02:24:39.131 | INFO     | __main__:train:314 - Epoch: [10][100/1251]	 loss 4.83341	 cls_loss: 0.5527 cluster_loss: 1.5386 sup_con_loss: 0.6056 contrastive_loss: 5.2674 nll_loss: 0.0041 
2023-10-26 02:28:23.047 | INFO     | __main__:train:314 - Epoch: [10][200/1251]	 loss 4.84276	 cls_loss: 0.7564 cluster_loss: 1.5786 sup_con_loss: 0.3603 contrastive_loss: 5.2668 nll_loss: 0.0024 
2023-10-26 02:32:09.052 | INFO     | __main__:train:314 - Epoch: [10][300/1251]	 loss 4.92757	 cls_loss: 0.6988 cluster_loss: 1.5897 sup_con_loss: 0.6356 contrastive_loss: 5.2690 nll_loss: 0.0024 
2023-10-26 02:35:52.728 | INFO     | __main__:train:314 - Epoch: [10][400/1251]	 loss 4.74813	 cls_loss: 0.5593 cluster_loss: 1.5476 sup_con_loss: 0.3404 contrastive_loss: 5.2694 nll_loss: 0.0022 
2023-10-26 02:39:34.469 | INFO     | __main__:train:314 - Epoch: [10][500/1251]	 loss 4.93850	 cls_loss: 0.5813 cluster_loss: 1.6527 sup_con_loss: 0.6474 contrastive_loss: 5.2794 nll_loss: 0.0026 
2023-10-26 02:43:21.155 | INFO     | __main__:train:314 - Epoch: [10][600/1251]	 loss 4.80131	 cls_loss: 0.4974 cluster_loss: 1.5783 sup_con_loss: 0.4997 contrastive_loss: 5.2687 nll_loss: 0.0018 
2023-10-26 02:47:06.475 | INFO     | __main__:train:314 - Epoch: [10][700/1251]	 loss 4.83969	 cls_loss: 0.4929 cluster_loss: 1.6095 sup_con_loss: 0.5441 contrastive_loss: 5.2733 nll_loss: 0.0029 
2023-10-26 02:50:49.317 | INFO     | __main__:train:314 - Epoch: [10][800/1251]	 loss 4.86250	 cls_loss: 0.6446 cluster_loss: 1.5844 sup_con_loss: 0.5070 contrastive_loss: 5.2726 nll_loss: 0.0023 
2023-10-26 02:54:34.434 | INFO     | __main__:train:314 - Epoch: [10][900/1251]	 loss 4.86479	 cls_loss: 0.6654 cluster_loss: 1.6480 sup_con_loss: 0.3750 contrastive_loss: 5.2729 nll_loss: 0.0020 
2023-10-26 02:58:22.658 | INFO     | __main__:train:314 - Epoch: [10][1000/1251]	 loss 4.94661	 cls_loss: 0.6621 cluster_loss: 1.6608 sup_con_loss: 0.5831 contrastive_loss: 5.2751 nll_loss: 0.0025 
2023-10-26 03:02:07.477 | INFO     | __main__:train:314 - Epoch: [10][1100/1251]	 loss 4.67940	 cls_loss: 0.4854 cluster_loss: 1.5077 sup_con_loss: 0.2955 contrastive_loss: 5.2654 nll_loss: 0.0035 
2023-10-26 03:05:54.589 | INFO     | __main__:train:314 - Epoch: [10][1200/1251]	 loss 4.95347	 cls_loss: 0.7331 cluster_loss: 1.6123 sup_con_loss: 0.6281 contrastive_loss: 5.2718 nll_loss: 0.0024 
2023-10-26 03:07:47.199 | INFO     | __main__:train:319 - Train Epoch: 10 Avg Loss: 4.8465 
2023-10-26 03:07:47.204 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 03:29:36.100 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 10, Train ACC Unlabelled_v2: All 0.5622 | Old 0.7716 | New 0.4569
2023-10-26 03:29:36.354 | INFO     | __main__:main:205 - Train Accuracies: All 0.5622 | Old 0.7716 | New 0.4569
2023-10-26 03:29:39.715 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 03:29:55.515 | INFO     | __main__:train:314 - Epoch: [11][0/1251]	 loss 4.87128	 cls_loss: 0.7588 cluster_loss: 1.6379 sup_con_loss: 0.3105 contrastive_loss: 5.2740 nll_loss: 0.0043 
2023-10-26 03:33:41.499 | INFO     | __main__:train:314 - Epoch: [11][100/1251]	 loss 4.82661	 cls_loss: 0.6035 cluster_loss: 1.6284 sup_con_loss: 0.3684 contrastive_loss: 5.2712 nll_loss: 0.0017 
2023-10-26 03:37:27.802 | INFO     | __main__:train:314 - Epoch: [11][200/1251]	 loss 4.76639	 cls_loss: 0.5166 cluster_loss: 1.6108 sup_con_loss: 0.3052 contrastive_loss: 5.2763 nll_loss: 0.0021 
2023-10-26 03:41:12.370 | INFO     | __main__:train:314 - Epoch: [11][300/1251]	 loss 4.84882	 cls_loss: 0.5624 cluster_loss: 1.6460 sup_con_loss: 0.4304 contrastive_loss: 5.2738 nll_loss: 0.0034 
2023-10-26 03:44:57.365 | INFO     | __main__:train:314 - Epoch: [11][400/1251]	 loss 4.81548	 cls_loss: 0.5967 cluster_loss: 1.5898 sup_con_loss: 0.4111 contrastive_loss: 5.2711 nll_loss: 0.0032 
2023-10-26 03:48:42.457 | INFO     | __main__:train:314 - Epoch: [11][500/1251]	 loss 4.81217	 cls_loss: 0.6220 cluster_loss: 1.5311 sup_con_loss: 0.4919 contrastive_loss: 5.2676 nll_loss: 0.0031 
2023-10-26 03:52:27.664 | INFO     | __main__:train:314 - Epoch: [11][600/1251]	 loss 4.78077	 cls_loss: 0.5542 cluster_loss: 1.5613 sup_con_loss: 0.4060 contrastive_loss: 5.2738 nll_loss: 0.0019 
2023-10-26 03:56:10.700 | INFO     | __main__:train:314 - Epoch: [11][700/1251]	 loss 4.90662	 cls_loss: 0.6861 cluster_loss: 1.6500 sup_con_loss: 0.4648 contrastive_loss: 5.2744 nll_loss: 0.0030 
2023-10-26 04:00:04.854 | INFO     | __main__:train:314 - Epoch: [11][800/1251]	 loss 4.80050	 cls_loss: 0.4965 cluster_loss: 1.5529 sup_con_loss: 0.5423 contrastive_loss: 5.2701 nll_loss: 0.0020 
2023-10-26 04:04:16.318 | INFO     | __main__:train:314 - Epoch: [11][900/1251]	 loss 4.75006	 cls_loss: 0.4912 cluster_loss: 1.5270 sup_con_loss: 0.4433 contrastive_loss: 5.2742 nll_loss: 0.0022 
2023-10-26 04:08:31.184 | INFO     | __main__:train:314 - Epoch: [11][1000/1251]	 loss 4.88340	 cls_loss: 0.7140 cluster_loss: 1.6109 sup_con_loss: 0.4425 contrastive_loss: 5.2753 nll_loss: 0.0026 
2023-10-26 04:12:15.088 | INFO     | __main__:train:314 - Epoch: [11][1100/1251]	 loss 4.81004	 cls_loss: 0.6879 cluster_loss: 1.5811 sup_con_loss: 0.3210 contrastive_loss: 5.2721 nll_loss: 0.0024 
2023-10-26 04:15:58.715 | INFO     | __main__:train:314 - Epoch: [11][1200/1251]	 loss 4.90751	 cls_loss: 0.9062 cluster_loss: 1.6141 sup_con_loss: 0.3162 contrastive_loss: 5.2722 nll_loss: 0.0036 
2023-10-26 04:17:50.326 | INFO     | __main__:train:319 - Train Epoch: 11 Avg Loss: 4.8240 
2023-10-26 04:17:50.335 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 04:38:02.395 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 11, Train ACC Unlabelled_v2: All 0.5688 | Old 0.7787 | New 0.4633
2023-10-26 04:38:02.852 | INFO     | __main__:main:205 - Train Accuracies: All 0.5688 | Old 0.7787 | New 0.4633
2023-10-26 04:38:05.790 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 04:38:21.855 | INFO     | __main__:train:314 - Epoch: [12][0/1251]	 loss 4.77990	 cls_loss: 0.5807 cluster_loss: 1.5469 sup_con_loss: 0.4106 contrastive_loss: 5.2689 nll_loss: 0.0027 
2023-10-26 04:42:05.714 | INFO     | __main__:train:314 - Epoch: [12][100/1251]	 loss 4.81146	 cls_loss: 0.5713 cluster_loss: 1.5448 sup_con_loss: 0.5052 contrastive_loss: 5.2728 nll_loss: 0.0032 
2023-10-26 04:45:56.371 | INFO     | __main__:train:314 - Epoch: [12][200/1251]	 loss 4.66824	 cls_loss: 0.4087 cluster_loss: 1.5486 sup_con_loss: 0.2568 contrastive_loss: 5.2699 nll_loss: 0.0032 
2023-10-26 04:49:41.042 | INFO     | __main__:train:314 - Epoch: [12][300/1251]	 loss 4.76874	 cls_loss: 0.5728 cluster_loss: 1.5173 sup_con_loss: 0.4374 contrastive_loss: 5.2733 nll_loss: 0.0013 
2023-10-26 04:53:36.228 | INFO     | __main__:train:314 - Epoch: [12][400/1251]	 loss 4.83546	 cls_loss: 0.5997 cluster_loss: 1.5989 sup_con_loss: 0.4424 contrastive_loss: 5.2745 nll_loss: 0.0030 
2023-10-26 04:57:22.117 | INFO     | __main__:train:314 - Epoch: [12][500/1251]	 loss 4.90051	 cls_loss: 0.6764 cluster_loss: 1.5496 sup_con_loss: 0.6465 contrastive_loss: 5.2729 nll_loss: 0.0029 
2023-10-26 05:01:08.769 | INFO     | __main__:train:314 - Epoch: [12][600/1251]	 loss 4.74862	 cls_loss: 0.5856 cluster_loss: 1.5260 sup_con_loss: 0.3507 contrastive_loss: 5.2696 nll_loss: 0.0038 
2023-10-26 05:04:51.580 | INFO     | __main__:train:314 - Epoch: [12][700/1251]	 loss 4.78678	 cls_loss: 0.5574 cluster_loss: 1.5418 sup_con_loss: 0.4550 contrastive_loss: 5.2720 nll_loss: 0.0035 
2023-10-26 05:08:34.647 | INFO     | __main__:train:314 - Epoch: [12][800/1251]	 loss 4.84786	 cls_loss: 0.6054 cluster_loss: 1.5378 sup_con_loss: 0.5945 contrastive_loss: 5.2707 nll_loss: 0.0024 
2023-10-26 05:12:18.652 | INFO     | __main__:train:314 - Epoch: [12][900/1251]	 loss 4.70710	 cls_loss: 0.5307 cluster_loss: 1.5026 sup_con_loss: 0.3300 contrastive_loss: 5.2722 nll_loss: 0.0023 
2023-10-26 05:16:04.034 | INFO     | __main__:train:314 - Epoch: [12][1000/1251]	 loss 4.73934	 cls_loss: 0.6543 cluster_loss: 1.5078 sup_con_loss: 0.2947 contrastive_loss: 5.2683 nll_loss: 0.0027 
2023-10-26 05:19:49.104 | INFO     | __main__:train:314 - Epoch: [12][1100/1251]	 loss 4.77726	 cls_loss: 0.6442 cluster_loss: 1.4805 sup_con_loss: 0.4681 contrastive_loss: 5.2657 nll_loss: 0.0029 
2023-10-26 05:23:32.025 | INFO     | __main__:train:314 - Epoch: [12][1200/1251]	 loss 4.70080	 cls_loss: 0.4413 cluster_loss: 1.5236 sup_con_loss: 0.3642 contrastive_loss: 5.2709 nll_loss: 0.0024 
2023-10-26 05:25:22.684 | INFO     | __main__:train:319 - Train Epoch: 12 Avg Loss: 4.8032 
2023-10-26 05:25:22.693 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 05:45:46.654 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 12, Train ACC Unlabelled_v2: All 0.5763 | Old 0.7811 | New 0.4733
2023-10-26 05:45:46.895 | INFO     | __main__:main:205 - Train Accuracies: All 0.5763 | Old 0.7811 | New 0.4733
2023-10-26 05:45:50.412 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 05:46:07.933 | INFO     | __main__:train:314 - Epoch: [13][0/1251]	 loss 4.80935	 cls_loss: 0.5646 cluster_loss: 1.5644 sup_con_loss: 0.4637 contrastive_loss: 5.2748 nll_loss: 0.0040 
2023-10-26 05:49:50.159 | INFO     | __main__:train:314 - Epoch: [13][100/1251]	 loss 4.79125	 cls_loss: 0.5041 cluster_loss: 1.5599 sup_con_loss: 0.4919 contrastive_loss: 5.2707 nll_loss: 0.0028 
2023-10-26 05:53:33.792 | INFO     | __main__:train:314 - Epoch: [13][200/1251]	 loss 4.75585	 cls_loss: 0.5577 cluster_loss: 1.5499 sup_con_loss: 0.3515 contrastive_loss: 5.2724 nll_loss: 0.0031 
2023-10-26 05:57:18.753 | INFO     | __main__:train:314 - Epoch: [13][300/1251]	 loss 4.81254	 cls_loss: 0.6340 cluster_loss: 1.4798 sup_con_loss: 0.5844 contrastive_loss: 5.2637 nll_loss: 0.0028 
2023-10-26 06:01:04.255 | INFO     | __main__:train:314 - Epoch: [13][400/1251]	 loss 4.71479	 cls_loss: 0.5739 cluster_loss: 1.4744 sup_con_loss: 0.3592 contrastive_loss: 5.2709 nll_loss: 0.0037 
2023-10-26 06:04:49.521 | INFO     | __main__:train:314 - Epoch: [13][500/1251]	 loss 4.75850	 cls_loss: 0.5508 cluster_loss: 1.4988 sup_con_loss: 0.4688 contrastive_loss: 5.2705 nll_loss: 0.0016 
2023-10-26 06:08:35.348 | INFO     | __main__:train:314 - Epoch: [13][600/1251]	 loss 4.80074	 cls_loss: 0.5038 cluster_loss: 1.5865 sup_con_loss: 0.4566 contrastive_loss: 5.2776 nll_loss: 0.0030 
2023-10-26 06:12:19.631 | INFO     | __main__:train:314 - Epoch: [13][700/1251]	 loss 4.77323	 cls_loss: 0.5895 cluster_loss: 1.5085 sup_con_loss: 0.4488 contrastive_loss: 5.2742 nll_loss: 0.0011 
2023-10-26 06:16:02.326 | INFO     | __main__:train:314 - Epoch: [13][800/1251]	 loss 4.81551	 cls_loss: 0.6742 cluster_loss: 1.5513 sup_con_loss: 0.4015 contrastive_loss: 5.2754 nll_loss: 0.0017 
2023-10-26 06:19:46.379 | INFO     | __main__:train:314 - Epoch: [13][900/1251]	 loss 4.91250	 cls_loss: 0.5527 cluster_loss: 1.6159 sup_con_loss: 0.6627 contrastive_loss: 5.2826 nll_loss: 0.0030 
2023-10-26 06:23:31.077 | INFO     | __main__:train:314 - Epoch: [13][1000/1251]	 loss 4.79245	 cls_loss: 0.5818 cluster_loss: 1.5349 sup_con_loss: 0.4668 contrastive_loss: 5.2684 nll_loss: 0.0033 
2023-10-26 06:27:17.469 | INFO     | __main__:train:314 - Epoch: [13][1100/1251]	 loss 4.82434	 cls_loss: 0.6585 cluster_loss: 1.4810 sup_con_loss: 0.5810 contrastive_loss: 5.2696 nll_loss: 0.0026 
2023-10-26 06:31:02.259 | INFO     | __main__:train:314 - Epoch: [13][1200/1251]	 loss 4.82571	 cls_loss: 0.4958 cluster_loss: 1.5817 sup_con_loss: 0.5385 contrastive_loss: 5.2810 nll_loss: 0.0029 
2023-10-26 06:32:54.753 | INFO     | __main__:train:319 - Train Epoch: 13 Avg Loss: 4.7840 
2023-10-26 06:32:54.757 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 06:52:22.027 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 13, Train ACC Unlabelled_v2: All 0.5786 | Old 0.7789 | New 0.4780
2023-10-26 06:52:22.308 | INFO     | __main__:main:205 - Train Accuracies: All 0.5786 | Old 0.7789 | New 0.4780
2023-10-26 06:52:25.326 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 06:52:41.722 | INFO     | __main__:train:314 - Epoch: [14][0/1251]	 loss 4.80542	 cls_loss: 0.6180 cluster_loss: 1.5207 sup_con_loss: 0.4946 contrastive_loss: 5.2704 nll_loss: 0.0017 
2023-10-26 06:56:24.869 | INFO     | __main__:train:314 - Epoch: [14][100/1251]	 loss 4.77963	 cls_loss: 0.6887 cluster_loss: 1.4792 sup_con_loss: 0.4213 contrastive_loss: 5.2722 nll_loss: 0.0027 
2023-10-26 07:00:09.872 | INFO     | __main__:train:314 - Epoch: [14][200/1251]	 loss 4.82463	 cls_loss: 0.6398 cluster_loss: 1.5738 sup_con_loss: 0.4152 contrastive_loss: 5.2779 nll_loss: 0.0018 
2023-10-26 07:03:53.522 | INFO     | __main__:train:314 - Epoch: [14][300/1251]	 loss 4.76036	 cls_loss: 0.6479 cluster_loss: 1.4866 sup_con_loss: 0.3930 contrastive_loss: 5.2730 nll_loss: 0.0023 
2023-10-26 07:07:38.431 | INFO     | __main__:train:314 - Epoch: [14][400/1251]	 loss 4.72698	 cls_loss: 0.5753 cluster_loss: 1.4425 sup_con_loss: 0.4565 contrastive_loss: 5.2689 nll_loss: 0.0035 
2023-10-26 07:11:23.264 | INFO     | __main__:train:314 - Epoch: [14][500/1251]	 loss 4.72706	 cls_loss: 0.6023 cluster_loss: 1.4708 sup_con_loss: 0.3749 contrastive_loss: 5.2686 nll_loss: 0.0044 
2023-10-26 07:15:07.459 | INFO     | __main__:train:314 - Epoch: [14][600/1251]	 loss 4.76880	 cls_loss: 0.6247 cluster_loss: 1.4992 sup_con_loss: 0.4146 contrastive_loss: 5.2709 nll_loss: 0.0045 
2023-10-26 07:18:51.894 | INFO     | __main__:train:314 - Epoch: [14][700/1251]	 loss 4.70029	 cls_loss: 0.7174 cluster_loss: 1.4298 sup_con_loss: 0.2699 contrastive_loss: 5.2654 nll_loss: 0.0028 
2023-10-26 07:22:37.841 | INFO     | __main__:train:314 - Epoch: [14][800/1251]	 loss 4.73923	 cls_loss: 0.5202 cluster_loss: 1.4713 sup_con_loss: 0.4955 contrastive_loss: 5.2665 nll_loss: 0.0042 
2023-10-26 07:26:22.770 | INFO     | __main__:train:314 - Epoch: [14][900/1251]	 loss 4.77871	 cls_loss: 0.6365 cluster_loss: 1.5463 sup_con_loss: 0.3431 contrastive_loss: 5.2718 nll_loss: 0.0041 
2023-10-26 07:30:07.300 | INFO     | __main__:train:314 - Epoch: [14][1000/1251]	 loss 4.70494	 cls_loss: 0.5395 cluster_loss: 1.4811 sup_con_loss: 0.3508 contrastive_loss: 5.2734 nll_loss: 0.0029 
2023-10-26 07:33:50.413 | INFO     | __main__:train:314 - Epoch: [14][1100/1251]	 loss 4.82459	 cls_loss: 0.5645 cluster_loss: 1.5585 sup_con_loss: 0.5236 contrastive_loss: 5.2736 nll_loss: 0.0029 
2023-10-26 07:37:35.391 | INFO     | __main__:train:314 - Epoch: [14][1200/1251]	 loss 4.77714	 cls_loss: 0.5229 cluster_loss: 1.5287 sup_con_loss: 0.4756 contrastive_loss: 5.2778 nll_loss: 0.0035 
2023-10-26 07:39:27.703 | INFO     | __main__:train:319 - Train Epoch: 14 Avg Loss: 4.7728 
2023-10-26 07:39:27.711 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 07:59:21.707 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 14, Train ACC Unlabelled_v2: All 0.5807 | Old 0.7811 | New 0.4799
2023-10-26 07:59:22.033 | INFO     | __main__:main:205 - Train Accuracies: All 0.5807 | Old 0.7811 | New 0.4799
2023-10-26 07:59:25.158 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 07:59:38.634 | INFO     | __main__:train:314 - Epoch: [15][0/1251]	 loss 4.76423	 cls_loss: 0.4703 cluster_loss: 1.4987 sup_con_loss: 0.5677 contrastive_loss: 5.2680 nll_loss: 0.0026 
2023-10-26 08:03:23.841 | INFO     | __main__:train:314 - Epoch: [15][100/1251]	 loss 4.90013	 cls_loss: 0.7978 cluster_loss: 1.5285 sup_con_loss: 0.5645 contrastive_loss: 5.2740 nll_loss: 0.0017 
2023-10-26 08:07:08.748 | INFO     | __main__:train:314 - Epoch: [15][200/1251]	 loss 4.81100	 cls_loss: 0.6644 cluster_loss: 1.5232 sup_con_loss: 0.4533 contrastive_loss: 5.2740 nll_loss: 0.0017 
2023-10-26 08:10:52.772 | INFO     | __main__:train:314 - Epoch: [15][300/1251]	 loss 4.80504	 cls_loss: 0.5755 cluster_loss: 1.5354 sup_con_loss: 0.5043 contrastive_loss: 5.2707 nll_loss: 0.0032 
2023-10-26 08:14:36.106 | INFO     | __main__:train:314 - Epoch: [15][400/1251]	 loss 4.87613	 cls_loss: 0.7017 cluster_loss: 1.5073 sup_con_loss: 0.6269 contrastive_loss: 5.2751 nll_loss: 0.0026 
2023-10-26 08:18:19.510 | INFO     | __main__:train:314 - Epoch: [15][500/1251]	 loss 4.80538	 cls_loss: 0.7131 cluster_loss: 1.5193 sup_con_loss: 0.3957 contrastive_loss: 5.2737 nll_loss: 0.0018 
2023-10-26 08:22:04.493 | INFO     | __main__:train:314 - Epoch: [15][600/1251]	 loss 4.66537	 cls_loss: 0.6066 cluster_loss: 1.4034 sup_con_loss: 0.3315 contrastive_loss: 5.2648 nll_loss: 0.0027 
2023-10-26 08:25:50.656 | INFO     | __main__:train:314 - Epoch: [15][700/1251]	 loss 4.73833	 cls_loss: 0.8302 cluster_loss: 1.4195 sup_con_loss: 0.2780 contrastive_loss: 5.2688 nll_loss: 0.0031 
2023-10-26 08:29:34.307 | INFO     | __main__:train:314 - Epoch: [15][800/1251]	 loss 4.74872	 cls_loss: 0.5647 cluster_loss: 1.4845 sup_con_loss: 0.4437 contrastive_loss: 5.2754 nll_loss: 0.0019 
2023-10-26 08:33:16.823 | INFO     | __main__:train:314 - Epoch: [15][900/1251]	 loss 4.79531	 cls_loss: 0.5976 cluster_loss: 1.5096 sup_con_loss: 0.5021 contrastive_loss: 5.2728 nll_loss: 0.0019 
2023-10-26 08:37:01.543 | INFO     | __main__:train:314 - Epoch: [15][1000/1251]	 loss 4.73903	 cls_loss: 0.5447 cluster_loss: 1.4509 sup_con_loss: 0.5135 contrastive_loss: 5.2684 nll_loss: 0.0011 
2023-10-26 08:40:45.157 | INFO     | __main__:train:314 - Epoch: [15][1100/1251]	 loss 4.84926	 cls_loss: 0.6394 cluster_loss: 1.5393 sup_con_loss: 0.5595 contrastive_loss: 5.2706 nll_loss: 0.0032 
2023-10-26 08:44:29.211 | INFO     | __main__:train:314 - Epoch: [15][1200/1251]	 loss 4.68028	 cls_loss: 0.5691 cluster_loss: 1.4852 sup_con_loss: 0.2511 contrastive_loss: 5.2703 nll_loss: 0.0022 
2023-10-26 08:46:20.936 | INFO     | __main__:train:319 - Train Epoch: 15 Avg Loss: 4.7591 
2023-10-26 08:46:21.019 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 09:06:04.348 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 15, Train ACC Unlabelled_v2: All 0.5844 | Old 0.7802 | New 0.4861
2023-10-26 09:06:04.831 | INFO     | __main__:main:205 - Train Accuracies: All 0.5844 | Old 0.7802 | New 0.4861
2023-10-26 09:06:08.606 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 09:06:32.790 | INFO     | __main__:train:314 - Epoch: [16][0/1251]	 loss 4.72571	 cls_loss: 0.6379 cluster_loss: 1.4425 sup_con_loss: 0.3899 contrastive_loss: 5.2701 nll_loss: 0.0028 
2023-10-26 09:10:20.251 | INFO     | __main__:train:314 - Epoch: [16][100/1251]	 loss 4.86164	 cls_loss: 0.8388 cluster_loss: 1.5325 sup_con_loss: 0.4036 contrastive_loss: 5.2735 nll_loss: 0.0029 
2023-10-26 09:14:04.861 | INFO     | __main__:train:314 - Epoch: [16][200/1251]	 loss 4.75239	 cls_loss: 0.6375 cluster_loss: 1.4924 sup_con_loss: 0.3661 contrastive_loss: 5.2740 nll_loss: 0.0030 
2023-10-26 09:17:53.512 | INFO     | __main__:train:314 - Epoch: [16][300/1251]	 loss 4.69512	 cls_loss: 0.5213 cluster_loss: 1.4225 sup_con_loss: 0.4530 contrastive_loss: 5.2701 nll_loss: 0.0039 
2023-10-26 09:21:38.801 | INFO     | __main__:train:314 - Epoch: [16][400/1251]	 loss 4.75719	 cls_loss: 0.5662 cluster_loss: 1.4537 sup_con_loss: 0.5321 contrastive_loss: 5.2701 nll_loss: 0.0023 
2023-10-26 09:25:22.854 | INFO     | __main__:train:314 - Epoch: [16][500/1251]	 loss 4.83091	 cls_loss: 0.6459 cluster_loss: 1.5154 sup_con_loss: 0.5189 contrastive_loss: 5.2843 nll_loss: 0.0034 
2023-10-26 09:29:07.461 | INFO     | __main__:train:314 - Epoch: [16][600/1251]	 loss 4.79939	 cls_loss: 0.6586 cluster_loss: 1.4804 sup_con_loss: 0.5049 contrastive_loss: 5.2726 nll_loss: 0.0027 
2023-10-26 09:32:50.913 | INFO     | __main__:train:314 - Epoch: [16][700/1251]	 loss 4.74952	 cls_loss: 0.7314 cluster_loss: 1.4536 sup_con_loss: 0.3433 contrastive_loss: 5.2707 nll_loss: 0.0026 
2023-10-26 09:36:36.262 | INFO     | __main__:train:314 - Epoch: [16][800/1251]	 loss 4.64563	 cls_loss: 0.5502 cluster_loss: 1.4282 sup_con_loss: 0.2827 contrastive_loss: 5.2678 nll_loss: 0.0017 
2023-10-26 09:40:19.093 | INFO     | __main__:train:314 - Epoch: [16][900/1251]	 loss 4.76552	 cls_loss: 0.6810 cluster_loss: 1.4590 sup_con_loss: 0.4211 contrastive_loss: 5.2747 nll_loss: 0.0029 
2023-10-26 09:44:01.403 | INFO     | __main__:train:314 - Epoch: [16][1000/1251]	 loss 4.65779	 cls_loss: 0.5339 cluster_loss: 1.4405 sup_con_loss: 0.3060 contrastive_loss: 5.2696 nll_loss: 0.0023 
2023-10-26 09:47:47.586 | INFO     | __main__:train:314 - Epoch: [16][1100/1251]	 loss 4.66233	 cls_loss: 0.5934 cluster_loss: 1.4072 sup_con_loss: 0.3287 contrastive_loss: 5.2648 nll_loss: 0.0028 
2023-10-26 09:51:34.601 | INFO     | __main__:train:314 - Epoch: [16][1200/1251]	 loss 4.77146	 cls_loss: 0.6492 cluster_loss: 1.4637 sup_con_loss: 0.4514 contrastive_loss: 5.2785 nll_loss: 0.0039 
2023-10-26 09:53:27.185 | INFO     | __main__:train:319 - Train Epoch: 16 Avg Loss: 4.7485 
2023-10-26 09:53:27.192 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 10:13:59.329 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 16, Train ACC Unlabelled_v2: All 0.5867 | Old 0.7811 | New 0.4889
2023-10-26 10:13:59.379 | INFO     | __main__:main:205 - Train Accuracies: All 0.5867 | Old 0.7811 | New 0.4889
2023-10-26 10:14:02.219 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 10:14:17.463 | INFO     | __main__:train:314 - Epoch: [17][0/1251]	 loss 4.94184	 cls_loss: 0.8111 cluster_loss: 1.4903 sup_con_loss: 0.7381 contrastive_loss: 5.2749 nll_loss: 0.0022 
2023-10-26 10:18:03.381 | INFO     | __main__:train:314 - Epoch: [17][100/1251]	 loss 4.83568	 cls_loss: 0.7831 cluster_loss: 1.4880 sup_con_loss: 0.4715 contrastive_loss: 5.2729 nll_loss: 0.0019 
2023-10-26 10:21:54.545 | INFO     | __main__:train:314 - Epoch: [17][200/1251]	 loss 4.68885	 cls_loss: 0.6291 cluster_loss: 1.3988 sup_con_loss: 0.3768 contrastive_loss: 5.2676 nll_loss: 0.0036 
2023-10-26 10:25:52.871 | INFO     | __main__:train:314 - Epoch: [17][300/1251]	 loss 4.75167	 cls_loss: 0.6427 cluster_loss: 1.4681 sup_con_loss: 0.4150 contrastive_loss: 5.2696 nll_loss: 0.0020 
2023-10-26 10:29:42.937 | INFO     | __main__:train:314 - Epoch: [17][400/1251]	 loss 4.77346	 cls_loss: 0.5817 cluster_loss: 1.4796 sup_con_loss: 0.5000 contrastive_loss: 5.2776 nll_loss: 0.0027 
2023-10-26 10:33:26.401 | INFO     | __main__:train:314 - Epoch: [17][500/1251]	 loss 4.74356	 cls_loss: 0.6346 cluster_loss: 1.3851 sup_con_loss: 0.5479 contrastive_loss: 5.2709 nll_loss: 0.0033 
2023-10-26 10:37:14.245 | INFO     | __main__:train:314 - Epoch: [17][600/1251]	 loss 4.72926	 cls_loss: 0.5394 cluster_loss: 1.4727 sup_con_loss: 0.4462 contrastive_loss: 5.2701 nll_loss: 0.0015 
2023-10-26 10:41:00.147 | INFO     | __main__:train:314 - Epoch: [17][700/1251]	 loss 4.72928	 cls_loss: 0.4899 cluster_loss: 1.4785 sup_con_loss: 0.4739 contrastive_loss: 5.2713 nll_loss: 0.0046 
2023-10-26 10:44:44.216 | INFO     | __main__:train:314 - Epoch: [17][800/1251]	 loss 4.83833	 cls_loss: 0.5285 cluster_loss: 1.4737 sup_con_loss: 0.7485 contrastive_loss: 5.2740 nll_loss: 0.0054 
2023-10-26 10:48:29.732 | INFO     | __main__:train:314 - Epoch: [17][900/1251]	 loss 4.82222	 cls_loss: 0.6988 cluster_loss: 1.4678 sup_con_loss: 0.5544 contrastive_loss: 5.2718 nll_loss: 0.0028 
2023-10-26 10:52:24.891 | INFO     | __main__:train:314 - Epoch: [17][1000/1251]	 loss 4.68778	 cls_loss: 0.5522 cluster_loss: 1.4498 sup_con_loss: 0.3509 contrastive_loss: 5.2733 nll_loss: 0.0016 
2023-10-26 10:56:10.630 | INFO     | __main__:train:314 - Epoch: [17][1100/1251]	 loss 4.87444	 cls_loss: 0.7356 cluster_loss: 1.5176 sup_con_loss: 0.5576 contrastive_loss: 5.2803 nll_loss: 0.0032 
2023-10-26 11:00:04.795 | INFO     | __main__:train:314 - Epoch: [17][1200/1251]	 loss 4.67423	 cls_loss: 0.5629 cluster_loss: 1.4437 sup_con_loss: 0.3135 contrastive_loss: 5.2716 nll_loss: 0.0025 
2023-10-26 11:01:58.244 | INFO     | __main__:train:319 - Train Epoch: 17 Avg Loss: 4.7400 
2023-10-26 11:01:58.894 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 11:24:38.544 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 17, Train ACC Unlabelled_v2: All 0.5863 | Old 0.7726 | New 0.4927
2023-10-26 11:24:38.901 | INFO     | __main__:main:205 - Train Accuracies: All 0.5863 | Old 0.7726 | New 0.4927
2023-10-26 11:24:42.791 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 11:25:02.651 | INFO     | __main__:train:314 - Epoch: [18][0/1251]	 loss 4.77757	 cls_loss: 0.6314 cluster_loss: 1.4468 sup_con_loss: 0.5323 contrastive_loss: 5.2700 nll_loss: 0.0044 
2023-10-26 11:29:29.868 | INFO     | __main__:train:314 - Epoch: [18][100/1251]	 loss 4.81635	 cls_loss: 0.6191 cluster_loss: 1.4909 sup_con_loss: 0.5728 contrastive_loss: 5.2739 nll_loss: 0.0021 
2023-10-26 11:33:15.677 | INFO     | __main__:train:314 - Epoch: [18][200/1251]	 loss 4.69910	 cls_loss: 0.4542 cluster_loss: 1.4552 sup_con_loss: 0.4726 contrastive_loss: 5.2715 nll_loss: 0.0024 
2023-10-26 11:37:34.824 | INFO     | __main__:train:314 - Epoch: [18][300/1251]	 loss 4.82127	 cls_loss: 0.8038 cluster_loss: 1.4779 sup_con_loss: 0.4236 contrastive_loss: 5.2756 nll_loss: 0.0019 
2023-10-26 11:41:25.430 | INFO     | __main__:train:314 - Epoch: [18][400/1251]	 loss 4.69545	 cls_loss: 0.5718 cluster_loss: 1.3984 sup_con_loss: 0.4528 contrastive_loss: 5.2705 nll_loss: 0.0020 
2023-10-26 11:45:10.723 | INFO     | __main__:train:314 - Epoch: [18][500/1251]	 loss 4.91525	 cls_loss: 0.7906 cluster_loss: 1.5385 sup_con_loss: 0.5847 contrastive_loss: 5.2792 nll_loss: 0.0024 
2023-10-26 11:48:58.895 | INFO     | __main__:train:314 - Epoch: [18][600/1251]	 loss 4.76813	 cls_loss: 0.6039 cluster_loss: 1.4704 sup_con_loss: 0.4856 contrastive_loss: 5.2735 nll_loss: 0.0032 
2023-10-26 11:52:44.810 | INFO     | __main__:train:314 - Epoch: [18][700/1251]	 loss 4.73545	 cls_loss: 0.5242 cluster_loss: 1.4617 sup_con_loss: 0.4975 contrastive_loss: 5.2699 nll_loss: 0.0023 
2023-10-26 11:56:31.475 | INFO     | __main__:train:314 - Epoch: [18][800/1251]	 loss 4.69177	 cls_loss: 0.6106 cluster_loss: 1.4403 sup_con_loss: 0.3264 contrastive_loss: 5.2668 nll_loss: 0.0042 
2023-10-26 12:00:34.455 | INFO     | __main__:train:314 - Epoch: [18][900/1251]	 loss 4.70134	 cls_loss: 0.6155 cluster_loss: 1.4433 sup_con_loss: 0.3356 contrastive_loss: 5.2750 nll_loss: 0.0016 
2023-10-26 12:04:22.762 | INFO     | __main__:train:314 - Epoch: [18][1000/1251]	 loss 4.66001	 cls_loss: 0.5863 cluster_loss: 1.3858 sup_con_loss: 0.3589 contrastive_loss: 5.2716 nll_loss: 0.0018 
2023-10-26 12:08:12.857 | INFO     | __main__:train:314 - Epoch: [18][1100/1251]	 loss 4.82277	 cls_loss: 0.6132 cluster_loss: 1.4796 sup_con_loss: 0.6207 contrastive_loss: 5.2727 nll_loss: 0.0019 
2023-10-26 12:12:02.562 | INFO     | __main__:train:314 - Epoch: [18][1200/1251]	 loss 4.80407	 cls_loss: 0.6092 cluster_loss: 1.4785 sup_con_loss: 0.5738 contrastive_loss: 5.2718 nll_loss: 0.0023 
2023-10-26 12:13:58.243 | INFO     | __main__:train:319 - Train Epoch: 18 Avg Loss: 4.7280 
2023-10-26 12:13:58.252 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 12:36:22.334 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 18, Train ACC Unlabelled_v2: All 0.5918 | Old 0.7795 | New 0.4974
2023-10-26 12:36:22.744 | INFO     | __main__:main:205 - Train Accuracies: All 0.5918 | Old 0.7795 | New 0.4974
2023-10-26 12:36:26.592 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 12:36:44.731 | INFO     | __main__:train:314 - Epoch: [19][0/1251]	 loss 4.54372	 cls_loss: 0.4579 cluster_loss: 1.3154 sup_con_loss: 0.2861 contrastive_loss: 5.2674 nll_loss: 0.0045 
2023-10-26 12:40:29.714 | INFO     | __main__:train:314 - Epoch: [19][100/1251]	 loss 4.73402	 cls_loss: 0.6288 cluster_loss: 1.3779 sup_con_loss: 0.5522 contrastive_loss: 5.2660 nll_loss: 0.0022 
2023-10-26 12:44:16.745 | INFO     | __main__:train:314 - Epoch: [19][200/1251]	 loss 4.68831	 cls_loss: 0.7728 cluster_loss: 1.4072 sup_con_loss: 0.2120 contrastive_loss: 5.2692 nll_loss: 0.0040 
2023-10-26 12:48:02.505 | INFO     | __main__:train:314 - Epoch: [19][300/1251]	 loss 4.74234	 cls_loss: 0.6108 cluster_loss: 1.4195 sup_con_loss: 0.5046 contrastive_loss: 5.2729 nll_loss: 0.0019 
2023-10-26 12:51:49.608 | INFO     | __main__:train:314 - Epoch: [19][400/1251]	 loss 4.74164	 cls_loss: 0.5495 cluster_loss: 1.4635 sup_con_loss: 0.4761 contrastive_loss: 5.2744 nll_loss: 0.0030 
2023-10-26 12:56:01.164 | INFO     | __main__:train:314 - Epoch: [19][500/1251]	 loss 4.64017	 cls_loss: 0.4839 cluster_loss: 1.4056 sup_con_loss: 0.3641 contrastive_loss: 5.2722 nll_loss: 0.0028 
2023-10-26 12:59:50.102 | INFO     | __main__:train:314 - Epoch: [19][600/1251]	 loss 4.78632	 cls_loss: 0.7248 cluster_loss: 1.4554 sup_con_loss: 0.4438 contrastive_loss: 5.2754 nll_loss: 0.0023 
2023-10-26 13:03:36.645 | INFO     | __main__:train:314 - Epoch: [19][700/1251]	 loss 4.67090	 cls_loss: 0.5644 cluster_loss: 1.4006 sup_con_loss: 0.3881 contrastive_loss: 5.2680 nll_loss: 0.0029 
2023-10-26 13:07:22.804 | INFO     | __main__:train:314 - Epoch: [19][800/1251]	 loss 4.59339	 cls_loss: 0.4352 cluster_loss: 1.3909 sup_con_loss: 0.3091 contrastive_loss: 5.2721 nll_loss: 0.0019 
2023-10-26 13:11:06.625 | INFO     | __main__:train:314 - Epoch: [19][900/1251]	 loss 4.74394	 cls_loss: 0.7053 cluster_loss: 1.4325 sup_con_loss: 0.3933 contrastive_loss: 5.2708 nll_loss: 0.0023 
2023-10-26 13:14:49.781 | INFO     | __main__:train:314 - Epoch: [19][1000/1251]	 loss 4.75973	 cls_loss: 0.7598 cluster_loss: 1.4145 sup_con_loss: 0.4197 contrastive_loss: 5.2687 nll_loss: 0.0028 
2023-10-26 13:18:34.338 | INFO     | __main__:train:314 - Epoch: [19][1100/1251]	 loss 4.70309	 cls_loss: 0.5578 cluster_loss: 1.3990 sup_con_loss: 0.4833 contrastive_loss: 5.2703 nll_loss: 0.0037 
2023-10-26 13:22:18.693 | INFO     | __main__:train:314 - Epoch: [19][1200/1251]	 loss 4.78564	 cls_loss: 0.5583 cluster_loss: 1.5120 sup_con_loss: 0.4954 contrastive_loss: 5.2786 nll_loss: 0.0030 
2023-10-26 13:24:10.405 | INFO     | __main__:train:319 - Train Epoch: 19 Avg Loss: 4.7183 
2023-10-26 13:24:10.413 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 13:44:45.829 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 19, Train ACC Unlabelled_v2: All 0.5903 | Old 0.7774 | New 0.4962
2023-10-26 13:44:46.284 | INFO     | __main__:main:205 - Train Accuracies: All 0.5903 | Old 0.7774 | New 0.4962
2023-10-26 13:44:49.647 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 13:45:04.173 | INFO     | __main__:train:314 - Epoch: [20][0/1251]	 loss 4.74002	 cls_loss: 0.5563 cluster_loss: 1.4260 sup_con_loss: 0.5440 contrastive_loss: 5.2701 nll_loss: 0.0024 
2023-10-26 13:48:50.382 | INFO     | __main__:train:314 - Epoch: [20][100/1251]	 loss 4.71180	 cls_loss: 0.6298 cluster_loss: 1.4070 sup_con_loss: 0.4277 contrastive_loss: 5.2705 nll_loss: 0.0013 
2023-10-26 13:52:47.947 | INFO     | __main__:train:314 - Epoch: [20][200/1251]	 loss 4.66918	 cls_loss: 0.5132 cluster_loss: 1.3891 sup_con_loss: 0.4493 contrastive_loss: 5.2701 nll_loss: 0.0039 
2023-10-26 13:56:34.045 | INFO     | __main__:train:314 - Epoch: [20][300/1251]	 loss 4.73340	 cls_loss: 0.5756 cluster_loss: 1.5131 sup_con_loss: 0.3327 contrastive_loss: 5.2763 nll_loss: 0.0024 
2023-10-26 14:00:35.075 | INFO     | __main__:train:314 - Epoch: [20][400/1251]	 loss 4.57957	 cls_loss: 0.4194 cluster_loss: 1.3494 sup_con_loss: 0.3625 contrastive_loss: 5.2708 nll_loss: 0.0028 
2023-10-26 14:04:50.899 | INFO     | __main__:train:314 - Epoch: [20][500/1251]	 loss 4.68637	 cls_loss: 0.5120 cluster_loss: 1.4301 sup_con_loss: 0.4314 contrastive_loss: 5.2689 nll_loss: 0.0018 
2023-10-26 14:08:46.640 | INFO     | __main__:train:314 - Epoch: [20][600/1251]	 loss 4.75260	 cls_loss: 0.6629 cluster_loss: 1.4181 sup_con_loss: 0.4884 contrastive_loss: 5.2700 nll_loss: 0.0024 
2023-10-26 14:12:38.579 | INFO     | __main__:train:314 - Epoch: [20][700/1251]	 loss 4.59230	 cls_loss: 0.4991 cluster_loss: 1.3686 sup_con_loss: 0.2892 contrastive_loss: 5.2691 nll_loss: 0.0018 
2023-10-26 14:16:44.273 | INFO     | __main__:train:314 - Epoch: [20][800/1251]	 loss 4.62274	 cls_loss: 0.5338 cluster_loss: 1.3483 sup_con_loss: 0.3832 contrastive_loss: 5.2661 nll_loss: 0.0024 
2023-10-26 14:20:29.268 | INFO     | __main__:train:314 - Epoch: [20][900/1251]	 loss 4.70689	 cls_loss: 0.6474 cluster_loss: 1.4073 sup_con_loss: 0.4002 contrastive_loss: 5.2675 nll_loss: 0.0016 
2023-10-26 14:24:16.146 | INFO     | __main__:train:314 - Epoch: [20][1000/1251]	 loss 4.60824	 cls_loss: 0.4601 cluster_loss: 1.4203 sup_con_loss: 0.2724 contrastive_loss: 5.2713 nll_loss: 0.0023 
2023-10-26 14:28:00.156 | INFO     | __main__:train:314 - Epoch: [20][1100/1251]	 loss 4.72512	 cls_loss: 0.6434 cluster_loss: 1.4768 sup_con_loss: 0.3162 contrastive_loss: 5.2712 nll_loss: 0.0031 
2023-10-26 14:31:43.010 | INFO     | __main__:train:314 - Epoch: [20][1200/1251]	 loss 4.70214	 cls_loss: 0.5088 cluster_loss: 1.4772 sup_con_loss: 0.3782 contrastive_loss: 5.2755 nll_loss: 0.0024 
2023-10-26 14:33:35.497 | INFO     | __main__:train:319 - Train Epoch: 20 Avg Loss: 4.7125 
2023-10-26 14:33:35.522 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 14:54:21.435 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 20, Train ACC Unlabelled_v2: All 0.5917 | Old 0.7777 | New 0.4982
2023-10-26 14:54:21.873 | INFO     | __main__:main:205 - Train Accuracies: All 0.5917 | Old 0.7777 | New 0.4982
2023-10-26 14:54:25.638 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 14:54:40.805 | INFO     | __main__:train:314 - Epoch: [21][0/1251]	 loss 4.75173	 cls_loss: 0.6659 cluster_loss: 1.4181 sup_con_loss: 0.4777 contrastive_loss: 5.2737 nll_loss: 0.0018 
2023-10-26 14:58:29.660 | INFO     | __main__:train:314 - Epoch: [21][100/1251]	 loss 4.70027	 cls_loss: 0.6173 cluster_loss: 1.3212 sup_con_loss: 0.5729 contrastive_loss: 5.2655 nll_loss: 0.0023 
2023-10-26 15:02:13.276 | INFO     | __main__:train:314 - Epoch: [21][200/1251]	 loss 4.60817	 cls_loss: 0.6756 cluster_loss: 1.3057 sup_con_loss: 0.2705 contrastive_loss: 5.2695 nll_loss: 0.0031 
2023-10-26 15:05:58.066 | INFO     | __main__:train:314 - Epoch: [21][300/1251]	 loss 4.81666	 cls_loss: 0.6910 cluster_loss: 1.4776 sup_con_loss: 0.5010 contrastive_loss: 5.2862 nll_loss: 0.0030 
2023-10-26 15:09:45.289 | INFO     | __main__:train:314 - Epoch: [21][400/1251]	 loss 4.74297	 cls_loss: 0.5997 cluster_loss: 1.4410 sup_con_loss: 0.4716 contrastive_loss: 5.2716 nll_loss: 0.0049 
2023-10-26 15:13:30.397 | INFO     | __main__:train:314 - Epoch: [21][500/1251]	 loss 4.77923	 cls_loss: 0.6101 cluster_loss: 1.4535 sup_con_loss: 0.5510 contrastive_loss: 5.2714 nll_loss: 0.0017 
2023-10-26 15:17:16.387 | INFO     | __main__:train:314 - Epoch: [21][600/1251]	 loss 4.66514	 cls_loss: 0.6231 cluster_loss: 1.3529 sup_con_loss: 0.3998 contrastive_loss: 5.2706 nll_loss: 0.0019 
2023-10-26 15:21:05.258 | INFO     | __main__:train:314 - Epoch: [21][700/1251]	 loss 4.68697	 cls_loss: 0.6135 cluster_loss: 1.4049 sup_con_loss: 0.3664 contrastive_loss: 5.2720 nll_loss: 0.0040 
2023-10-26 15:24:51.628 | INFO     | __main__:train:314 - Epoch: [21][800/1251]	 loss 4.69132	 cls_loss: 0.6377 cluster_loss: 1.3954 sup_con_loss: 0.3769 contrastive_loss: 5.2721 nll_loss: 0.0024 
2023-10-26 15:28:38.067 | INFO     | __main__:train:314 - Epoch: [21][900/1251]	 loss 4.66204	 cls_loss: 0.5921 cluster_loss: 1.4200 sup_con_loss: 0.2879 contrastive_loss: 5.2753 nll_loss: 0.0021 
2023-10-26 15:32:36.141 | INFO     | __main__:train:314 - Epoch: [21][1000/1251]	 loss 4.70769	 cls_loss: 0.6190 cluster_loss: 1.3412 sup_con_loss: 0.5507 contrastive_loss: 5.2681 nll_loss: 0.0022 
2023-10-26 15:36:29.955 | INFO     | __main__:train:314 - Epoch: [21][1100/1251]	 loss 4.80213	 cls_loss: 0.6616 cluster_loss: 1.3752 sup_con_loss: 0.7163 contrastive_loss: 5.2686 nll_loss: 0.0014 
2023-10-26 15:40:21.184 | INFO     | __main__:train:314 - Epoch: [21][1200/1251]	 loss 4.68527	 cls_loss: 0.5759 cluster_loss: 1.3819 sup_con_loss: 0.4573 contrastive_loss: 5.2670 nll_loss: 0.0019 
2023-10-26 15:42:14.614 | INFO     | __main__:train:319 - Train Epoch: 21 Avg Loss: 4.7054 
2023-10-26 15:42:14.623 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 16:08:13.869 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 21, Train ACC Unlabelled_v2: All 0.5919 | Old 0.7776 | New 0.4985
2023-10-26 16:08:14.316 | INFO     | __main__:main:205 - Train Accuracies: All 0.5919 | Old 0.7776 | New 0.4985
2023-10-26 16:08:18.536 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 16:08:36.691 | INFO     | __main__:train:314 - Epoch: [22][0/1251]	 loss 4.72158	 cls_loss: 0.5705 cluster_loss: 1.4375 sup_con_loss: 0.4411 contrastive_loss: 5.2782 nll_loss: 0.0023 
2023-10-26 16:12:23.871 | INFO     | __main__:train:314 - Epoch: [22][100/1251]	 loss 4.77170	 cls_loss: 0.6528 cluster_loss: 1.4217 sup_con_loss: 0.5353 contrastive_loss: 5.2757 nll_loss: 0.0026 
2023-10-26 16:16:13.869 | INFO     | __main__:train:314 - Epoch: [22][200/1251]	 loss 4.62580	 cls_loss: 0.5059 cluster_loss: 1.3592 sup_con_loss: 0.3994 contrastive_loss: 5.2664 nll_loss: 0.0023 
2023-10-26 16:20:02.568 | INFO     | __main__:train:314 - Epoch: [22][300/1251]	 loss 4.60354	 cls_loss: 0.5384 cluster_loss: 1.4030 sup_con_loss: 0.2033 contrastive_loss: 5.2772 nll_loss: 0.0018 
2023-10-26 16:23:53.809 | INFO     | __main__:train:314 - Epoch: [22][400/1251]	 loss 4.61947	 cls_loss: 0.5397 cluster_loss: 1.3414 sup_con_loss: 0.3761 contrastive_loss: 5.2699 nll_loss: 0.0016 
2023-10-26 16:27:41.474 | INFO     | __main__:train:314 - Epoch: [22][500/1251]	 loss 4.58868	 cls_loss: 0.5255 cluster_loss: 1.3669 sup_con_loss: 0.2465 contrastive_loss: 5.2725 nll_loss: 0.0028 
2023-10-26 16:31:33.565 | INFO     | __main__:train:314 - Epoch: [22][600/1251]	 loss 4.64119	 cls_loss: 0.5017 cluster_loss: 1.4203 sup_con_loss: 0.3197 contrastive_loss: 5.2736 nll_loss: 0.0027 
2023-10-26 16:35:22.356 | INFO     | __main__:train:314 - Epoch: [22][700/1251]	 loss 4.63167	 cls_loss: 0.4636 cluster_loss: 1.3789 sup_con_loss: 0.4112 contrastive_loss: 5.2724 nll_loss: 0.0022 
2023-10-26 16:39:09.830 | INFO     | __main__:train:314 - Epoch: [22][800/1251]	 loss 4.64308	 cls_loss: 0.4936 cluster_loss: 1.3816 sup_con_loss: 0.4098 contrastive_loss: 5.2714 nll_loss: 0.0024 
2023-10-26 16:43:33.212 | INFO     | __main__:train:314 - Epoch: [22][900/1251]	 loss 4.75524	 cls_loss: 0.6890 cluster_loss: 1.3905 sup_con_loss: 0.5209 contrastive_loss: 5.2712 nll_loss: 0.0017 
2023-10-26 16:51:23.868 | INFO     | __main__:train:314 - Epoch: [22][1000/1251]	 loss 4.65911	 cls_loss: 0.4732 cluster_loss: 1.4380 sup_con_loss: 0.3763 contrastive_loss: 5.2695 nll_loss: 0.0019 
2023-10-26 16:57:51.991 | INFO     | __main__:train:314 - Epoch: [22][1100/1251]	 loss 4.59813	 cls_loss: 0.5312 cluster_loss: 1.3477 sup_con_loss: 0.3148 contrastive_loss: 5.2673 nll_loss: 0.0023 
2023-10-26 17:03:06.440 | INFO     | __main__:train:314 - Epoch: [22][1200/1251]	 loss 4.67351	 cls_loss: 0.4693 cluster_loss: 1.4086 sup_con_loss: 0.4687 contrastive_loss: 5.2729 nll_loss: 0.0023 
2023-10-26 17:05:33.140 | INFO     | __main__:train:319 - Train Epoch: 22 Avg Loss: 4.6987 
2023-10-26 17:05:33.203 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 17:39:44.679 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 22, Train ACC Unlabelled_v2: All 0.5895 | Old 0.7715 | New 0.4980
2023-10-26 17:39:45.100 | INFO     | __main__:main:205 - Train Accuracies: All 0.5895 | Old 0.7715 | New 0.4980
2023-10-26 17:39:48.795 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 17:40:08.597 | INFO     | __main__:train:314 - Epoch: [23][0/1251]	 loss 4.65179	 cls_loss: 0.6002 cluster_loss: 1.4140 sup_con_loss: 0.2636 contrastive_loss: 5.2741 nll_loss: 0.0022 
2023-10-26 17:43:54.446 | INFO     | __main__:train:314 - Epoch: [23][100/1251]	 loss 4.77403	 cls_loss: 0.8460 cluster_loss: 1.3151 sup_con_loss: 0.5663 contrastive_loss: 5.2665 nll_loss: 0.0016 
2023-10-26 17:47:45.419 | INFO     | __main__:train:314 - Epoch: [23][200/1251]	 loss 4.70109	 cls_loss: 0.6401 cluster_loss: 1.3901 sup_con_loss: 0.4016 contrastive_loss: 5.2760 nll_loss: 0.0035 
2023-10-26 17:51:41.854 | INFO     | __main__:train:314 - Epoch: [23][300/1251]	 loss 4.59255	 cls_loss: 0.4385 cluster_loss: 1.3661 sup_con_loss: 0.3484 contrastive_loss: 5.2702 nll_loss: 0.0035 
2023-10-26 17:55:27.207 | INFO     | __main__:train:314 - Epoch: [23][400/1251]	 loss 4.81210	 cls_loss: 0.6944 cluster_loss: 1.4558 sup_con_loss: 0.5502 contrastive_loss: 5.2754 nll_loss: 0.0012 
2023-10-26 17:59:15.240 | INFO     | __main__:train:314 - Epoch: [23][500/1251]	 loss 4.76930	 cls_loss: 0.6960 cluster_loss: 1.4713 sup_con_loss: 0.3910 contrastive_loss: 5.2749 nll_loss: 0.0038 
2023-10-26 18:03:00.624 | INFO     | __main__:train:314 - Epoch: [23][600/1251]	 loss 4.71341	 cls_loss: 0.6263 cluster_loss: 1.4321 sup_con_loss: 0.3850 contrastive_loss: 5.2710 nll_loss: 0.0024 
2023-10-26 18:06:56.198 | INFO     | __main__:train:314 - Epoch: [23][700/1251]	 loss 4.65521	 cls_loss: 0.5426 cluster_loss: 1.3720 sup_con_loss: 0.4094 contrastive_loss: 5.2759 nll_loss: 0.0009 
2023-10-26 18:10:49.322 | INFO     | __main__:train:314 - Epoch: [23][800/1251]	 loss 4.74841	 cls_loss: 0.7393 cluster_loss: 1.4107 sup_con_loss: 0.4116 contrastive_loss: 5.2727 nll_loss: 0.0013 
2023-10-26 18:14:41.468 | INFO     | __main__:train:314 - Epoch: [23][900/1251]	 loss 4.77748	 cls_loss: 0.6801 cluster_loss: 1.3924 sup_con_loss: 0.5912 contrastive_loss: 5.2708 nll_loss: 0.0015 
2023-10-26 18:20:01.201 | INFO     | __main__:train:314 - Epoch: [23][1000/1251]	 loss 4.76653	 cls_loss: 0.6887 cluster_loss: 1.4555 sup_con_loss: 0.4139 contrastive_loss: 5.2787 nll_loss: 0.0034 
2023-10-26 18:24:00.950 | INFO     | __main__:train:314 - Epoch: [23][1100/1251]	 loss 4.83399	 cls_loss: 0.6785 cluster_loss: 1.4054 sup_con_loss: 0.7240 contrastive_loss: 5.2727 nll_loss: 0.0024 
2023-10-26 18:27:47.456 | INFO     | __main__:train:314 - Epoch: [23][1200/1251]	 loss 4.74514	 cls_loss: 0.5675 cluster_loss: 1.3757 sup_con_loss: 0.6443 contrastive_loss: 5.2682 nll_loss: 0.0025 
2023-10-26 18:29:40.530 | INFO     | __main__:train:319 - Train Epoch: 23 Avg Loss: 4.6956 
2023-10-26 18:29:40.536 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 18:56:16.166 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 23, Train ACC Unlabelled_v2: All 0.5915 | Old 0.7778 | New 0.4979
2023-10-26 18:56:16.650 | INFO     | __main__:main:205 - Train Accuracies: All 0.5915 | Old 0.7778 | New 0.4979
2023-10-26 18:56:22.686 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 18:56:47.304 | INFO     | __main__:train:314 - Epoch: [24][0/1251]	 loss 4.63074	 cls_loss: 0.5600 cluster_loss: 1.3435 sup_con_loss: 0.3874 contrastive_loss: 5.2667 nll_loss: 0.0025 
2023-10-26 19:00:49.288 | INFO     | __main__:train:314 - Epoch: [24][100/1251]	 loss 4.57801	 cls_loss: 0.4080 cluster_loss: 1.3604 sup_con_loss: 0.3455 contrastive_loss: 5.2712 nll_loss: 0.0038 
2023-10-26 19:04:35.120 | INFO     | __main__:train:314 - Epoch: [24][200/1251]	 loss 4.66688	 cls_loss: 0.6512 cluster_loss: 1.3458 sup_con_loss: 0.3907 contrastive_loss: 5.2686 nll_loss: 0.0028 
2023-10-26 19:08:26.444 | INFO     | __main__:train:314 - Epoch: [24][300/1251]	 loss 4.59338	 cls_loss: 0.4645 cluster_loss: 1.3288 sup_con_loss: 0.4079 contrastive_loss: 5.2652 nll_loss: 0.0020 
2023-10-26 19:12:13.928 | INFO     | __main__:train:314 - Epoch: [24][400/1251]	 loss 4.76761	 cls_loss: 0.6795 cluster_loss: 1.3568 sup_con_loss: 0.6308 contrastive_loss: 5.2686 nll_loss: 0.0025 
2023-10-26 19:15:59.297 | INFO     | __main__:train:314 - Epoch: [24][500/1251]	 loss 4.63297	 cls_loss: 0.6425 cluster_loss: 1.3547 sup_con_loss: 0.2826 contrastive_loss: 5.2699 nll_loss: 0.0032 
2023-10-26 19:19:44.900 | INFO     | __main__:train:314 - Epoch: [24][600/1251]	 loss 4.73002	 cls_loss: 0.5599 cluster_loss: 1.4478 sup_con_loss: 0.4599 contrastive_loss: 5.2754 nll_loss: 0.0030 
2023-10-26 19:23:28.630 | INFO     | __main__:train:314 - Epoch: [24][700/1251]	 loss 4.66859	 cls_loss: 0.5947 cluster_loss: 1.4023 sup_con_loss: 0.3387 contrastive_loss: 5.2749 nll_loss: 0.0017 
2023-10-26 19:27:12.896 | INFO     | __main__:train:314 - Epoch: [24][800/1251]	 loss 4.61159	 cls_loss: 0.3883 cluster_loss: 1.3885 sup_con_loss: 0.4133 contrastive_loss: 5.2701 nll_loss: 0.0029 
2023-10-26 19:30:58.378 | INFO     | __main__:train:314 - Epoch: [24][900/1251]	 loss 4.71604	 cls_loss: 0.6612 cluster_loss: 1.3635 sup_con_loss: 0.4857 contrastive_loss: 5.2704 nll_loss: 0.0026 
2023-10-26 19:34:44.236 | INFO     | __main__:train:314 - Epoch: [24][1000/1251]	 loss 4.73353	 cls_loss: 0.5913 cluster_loss: 1.3743 sup_con_loss: 0.5848 contrastive_loss: 5.2699 nll_loss: 0.0032 
2023-10-26 19:38:29.156 | INFO     | __main__:train:314 - Epoch: [24][1100/1251]	 loss 4.68692	 cls_loss: 0.5493 cluster_loss: 1.4095 sup_con_loss: 0.4239 contrastive_loss: 5.2728 nll_loss: 0.0027 
2023-10-26 19:42:15.360 | INFO     | __main__:train:314 - Epoch: [24][1200/1251]	 loss 4.70409	 cls_loss: 0.6083 cluster_loss: 1.3902 sup_con_loss: 0.4543 contrastive_loss: 5.2708 nll_loss: 0.0025 
2023-10-26 19:44:07.360 | INFO     | __main__:train:319 - Train Epoch: 24 Avg Loss: 4.6887 
2023-10-26 19:44:07.363 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 20:07:14.505 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 24, Train ACC Unlabelled_v2: All 0.5920 | Old 0.7752 | New 0.4999
2023-10-26 20:07:15.157 | INFO     | __main__:main:205 - Train Accuracies: All 0.5920 | Old 0.7752 | New 0.4999
2023-10-26 20:07:19.499 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 20:07:48.772 | INFO     | __main__:train:314 - Epoch: [25][0/1251]	 loss 4.74988	 cls_loss: 0.6413 cluster_loss: 1.4824 sup_con_loss: 0.3642 contrastive_loss: 5.2807 nll_loss: 0.0019 
2023-10-26 20:11:32.871 | INFO     | __main__:train:314 - Epoch: [25][100/1251]	 loss 4.61862	 cls_loss: 0.5132 cluster_loss: 1.3591 sup_con_loss: 0.3730 contrastive_loss: 5.2660 nll_loss: 0.0021 
2023-10-26 20:15:18.157 | INFO     | __main__:train:314 - Epoch: [25][200/1251]	 loss 4.80634	 cls_loss: 0.6333 cluster_loss: 1.4858 sup_con_loss: 0.5279 contrastive_loss: 5.2799 nll_loss: 0.0022 
2023-10-26 20:19:05.545 | INFO     | __main__:train:314 - Epoch: [25][300/1251]	 loss 4.70005	 cls_loss: 0.6187 cluster_loss: 1.3486 sup_con_loss: 0.5120 contrastive_loss: 5.2704 nll_loss: 0.0020 
2023-10-26 20:22:55.932 | INFO     | __main__:train:314 - Epoch: [25][400/1251]	 loss 4.66293	 cls_loss: 0.5861 cluster_loss: 1.3488 sup_con_loss: 0.4321 contrastive_loss: 5.2732 nll_loss: 0.0023 
2023-10-26 20:26:41.009 | INFO     | __main__:train:314 - Epoch: [25][500/1251]	 loss 4.65135	 cls_loss: 0.4930 cluster_loss: 1.3769 sup_con_loss: 0.4432 contrastive_loss: 5.2701 nll_loss: 0.0031 
2023-10-26 20:30:46.589 | INFO     | __main__:train:314 - Epoch: [25][600/1251]	 loss 4.81195	 cls_loss: 0.6180 cluster_loss: 1.4415 sup_con_loss: 0.6422 contrastive_loss: 5.2776 nll_loss: 0.0035 
2023-10-26 20:34:33.234 | INFO     | __main__:train:314 - Epoch: [25][700/1251]	 loss 4.82438	 cls_loss: 0.6030 cluster_loss: 1.4550 sup_con_loss: 0.6751 contrastive_loss: 5.2759 nll_loss: 0.0020 
2023-10-26 20:38:21.045 | INFO     | __main__:train:314 - Epoch: [25][800/1251]	 loss 4.63993	 cls_loss: 0.5568 cluster_loss: 1.3736 sup_con_loss: 0.3561 contrastive_loss: 5.2694 nll_loss: 0.0024 
2023-10-26 20:42:12.807 | INFO     | __main__:train:314 - Epoch: [25][900/1251]	 loss 4.72061	 cls_loss: 0.5633 cluster_loss: 1.4077 sup_con_loss: 0.5057 contrastive_loss: 5.2746 nll_loss: 0.0030 
2023-10-26 20:45:59.507 | INFO     | __main__:train:314 - Epoch: [25][1000/1251]	 loss 4.76534	 cls_loss: 0.6277 cluster_loss: 1.3968 sup_con_loss: 0.5964 contrastive_loss: 5.2718 nll_loss: 0.0023 
2023-10-26 20:49:45.038 | INFO     | __main__:train:314 - Epoch: [25][1100/1251]	 loss 4.67761	 cls_loss: 0.5308 cluster_loss: 1.4278 sup_con_loss: 0.3671 contrastive_loss: 5.2799 nll_loss: 0.0034 
2023-10-26 20:53:32.353 | INFO     | __main__:train:314 - Epoch: [25][1200/1251]	 loss 4.83388	 cls_loss: 0.7101 cluster_loss: 1.3860 sup_con_loss: 0.7281 contrastive_loss: 5.2733 nll_loss: 0.0020 
2023-10-26 20:55:24.969 | INFO     | __main__:train:319 - Train Epoch: 25 Avg Loss: 4.6891 
2023-10-26 20:55:24.977 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 21:23:02.064 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 25, Train ACC Unlabelled_v2: All 0.5919 | Old 0.7750 | New 0.4998
2023-10-26 21:23:02.985 | INFO     | __main__:main:205 - Train Accuracies: All 0.5919 | Old 0.7750 | New 0.4998
2023-10-26 21:23:08.920 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 21:23:27.567 | INFO     | __main__:train:314 - Epoch: [26][0/1251]	 loss 4.57231	 cls_loss: 0.5106 cluster_loss: 1.2879 sup_con_loss: 0.3698 contrastive_loss: 5.2676 nll_loss: 0.0031 
2023-10-26 21:27:16.595 | INFO     | __main__:train:314 - Epoch: [26][100/1251]	 loss 4.56861	 cls_loss: 0.3875 cluster_loss: 1.3583 sup_con_loss: 0.3481 contrastive_loss: 5.2704 nll_loss: 0.0025 
2023-10-26 21:31:12.787 | INFO     | __main__:train:314 - Epoch: [26][200/1251]	 loss 4.76739	 cls_loss: 0.6569 cluster_loss: 1.4317 sup_con_loss: 0.5022 contrastive_loss: 5.2756 nll_loss: 0.0020 
2023-10-26 21:35:00.066 | INFO     | __main__:train:314 - Epoch: [26][300/1251]	 loss 4.70060	 cls_loss: 0.7121 cluster_loss: 1.3753 sup_con_loss: 0.3685 contrastive_loss: 5.2703 nll_loss: 0.0027 
2023-10-26 21:38:46.341 | INFO     | __main__:train:314 - Epoch: [26][400/1251]	 loss 4.75653	 cls_loss: 0.5388 cluster_loss: 1.5187 sup_con_loss: 0.3928 contrastive_loss: 5.2920 nll_loss: 0.0035 
2023-10-26 21:42:32.351 | INFO     | __main__:train:314 - Epoch: [26][500/1251]	 loss 4.60712	 cls_loss: 0.4876 cluster_loss: 1.3540 sup_con_loss: 0.3678 contrastive_loss: 5.2699 nll_loss: 0.0022 
2023-10-26 21:46:25.517 | INFO     | __main__:train:314 - Epoch: [26][600/1251]	 loss 4.68994	 cls_loss: 0.6329 cluster_loss: 1.3685 sup_con_loss: 0.4292 contrastive_loss: 5.2711 nll_loss: 0.0024 
2023-10-26 21:50:22.745 | INFO     | __main__:train:314 - Epoch: [26][700/1251]	 loss 4.79444	 cls_loss: 0.7550 cluster_loss: 1.4014 sup_con_loss: 0.5335 contrastive_loss: 5.2768 nll_loss: 0.0027 
2023-10-26 21:54:09.785 | INFO     | __main__:train:314 - Epoch: [26][800/1251]	 loss 4.69144	 cls_loss: 0.5572 cluster_loss: 1.3458 sup_con_loss: 0.5504 contrastive_loss: 5.2706 nll_loss: 0.0031 
2023-10-26 21:57:56.959 | INFO     | __main__:train:314 - Epoch: [26][900/1251]	 loss 4.63616	 cls_loss: 0.5215 cluster_loss: 1.3674 sup_con_loss: 0.3934 contrastive_loss: 5.2700 nll_loss: 0.0016 
2023-10-26 22:01:42.195 | INFO     | __main__:train:314 - Epoch: [26][1000/1251]	 loss 4.74081	 cls_loss: 0.6669 cluster_loss: 1.4716 sup_con_loss: 0.3357 contrastive_loss: 5.2791 nll_loss: 0.0019 
2023-10-26 22:05:29.074 | INFO     | __main__:train:314 - Epoch: [26][1100/1251]	 loss 4.66582	 cls_loss: 0.5877 cluster_loss: 1.3767 sup_con_loss: 0.3921 contrastive_loss: 5.2710 nll_loss: 0.0019 
2023-10-26 22:09:16.798 | INFO     | __main__:train:314 - Epoch: [26][1200/1251]	 loss 4.65224	 cls_loss: 0.4549 cluster_loss: 1.3981 sup_con_loss: 0.4494 contrastive_loss: 5.2681 nll_loss: 0.0027 
2023-10-26 22:11:08.950 | INFO     | __main__:train:319 - Train Epoch: 26 Avg Loss: 4.6800 
2023-10-26 22:11:08.960 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 22:36:16.886 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 26, Train ACC Unlabelled_v2: All 0.5950 | Old 0.7706 | New 0.5067
2023-10-26 22:36:17.132 | INFO     | __main__:main:205 - Train Accuracies: All 0.5950 | Old 0.7706 | New 0.5067
2023-10-26 22:36:20.856 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 22:36:36.332 | INFO     | __main__:train:314 - Epoch: [27][0/1251]	 loss 4.67522	 cls_loss: 0.6101 cluster_loss: 1.3509 sup_con_loss: 0.4363 contrastive_loss: 5.2727 nll_loss: 0.0037 
2023-10-26 22:40:25.089 | INFO     | __main__:train:314 - Epoch: [27][100/1251]	 loss 4.94016	 cls_loss: 0.7820 cluster_loss: 1.4978 sup_con_loss: 0.7419 contrastive_loss: 5.2789 nll_loss: 0.0019 
2023-10-26 22:44:12.022 | INFO     | __main__:train:314 - Epoch: [27][200/1251]	 loss 4.65713	 cls_loss: 0.5810 cluster_loss: 1.3786 sup_con_loss: 0.3702 contrastive_loss: 5.2719 nll_loss: 0.0014 
2023-10-26 22:49:22.319 | INFO     | __main__:train:314 - Epoch: [27][300/1251]	 loss 4.61006	 cls_loss: 0.4797 cluster_loss: 1.3624 sup_con_loss: 0.3617 contrastive_loss: 5.2715 nll_loss: 0.0035 
2023-10-26 22:54:32.367 | INFO     | __main__:train:314 - Epoch: [27][400/1251]	 loss 4.70570	 cls_loss: 0.5884 cluster_loss: 1.3704 sup_con_loss: 0.5205 contrastive_loss: 5.2672 nll_loss: 0.0032 
2023-10-26 22:58:33.400 | INFO     | __main__:train:314 - Epoch: [27][500/1251]	 loss 4.71377	 cls_loss: 0.5671 cluster_loss: 1.4215 sup_con_loss: 0.4562 contrastive_loss: 5.2748 nll_loss: 0.0030 
2023-10-26 23:02:39.498 | INFO     | __main__:train:314 - Epoch: [27][600/1251]	 loss 4.63160	 cls_loss: 0.6373 cluster_loss: 1.3207 sup_con_loss: 0.3509 contrastive_loss: 5.2694 nll_loss: 0.0022 
2023-10-26 23:06:34.413 | INFO     | __main__:train:314 - Epoch: [27][700/1251]	 loss 4.62535	 cls_loss: 0.6009 cluster_loss: 1.3190 sup_con_loss: 0.3748 contrastive_loss: 5.2699 nll_loss: 0.0011 
2023-10-26 23:10:31.922 | INFO     | __main__:train:314 - Epoch: [27][800/1251]	 loss 4.73847	 cls_loss: 0.7153 cluster_loss: 1.4351 sup_con_loss: 0.3579 contrastive_loss: 5.2742 nll_loss: 0.0018 
2023-10-26 23:14:18.993 | INFO     | __main__:train:314 - Epoch: [27][900/1251]	 loss 4.86093	 cls_loss: 0.6214 cluster_loss: 1.4613 sup_con_loss: 0.7453 contrastive_loss: 5.2769 nll_loss: 0.0028 
2023-10-26 23:18:10.418 | INFO     | __main__:train:314 - Epoch: [27][1000/1251]	 loss 4.83180	 cls_loss: 0.6906 cluster_loss: 1.4496 sup_con_loss: 0.6058 contrastive_loss: 5.2826 nll_loss: 0.0022 
2023-10-26 23:21:55.229 | INFO     | __main__:train:314 - Epoch: [27][1100/1251]	 loss 4.68996	 cls_loss: 0.5721 cluster_loss: 1.3553 sup_con_loss: 0.5105 contrastive_loss: 5.2731 nll_loss: 0.0026 
2023-10-26 23:25:40.132 | INFO     | __main__:train:314 - Epoch: [27][1200/1251]	 loss 4.80795	 cls_loss: 0.7083 cluster_loss: 1.4459 sup_con_loss: 0.5292 contrastive_loss: 5.2813 nll_loss: 0.0022 
2023-10-26 23:27:33.532 | INFO     | __main__:train:319 - Train Epoch: 27 Avg Loss: 4.6767 
2023-10-26 23:27:33.536 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-26 23:51:47.356 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 27, Train ACC Unlabelled_v2: All 0.5935 | Old 0.7808 | New 0.4993
2023-10-26 23:51:47.818 | INFO     | __main__:main:205 - Train Accuracies: All 0.5935 | Old 0.7808 | New 0.4993
2023-10-26 23:51:51.865 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-26 23:52:07.206 | INFO     | __main__:train:314 - Epoch: [28][0/1251]	 loss 4.67737	 cls_loss: 0.6819 cluster_loss: 1.3435 sup_con_loss: 0.3914 contrastive_loss: 5.2707 nll_loss: 0.0025 
2023-10-26 23:55:52.737 | INFO     | __main__:train:314 - Epoch: [28][100/1251]	 loss 4.57128	 cls_loss: 0.5007 cluster_loss: 1.3153 sup_con_loss: 0.3274 contrastive_loss: 5.2686 nll_loss: 0.0019 
2023-10-26 23:59:39.086 | INFO     | __main__:train:314 - Epoch: [28][200/1251]	 loss 4.61399	 cls_loss: 0.6185 cluster_loss: 1.3436 sup_con_loss: 0.2811 contrastive_loss: 5.2690 nll_loss: 0.0009 
2023-10-27 00:03:27.087 | INFO     | __main__:train:314 - Epoch: [28][300/1251]	 loss 4.58976	 cls_loss: 0.4760 cluster_loss: 1.3172 sup_con_loss: 0.4012 contrastive_loss: 5.2674 nll_loss: 0.0027 
2023-10-27 00:07:12.541 | INFO     | __main__:train:314 - Epoch: [28][400/1251]	 loss 4.62135	 cls_loss: 0.5137 cluster_loss: 1.3640 sup_con_loss: 0.3618 contrastive_loss: 5.2695 nll_loss: 0.0031 
2023-10-27 00:10:59.390 | INFO     | __main__:train:314 - Epoch: [28][500/1251]	 loss 4.64491	 cls_loss: 0.5582 cluster_loss: 1.4230 sup_con_loss: 0.2552 contrastive_loss: 5.2795 nll_loss: 0.0036 
2023-10-27 00:14:53.072 | INFO     | __main__:train:314 - Epoch: [28][600/1251]	 loss 4.60157	 cls_loss: 0.5303 cluster_loss: 1.3495 sup_con_loss: 0.3159 contrastive_loss: 5.2704 nll_loss: 0.0024 
2023-10-27 00:19:54.439 | INFO     | __main__:train:314 - Epoch: [28][700/1251]	 loss 4.68291	 cls_loss: 0.5788 cluster_loss: 1.3771 sup_con_loss: 0.4432 contrastive_loss: 5.2736 nll_loss: 0.0023 
2023-10-27 00:24:40.410 | INFO     | __main__:train:314 - Epoch: [28][800/1251]	 loss 4.66338	 cls_loss: 0.7442 cluster_loss: 1.3326 sup_con_loss: 0.3133 contrastive_loss: 5.2689 nll_loss: 0.0022 
2023-10-27 00:29:18.407 | INFO     | __main__:train:314 - Epoch: [28][900/1251]	 loss 4.62571	 cls_loss: 0.6247 cluster_loss: 1.3396 sup_con_loss: 0.3154 contrastive_loss: 5.2661 nll_loss: 0.0030 
2023-10-27 00:33:06.333 | INFO     | __main__:train:314 - Epoch: [28][1000/1251]	 loss 4.74662	 cls_loss: 0.6794 cluster_loss: 1.3850 sup_con_loss: 0.5037 contrastive_loss: 5.2762 nll_loss: 0.0027 
2023-10-27 00:36:50.852 | INFO     | __main__:train:314 - Epoch: [28][1100/1251]	 loss 4.60440	 cls_loss: 0.5159 cluster_loss: 1.3789 sup_con_loss: 0.2800 contrastive_loss: 5.2732 nll_loss: 0.0020 
2023-10-27 00:40:52.780 | INFO     | __main__:train:314 - Epoch: [28][1200/1251]	 loss 4.76876	 cls_loss: 0.5648 cluster_loss: 1.4451 sup_con_loss: 0.5673 contrastive_loss: 5.2777 nll_loss: 0.0027 
2023-10-27 00:42:44.100 | INFO     | __main__:train:319 - Train Epoch: 28 Avg Loss: 4.6750 
2023-10-27 00:42:44.110 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 01:07:41.359 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 28, Train ACC Unlabelled_v2: All 0.5955 | Old 0.7732 | New 0.5062
2023-10-27 01:07:41.962 | INFO     | __main__:main:205 - Train Accuracies: All 0.5955 | Old 0.7732 | New 0.5062
2023-10-27 01:07:46.165 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 01:08:04.128 | INFO     | __main__:train:314 - Epoch: [29][0/1251]	 loss 4.66906	 cls_loss: 0.6572 cluster_loss: 1.3620 sup_con_loss: 0.3580 contrastive_loss: 5.2705 nll_loss: 0.0026 
2023-10-27 01:11:49.811 | INFO     | __main__:train:314 - Epoch: [29][100/1251]	 loss 4.61465	 cls_loss: 0.5769 cluster_loss: 1.3389 sup_con_loss: 0.3271 contrastive_loss: 5.2709 nll_loss: 0.0020 
2023-10-27 01:15:38.964 | INFO     | __main__:train:314 - Epoch: [29][200/1251]	 loss 4.57009	 cls_loss: 0.5096 cluster_loss: 1.3211 sup_con_loss: 0.2915 contrastive_loss: 5.2712 nll_loss: 0.0047 
2023-10-27 01:19:25.571 | INFO     | __main__:train:314 - Epoch: [29][300/1251]	 loss 4.63907	 cls_loss: 0.5852 cluster_loss: 1.3520 sup_con_loss: 0.3623 contrastive_loss: 5.2709 nll_loss: 0.0026 
2023-10-27 01:23:10.350 | INFO     | __main__:train:314 - Epoch: [29][400/1251]	 loss 4.74446	 cls_loss: 0.6003 cluster_loss: 1.4175 sup_con_loss: 0.5131 contrastive_loss: 5.2794 nll_loss: 0.0018 
2023-10-27 01:26:58.432 | INFO     | __main__:train:314 - Epoch: [29][500/1251]	 loss 4.52352	 cls_loss: 0.4216 cluster_loss: 1.2975 sup_con_loss: 0.3051 contrastive_loss: 5.2669 nll_loss: 0.0023 
2023-10-27 01:30:43.072 | INFO     | __main__:train:314 - Epoch: [29][600/1251]	 loss 4.75149	 cls_loss: 0.7275 cluster_loss: 1.3781 sup_con_loss: 0.4881 contrastive_loss: 5.2723 nll_loss: 0.0033 
2023-10-27 01:34:29.846 | INFO     | __main__:train:314 - Epoch: [29][700/1251]	 loss 4.62381	 cls_loss: 0.5416 cluster_loss: 1.3002 sup_con_loss: 0.4561 contrastive_loss: 5.2713 nll_loss: 0.0032 
2023-10-27 01:38:14.345 | INFO     | __main__:train:314 - Epoch: [29][800/1251]	 loss 4.73210	 cls_loss: 0.5693 cluster_loss: 1.4009 sup_con_loss: 0.5488 contrastive_loss: 5.2730 nll_loss: 0.0027 
2023-10-27 01:41:58.287 | INFO     | __main__:train:314 - Epoch: [29][900/1251]	 loss 4.70305	 cls_loss: 0.7168 cluster_loss: 1.3794 sup_con_loss: 0.3635 contrastive_loss: 5.2718 nll_loss: 0.0017 
2023-10-27 01:45:42.268 | INFO     | __main__:train:314 - Epoch: [29][1000/1251]	 loss 4.75164	 cls_loss: 0.6124 cluster_loss: 1.3455 sup_con_loss: 0.6792 contrastive_loss: 5.2673 nll_loss: 0.0012 
2023-10-27 01:49:32.066 | INFO     | __main__:train:314 - Epoch: [29][1100/1251]	 loss 4.67778	 cls_loss: 0.4735 cluster_loss: 1.4039 sup_con_loss: 0.4768 contrastive_loss: 5.2778 nll_loss: 0.0020 
2023-10-27 01:53:19.692 | INFO     | __main__:train:314 - Epoch: [29][1200/1251]	 loss 4.74470	 cls_loss: 0.6203 cluster_loss: 1.3894 sup_con_loss: 0.5612 contrastive_loss: 5.2715 nll_loss: 0.0016 
2023-10-27 01:55:13.183 | INFO     | __main__:train:319 - Train Epoch: 29 Avg Loss: 4.6691 
2023-10-27 01:55:13.202 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 02:16:07.815 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 29, Train ACC Unlabelled_v2: All 0.5931 | Old 0.7763 | New 0.5011
2023-10-27 02:16:08.058 | INFO     | __main__:main:205 - Train Accuracies: All 0.5931 | Old 0.7763 | New 0.5011
2023-10-27 02:16:11.343 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 02:16:29.409 | INFO     | __main__:train:314 - Epoch: [30][0/1251]	 loss 4.84412	 cls_loss: 0.7765 cluster_loss: 1.4320 sup_con_loss: 0.6007 contrastive_loss: 5.2763 nll_loss: 0.0017 
2023-10-27 02:20:15.815 | INFO     | __main__:train:314 - Epoch: [30][100/1251]	 loss 4.69612	 cls_loss: 0.5969 cluster_loss: 1.4226 sup_con_loss: 0.3685 contrastive_loss: 5.2780 nll_loss: 0.0028 
2023-10-27 02:24:04.587 | INFO     | __main__:train:314 - Epoch: [30][200/1251]	 loss 4.72794	 cls_loss: 0.7176 cluster_loss: 1.3372 sup_con_loss: 0.5190 contrastive_loss: 5.2690 nll_loss: 0.0011 
2023-10-27 02:27:50.271 | INFO     | __main__:train:314 - Epoch: [30][300/1251]	 loss 4.67649	 cls_loss: 0.5952 cluster_loss: 1.3757 sup_con_loss: 0.4190 contrastive_loss: 5.2696 nll_loss: 0.0021 
2023-10-27 02:31:35.045 | INFO     | __main__:train:314 - Epoch: [30][400/1251]	 loss 4.65407	 cls_loss: 0.6419 cluster_loss: 1.3437 sup_con_loss: 0.3609 contrastive_loss: 5.2726 nll_loss: 0.0025 
2023-10-27 02:35:18.835 | INFO     | __main__:train:314 - Epoch: [30][500/1251]	 loss 4.66342	 cls_loss: 0.5112 cluster_loss: 1.3401 sup_con_loss: 0.5328 contrastive_loss: 5.2692 nll_loss: 0.0020 
2023-10-27 02:39:04.718 | INFO     | __main__:train:314 - Epoch: [30][600/1251]	 loss 4.66817	 cls_loss: 0.6443 cluster_loss: 1.3425 sup_con_loss: 0.4132 contrastive_loss: 5.2662 nll_loss: 0.0024 
2023-10-27 02:42:54.680 | INFO     | __main__:train:314 - Epoch: [30][700/1251]	 loss 4.71137	 cls_loss: 0.6319 cluster_loss: 1.3494 sup_con_loss: 0.5270 contrastive_loss: 5.2705 nll_loss: 0.0028 
2023-10-27 02:46:38.591 | INFO     | __main__:train:314 - Epoch: [30][800/1251]	 loss 4.64160	 cls_loss: 0.5268 cluster_loss: 1.3426 sup_con_loss: 0.4504 contrastive_loss: 5.2696 nll_loss: 0.0017 
2023-10-27 02:50:20.979 | INFO     | __main__:train:314 - Epoch: [30][900/1251]	 loss 4.65232	 cls_loss: 0.6040 cluster_loss: 1.3207 sup_con_loss: 0.4403 contrastive_loss: 5.2721 nll_loss: 0.0015 
2023-10-27 02:54:05.397 | INFO     | __main__:train:314 - Epoch: [30][1000/1251]	 loss 4.75608	 cls_loss: 0.6331 cluster_loss: 1.3607 sup_con_loss: 0.6414 contrastive_loss: 5.2688 nll_loss: 0.0008 
2023-10-27 02:57:51.874 | INFO     | __main__:train:314 - Epoch: [30][1100/1251]	 loss 4.60039	 cls_loss: 0.6331 cluster_loss: 1.3024 sup_con_loss: 0.3038 contrastive_loss: 5.2667 nll_loss: 0.0025 
2023-10-27 03:01:34.261 | INFO     | __main__:train:314 - Epoch: [30][1200/1251]	 loss 4.75367	 cls_loss: 0.5858 cluster_loss: 1.4087 sup_con_loss: 0.5801 contrastive_loss: 5.2724 nll_loss: 0.0029 
2023-10-27 03:03:27.203 | INFO     | __main__:train:319 - Train Epoch: 30 Avg Loss: 4.6710 
2023-10-27 03:03:27.211 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 03:23:57.797 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 30, Train ACC Unlabelled_v2: All 0.5952 | Old 0.7753 | New 0.5047
2023-10-27 03:24:00.098 | INFO     | __main__:main:205 - Train Accuracies: All 0.5952 | Old 0.7753 | New 0.5047
2023-10-27 03:24:06.306 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 03:24:31.557 | INFO     | __main__:train:314 - Epoch: [31][0/1251]	 loss 4.74655	 cls_loss: 0.5359 cluster_loss: 1.4281 sup_con_loss: 0.5643 contrastive_loss: 5.2774 nll_loss: 0.0029 
2023-10-27 03:28:16.057 | INFO     | __main__:train:314 - Epoch: [31][100/1251]	 loss 4.63403	 cls_loss: 0.4448 cluster_loss: 1.3558 sup_con_loss: 0.4765 contrastive_loss: 5.2714 nll_loss: 0.0038 
2023-10-27 03:32:00.869 | INFO     | __main__:train:314 - Epoch: [31][200/1251]	 loss 4.57794	 cls_loss: 0.4886 cluster_loss: 1.3480 sup_con_loss: 0.2921 contrastive_loss: 5.2707 nll_loss: 0.0026 
2023-10-27 03:35:46.401 | INFO     | __main__:train:314 - Epoch: [31][300/1251]	 loss 4.73698	 cls_loss: 0.6157 cluster_loss: 1.4454 sup_con_loss: 0.4296 contrastive_loss: 5.2754 nll_loss: 0.0026 
2023-10-27 03:39:30.216 | INFO     | __main__:train:314 - Epoch: [31][400/1251]	 loss 4.64819	 cls_loss: 0.7169 cluster_loss: 1.3305 sup_con_loss: 0.2937 contrastive_loss: 5.2725 nll_loss: 0.0026 
2023-10-27 03:43:15.299 | INFO     | __main__:train:314 - Epoch: [31][500/1251]	 loss 4.71731	 cls_loss: 0.6174 cluster_loss: 1.3303 sup_con_loss: 0.5989 contrastive_loss: 5.2685 nll_loss: 0.0024 
2023-10-27 03:46:59.123 | INFO     | __main__:train:314 - Epoch: [31][600/1251]	 loss 4.74564	 cls_loss: 0.5909 cluster_loss: 1.4180 sup_con_loss: 0.5390 contrastive_loss: 5.2729 nll_loss: 0.0011 
2023-10-27 03:50:43.422 | INFO     | __main__:train:314 - Epoch: [31][700/1251]	 loss 4.68162	 cls_loss: 0.6170 cluster_loss: 1.3690 sup_con_loss: 0.4116 contrastive_loss: 5.2752 nll_loss: 0.0029 
2023-10-27 03:54:28.155 | INFO     | __main__:train:314 - Epoch: [31][800/1251]	 loss 4.66151	 cls_loss: 0.6377 cluster_loss: 1.3674 sup_con_loss: 0.3425 contrastive_loss: 5.2703 nll_loss: 0.0039 
2023-10-27 03:58:11.611 | INFO     | __main__:train:314 - Epoch: [31][900/1251]	 loss 4.72471	 cls_loss: 0.6265 cluster_loss: 1.3886 sup_con_loss: 0.5002 contrastive_loss: 5.2712 nll_loss: 0.0015 
2023-10-27 04:01:58.335 | INFO     | __main__:train:314 - Epoch: [31][1000/1251]	 loss 4.60888	 cls_loss: 0.4972 cluster_loss: 1.3026 sup_con_loss: 0.4584 contrastive_loss: 5.2695 nll_loss: 0.0025 
2023-10-27 04:05:43.791 | INFO     | __main__:train:314 - Epoch: [31][1100/1251]	 loss 4.65918	 cls_loss: 0.6384 cluster_loss: 1.3476 sup_con_loss: 0.3730 contrastive_loss: 5.2724 nll_loss: 0.0022 
2023-10-27 04:09:29.602 | INFO     | __main__:train:314 - Epoch: [31][1200/1251]	 loss 4.73345	 cls_loss: 0.5773 cluster_loss: 1.3579 sup_con_loss: 0.6317 contrastive_loss: 5.2701 nll_loss: 0.0021 
2023-10-27 04:11:21.929 | INFO     | __main__:train:319 - Train Epoch: 31 Avg Loss: 4.6670 
2023-10-27 04:11:21.934 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 04:31:50.716 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 31, Train ACC Unlabelled_v2: All 0.5952 | Old 0.7740 | New 0.5053
2023-10-27 04:31:51.071 | INFO     | __main__:main:205 - Train Accuracies: All 0.5952 | Old 0.7740 | New 0.5053
2023-10-27 04:31:56.643 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 04:32:14.263 | INFO     | __main__:train:314 - Epoch: [32][0/1251]	 loss 4.64687	 cls_loss: 0.5922 cluster_loss: 1.3130 sup_con_loss: 0.4481 contrastive_loss: 5.2731 nll_loss: 0.0018 
2023-10-27 04:35:59.333 | INFO     | __main__:train:314 - Epoch: [32][100/1251]	 loss 4.59202	 cls_loss: 0.6057 cluster_loss: 1.3141 sup_con_loss: 0.2773 contrastive_loss: 5.2702 nll_loss: 0.0031 
2023-10-27 04:39:45.537 | INFO     | __main__:train:314 - Epoch: [32][200/1251]	 loss 4.60263	 cls_loss: 0.5431 cluster_loss: 1.3583 sup_con_loss: 0.2883 contrastive_loss: 5.2728 nll_loss: 0.0014 
2023-10-27 04:43:30.036 | INFO     | __main__:train:314 - Epoch: [32][300/1251]	 loss 4.74068	 cls_loss: 0.5300 cluster_loss: 1.3924 sup_con_loss: 0.6289 contrastive_loss: 5.2748 nll_loss: 0.0014 
2023-10-27 04:47:14.064 | INFO     | __main__:train:314 - Epoch: [32][400/1251]	 loss 4.83835	 cls_loss: 0.7820 cluster_loss: 1.3943 sup_con_loss: 0.6562 contrastive_loss: 5.2726 nll_loss: 0.0015 
2023-10-27 04:51:00.378 | INFO     | __main__:train:314 - Epoch: [32][500/1251]	 loss 4.61414	 cls_loss: 0.4709 cluster_loss: 1.3791 sup_con_loss: 0.3536 contrastive_loss: 5.2736 nll_loss: 0.0013 
2023-10-27 04:54:45.160 | INFO     | __main__:train:314 - Epoch: [32][600/1251]	 loss 4.66537	 cls_loss: 0.5997 cluster_loss: 1.3820 sup_con_loss: 0.3588 contrastive_loss: 5.2769 nll_loss: 0.0016 
2023-10-27 04:58:44.379 | INFO     | __main__:train:314 - Epoch: [32][700/1251]	 loss 4.71294	 cls_loss: 0.6132 cluster_loss: 1.3955 sup_con_loss: 0.4624 contrastive_loss: 5.2722 nll_loss: 0.0025 
2023-10-27 05:02:30.275 | INFO     | __main__:train:314 - Epoch: [32][800/1251]	 loss 4.66064	 cls_loss: 0.6027 cluster_loss: 1.3285 sup_con_loss: 0.4514 contrastive_loss: 5.2684 nll_loss: 0.0037 
2023-10-27 05:06:13.770 | INFO     | __main__:train:314 - Epoch: [32][900/1251]	 loss 4.57258	 cls_loss: 0.5361 cluster_loss: 1.2872 sup_con_loss: 0.3486 contrastive_loss: 5.2670 nll_loss: 0.0027 
2023-10-27 05:09:57.214 | INFO     | __main__:train:314 - Epoch: [32][1000/1251]	 loss 4.69800	 cls_loss: 0.5632 cluster_loss: 1.4004 sup_con_loss: 0.4564 contrastive_loss: 5.2755 nll_loss: 0.0018 
2023-10-27 05:13:45.416 | INFO     | __main__:train:314 - Epoch: [32][1100/1251]	 loss 4.82745	 cls_loss: 0.6875 cluster_loss: 1.4268 sup_con_loss: 0.6525 contrastive_loss: 5.2730 nll_loss: 0.0035 
2023-10-27 05:17:33.975 | INFO     | __main__:train:314 - Epoch: [32][1200/1251]	 loss 4.68120	 cls_loss: 0.5575 cluster_loss: 1.3590 sup_con_loss: 0.4938 contrastive_loss: 5.2733 nll_loss: 0.0022 
2023-10-27 05:19:26.791 | INFO     | __main__:train:319 - Train Epoch: 32 Avg Loss: 4.6672 
2023-10-27 05:19:26.794 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 05:39:25.873 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 32, Train ACC Unlabelled_v2: All 0.5949 | Old 0.7749 | New 0.5045
2023-10-27 05:39:26.128 | INFO     | __main__:main:205 - Train Accuracies: All 0.5949 | Old 0.7749 | New 0.5045
2023-10-27 05:39:30.172 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 05:39:44.664 | INFO     | __main__:train:314 - Epoch: [33][0/1251]	 loss 4.78651	 cls_loss: 0.6590 cluster_loss: 1.4206 sup_con_loss: 0.5670 contrastive_loss: 5.2802 nll_loss: 0.0019 
2023-10-27 05:43:30.654 | INFO     | __main__:train:314 - Epoch: [33][100/1251]	 loss 4.61762	 cls_loss: 0.5648 cluster_loss: 1.3494 sup_con_loss: 0.3328 contrastive_loss: 5.2685 nll_loss: 0.0018 
2023-10-27 05:47:14.703 | INFO     | __main__:train:314 - Epoch: [33][200/1251]	 loss 4.74609	 cls_loss: 0.6491 cluster_loss: 1.3725 sup_con_loss: 0.5680 contrastive_loss: 5.2694 nll_loss: 0.0029 
2023-10-27 05:51:00.194 | INFO     | __main__:train:314 - Epoch: [33][300/1251]	 loss 4.67482	 cls_loss: 0.6266 cluster_loss: 1.3642 sup_con_loss: 0.3988 contrastive_loss: 5.2736 nll_loss: 0.0014 
2023-10-27 05:54:46.918 | INFO     | __main__:train:314 - Epoch: [33][400/1251]	 loss 4.60204	 cls_loss: 0.5787 cluster_loss: 1.3280 sup_con_loss: 0.3094 contrastive_loss: 5.2705 nll_loss: 0.0021 
2023-10-27 05:58:30.193 | INFO     | __main__:train:314 - Epoch: [33][500/1251]	 loss 4.61419	 cls_loss: 0.4775 cluster_loss: 1.3394 sup_con_loss: 0.4228 contrastive_loss: 5.2714 nll_loss: 0.0021 
2023-10-27 06:02:14.991 | INFO     | __main__:train:314 - Epoch: [33][600/1251]	 loss 4.60497	 cls_loss: 0.5096 cluster_loss: 1.3261 sup_con_loss: 0.3972 contrastive_loss: 5.2674 nll_loss: 0.0018 
2023-10-27 06:05:59.998 | INFO     | __main__:train:314 - Epoch: [33][700/1251]	 loss 4.64153	 cls_loss: 0.5460 cluster_loss: 1.3809 sup_con_loss: 0.3556 contrastive_loss: 5.2707 nll_loss: 0.0024 
2023-10-27 06:09:42.234 | INFO     | __main__:train:314 - Epoch: [33][800/1251]	 loss 4.65675	 cls_loss: 0.6308 cluster_loss: 1.3237 sup_con_loss: 0.4220 contrastive_loss: 5.2685 nll_loss: 0.0034 
2023-10-27 06:13:28.088 | INFO     | __main__:train:314 - Epoch: [33][900/1251]	 loss 4.79433	 cls_loss: 0.6963 cluster_loss: 1.4739 sup_con_loss: 0.4582 contrastive_loss: 5.2775 nll_loss: 0.0019 
2023-10-27 06:17:13.403 | INFO     | __main__:train:314 - Epoch: [33][1000/1251]	 loss 4.58453	 cls_loss: 0.5172 cluster_loss: 1.3118 sup_con_loss: 0.3519 contrastive_loss: 5.2701 nll_loss: 0.0021 
2023-10-27 06:20:56.409 | INFO     | __main__:train:314 - Epoch: [33][1100/1251]	 loss 4.53522	 cls_loss: 0.4971 cluster_loss: 1.2945 sup_con_loss: 0.2648 contrastive_loss: 5.2676 nll_loss: 0.0032 
2023-10-27 06:24:41.451 | INFO     | __main__:train:314 - Epoch: [33][1200/1251]	 loss 4.57702	 cls_loss: 0.5639 cluster_loss: 1.2937 sup_con_loss: 0.3208 contrastive_loss: 5.2692 nll_loss: 0.0015 
2023-10-27 06:26:33.121 | INFO     | __main__:train:319 - Train Epoch: 33 Avg Loss: 4.6662 
2023-10-27 06:26:33.131 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 06:46:25.220 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 33, Train ACC Unlabelled_v2: All 0.5942 | Old 0.7754 | New 0.5030
2023-10-27 06:46:25.706 | INFO     | __main__:main:205 - Train Accuracies: All 0.5942 | Old 0.7754 | New 0.5030
2023-10-27 06:46:30.719 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 06:46:46.798 | INFO     | __main__:train:314 - Epoch: [34][0/1251]	 loss 4.62600	 cls_loss: 0.5337 cluster_loss: 1.3466 sup_con_loss: 0.3890 contrastive_loss: 5.2694 nll_loss: 0.0027 
2023-10-27 06:50:31.402 | INFO     | __main__:train:314 - Epoch: [34][100/1251]	 loss 4.69028	 cls_loss: 0.7131 cluster_loss: 1.3720 sup_con_loss: 0.3452 contrastive_loss: 5.2695 nll_loss: 0.0029 
2023-10-27 06:54:17.992 | INFO     | __main__:train:314 - Epoch: [34][200/1251]	 loss 4.75605	 cls_loss: 0.7255 cluster_loss: 1.3755 sup_con_loss: 0.5130 contrastive_loss: 5.2711 nll_loss: 0.0023 
2023-10-27 06:58:02.476 | INFO     | __main__:train:314 - Epoch: [34][300/1251]	 loss 4.66185	 cls_loss: 0.5951 cluster_loss: 1.3411 sup_con_loss: 0.4406 contrastive_loss: 5.2682 nll_loss: 0.0033 
2023-10-27 07:01:47.206 | INFO     | __main__:train:314 - Epoch: [34][400/1251]	 loss 4.68569	 cls_loss: 0.5297 cluster_loss: 1.3541 sup_con_loss: 0.5538 contrastive_loss: 5.2680 nll_loss: 0.0021 
2023-10-27 07:05:32.422 | INFO     | __main__:train:314 - Epoch: [34][500/1251]	 loss 4.79640	 cls_loss: 0.7260 cluster_loss: 1.4190 sup_con_loss: 0.5288 contrastive_loss: 5.2811 nll_loss: 0.0022 
2023-10-27 07:09:16.871 | INFO     | __main__:train:314 - Epoch: [34][600/1251]	 loss 4.74234	 cls_loss: 0.6795 cluster_loss: 1.3606 sup_con_loss: 0.5386 contrastive_loss: 5.2730 nll_loss: 0.0042 
2023-10-27 07:13:02.720 | INFO     | __main__:train:314 - Epoch: [34][700/1251]	 loss 4.74334	 cls_loss: 0.6179 cluster_loss: 1.3589 sup_con_loss: 0.6153 contrastive_loss: 5.2699 nll_loss: 0.0029 
2023-10-27 07:16:47.085 | INFO     | __main__:train:314 - Epoch: [34][800/1251]	 loss 4.53770	 cls_loss: 0.3846 cluster_loss: 1.3183 sup_con_loss: 0.3445 contrastive_loss: 5.2678 nll_loss: 0.0015 
2023-10-27 07:20:31.167 | INFO     | __main__:train:314 - Epoch: [34][900/1251]	 loss 4.74714	 cls_loss: 0.6831 cluster_loss: 1.4309 sup_con_loss: 0.4191 contrastive_loss: 5.2763 nll_loss: 0.0017 
2023-10-27 07:24:13.683 | INFO     | __main__:train:314 - Epoch: [34][1000/1251]	 loss 4.67519	 cls_loss: 0.5299 cluster_loss: 1.3036 sup_con_loss: 0.6130 contrastive_loss: 5.2692 nll_loss: 0.0028 
2023-10-27 07:27:57.561 | INFO     | __main__:train:314 - Epoch: [34][1100/1251]	 loss 4.65428	 cls_loss: 0.6417 cluster_loss: 1.3636 sup_con_loss: 0.3292 contrastive_loss: 5.2692 nll_loss: 0.0032 
2023-10-27 07:31:43.789 | INFO     | __main__:train:314 - Epoch: [34][1200/1251]	 loss 4.68081	 cls_loss: 0.5379 cluster_loss: 1.3906 sup_con_loss: 0.4599 contrastive_loss: 5.2710 nll_loss: 0.0015 
2023-10-27 07:33:35.273 | INFO     | __main__:train:319 - Train Epoch: 34 Avg Loss: 4.6655 
2023-10-27 07:33:35.277 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 07:53:16.749 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 34, Train ACC Unlabelled_v2: All 0.5956 | Old 0.7751 | New 0.5053
2023-10-27 07:53:16.950 | INFO     | __main__:main:205 - Train Accuracies: All 0.5956 | Old 0.7751 | New 0.5053
2023-10-27 07:53:20.681 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 07:53:36.603 | INFO     | __main__:train:314 - Epoch: [35][0/1251]	 loss 4.66754	 cls_loss: 0.5499 cluster_loss: 1.3430 sup_con_loss: 0.5013 contrastive_loss: 5.2688 nll_loss: 0.0019 
2023-10-27 07:57:21.325 | INFO     | __main__:train:314 - Epoch: [35][100/1251]	 loss 4.71377	 cls_loss: 0.6309 cluster_loss: 1.3326 sup_con_loss: 0.5678 contrastive_loss: 5.2714 nll_loss: 0.0016 
2023-10-27 08:01:03.974 | INFO     | __main__:train:314 - Epoch: [35][200/1251]	 loss 4.93117	 cls_loss: 0.8493 cluster_loss: 1.5253 sup_con_loss: 0.5895 contrastive_loss: 5.2842 nll_loss: 0.0014 
2023-10-27 08:04:47.665 | INFO     | __main__:train:314 - Epoch: [35][300/1251]	 loss 4.65098	 cls_loss: 0.5245 cluster_loss: 1.3959 sup_con_loss: 0.3752 contrastive_loss: 5.2716 nll_loss: 0.0022 
2023-10-27 08:08:34.308 | INFO     | __main__:train:314 - Epoch: [35][400/1251]	 loss 4.67321	 cls_loss: 0.6161 cluster_loss: 1.3288 sup_con_loss: 0.4822 contrastive_loss: 5.2669 nll_loss: 0.0015 
2023-10-27 08:12:18.205 | INFO     | __main__:train:314 - Epoch: [35][500/1251]	 loss 4.82691	 cls_loss: 0.7329 cluster_loss: 1.3645 sup_con_loss: 0.7290 contrastive_loss: 5.2715 nll_loss: 0.0019 
2023-10-27 08:16:01.809 | INFO     | __main__:train:314 - Epoch: [35][600/1251]	 loss 4.65559	 cls_loss: 0.5800 cluster_loss: 1.3357 sup_con_loss: 0.4577 contrastive_loss: 5.2654 nll_loss: 0.0017 
2023-10-27 08:19:46.108 | INFO     | __main__:train:314 - Epoch: [35][700/1251]	 loss 4.70145	 cls_loss: 0.7196 cluster_loss: 1.3883 sup_con_loss: 0.3351 contrastive_loss: 5.2736 nll_loss: 0.0021 
2023-10-27 08:23:29.506 | INFO     | __main__:train:314 - Epoch: [35][800/1251]	 loss 4.62098	 cls_loss: 0.4933 cluster_loss: 1.3952 sup_con_loss: 0.3093 contrastive_loss: 5.2785 nll_loss: 0.0022 
2023-10-27 08:27:13.147 | INFO     | __main__:train:314 - Epoch: [35][900/1251]	 loss 4.61008	 cls_loss: 0.5414 cluster_loss: 1.3634 sup_con_loss: 0.2964 contrastive_loss: 5.2739 nll_loss: 0.0026 
2023-10-27 08:30:56.102 | INFO     | __main__:train:314 - Epoch: [35][1000/1251]	 loss 4.72659	 cls_loss: 0.6807 cluster_loss: 1.3182 sup_con_loss: 0.5853 contrastive_loss: 5.2690 nll_loss: 0.0018 
2023-10-27 08:34:40.630 | INFO     | __main__:train:314 - Epoch: [35][1100/1251]	 loss 4.64672	 cls_loss: 0.5952 cluster_loss: 1.3266 sup_con_loss: 0.4308 contrastive_loss: 5.2674 nll_loss: 0.0015 
2023-10-27 08:38:26.233 | INFO     | __main__:train:314 - Epoch: [35][1200/1251]	 loss 4.56503	 cls_loss: 0.4798 cluster_loss: 1.3088 sup_con_loss: 0.3285 contrastive_loss: 5.2703 nll_loss: 0.0057 
2023-10-27 08:40:17.393 | INFO     | __main__:train:319 - Train Epoch: 35 Avg Loss: 4.6628 
2023-10-27 08:40:17.402 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 09:01:02.597 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 35, Train ACC Unlabelled_v2: All 0.5961 | Old 0.7740 | New 0.5067
2023-10-27 09:01:02.934 | INFO     | __main__:main:205 - Train Accuracies: All 0.5961 | Old 0.7740 | New 0.5067
2023-10-27 09:01:06.118 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 09:01:22.359 | INFO     | __main__:train:314 - Epoch: [36][0/1251]	 loss 4.77272	 cls_loss: 0.5559 cluster_loss: 1.4149 sup_con_loss: 0.6596 contrastive_loss: 5.2716 nll_loss: 0.0011 
2023-10-27 09:05:05.318 | INFO     | __main__:train:314 - Epoch: [36][100/1251]	 loss 4.62143	 cls_loss: 0.4846 cluster_loss: 1.3376 sup_con_loss: 0.4391 contrastive_loss: 5.2720 nll_loss: 0.0019 
2023-10-27 09:08:48.435 | INFO     | __main__:train:314 - Epoch: [36][200/1251]	 loss 4.68108	 cls_loss: 0.5492 cluster_loss: 1.4235 sup_con_loss: 0.3692 contrastive_loss: 5.2798 nll_loss: 0.0026 
2023-10-27 09:12:30.524 | INFO     | __main__:train:314 - Epoch: [36][300/1251]	 loss 4.67358	 cls_loss: 0.5829 cluster_loss: 1.3824 sup_con_loss: 0.3996 contrastive_loss: 5.2750 nll_loss: 0.0024 
2023-10-27 09:16:12.832 | INFO     | __main__:train:314 - Epoch: [36][400/1251]	 loss 4.63715	 cls_loss: 0.5245 cluster_loss: 1.3668 sup_con_loss: 0.3949 contrastive_loss: 5.2699 nll_loss: 0.0015 
2023-10-27 09:19:57.674 | INFO     | __main__:train:314 - Epoch: [36][500/1251]	 loss 4.67961	 cls_loss: 0.5057 cluster_loss: 1.3711 sup_con_loss: 0.5209 contrastive_loss: 5.2724 nll_loss: 0.0021 
2023-10-27 09:23:40.454 | INFO     | __main__:train:314 - Epoch: [36][600/1251]	 loss 4.73044	 cls_loss: 0.6062 cluster_loss: 1.3870 sup_con_loss: 0.5325 contrastive_loss: 5.2744 nll_loss: 0.0020 
2023-10-27 09:27:23.172 | INFO     | __main__:train:314 - Epoch: [36][700/1251]	 loss 4.62307	 cls_loss: 0.5476 cluster_loss: 1.3486 sup_con_loss: 0.3614 contrastive_loss: 5.2716 nll_loss: 0.0018 
2023-10-27 09:31:08.433 | INFO     | __main__:train:314 - Epoch: [36][800/1251]	 loss 4.69072	 cls_loss: 0.5896 cluster_loss: 1.3336 sup_con_loss: 0.5478 contrastive_loss: 5.2678 nll_loss: 0.0017 
2023-10-27 09:34:52.089 | INFO     | __main__:train:314 - Epoch: [36][900/1251]	 loss 4.78293	 cls_loss: 0.6725 cluster_loss: 1.4527 sup_con_loss: 0.4883 contrastive_loss: 5.2767 nll_loss: 0.0026 
2023-10-27 09:38:34.423 | INFO     | __main__:train:314 - Epoch: [36][1000/1251]	 loss 4.74173	 cls_loss: 0.5618 cluster_loss: 1.3724 sup_con_loss: 0.6460 contrastive_loss: 5.2702 nll_loss: 0.0013 
2023-10-27 09:42:19.004 | INFO     | __main__:train:314 - Epoch: [36][1100/1251]	 loss 4.66617	 cls_loss: 0.5918 cluster_loss: 1.3554 sup_con_loss: 0.4313 contrastive_loss: 5.2675 nll_loss: 0.0032 
2023-10-27 09:46:01.515 | INFO     | __main__:train:314 - Epoch: [36][1200/1251]	 loss 4.66746	 cls_loss: 0.5410 cluster_loss: 1.3840 sup_con_loss: 0.4216 contrastive_loss: 5.2739 nll_loss: 0.0029 
2023-10-27 09:47:52.648 | INFO     | __main__:train:319 - Train Epoch: 36 Avg Loss: 4.6665 
2023-10-27 09:47:52.652 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 10:08:01.626 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 36, Train ACC Unlabelled_v2: All 0.5964 | Old 0.7746 | New 0.5069
2023-10-27 10:08:01.912 | INFO     | __main__:main:205 - Train Accuracies: All 0.5964 | Old 0.7746 | New 0.5069
2023-10-27 10:08:05.939 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 10:08:21.730 | INFO     | __main__:train:314 - Epoch: [37][0/1251]	 loss 4.60522	 cls_loss: 0.6568 cluster_loss: 1.3023 sup_con_loss: 0.2971 contrastive_loss: 5.2665 nll_loss: 0.0016 
2023-10-27 10:12:11.382 | INFO     | __main__:train:314 - Epoch: [37][100/1251]	 loss 4.57776	 cls_loss: 0.5483 cluster_loss: 1.3417 sup_con_loss: 0.2477 contrastive_loss: 5.2692 nll_loss: 0.0021 
2023-10-27 10:15:56.295 | INFO     | __main__:train:314 - Epoch: [37][200/1251]	 loss 4.56382	 cls_loss: 0.4557 cluster_loss: 1.3013 sup_con_loss: 0.3808 contrastive_loss: 5.2679 nll_loss: 0.0010 
2023-10-27 10:19:41.436 | INFO     | __main__:train:314 - Epoch: [37][300/1251]	 loss 4.68854	 cls_loss: 0.5360 cluster_loss: 1.3775 sup_con_loss: 0.5128 contrastive_loss: 5.2687 nll_loss: 0.0014 
2023-10-27 10:23:25.090 | INFO     | __main__:train:314 - Epoch: [37][400/1251]	 loss 4.55915	 cls_loss: 0.5143 cluster_loss: 1.2633 sup_con_loss: 0.3817 contrastive_loss: 5.2651 nll_loss: 0.0021 
2023-10-27 10:27:10.604 | INFO     | __main__:train:314 - Epoch: [37][500/1251]	 loss 4.70547	 cls_loss: 0.6568 cluster_loss: 1.3721 sup_con_loss: 0.4359 contrastive_loss: 5.2751 nll_loss: 0.0023 
2023-10-27 10:30:55.118 | INFO     | __main__:train:314 - Epoch: [37][600/1251]	 loss 4.72141	 cls_loss: 0.6157 cluster_loss: 1.3360 sup_con_loss: 0.6010 contrastive_loss: 5.2688 nll_loss: 0.0024 
2023-10-27 10:34:43.245 | INFO     | __main__:train:314 - Epoch: [37][700/1251]	 loss 4.67359	 cls_loss: 0.6436 cluster_loss: 1.3024 sup_con_loss: 0.5059 contrastive_loss: 5.2663 nll_loss: 0.0016 
2023-10-27 10:38:26.886 | INFO     | __main__:train:314 - Epoch: [37][800/1251]	 loss 4.74635	 cls_loss: 0.6964 cluster_loss: 1.3927 sup_con_loss: 0.4741 contrastive_loss: 5.2769 nll_loss: 0.0014 
2023-10-27 10:42:09.766 | INFO     | __main__:train:314 - Epoch: [37][900/1251]	 loss 4.60259	 cls_loss: 0.5516 cluster_loss: 1.3391 sup_con_loss: 0.3082 contrastive_loss: 5.2739 nll_loss: 0.0032 
2023-10-27 10:45:53.602 | INFO     | __main__:train:314 - Epoch: [37][1000/1251]	 loss 4.69107	 cls_loss: 0.5743 cluster_loss: 1.4062 sup_con_loss: 0.4189 contrastive_loss: 5.2725 nll_loss: 0.0023 
2023-10-27 10:49:37.669 | INFO     | __main__:train:314 - Epoch: [37][1100/1251]	 loss 4.74474	 cls_loss: 0.5244 cluster_loss: 1.4287 sup_con_loss: 0.5737 contrastive_loss: 5.2754 nll_loss: 0.0027 
2023-10-27 10:53:20.590 | INFO     | __main__:train:314 - Epoch: [37][1200/1251]	 loss 4.68778	 cls_loss: 0.6223 cluster_loss: 1.3477 sup_con_loss: 0.4793 contrastive_loss: 5.2684 nll_loss: 0.0018 
2023-10-27 10:55:12.103 | INFO     | __main__:train:319 - Train Epoch: 37 Avg Loss: 4.6631 
2023-10-27 10:55:12.110 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 11:16:01.665 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 37, Train ACC Unlabelled_v2: All 0.5957 | Old 0.7770 | New 0.5046
2023-10-27 11:16:02.074 | INFO     | __main__:main:205 - Train Accuracies: All 0.5957 | Old 0.7770 | New 0.5046
2023-10-27 11:16:05.220 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 11:16:20.431 | INFO     | __main__:train:314 - Epoch: [38][0/1251]	 loss 4.61510	 cls_loss: 0.5447 cluster_loss: 1.3793 sup_con_loss: 0.2684 contrastive_loss: 5.2781 nll_loss: 0.0033 
2023-10-27 11:20:09.314 | INFO     | __main__:train:314 - Epoch: [38][100/1251]	 loss 4.70984	 cls_loss: 0.6013 cluster_loss: 1.3604 sup_con_loss: 0.5314 contrastive_loss: 5.2725 nll_loss: 0.0020 
2023-10-27 11:23:52.996 | INFO     | __main__:train:314 - Epoch: [38][200/1251]	 loss 4.61131	 cls_loss: 0.5882 cluster_loss: 1.3103 sup_con_loss: 0.3633 contrastive_loss: 5.2686 nll_loss: 0.0020 
2023-10-27 11:27:36.149 | INFO     | __main__:train:314 - Epoch: [38][300/1251]	 loss 4.65919	 cls_loss: 0.5723 cluster_loss: 1.3440 sup_con_loss: 0.4565 contrastive_loss: 5.2674 nll_loss: 0.0017 
2023-10-27 11:31:20.770 | INFO     | __main__:train:314 - Epoch: [38][400/1251]	 loss 4.71862	 cls_loss: 0.5200 cluster_loss: 1.3885 sup_con_loss: 0.5812 contrastive_loss: 5.2740 nll_loss: 0.0026 
2023-10-27 11:35:03.518 | INFO     | __main__:train:314 - Epoch: [38][500/1251]	 loss 4.73566	 cls_loss: 0.6011 cluster_loss: 1.4532 sup_con_loss: 0.4196 contrastive_loss: 5.2796 nll_loss: 0.0020 
2023-10-27 11:38:47.987 | INFO     | __main__:train:314 - Epoch: [38][600/1251]	 loss 4.64650	 cls_loss: 0.4763 cluster_loss: 1.3671 sup_con_loss: 0.4665 contrastive_loss: 5.2701 nll_loss: 0.0024 
2023-10-27 11:42:32.905 | INFO     | __main__:train:314 - Epoch: [38][700/1251]	 loss 4.76147	 cls_loss: 0.5839 cluster_loss: 1.3981 sup_con_loss: 0.6249 contrastive_loss: 5.2743 nll_loss: 0.0013 
2023-10-27 11:46:16.656 | INFO     | __main__:train:314 - Epoch: [38][800/1251]	 loss 4.66691	 cls_loss: 0.5654 cluster_loss: 1.3428 sup_con_loss: 0.4785 contrastive_loss: 5.2699 nll_loss: 0.0033 
2023-10-27 11:50:00.591 | INFO     | __main__:train:314 - Epoch: [38][900/1251]	 loss 4.68837	 cls_loss: 0.6195 cluster_loss: 1.3402 sup_con_loss: 0.5050 contrastive_loss: 5.2648 nll_loss: 0.0016 
2023-10-27 11:53:43.930 | INFO     | __main__:train:314 - Epoch: [38][1000/1251]	 loss 4.60468	 cls_loss: 0.5340 cluster_loss: 1.3189 sup_con_loss: 0.3825 contrastive_loss: 5.2660 nll_loss: 0.0037 
2023-10-27 11:57:25.753 | INFO     | __main__:train:314 - Epoch: [38][1100/1251]	 loss 4.69163	 cls_loss: 0.5780 cluster_loss: 1.3794 sup_con_loss: 0.4693 contrastive_loss: 5.2713 nll_loss: 0.0021 
2023-10-27 12:01:09.527 | INFO     | __main__:train:314 - Epoch: [38][1200/1251]	 loss 4.54619	 cls_loss: 0.5635 cluster_loss: 1.2767 sup_con_loss: 0.2700 contrastive_loss: 5.2653 nll_loss: 0.0022 
2023-10-27 12:03:04.261 | INFO     | __main__:train:319 - Train Epoch: 38 Avg Loss: 4.6604 
2023-10-27 12:03:04.265 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 12:22:11.389 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 38, Train ACC Unlabelled_v2: All 0.5967 | Old 0.7732 | New 0.5080
2023-10-27 12:22:11.616 | INFO     | __main__:main:205 - Train Accuracies: All 0.5967 | Old 0.7732 | New 0.5080
2023-10-27 12:22:17.133 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 12:22:34.499 | INFO     | __main__:train:314 - Epoch: [39][0/1251]	 loss 4.76913	 cls_loss: 0.6227 cluster_loss: 1.4256 sup_con_loss: 0.5557 contrastive_loss: 5.2741 nll_loss: 0.0019 
2023-10-27 12:26:17.838 | INFO     | __main__:train:314 - Epoch: [39][100/1251]	 loss 4.68039	 cls_loss: 0.6080 cluster_loss: 1.3278 sup_con_loss: 0.4949 contrastive_loss: 5.2752 nll_loss: 0.0025 
2023-10-27 12:30:05.469 | INFO     | __main__:train:314 - Epoch: [39][200/1251]	 loss 4.71373	 cls_loss: 0.6519 cluster_loss: 1.3330 sup_con_loss: 0.5428 contrastive_loss: 5.2710 nll_loss: 0.0030 
2023-10-27 12:33:52.368 | INFO     | __main__:train:314 - Epoch: [39][300/1251]	 loss 4.65371	 cls_loss: 0.6105 cluster_loss: 1.2796 sup_con_loss: 0.5265 contrastive_loss: 5.2647 nll_loss: 0.0020 
2023-10-27 12:37:37.049 | INFO     | __main__:train:314 - Epoch: [39][400/1251]	 loss 4.70803	 cls_loss: 0.6058 cluster_loss: 1.4037 sup_con_loss: 0.4457 contrastive_loss: 5.2714 nll_loss: 0.0012 
2023-10-27 12:41:24.164 | INFO     | __main__:train:314 - Epoch: [39][500/1251]	 loss 4.67502	 cls_loss: 0.5642 cluster_loss: 1.3599 sup_con_loss: 0.4797 contrastive_loss: 5.2681 nll_loss: 0.0014 
2023-10-27 12:45:07.505 | INFO     | __main__:train:314 - Epoch: [39][600/1251]	 loss 4.66968	 cls_loss: 0.5305 cluster_loss: 1.3423 sup_con_loss: 0.5225 contrastive_loss: 5.2694 nll_loss: 0.0035 
2023-10-27 12:48:53.138 | INFO     | __main__:train:314 - Epoch: [39][700/1251]	 loss 4.81392	 cls_loss: 0.5756 cluster_loss: 1.4443 sup_con_loss: 0.7004 contrastive_loss: 5.2712 nll_loss: 0.0023 
2023-10-27 12:52:37.177 | INFO     | __main__:train:314 - Epoch: [39][800/1251]	 loss 4.68919	 cls_loss: 0.5903 cluster_loss: 1.4251 sup_con_loss: 0.3561 contrastive_loss: 5.2757 nll_loss: 0.0024 
2023-10-27 12:56:20.644 | INFO     | __main__:train:314 - Epoch: [39][900/1251]	 loss 4.66206	 cls_loss: 0.4979 cluster_loss: 1.4010 sup_con_loss: 0.4278 contrastive_loss: 5.2702 nll_loss: 0.0017 
2023-10-27 13:00:05.578 | INFO     | __main__:train:314 - Epoch: [39][1000/1251]	 loss 4.83563	 cls_loss: 0.6403 cluster_loss: 1.4029 sup_con_loss: 0.7585 contrastive_loss: 5.2787 nll_loss: 0.0030 
2023-10-27 13:03:50.425 | INFO     | __main__:train:314 - Epoch: [39][1100/1251]	 loss 4.68680	 cls_loss: 0.6271 cluster_loss: 1.3661 sup_con_loss: 0.4341 contrastive_loss: 5.2695 nll_loss: 0.0022 
2023-10-27 13:07:34.855 | INFO     | __main__:train:314 - Epoch: [39][1200/1251]	 loss 4.58868	 cls_loss: 0.5673 cluster_loss: 1.3056 sup_con_loss: 0.3308 contrastive_loss: 5.2676 nll_loss: 0.0017 
2023-10-27 13:09:26.749 | INFO     | __main__:train:319 - Train Epoch: 39 Avg Loss: 4.6632 
2023-10-27 13:09:26.769 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 13:29:15.615 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 39, Train ACC Unlabelled_v2: All 0.5942 | Old 0.7790 | New 0.5013
2023-10-27 13:29:15.852 | INFO     | __main__:main:205 - Train Accuracies: All 0.5942 | Old 0.7790 | New 0.5013
2023-10-27 13:29:20.538 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 13:29:36.733 | INFO     | __main__:train:314 - Epoch: [40][0/1251]	 loss 4.73294	 cls_loss: 0.6306 cluster_loss: 1.3770 sup_con_loss: 0.5367 contrastive_loss: 5.2735 nll_loss: 0.0016 
2023-10-27 13:33:21.091 | INFO     | __main__:train:314 - Epoch: [40][100/1251]	 loss 4.68918	 cls_loss: 0.5315 cluster_loss: 1.4549 sup_con_loss: 0.3660 contrastive_loss: 5.2721 nll_loss: 0.0025 
2023-10-27 13:37:07.481 | INFO     | __main__:train:314 - Epoch: [40][200/1251]	 loss 4.54300	 cls_loss: 0.5567 cluster_loss: 1.2741 sup_con_loss: 0.2687 contrastive_loss: 5.2664 nll_loss: 0.0028 
2023-10-27 13:40:51.622 | INFO     | __main__:train:314 - Epoch: [40][300/1251]	 loss 4.74498	 cls_loss: 0.5602 cluster_loss: 1.4294 sup_con_loss: 0.5384 contrastive_loss: 5.2753 nll_loss: 0.0024 
2023-10-27 13:44:34.699 | INFO     | __main__:train:314 - Epoch: [40][400/1251]	 loss 4.73429	 cls_loss: 0.5919 cluster_loss: 1.3716 sup_con_loss: 0.5851 contrastive_loss: 5.2751 nll_loss: 0.0020 
2023-10-27 13:48:18.310 | INFO     | __main__:train:314 - Epoch: [40][500/1251]	 loss 4.57798	 cls_loss: 0.4957 cluster_loss: 1.3068 sup_con_loss: 0.3706 contrastive_loss: 5.2675 nll_loss: 0.0015 
2023-10-27 13:52:03.697 | INFO     | __main__:train:314 - Epoch: [40][600/1251]	 loss 4.60724	 cls_loss: 0.4750 cluster_loss: 1.3766 sup_con_loss: 0.3316 contrastive_loss: 5.2736 nll_loss: 0.0023 
2023-10-27 13:56:09.380 | INFO     | __main__:train:314 - Epoch: [40][700/1251]	 loss 4.63534	 cls_loss: 0.4802 cluster_loss: 1.3635 sup_con_loss: 0.4204 contrastive_loss: 5.2781 nll_loss: 0.0031 
2023-10-27 14:00:54.267 | INFO     | __main__:train:314 - Epoch: [40][800/1251]	 loss 4.60652	 cls_loss: 0.4684 cluster_loss: 1.3222 sup_con_loss: 0.4516 contrastive_loss: 5.2660 nll_loss: 0.0022 
2023-10-27 14:04:52.940 | INFO     | __main__:train:314 - Epoch: [40][900/1251]	 loss 4.64549	 cls_loss: 0.5591 cluster_loss: 1.3484 sup_con_loss: 0.4199 contrastive_loss: 5.2666 nll_loss: 0.0031 
2023-10-27 14:08:40.589 | INFO     | __main__:train:314 - Epoch: [40][1000/1251]	 loss 4.68787	 cls_loss: 0.5580 cluster_loss: 1.3801 sup_con_loss: 0.4678 contrastive_loss: 5.2765 nll_loss: 0.0020 
2023-10-27 14:12:26.407 | INFO     | __main__:train:314 - Epoch: [40][1100/1251]	 loss 4.67086	 cls_loss: 0.7296 cluster_loss: 1.3726 sup_con_loss: 0.2701 contrastive_loss: 5.2722 nll_loss: 0.0019 
2023-10-27 14:16:10.545 | INFO     | __main__:train:314 - Epoch: [40][1200/1251]	 loss 4.57940	 cls_loss: 0.5291 cluster_loss: 1.3546 sup_con_loss: 0.2398 contrastive_loss: 5.2715 nll_loss: 0.0033 
2023-10-27 14:18:02.584 | INFO     | __main__:train:319 - Train Epoch: 40 Avg Loss: 4.6562 
2023-10-27 14:18:02.610 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 14:38:45.457 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 40, Train ACC Unlabelled_v2: All 0.5945 | Old 0.7746 | New 0.5040
2023-10-27 14:38:45.699 | INFO     | __main__:main:205 - Train Accuracies: All 0.5945 | Old 0.7746 | New 0.5040
2023-10-27 14:38:49.121 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 14:39:05.663 | INFO     | __main__:train:314 - Epoch: [41][0/1251]	 loss 4.70272	 cls_loss: 0.5438 cluster_loss: 1.3809 sup_con_loss: 0.5391 contrastive_loss: 5.2668 nll_loss: 0.0027 
2023-10-27 14:42:50.925 | INFO     | __main__:train:314 - Epoch: [41][100/1251]	 loss 4.48142	 cls_loss: 0.4125 cluster_loss: 1.2678 sup_con_loss: 0.2496 contrastive_loss: 5.2656 nll_loss: 0.0030 
2023-10-27 14:46:37.986 | INFO     | __main__:train:314 - Epoch: [41][200/1251]	 loss 4.72589	 cls_loss: 0.5790 cluster_loss: 1.4162 sup_con_loss: 0.5033 contrastive_loss: 5.2683 nll_loss: 0.0022 
2023-10-27 14:50:26.250 | INFO     | __main__:train:314 - Epoch: [41][300/1251]	 loss 4.67882	 cls_loss: 0.5427 cluster_loss: 1.3778 sup_con_loss: 0.4676 contrastive_loss: 5.2719 nll_loss: 0.0029 
2023-10-27 14:54:11.138 | INFO     | __main__:train:314 - Epoch: [41][400/1251]	 loss 4.60639	 cls_loss: 0.5377 cluster_loss: 1.3627 sup_con_loss: 0.2897 contrastive_loss: 5.2740 nll_loss: 0.0030 
2023-10-27 14:57:56.820 | INFO     | __main__:train:314 - Epoch: [41][500/1251]	 loss 4.75210	 cls_loss: 0.6234 cluster_loss: 1.3292 sup_con_loss: 0.7029 contrastive_loss: 5.2644 nll_loss: 0.0021 
2023-10-27 15:01:40.260 | INFO     | __main__:train:314 - Epoch: [41][600/1251]	 loss 4.67209	 cls_loss: 0.6825 cluster_loss: 1.3500 sup_con_loss: 0.3607 contrastive_loss: 5.2729 nll_loss: 0.0021 
2023-10-27 15:05:26.276 | INFO     | __main__:train:314 - Epoch: [41][700/1251]	 loss 4.59928	 cls_loss: 0.5992 cluster_loss: 1.2763 sup_con_loss: 0.3848 contrastive_loss: 5.2660 nll_loss: 0.0024 
2023-10-27 15:09:15.692 | INFO     | __main__:train:314 - Epoch: [41][800/1251]	 loss 4.59667	 cls_loss: 0.5503 cluster_loss: 1.3325 sup_con_loss: 0.3140 contrastive_loss: 5.2700 nll_loss: 0.0026 
2023-10-27 15:13:06.316 | INFO     | __main__:train:314 - Epoch: [41][900/1251]	 loss 4.78777	 cls_loss: 0.6062 cluster_loss: 1.4560 sup_con_loss: 0.5604 contrastive_loss: 5.2786 nll_loss: 0.0020 
2023-10-27 15:17:00.089 | INFO     | __main__:train:314 - Epoch: [41][1000/1251]	 loss 4.58584	 cls_loss: 0.4615 cluster_loss: 1.3552 sup_con_loss: 0.3252 contrastive_loss: 5.2741 nll_loss: 0.0014 
2023-10-27 15:20:47.749 | INFO     | __main__:train:314 - Epoch: [41][1100/1251]	 loss 4.78699	 cls_loss: 0.7164 cluster_loss: 1.3581 sup_con_loss: 0.6450 contrastive_loss: 5.2705 nll_loss: 0.0019 
2023-10-27 15:24:35.979 | INFO     | __main__:train:314 - Epoch: [41][1200/1251]	 loss 4.69228	 cls_loss: 0.5441 cluster_loss: 1.3721 sup_con_loss: 0.5192 contrastive_loss: 5.2712 nll_loss: 0.0020 
2023-10-27 15:26:26.823 | INFO     | __main__:train:319 - Train Epoch: 41 Avg Loss: 4.6559 
2023-10-27 15:26:26.849 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 15:48:17.234 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 41, Train ACC Unlabelled_v2: All 0.5965 | Old 0.7762 | New 0.5062
2023-10-27 15:48:17.487 | INFO     | __main__:main:205 - Train Accuracies: All 0.5965 | Old 0.7762 | New 0.5062
2023-10-27 15:48:20.758 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 15:48:38.806 | INFO     | __main__:train:314 - Epoch: [42][0/1251]	 loss 4.67488	 cls_loss: 0.4488 cluster_loss: 1.3827 sup_con_loss: 0.5445 contrastive_loss: 5.2716 nll_loss: 0.0020 
2023-10-27 15:52:26.419 | INFO     | __main__:train:314 - Epoch: [42][100/1251]	 loss 4.69379	 cls_loss: 0.6358 cluster_loss: 1.3732 sup_con_loss: 0.4320 contrastive_loss: 5.2704 nll_loss: 0.0017 
2023-10-27 15:56:16.147 | INFO     | __main__:train:314 - Epoch: [42][200/1251]	 loss 4.63396	 cls_loss: 0.5372 cluster_loss: 1.3336 sup_con_loss: 0.4309 contrastive_loss: 5.2704 nll_loss: 0.0025 
2023-10-27 16:00:01.568 | INFO     | __main__:train:314 - Epoch: [42][300/1251]	 loss 4.68044	 cls_loss: 0.5462 cluster_loss: 1.4191 sup_con_loss: 0.3840 contrastive_loss: 5.2778 nll_loss: 0.0019 
2023-10-27 16:03:44.354 | INFO     | __main__:train:314 - Epoch: [42][400/1251]	 loss 4.66923	 cls_loss: 0.5500 cluster_loss: 1.3709 sup_con_loss: 0.4435 contrastive_loss: 5.2742 nll_loss: 0.0022 
2023-10-27 16:07:27.351 | INFO     | __main__:train:314 - Epoch: [42][500/1251]	 loss 4.63803	 cls_loss: 0.6221 cluster_loss: 1.2857 sup_con_loss: 0.4610 contrastive_loss: 5.2637 nll_loss: 0.0019 
2023-10-27 16:11:14.085 | INFO     | __main__:train:314 - Epoch: [42][600/1251]	 loss 4.70088	 cls_loss: 0.6046 cluster_loss: 1.4017 sup_con_loss: 0.4162 contrastive_loss: 5.2768 nll_loss: 0.0025 
2023-10-27 16:14:58.418 | INFO     | __main__:train:314 - Epoch: [42][700/1251]	 loss 4.53585	 cls_loss: 0.4098 cluster_loss: 1.3325 sup_con_loss: 0.2808 contrastive_loss: 5.2714 nll_loss: 0.0016 
2023-10-27 16:18:42.946 | INFO     | __main__:train:314 - Epoch: [42][800/1251]	 loss 4.66832	 cls_loss: 0.5412 cluster_loss: 1.3202 sup_con_loss: 0.5550 contrastive_loss: 5.2675 nll_loss: 0.0026 
2023-10-27 16:22:28.525 | INFO     | __main__:train:314 - Epoch: [42][900/1251]	 loss 4.67889	 cls_loss: 0.6593 cluster_loss: 1.3752 sup_con_loss: 0.3524 contrastive_loss: 5.2742 nll_loss: 0.0027 
2023-10-27 16:26:12.926 | INFO     | __main__:train:314 - Epoch: [42][1000/1251]	 loss 4.70360	 cls_loss: 0.4963 cluster_loss: 1.4115 sup_con_loss: 0.5235 contrastive_loss: 5.2719 nll_loss: 0.0025 
2023-10-27 16:29:59.408 | INFO     | __main__:train:314 - Epoch: [42][1100/1251]	 loss 4.59824	 cls_loss: 0.4909 cluster_loss: 1.3566 sup_con_loss: 0.3262 contrastive_loss: 5.2732 nll_loss: 0.0029 
2023-10-27 16:33:44.774 | INFO     | __main__:train:314 - Epoch: [42][1200/1251]	 loss 4.57215	 cls_loss: 0.4550 cluster_loss: 1.2861 sup_con_loss: 0.4361 contrastive_loss: 5.2651 nll_loss: 0.0020 
2023-10-27 16:35:36.556 | INFO     | __main__:train:319 - Train Epoch: 42 Avg Loss: 4.6572 
2023-10-27 16:35:36.565 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 16:56:45.286 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 42, Train ACC Unlabelled_v2: All 0.5967 | Old 0.7760 | New 0.5066
2023-10-27 16:56:45.510 | INFO     | __main__:main:205 - Train Accuracies: All 0.5967 | Old 0.7760 | New 0.5066
2023-10-27 16:56:49.493 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 16:57:04.081 | INFO     | __main__:train:314 - Epoch: [43][0/1251]	 loss 4.66410	 cls_loss: 0.5256 cluster_loss: 1.3966 sup_con_loss: 0.4110 contrastive_loss: 5.2692 nll_loss: 0.0035 
2023-10-27 17:00:50.497 | INFO     | __main__:train:314 - Epoch: [43][100/1251]	 loss 4.55655	 cls_loss: 0.4429 cluster_loss: 1.3185 sup_con_loss: 0.3304 contrastive_loss: 5.2705 nll_loss: 0.0030 
2023-10-27 17:04:33.769 | INFO     | __main__:train:314 - Epoch: [43][200/1251]	 loss 4.53635	 cls_loss: 0.4442 cluster_loss: 1.2824 sup_con_loss: 0.3472 contrastive_loss: 5.2678 nll_loss: 0.0018 
2023-10-27 17:08:16.493 | INFO     | __main__:train:314 - Epoch: [43][300/1251]	 loss 4.57870	 cls_loss: 0.4076 cluster_loss: 1.3228 sup_con_loss: 0.4222 contrastive_loss: 5.2715 nll_loss: 0.0020 
2023-10-27 17:12:02.555 | INFO     | __main__:train:314 - Epoch: [43][400/1251]	 loss 4.59889	 cls_loss: 0.4379 cluster_loss: 1.3751 sup_con_loss: 0.3519 contrastive_loss: 5.2714 nll_loss: 0.0022 
2023-10-27 17:15:47.042 | INFO     | __main__:train:314 - Epoch: [43][500/1251]	 loss 4.65829	 cls_loss: 0.5805 cluster_loss: 1.3927 sup_con_loss: 0.3495 contrastive_loss: 5.2707 nll_loss: 0.0016 
2023-10-27 17:19:34.830 | INFO     | __main__:train:314 - Epoch: [43][600/1251]	 loss 4.54831	 cls_loss: 0.4415 cluster_loss: 1.3347 sup_con_loss: 0.2863 contrastive_loss: 5.2661 nll_loss: 0.0031 
2023-10-27 17:23:20.990 | INFO     | __main__:train:314 - Epoch: [43][700/1251]	 loss 4.63299	 cls_loss: 0.4586 cluster_loss: 1.4062 sup_con_loss: 0.3741 contrastive_loss: 5.2710 nll_loss: 0.0014 
2023-10-27 17:27:07.522 | INFO     | __main__:train:314 - Epoch: [43][800/1251]	 loss 4.57242	 cls_loss: 0.5878 cluster_loss: 1.3049 sup_con_loss: 0.2611 contrastive_loss: 5.2668 nll_loss: 0.0037 
2023-10-27 17:30:52.887 | INFO     | __main__:train:314 - Epoch: [43][900/1251]	 loss 4.64503	 cls_loss: 0.5866 cluster_loss: 1.2887 sup_con_loss: 0.5080 contrastive_loss: 5.2650 nll_loss: 0.0020 
2023-10-27 17:34:39.573 | INFO     | __main__:train:314 - Epoch: [43][1000/1251]	 loss 4.60385	 cls_loss: 0.5334 cluster_loss: 1.3525 sup_con_loss: 0.3167 contrastive_loss: 5.2674 nll_loss: 0.0034 
2023-10-27 17:38:24.518 | INFO     | __main__:train:314 - Epoch: [43][1100/1251]	 loss 4.59794	 cls_loss: 0.4780 cluster_loss: 1.3293 sup_con_loss: 0.4027 contrastive_loss: 5.2680 nll_loss: 0.0015 
2023-10-27 17:42:08.642 | INFO     | __main__:train:314 - Epoch: [43][1200/1251]	 loss 4.78341	 cls_loss: 0.6005 cluster_loss: 1.3909 sup_con_loss: 0.6866 contrastive_loss: 5.2719 nll_loss: 0.0021 
2023-10-27 17:44:02.285 | INFO     | __main__:train:319 - Train Epoch: 43 Avg Loss: 4.6562 
2023-10-27 17:44:02.292 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 18:05:56.642 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 43, Train ACC Unlabelled_v2: All 0.5953 | Old 0.7734 | New 0.5057
2023-10-27 18:05:56.934 | INFO     | __main__:main:205 - Train Accuracies: All 0.5953 | Old 0.7734 | New 0.5057
2023-10-27 18:06:00.286 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 18:06:14.433 | INFO     | __main__:train:314 - Epoch: [44][0/1251]	 loss 4.73472	 cls_loss: 0.6351 cluster_loss: 1.3818 sup_con_loss: 0.5231 contrastive_loss: 5.2764 nll_loss: 0.0015 
2023-10-27 18:09:58.548 | INFO     | __main__:train:314 - Epoch: [44][100/1251]	 loss 4.77153	 cls_loss: 0.6179 cluster_loss: 1.4422 sup_con_loss: 0.5315 contrastive_loss: 5.2748 nll_loss: 0.0032 
2023-10-27 18:13:46.108 | INFO     | __main__:train:314 - Epoch: [44][200/1251]	 loss 4.66846	 cls_loss: 0.6485 cluster_loss: 1.3007 sup_con_loss: 0.4922 contrastive_loss: 5.2652 nll_loss: 0.0013 
2023-10-27 18:17:31.225 | INFO     | __main__:train:314 - Epoch: [44][300/1251]	 loss 4.78890	 cls_loss: 0.6308 cluster_loss: 1.4206 sup_con_loss: 0.6067 contrastive_loss: 5.2791 nll_loss: 0.0010 
2023-10-27 18:21:17.050 | INFO     | __main__:train:314 - Epoch: [44][400/1251]	 loss 4.69575	 cls_loss: 0.6401 cluster_loss: 1.3472 sup_con_loss: 0.4793 contrastive_loss: 5.2726 nll_loss: 0.0011 
2023-10-27 18:25:03.996 | INFO     | __main__:train:314 - Epoch: [44][500/1251]	 loss 4.65598	 cls_loss: 0.4833 cluster_loss: 1.3700 sup_con_loss: 0.4855 contrastive_loss: 5.2687 nll_loss: 0.0018 
2023-10-27 18:28:48.005 | INFO     | __main__:train:314 - Epoch: [44][600/1251]	 loss 4.67837	 cls_loss: 0.4555 cluster_loss: 1.3969 sup_con_loss: 0.5185 contrastive_loss: 5.2728 nll_loss: 0.0022 
2023-10-27 18:32:31.390 | INFO     | __main__:train:314 - Epoch: [44][700/1251]	 loss 4.81169	 cls_loss: 0.9037 cluster_loss: 1.3345 sup_con_loss: 0.5691 contrastive_loss: 5.2698 nll_loss: 0.0034 
2023-10-27 18:36:15.943 | INFO     | __main__:train:314 - Epoch: [44][800/1251]	 loss 4.64855	 cls_loss: 0.4447 cluster_loss: 1.3527 sup_con_loss: 0.5318 contrastive_loss: 5.2703 nll_loss: 0.0018 
2023-10-27 18:39:59.526 | INFO     | __main__:train:314 - Epoch: [44][900/1251]	 loss 4.64513	 cls_loss: 0.5479 cluster_loss: 1.3545 sup_con_loss: 0.4187 contrastive_loss: 5.2674 nll_loss: 0.0026 
2023-10-27 18:43:43.683 | INFO     | __main__:train:314 - Epoch: [44][1000/1251]	 loss 4.56939	 cls_loss: 0.4320 cluster_loss: 1.3313 sup_con_loss: 0.3634 contrastive_loss: 5.2681 nll_loss: 0.0014 
2023-10-27 18:47:27.814 | INFO     | __main__:train:314 - Epoch: [44][1100/1251]	 loss 4.65186	 cls_loss: 0.5638 cluster_loss: 1.3557 sup_con_loss: 0.4016 contrastive_loss: 5.2745 nll_loss: 0.0044 
2023-10-27 18:51:10.580 | INFO     | __main__:train:314 - Epoch: [44][1200/1251]	 loss 4.62579	 cls_loss: 0.5822 cluster_loss: 1.3611 sup_con_loss: 0.3132 contrastive_loss: 5.2700 nll_loss: 0.0022 
2023-10-27 18:53:03.749 | INFO     | __main__:train:319 - Train Epoch: 44 Avg Loss: 4.6556 
2023-10-27 18:53:03.757 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 19:12:01.126 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 44, Train ACC Unlabelled_v2: All 0.5960 | Old 0.7777 | New 0.5046
2023-10-27 19:12:01.351 | INFO     | __main__:main:205 - Train Accuracies: All 0.5960 | Old 0.7777 | New 0.5046
2023-10-27 19:12:04.485 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 19:12:19.635 | INFO     | __main__:train:314 - Epoch: [45][0/1251]	 loss 4.71014	 cls_loss: 0.6072 cluster_loss: 1.3140 sup_con_loss: 0.6173 contrastive_loss: 5.2684 nll_loss: 0.0030 
2023-10-27 19:16:08.500 | INFO     | __main__:train:314 - Epoch: [45][100/1251]	 loss 4.64437	 cls_loss: 0.4725 cluster_loss: 1.4254 sup_con_loss: 0.3446 contrastive_loss: 5.2747 nll_loss: 0.0033 
2023-10-27 19:19:53.423 | INFO     | __main__:train:314 - Epoch: [45][200/1251]	 loss 4.59935	 cls_loss: 0.4525 cluster_loss: 1.3528 sup_con_loss: 0.3888 contrastive_loss: 5.2670 nll_loss: 0.0020 
2023-10-27 19:23:38.277 | INFO     | __main__:train:314 - Epoch: [45][300/1251]	 loss 4.57237	 cls_loss: 0.4912 cluster_loss: 1.3332 sup_con_loss: 0.3002 contrastive_loss: 5.2709 nll_loss: 0.0028 
2023-10-27 19:27:22.080 | INFO     | __main__:train:314 - Epoch: [45][400/1251]	 loss 4.70346	 cls_loss: 0.6198 cluster_loss: 1.3724 sup_con_loss: 0.4751 contrastive_loss: 5.2711 nll_loss: 0.0020 
2023-10-27 19:31:04.804 | INFO     | __main__:train:314 - Epoch: [45][500/1251]	 loss 4.69856	 cls_loss: 0.5191 cluster_loss: 1.3463 sup_con_loss: 0.6182 contrastive_loss: 5.2673 nll_loss: 0.0017 
2023-10-27 19:34:48.709 | INFO     | __main__:train:314 - Epoch: [45][600/1251]	 loss 4.72343	 cls_loss: 0.5581 cluster_loss: 1.4129 sup_con_loss: 0.5030 contrastive_loss: 5.2777 nll_loss: 0.0032 
2023-10-27 19:38:32.629 | INFO     | __main__:train:314 - Epoch: [45][700/1251]	 loss 4.60000	 cls_loss: 0.5283 cluster_loss: 1.3241 sup_con_loss: 0.3612 contrastive_loss: 5.2708 nll_loss: 0.0020 
2023-10-27 19:42:16.892 | INFO     | __main__:train:314 - Epoch: [45][800/1251]	 loss 4.71848	 cls_loss: 0.6322 cluster_loss: 1.3654 sup_con_loss: 0.5166 contrastive_loss: 5.2717 nll_loss: 0.0023 
2023-10-27 19:46:00.674 | INFO     | __main__:train:314 - Epoch: [45][900/1251]	 loss 4.62185	 cls_loss: 0.5282 cluster_loss: 1.3418 sup_con_loss: 0.3945 contrastive_loss: 5.2702 nll_loss: 0.0011 
2023-10-27 19:49:44.882 | INFO     | __main__:train:314 - Epoch: [45][1000/1251]	 loss 4.61068	 cls_loss: 0.5954 cluster_loss: 1.3279 sup_con_loss: 0.3284 contrastive_loss: 5.2653 nll_loss: 0.0018 
2023-10-27 19:53:29.485 | INFO     | __main__:train:314 - Epoch: [45][1100/1251]	 loss 4.67687	 cls_loss: 0.5911 cluster_loss: 1.3686 sup_con_loss: 0.4264 contrastive_loss: 5.2757 nll_loss: 0.0019 
2023-10-27 19:57:15.815 | INFO     | __main__:train:314 - Epoch: [45][1200/1251]	 loss 4.67872	 cls_loss: 0.5669 cluster_loss: 1.3559 sup_con_loss: 0.4969 contrastive_loss: 5.2668 nll_loss: 0.0017 
2023-10-27 19:59:07.200 | INFO     | __main__:train:319 - Train Epoch: 45 Avg Loss: 4.6520 
2023-10-27 19:59:07.203 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 20:19:10.734 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 45, Train ACC Unlabelled_v2: All 0.5947 | Old 0.7719 | New 0.5056
2023-10-27 20:19:11.025 | INFO     | __main__:main:205 - Train Accuracies: All 0.5947 | Old 0.7719 | New 0.5056
2023-10-27 20:19:15.665 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 20:19:30.254 | INFO     | __main__:train:314 - Epoch: [46][0/1251]	 loss 4.64573	 cls_loss: 0.5771 cluster_loss: 1.3297 sup_con_loss: 0.4398 contrastive_loss: 5.2652 nll_loss: 0.0031 
2023-10-27 20:23:13.516 | INFO     | __main__:train:314 - Epoch: [46][100/1251]	 loss 4.71113	 cls_loss: 0.6237 cluster_loss: 1.3610 sup_con_loss: 0.5189 contrastive_loss: 5.2682 nll_loss: 0.0022 
2023-10-27 20:27:00.883 | INFO     | __main__:train:314 - Epoch: [46][200/1251]	 loss 4.64637	 cls_loss: 0.6113 cluster_loss: 1.3339 sup_con_loss: 0.3967 contrastive_loss: 5.2690 nll_loss: 0.0017 
2023-10-27 20:30:45.607 | INFO     | __main__:train:314 - Epoch: [46][300/1251]	 loss 4.68986	 cls_loss: 0.6736 cluster_loss: 1.3521 sup_con_loss: 0.4251 contrastive_loss: 5.2673 nll_loss: 0.0027 
2023-10-27 20:34:30.548 | INFO     | __main__:train:314 - Epoch: [46][400/1251]	 loss 4.62197	 cls_loss: 0.6425 cluster_loss: 1.3448 sup_con_loss: 0.2697 contrastive_loss: 5.2703 nll_loss: 0.0029 
2023-10-27 20:38:13.363 | INFO     | __main__:train:314 - Epoch: [46][500/1251]	 loss 4.68850	 cls_loss: 0.5462 cluster_loss: 1.3582 sup_con_loss: 0.5281 contrastive_loss: 5.2724 nll_loss: 0.0026 
2023-10-27 20:41:57.898 | INFO     | __main__:train:314 - Epoch: [46][600/1251]	 loss 4.64090	 cls_loss: 0.4996 cluster_loss: 1.3518 sup_con_loss: 0.4560 contrastive_loss: 5.2696 nll_loss: 0.0025 
2023-10-27 20:45:41.024 | INFO     | __main__:train:314 - Epoch: [46][700/1251]	 loss 4.62767	 cls_loss: 0.5122 cluster_loss: 1.3359 sup_con_loss: 0.4330 contrastive_loss: 5.2709 nll_loss: 0.0024 
2023-10-27 20:49:35.584 | INFO     | __main__:train:314 - Epoch: [46][800/1251]	 loss 4.60778	 cls_loss: 0.4644 cluster_loss: 1.3945 sup_con_loss: 0.3043 contrastive_loss: 5.2774 nll_loss: 0.0020 
2023-10-27 20:53:21.912 | INFO     | __main__:train:314 - Epoch: [46][900/1251]	 loss 4.71217	 cls_loss: 0.5636 cluster_loss: 1.3781 sup_con_loss: 0.5442 contrastive_loss: 5.2728 nll_loss: 0.0013 
2023-10-27 20:57:06.885 | INFO     | __main__:train:314 - Epoch: [46][1000/1251]	 loss 4.67375	 cls_loss: 0.6554 cluster_loss: 1.3326 sup_con_loss: 0.4311 contrastive_loss: 5.2683 nll_loss: 0.0029 
2023-10-27 21:01:02.021 | INFO     | __main__:train:314 - Epoch: [46][1100/1251]	 loss 4.79294	 cls_loss: 0.6210 cluster_loss: 1.3471 sup_con_loss: 0.7768 contrastive_loss: 5.2698 nll_loss: 0.0027 
2023-10-27 21:04:53.845 | INFO     | __main__:train:314 - Epoch: [46][1200/1251]	 loss 4.56451	 cls_loss: 0.4904 cluster_loss: 1.3464 sup_con_loss: 0.2574 contrastive_loss: 5.2706 nll_loss: 0.0017 
2023-10-27 21:06:49.654 | INFO     | __main__:train:319 - Train Epoch: 46 Avg Loss: 4.6573 
2023-10-27 21:06:49.662 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 21:47:59.253 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 46, Train ACC Unlabelled_v2: All 0.5968 | Old 0.7762 | New 0.5066
2023-10-27 21:48:01.699 | INFO     | __main__:main:205 - Train Accuracies: All 0.5968 | Old 0.7762 | New 0.5066
2023-10-27 21:48:10.123 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 21:48:52.043 | INFO     | __main__:train:314 - Epoch: [47][0/1251]	 loss 4.65925	 cls_loss: 0.6501 cluster_loss: 1.3106 sup_con_loss: 0.4517 contrastive_loss: 5.2628 nll_loss: 0.0009 
2023-10-27 21:52:54.929 | INFO     | __main__:train:314 - Epoch: [47][100/1251]	 loss 4.71095	 cls_loss: 0.7745 cluster_loss: 1.3379 sup_con_loss: 0.4038 contrastive_loss: 5.2714 nll_loss: 0.0025 
2023-10-27 21:57:14.911 | INFO     | __main__:train:314 - Epoch: [47][200/1251]	 loss 4.76629	 cls_loss: 0.6875 cluster_loss: 1.3699 sup_con_loss: 0.5882 contrastive_loss: 5.2724 nll_loss: 0.0023 
2023-10-27 22:01:00.053 | INFO     | __main__:train:314 - Epoch: [47][300/1251]	 loss 4.50304	 cls_loss: 0.4490 cluster_loss: 1.2587 sup_con_loss: 0.3015 contrastive_loss: 5.2630 nll_loss: 0.0013 
2023-10-27 22:04:50.501 | INFO     | __main__:train:314 - Epoch: [47][400/1251]	 loss 4.65253	 cls_loss: 0.6152 cluster_loss: 1.3039 sup_con_loss: 0.4638 contrastive_loss: 5.2685 nll_loss: 0.0028 
2023-10-27 22:08:43.666 | INFO     | __main__:train:314 - Epoch: [47][500/1251]	 loss 4.63322	 cls_loss: 0.5073 cluster_loss: 1.3201 sup_con_loss: 0.4868 contrastive_loss: 5.2695 nll_loss: 0.0020 
2023-10-27 22:12:55.106 | INFO     | __main__:train:314 - Epoch: [47][600/1251]	 loss 4.61335	 cls_loss: 0.4586 cluster_loss: 1.3588 sup_con_loss: 0.3914 contrastive_loss: 5.2767 nll_loss: 0.0028 
2023-10-27 22:17:04.872 | INFO     | __main__:train:314 - Epoch: [47][700/1251]	 loss 4.63483	 cls_loss: 0.5178 cluster_loss: 1.3468 sup_con_loss: 0.4266 contrastive_loss: 5.2714 nll_loss: 0.0025 
2023-10-27 22:21:18.711 | INFO     | __main__:train:314 - Epoch: [47][800/1251]	 loss 4.57236	 cls_loss: 0.4791 cluster_loss: 1.3328 sup_con_loss: 0.3172 contrastive_loss: 5.2678 nll_loss: 0.0032 
2023-10-27 22:26:11.693 | INFO     | __main__:train:314 - Epoch: [47][900/1251]	 loss 4.63864	 cls_loss: 0.5070 cluster_loss: 1.3917 sup_con_loss: 0.3557 contrastive_loss: 5.2761 nll_loss: 0.0026 
2023-10-27 22:30:54.107 | INFO     | __main__:train:314 - Epoch: [47][1000/1251]	 loss 4.57303	 cls_loss: 0.4820 cluster_loss: 1.3658 sup_con_loss: 0.2456 contrastive_loss: 5.2735 nll_loss: 0.0028 
2023-10-27 22:35:58.447 | INFO     | __main__:train:314 - Epoch: [47][1100/1251]	 loss 4.61088	 cls_loss: 0.4703 cluster_loss: 1.2858 sup_con_loss: 0.5338 contrastive_loss: 5.2654 nll_loss: 0.0012 
2023-10-27 22:40:14.071 | INFO     | __main__:train:314 - Epoch: [47][1200/1251]	 loss 4.73871	 cls_loss: 0.6225 cluster_loss: 1.3994 sup_con_loss: 0.5198 contrastive_loss: 5.2706 nll_loss: 0.0035 
2023-10-27 22:42:11.041 | INFO     | __main__:train:319 - Train Epoch: 47 Avg Loss: 4.6508 
2023-10-27 22:42:11.056 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-27 23:08:22.985 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 47, Train ACC Unlabelled_v2: All 0.5964 | Old 0.7782 | New 0.5050
2023-10-27 23:08:23.375 | INFO     | __main__:main:205 - Train Accuracies: All 0.5964 | Old 0.7782 | New 0.5050
2023-10-27 23:08:26.916 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-27 23:08:50.387 | INFO     | __main__:train:314 - Epoch: [48][0/1251]	 loss 4.53545	 cls_loss: 0.4959 cluster_loss: 1.3277 sup_con_loss: 0.2024 contrastive_loss: 5.2696 nll_loss: 0.0028 
2023-10-27 23:12:38.017 | INFO     | __main__:train:314 - Epoch: [48][100/1251]	 loss 4.72043	 cls_loss: 0.5554 cluster_loss: 1.3566 sup_con_loss: 0.6157 contrastive_loss: 5.2733 nll_loss: 0.0011 
2023-10-27 23:16:36.799 | INFO     | __main__:train:314 - Epoch: [48][200/1251]	 loss 4.73445	 cls_loss: 0.7260 cluster_loss: 1.4117 sup_con_loss: 0.3730 contrastive_loss: 5.2758 nll_loss: 0.0029 
2023-10-27 23:20:22.798 | INFO     | __main__:train:314 - Epoch: [48][300/1251]	 loss 4.60829	 cls_loss: 0.4852 cluster_loss: 1.3947 sup_con_loss: 0.2909 contrastive_loss: 5.2712 nll_loss: 0.0038 
2023-10-27 23:24:11.136 | INFO     | __main__:train:314 - Epoch: [48][400/1251]	 loss 4.61827	 cls_loss: 0.5091 cluster_loss: 1.3236 sup_con_loss: 0.4399 contrastive_loss: 5.2663 nll_loss: 0.0027 
2023-10-27 23:27:56.371 | INFO     | __main__:train:314 - Epoch: [48][500/1251]	 loss 4.71576	 cls_loss: 0.5650 cluster_loss: 1.3658 sup_con_loss: 0.5788 contrastive_loss: 5.2699 nll_loss: 0.0023 
2023-10-27 23:31:39.643 | INFO     | __main__:train:314 - Epoch: [48][600/1251]	 loss 4.64136	 cls_loss: 0.5884 cluster_loss: 1.3607 sup_con_loss: 0.3510 contrastive_loss: 5.2704 nll_loss: 0.0023 
2023-10-27 23:35:36.799 | INFO     | __main__:train:314 - Epoch: [48][700/1251]	 loss 4.58718	 cls_loss: 0.4928 cluster_loss: 1.3406 sup_con_loss: 0.3247 contrastive_loss: 5.2724 nll_loss: 0.0026 
2023-10-27 23:39:23.384 | INFO     | __main__:train:314 - Epoch: [48][800/1251]	 loss 4.76129	 cls_loss: 0.7003 cluster_loss: 1.3298 sup_con_loss: 0.6372 contrastive_loss: 5.2702 nll_loss: 0.0032 
2023-10-27 23:43:06.749 | INFO     | __main__:train:314 - Epoch: [48][900/1251]	 loss 4.69230	 cls_loss: 0.5310 cluster_loss: 1.3980 sup_con_loss: 0.4787 contrastive_loss: 5.2735 nll_loss: 0.0024 
2023-10-27 23:46:51.188 | INFO     | __main__:train:314 - Epoch: [48][1000/1251]	 loss 4.61410	 cls_loss: 0.5826 cluster_loss: 1.3032 sup_con_loss: 0.3890 contrastive_loss: 5.2672 nll_loss: 0.0033 
2023-10-27 23:50:35.939 | INFO     | __main__:train:314 - Epoch: [48][1100/1251]	 loss 4.70427	 cls_loss: 0.6030 cluster_loss: 1.3936 sup_con_loss: 0.4578 contrastive_loss: 5.2683 nll_loss: 0.0028 
2023-10-27 23:54:20.520 | INFO     | __main__:train:314 - Epoch: [48][1200/1251]	 loss 4.67592	 cls_loss: 0.5793 cluster_loss: 1.3411 sup_con_loss: 0.4861 contrastive_loss: 5.2760 nll_loss: 0.0019 
2023-10-27 23:56:11.623 | INFO     | __main__:train:319 - Train Epoch: 48 Avg Loss: 4.6537 
2023-10-27 23:56:11.637 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 00:25:24.039 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 48, Train ACC Unlabelled_v2: All 0.5963 | Old 0.7749 | New 0.5065
2023-10-28 00:25:24.226 | INFO     | __main__:main:205 - Train Accuracies: All 0.5963 | Old 0.7749 | New 0.5065
2023-10-28 00:25:29.498 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 00:25:54.399 | INFO     | __main__:train:314 - Epoch: [49][0/1251]	 loss 4.72862	 cls_loss: 0.5782 cluster_loss: 1.3948 sup_con_loss: 0.5371 contrastive_loss: 5.2748 nll_loss: 0.0030 
2023-10-28 00:29:42.375 | INFO     | __main__:train:314 - Epoch: [49][100/1251]	 loss 4.50402	 cls_loss: 0.4461 cluster_loss: 1.2415 sup_con_loss: 0.3359 contrastive_loss: 5.2632 nll_loss: 0.0022 
2023-10-28 00:33:30.848 | INFO     | __main__:train:314 - Epoch: [49][200/1251]	 loss 4.67216	 cls_loss: 0.5170 cluster_loss: 1.4204 sup_con_loss: 0.3912 contrastive_loss: 5.2758 nll_loss: 0.0018 
2023-10-28 00:37:15.001 | INFO     | __main__:train:314 - Epoch: [49][300/1251]	 loss 4.65989	 cls_loss: 0.5148 cluster_loss: 1.3393 sup_con_loss: 0.5188 contrastive_loss: 5.2703 nll_loss: 0.0019 
2023-10-28 00:41:11.049 | INFO     | __main__:train:314 - Epoch: [49][400/1251]	 loss 4.72033	 cls_loss: 0.6612 cluster_loss: 1.3235 sup_con_loss: 0.5756 contrastive_loss: 5.2685 nll_loss: 0.0026 
2023-10-28 00:45:00.890 | INFO     | __main__:train:314 - Epoch: [49][500/1251]	 loss 4.56383	 cls_loss: 0.4779 cluster_loss: 1.2765 sup_con_loss: 0.4068 contrastive_loss: 5.2655 nll_loss: 0.0020 
2023-10-28 00:49:04.582 | INFO     | __main__:train:314 - Epoch: [49][600/1251]	 loss 4.68791	 cls_loss: 0.5637 cluster_loss: 1.4221 sup_con_loss: 0.3799 contrastive_loss: 5.2764 nll_loss: 0.0035 
2023-10-28 00:53:00.312 | INFO     | __main__:train:314 - Epoch: [49][700/1251]	 loss 4.69250	 cls_loss: 0.5794 cluster_loss: 1.3866 sup_con_loss: 0.4597 contrastive_loss: 5.2688 nll_loss: 0.0028 
2023-10-28 00:58:12.115 | INFO     | __main__:train:314 - Epoch: [49][800/1251]	 loss 4.58957	 cls_loss: 0.5476 cluster_loss: 1.3230 sup_con_loss: 0.3135 contrastive_loss: 5.2717 nll_loss: 0.0016 
2023-10-28 01:01:57.158 | INFO     | __main__:train:314 - Epoch: [49][900/1251]	 loss 4.48728	 cls_loss: 0.3782 cluster_loss: 1.3015 sup_con_loss: 0.2352 contrastive_loss: 5.2641 nll_loss: 0.0049 
2023-10-28 01:05:42.108 | INFO     | __main__:train:314 - Epoch: [49][1000/1251]	 loss 4.62491	 cls_loss: 0.4925 cluster_loss: 1.3422 sup_con_loss: 0.4430 contrastive_loss: 5.2659 nll_loss: 0.0023 
2023-10-28 01:09:28.036 | INFO     | __main__:train:314 - Epoch: [49][1100/1251]	 loss 4.71194	 cls_loss: 0.5567 cluster_loss: 1.3941 sup_con_loss: 0.5193 contrastive_loss: 5.2735 nll_loss: 0.0013 
2023-10-28 01:13:14.064 | INFO     | __main__:train:314 - Epoch: [49][1200/1251]	 loss 4.67262	 cls_loss: 0.5370 cluster_loss: 1.3911 sup_con_loss: 0.4403 contrastive_loss: 5.2685 nll_loss: 0.0018 
2023-10-28 01:15:05.602 | INFO     | __main__:train:319 - Train Epoch: 49 Avg Loss: 4.6474 
2023-10-28 01:15:05.611 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 01:34:09.028 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 49, Train ACC Unlabelled_v2: All 0.5927 | Old 0.7783 | New 0.4994
2023-10-28 01:34:09.303 | INFO     | __main__:main:205 - Train Accuracies: All 0.5927 | Old 0.7783 | New 0.4994
2023-10-28 01:34:13.058 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 01:34:27.480 | INFO     | __main__:train:314 - Epoch: [50][0/1251]	 loss 4.71965	 cls_loss: 0.5946 cluster_loss: 1.3576 sup_con_loss: 0.5687 contrastive_loss: 5.2752 nll_loss: 0.0012 
2023-10-28 01:38:11.301 | INFO     | __main__:train:314 - Epoch: [50][100/1251]	 loss 4.58874	 cls_loss: 0.5014 cluster_loss: 1.2818 sup_con_loss: 0.4450 contrastive_loss: 5.2640 nll_loss: 0.0027 
2023-10-28 01:41:57.199 | INFO     | __main__:train:314 - Epoch: [50][200/1251]	 loss 4.77027	 cls_loss: 0.6460 cluster_loss: 1.3678 sup_con_loss: 0.6531 contrastive_loss: 5.2677 nll_loss: 0.0025 
2023-10-28 01:45:42.959 | INFO     | __main__:train:314 - Epoch: [50][300/1251]	 loss 4.72164	 cls_loss: 0.5619 cluster_loss: 1.3712 sup_con_loss: 0.5815 contrastive_loss: 5.2708 nll_loss: 0.0042 
2023-10-28 01:49:26.139 | INFO     | __main__:train:314 - Epoch: [50][400/1251]	 loss 4.69432	 cls_loss: 0.5976 cluster_loss: 1.3438 sup_con_loss: 0.5283 contrastive_loss: 5.2684 nll_loss: 0.0023 
2023-10-28 01:53:10.543 | INFO     | __main__:train:314 - Epoch: [50][500/1251]	 loss 4.59271	 cls_loss: 0.4914 cluster_loss: 1.3713 sup_con_loss: 0.2851 contrastive_loss: 5.2726 nll_loss: 0.0024 
2023-10-28 01:56:54.547 | INFO     | __main__:train:314 - Epoch: [50][600/1251]	 loss 4.63946	 cls_loss: 0.5766 cluster_loss: 1.3570 sup_con_loss: 0.3592 contrastive_loss: 5.2726 nll_loss: 0.0027 
2023-10-28 02:00:39.278 | INFO     | __main__:train:314 - Epoch: [50][700/1251]	 loss 4.65722	 cls_loss: 0.5095 cluster_loss: 1.3761 sup_con_loss: 0.4427 contrastive_loss: 5.2719 nll_loss: 0.0027 
2023-10-28 02:04:21.484 | INFO     | __main__:train:314 - Epoch: [50][800/1251]	 loss 4.71972	 cls_loss: 0.5583 cluster_loss: 1.4042 sup_con_loss: 0.5235 contrastive_loss: 5.2702 nll_loss: 0.0027 
2023-10-28 02:08:04.978 | INFO     | __main__:train:314 - Epoch: [50][900/1251]	 loss 4.63182	 cls_loss: 0.5126 cluster_loss: 1.3485 sup_con_loss: 0.4272 contrastive_loss: 5.2692 nll_loss: 0.0014 
2023-10-28 02:11:50.516 | INFO     | __main__:train:314 - Epoch: [50][1000/1251]	 loss 4.63811	 cls_loss: 0.5586 cluster_loss: 1.3580 sup_con_loss: 0.3810 contrastive_loss: 5.2694 nll_loss: 0.0015 
2023-10-28 02:15:34.382 | INFO     | __main__:train:314 - Epoch: [50][1100/1251]	 loss 4.51957	 cls_loss: 0.3972 cluster_loss: 1.2993 sup_con_loss: 0.3159 contrastive_loss: 5.2670 nll_loss: 0.0019 
2023-10-28 02:19:18.168 | INFO     | __main__:train:314 - Epoch: [50][1200/1251]	 loss 4.67275	 cls_loss: 0.5289 cluster_loss: 1.3460 sup_con_loss: 0.5264 contrastive_loss: 5.2707 nll_loss: 0.0025 
2023-10-28 02:21:10.842 | INFO     | __main__:train:319 - Train Epoch: 50 Avg Loss: 4.6469 
2023-10-28 02:21:10.849 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 02:40:08.755 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 50, Train ACC Unlabelled_v2: All 0.5971 | Old 0.7790 | New 0.5057
2023-10-28 02:40:09.124 | INFO     | __main__:main:205 - Train Accuracies: All 0.5971 | Old 0.7790 | New 0.5057
2023-10-28 02:40:12.884 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 02:40:28.673 | INFO     | __main__:train:314 - Epoch: [51][0/1251]	 loss 4.63800	 cls_loss: 0.5259 cluster_loss: 1.3358 sup_con_loss: 0.4544 contrastive_loss: 5.2690 nll_loss: 0.0018 
2023-10-28 02:44:13.412 | INFO     | __main__:train:314 - Epoch: [51][100/1251]	 loss 4.63778	 cls_loss: 0.5489 cluster_loss: 1.3276 sup_con_loss: 0.4498 contrastive_loss: 5.2654 nll_loss: 0.0028 
2023-10-28 02:47:57.201 | INFO     | __main__:train:314 - Epoch: [51][200/1251]	 loss 4.70653	 cls_loss: 0.5799 cluster_loss: 1.3853 sup_con_loss: 0.4973 contrastive_loss: 5.2719 nll_loss: 0.0023 
2023-10-28 02:51:41.168 | INFO     | __main__:train:314 - Epoch: [51][300/1251]	 loss 4.71710	 cls_loss: 0.5299 cluster_loss: 1.3652 sup_con_loss: 0.6160 contrastive_loss: 5.2731 nll_loss: 0.0011 
2023-10-28 02:55:25.527 | INFO     | __main__:train:314 - Epoch: [51][400/1251]	 loss 4.80106	 cls_loss: 0.7254 cluster_loss: 1.4027 sup_con_loss: 0.5868 contrastive_loss: 5.2738 nll_loss: 0.0021 
2023-10-28 02:59:10.404 | INFO     | __main__:train:314 - Epoch: [51][500/1251]	 loss 4.72397	 cls_loss: 0.6976 cluster_loss: 1.3807 sup_con_loss: 0.4403 contrastive_loss: 5.2716 nll_loss: 0.0017 
2023-10-28 03:02:53.594 | INFO     | __main__:train:314 - Epoch: [51][600/1251]	 loss 4.70267	 cls_loss: 0.5289 cluster_loss: 1.3890 sup_con_loss: 0.5198 contrastive_loss: 5.2749 nll_loss: 0.0041 
2023-10-28 03:06:40.015 | INFO     | __main__:train:314 - Epoch: [51][700/1251]	 loss 4.58097	 cls_loss: 0.5210 cluster_loss: 1.3164 sup_con_loss: 0.3419 contrastive_loss: 5.2637 nll_loss: 0.0019 
2023-10-28 03:10:24.483 | INFO     | __main__:train:314 - Epoch: [51][800/1251]	 loss 4.77492	 cls_loss: 0.6796 cluster_loss: 1.3722 sup_con_loss: 0.6302 contrastive_loss: 5.2668 nll_loss: 0.0012 
2023-10-28 03:14:08.345 | INFO     | __main__:train:314 - Epoch: [51][900/1251]	 loss 4.58323	 cls_loss: 0.4602 cluster_loss: 1.3047 sup_con_loss: 0.4257 contrastive_loss: 5.2660 nll_loss: 0.0022 
2023-10-28 03:17:52.281 | INFO     | __main__:train:314 - Epoch: [51][1000/1251]	 loss 4.65765	 cls_loss: 0.5271 cluster_loss: 1.3736 sup_con_loss: 0.4388 contrastive_loss: 5.2695 nll_loss: 0.0016 
2023-10-28 03:21:35.017 | INFO     | __main__:train:314 - Epoch: [51][1100/1251]	 loss 4.65561	 cls_loss: 0.4768 cluster_loss: 1.3849 sup_con_loss: 0.4516 contrastive_loss: 5.2744 nll_loss: 0.0021 
2023-10-28 03:25:19.909 | INFO     | __main__:train:314 - Epoch: [51][1200/1251]	 loss 4.59290	 cls_loss: 0.5496 cluster_loss: 1.3515 sup_con_loss: 0.2751 contrastive_loss: 5.2683 nll_loss: 0.0014 
2023-10-28 03:27:11.950 | INFO     | __main__:train:319 - Train Epoch: 51 Avg Loss: 4.6475 
2023-10-28 03:27:11.957 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 03:45:23.160 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 51, Train ACC Unlabelled_v2: All 0.5960 | Old 0.7773 | New 0.5049
2023-10-28 03:45:23.619 | INFO     | __main__:main:205 - Train Accuracies: All 0.5960 | Old 0.7773 | New 0.5049
2023-10-28 03:45:28.034 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 03:45:44.134 | INFO     | __main__:train:314 - Epoch: [52][0/1251]	 loss 4.64336	 cls_loss: 0.4167 cluster_loss: 1.3750 sup_con_loss: 0.5073 contrastive_loss: 5.2675 nll_loss: 0.0024 
2023-10-28 03:49:27.482 | INFO     | __main__:train:314 - Epoch: [52][100/1251]	 loss 4.68440	 cls_loss: 0.5188 cluster_loss: 1.3375 sup_con_loss: 0.5987 contrastive_loss: 5.2650 nll_loss: 0.0017 
2023-10-28 03:53:12.631 | INFO     | __main__:train:314 - Epoch: [52][200/1251]	 loss 4.62591	 cls_loss: 0.5013 cluster_loss: 1.3327 sup_con_loss: 0.4566 contrastive_loss: 5.2655 nll_loss: 0.0018 
2023-10-28 03:56:56.686 | INFO     | __main__:train:314 - Epoch: [52][300/1251]	 loss 4.56435	 cls_loss: 0.4431 cluster_loss: 1.2928 sup_con_loss: 0.4137 contrastive_loss: 5.2644 nll_loss: 0.0023 
2023-10-28 04:00:39.839 | INFO     | __main__:train:314 - Epoch: [52][400/1251]	 loss 4.57935	 cls_loss: 0.5153 cluster_loss: 1.2807 sup_con_loss: 0.4057 contrastive_loss: 5.2662 nll_loss: 0.0015 
2023-10-28 04:04:25.734 | INFO     | __main__:train:314 - Epoch: [52][500/1251]	 loss 4.71893	 cls_loss: 0.5726 cluster_loss: 1.3982 sup_con_loss: 0.5129 contrastive_loss: 5.2719 nll_loss: 0.0034 
2023-10-28 04:08:09.573 | INFO     | __main__:train:314 - Epoch: [52][600/1251]	 loss 4.66324	 cls_loss: 0.5814 cluster_loss: 1.3602 sup_con_loss: 0.4141 contrastive_loss: 5.2729 nll_loss: 0.0033 
2023-10-28 04:11:53.013 | INFO     | __main__:train:314 - Epoch: [52][700/1251]	 loss 4.64680	 cls_loss: 0.5332 cluster_loss: 1.3256 sup_con_loss: 0.4970 contrastive_loss: 5.2651 nll_loss: 0.0022 
2023-10-28 04:15:36.024 | INFO     | __main__:train:314 - Epoch: [52][800/1251]	 loss 4.54746	 cls_loss: 0.5002 cluster_loss: 1.2586 sup_con_loss: 0.3767 contrastive_loss: 5.2630 nll_loss: 0.0015 
2023-10-28 04:19:21.472 | INFO     | __main__:train:314 - Epoch: [52][900/1251]	 loss 4.61420	 cls_loss: 0.5231 cluster_loss: 1.3290 sup_con_loss: 0.4064 contrastive_loss: 5.2665 nll_loss: 0.0018 
2023-10-28 04:23:05.612 | INFO     | __main__:train:314 - Epoch: [52][1000/1251]	 loss 4.62671	 cls_loss: 0.5979 cluster_loss: 1.2980 sup_con_loss: 0.4196 contrastive_loss: 5.2685 nll_loss: 0.0023 
2023-10-28 04:26:51.098 | INFO     | __main__:train:314 - Epoch: [52][1100/1251]	 loss 4.53820	 cls_loss: 0.5076 cluster_loss: 1.3262 sup_con_loss: 0.1999 contrastive_loss: 5.2705 nll_loss: 0.0027 
2023-10-28 04:30:35.719 | INFO     | __main__:train:314 - Epoch: [52][1200/1251]	 loss 4.54911	 cls_loss: 0.4180 cluster_loss: 1.2945 sup_con_loss: 0.3863 contrastive_loss: 5.2675 nll_loss: 0.0023 
2023-10-28 04:32:27.468 | INFO     | __main__:train:319 - Train Epoch: 52 Avg Loss: 4.6426 
2023-10-28 04:32:27.496 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 04:50:12.991 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 52, Train ACC Unlabelled_v2: All 0.5967 | Old 0.7759 | New 0.5067
2023-10-28 04:50:13.241 | INFO     | __main__:main:205 - Train Accuracies: All 0.5967 | Old 0.7759 | New 0.5067
2023-10-28 04:50:17.605 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 04:50:30.617 | INFO     | __main__:train:314 - Epoch: [53][0/1251]	 loss 4.57042	 cls_loss: 0.5187 cluster_loss: 1.2989 sup_con_loss: 0.3401 contrastive_loss: 5.2675 nll_loss: 0.0016 
2023-10-28 04:54:15.036 | INFO     | __main__:train:314 - Epoch: [53][100/1251]	 loss 4.65620	 cls_loss: 0.5470 cluster_loss: 1.3246 sup_con_loss: 0.5064 contrastive_loss: 5.2658 nll_loss: 0.0037 
2023-10-28 04:58:00.974 | INFO     | __main__:train:314 - Epoch: [53][200/1251]	 loss 4.54519	 cls_loss: 0.4996 cluster_loss: 1.2844 sup_con_loss: 0.3215 contrastive_loss: 5.2618 nll_loss: 0.0028 
2023-10-28 05:01:45.596 | INFO     | __main__:train:314 - Epoch: [53][300/1251]	 loss 4.64579	 cls_loss: 0.5965 cluster_loss: 1.3434 sup_con_loss: 0.3881 contrastive_loss: 5.2697 nll_loss: 0.0026 
2023-10-28 05:05:31.659 | INFO     | __main__:train:314 - Epoch: [53][400/1251]	 loss 4.69472	 cls_loss: 0.5975 cluster_loss: 1.4060 sup_con_loss: 0.4058 contrastive_loss: 5.2730 nll_loss: 0.0022 
2023-10-28 05:09:15.232 | INFO     | __main__:train:314 - Epoch: [53][500/1251]	 loss 4.74389	 cls_loss: 0.5782 cluster_loss: 1.3841 sup_con_loss: 0.6025 contrastive_loss: 5.2770 nll_loss: 0.0010 
2023-10-28 05:12:59.067 | INFO     | __main__:train:314 - Epoch: [53][600/1251]	 loss 4.56876	 cls_loss: 0.5006 cluster_loss: 1.2961 sup_con_loss: 0.3528 contrastive_loss: 5.2675 nll_loss: 0.0037 
2023-10-28 05:16:44.557 | INFO     | __main__:train:314 - Epoch: [53][700/1251]	 loss 4.63051	 cls_loss: 0.4351 cluster_loss: 1.3218 sup_con_loss: 0.5477 contrastive_loss: 5.2676 nll_loss: 0.0034 
2023-10-28 05:20:28.896 | INFO     | __main__:train:314 - Epoch: [53][800/1251]	 loss 4.75582	 cls_loss: 0.6515 cluster_loss: 1.3495 sup_con_loss: 0.6414 contrastive_loss: 5.2679 nll_loss: 0.0020 
2023-10-28 05:24:12.709 | INFO     | __main__:train:314 - Epoch: [53][900/1251]	 loss 4.73973	 cls_loss: 0.6473 cluster_loss: 1.3907 sup_con_loss: 0.5113 contrastive_loss: 5.2752 nll_loss: 0.0014 
2023-10-28 05:27:57.821 | INFO     | __main__:train:314 - Epoch: [53][1000/1251]	 loss 4.66152	 cls_loss: 0.6284 cluster_loss: 1.3654 sup_con_loss: 0.3533 contrastive_loss: 5.2756 nll_loss: 0.0013 
2023-10-28 05:31:42.996 | INFO     | __main__:train:314 - Epoch: [53][1100/1251]	 loss 4.69863	 cls_loss: 0.6637 cluster_loss: 1.3274 sup_con_loss: 0.5033 contrastive_loss: 5.2697 nll_loss: 0.0021 
2023-10-28 05:35:26.281 | INFO     | __main__:train:314 - Epoch: [53][1200/1251]	 loss 4.58586	 cls_loss: 0.5292 cluster_loss: 1.3498 sup_con_loss: 0.2686 contrastive_loss: 5.2729 nll_loss: 0.0018 
2023-10-28 05:37:18.197 | INFO     | __main__:train:319 - Train Epoch: 53 Avg Loss: 4.6439 
2023-10-28 05:37:18.202 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 05:54:52.471 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 53, Train ACC Unlabelled_v2: All 0.5957 | Old 0.7769 | New 0.5047
2023-10-28 05:54:52.625 | INFO     | __main__:main:205 - Train Accuracies: All 0.5957 | Old 0.7769 | New 0.5047
2023-10-28 05:54:57.034 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 05:55:10.647 | INFO     | __main__:train:314 - Epoch: [54][0/1251]	 loss 4.71647	 cls_loss: 0.6505 cluster_loss: 1.3296 sup_con_loss: 0.5606 contrastive_loss: 5.2706 nll_loss: 0.0025 
2023-10-28 05:58:55.598 | INFO     | __main__:train:314 - Epoch: [54][100/1251]	 loss 4.58565	 cls_loss: 0.4889 cluster_loss: 1.3293 sup_con_loss: 0.3592 contrastive_loss: 5.2660 nll_loss: 0.0019 
2023-10-28 06:02:41.496 | INFO     | __main__:train:314 - Epoch: [54][200/1251]	 loss 4.62183	 cls_loss: 0.5698 cluster_loss: 1.3319 sup_con_loss: 0.3718 contrastive_loss: 5.2673 nll_loss: 0.0029 
2023-10-28 06:06:28.645 | INFO     | __main__:train:314 - Epoch: [54][300/1251]	 loss 4.57714	 cls_loss: 0.4634 cluster_loss: 1.2932 sup_con_loss: 0.4234 contrastive_loss: 5.2678 nll_loss: 0.0022 
2023-10-28 06:10:20.785 | INFO     | __main__:train:314 - Epoch: [54][400/1251]	 loss 4.74542	 cls_loss: 0.6646 cluster_loss: 1.3774 sup_con_loss: 0.5252 contrastive_loss: 5.2759 nll_loss: 0.0043 
2023-10-28 06:14:05.491 | INFO     | __main__:train:314 - Epoch: [54][500/1251]	 loss 4.67246	 cls_loss: 0.4513 cluster_loss: 1.4104 sup_con_loss: 0.4765 contrastive_loss: 5.2762 nll_loss: 0.0015 
2023-10-28 06:17:50.825 | INFO     | __main__:train:314 - Epoch: [54][600/1251]	 loss 4.62674	 cls_loss: 0.4818 cluster_loss: 1.3377 sup_con_loss: 0.4647 contrastive_loss: 5.2672 nll_loss: 0.0023 
2023-10-28 06:21:36.959 | INFO     | __main__:train:314 - Epoch: [54][700/1251]	 loss 4.53335	 cls_loss: 0.4030 cluster_loss: 1.2671 sup_con_loss: 0.4080 contrastive_loss: 5.2643 nll_loss: 0.0041 
2023-10-28 06:25:19.982 | INFO     | __main__:train:314 - Epoch: [54][800/1251]	 loss 4.56430	 cls_loss: 0.5055 cluster_loss: 1.2954 sup_con_loss: 0.3358 contrastive_loss: 5.2704 nll_loss: 0.0021 
2023-10-28 06:29:03.880 | INFO     | __main__:train:314 - Epoch: [54][900/1251]	 loss 4.77229	 cls_loss: 0.5563 cluster_loss: 1.4039 sup_con_loss: 0.6739 contrastive_loss: 5.2728 nll_loss: 0.0019 
2023-10-28 06:32:49.266 | INFO     | __main__:train:314 - Epoch: [54][1000/1251]	 loss 4.61428	 cls_loss: 0.4947 cluster_loss: 1.3162 sup_con_loss: 0.4601 contrastive_loss: 5.2654 nll_loss: 0.0021 
2023-10-28 06:36:41.294 | INFO     | __main__:train:314 - Epoch: [54][1100/1251]	 loss 4.54344	 cls_loss: 0.4311 cluster_loss: 1.3270 sup_con_loss: 0.3001 contrastive_loss: 5.2646 nll_loss: 0.0030 
2023-10-28 06:41:49.125 | INFO     | __main__:train:314 - Epoch: [54][1200/1251]	 loss 4.66776	 cls_loss: 0.6764 cluster_loss: 1.3549 sup_con_loss: 0.3407 contrastive_loss: 5.2768 nll_loss: 0.0011 
2023-10-28 06:43:43.941 | INFO     | __main__:train:319 - Train Epoch: 54 Avg Loss: 4.6422 
2023-10-28 06:43:44.029 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 07:02:13.502 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 54, Train ACC Unlabelled_v2: All 0.5981 | Old 0.7737 | New 0.5098
2023-10-28 07:02:13.767 | INFO     | __main__:main:205 - Train Accuracies: All 0.5981 | Old 0.7737 | New 0.5098
2023-10-28 07:02:17.498 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 07:02:31.081 | INFO     | __main__:train:314 - Epoch: [55][0/1251]	 loss 4.58686	 cls_loss: 0.4442 cluster_loss: 1.3630 sup_con_loss: 0.3354 contrastive_loss: 5.2708 nll_loss: 0.0020 
2023-10-28 07:06:15.149 | INFO     | __main__:train:314 - Epoch: [55][100/1251]	 loss 4.64433	 cls_loss: 0.5899 cluster_loss: 1.2868 sup_con_loss: 0.4973 contrastive_loss: 5.2682 nll_loss: 0.0030 
2023-10-28 07:10:01.619 | INFO     | __main__:train:314 - Epoch: [55][200/1251]	 loss 4.65658	 cls_loss: 0.5249 cluster_loss: 1.3220 sup_con_loss: 0.5368 contrastive_loss: 5.2650 nll_loss: 0.0035 
2023-10-28 07:13:48.405 | INFO     | __main__:train:314 - Epoch: [55][300/1251]	 loss 4.59379	 cls_loss: 0.4916 cluster_loss: 1.3276 sup_con_loss: 0.3735 contrastive_loss: 5.2701 nll_loss: 0.0025 
2023-10-28 07:17:33.172 | INFO     | __main__:train:314 - Epoch: [55][400/1251]	 loss 4.69580	 cls_loss: 0.6128 cluster_loss: 1.3190 sup_con_loss: 0.5695 contrastive_loss: 5.2659 nll_loss: 0.0018 
2023-10-28 07:21:17.987 | INFO     | __main__:train:314 - Epoch: [55][500/1251]	 loss 4.86763	 cls_loss: 0.6685 cluster_loss: 1.4350 sup_con_loss: 0.7639 contrastive_loss: 5.2793 nll_loss: 0.0020 
2023-10-28 07:25:20.468 | INFO     | __main__:train:314 - Epoch: [55][600/1251]	 loss 4.67654	 cls_loss: 0.5387 cluster_loss: 1.4162 sup_con_loss: 0.3849 contrastive_loss: 5.2778 nll_loss: 0.0022 
2023-10-28 07:29:06.193 | INFO     | __main__:train:314 - Epoch: [55][700/1251]	 loss 4.72962	 cls_loss: 0.5865 cluster_loss: 1.3760 sup_con_loss: 0.5777 contrastive_loss: 5.2703 nll_loss: 0.0020 
2023-10-28 07:32:53.387 | INFO     | __main__:train:314 - Epoch: [55][800/1251]	 loss 4.63703	 cls_loss: 0.6127 cluster_loss: 1.3252 sup_con_loss: 0.3822 contrastive_loss: 5.2693 nll_loss: 0.0024 
2023-10-28 07:36:37.649 | INFO     | __main__:train:314 - Epoch: [55][900/1251]	 loss 4.63777	 cls_loss: 0.5829 cluster_loss: 1.3323 sup_con_loss: 0.3999 contrastive_loss: 5.2697 nll_loss: 0.0025 
2023-10-28 07:40:22.048 | INFO     | __main__:train:314 - Epoch: [55][1000/1251]	 loss 4.55729	 cls_loss: 0.4816 cluster_loss: 1.2878 sup_con_loss: 0.3629 contrastive_loss: 5.2643 nll_loss: 0.0029 
2023-10-28 07:44:06.726 | INFO     | __main__:train:314 - Epoch: [55][1100/1251]	 loss 4.68118	 cls_loss: 0.6415 cluster_loss: 1.3245 sup_con_loss: 0.4852 contrastive_loss: 5.2657 nll_loss: 0.0032 
2023-10-28 07:47:51.413 | INFO     | __main__:train:314 - Epoch: [55][1200/1251]	 loss 4.69476	 cls_loss: 0.5201 cluster_loss: 1.3902 sup_con_loss: 0.5162 contrastive_loss: 5.2727 nll_loss: 0.0011 
2023-10-28 07:49:42.908 | INFO     | __main__:train:319 - Train Epoch: 55 Avg Loss: 4.6389 
2023-10-28 07:49:42.915 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 08:07:23.095 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 55, Train ACC Unlabelled_v2: All 0.5950 | Old 0.7721 | New 0.5060
2023-10-28 08:07:23.304 | INFO     | __main__:main:205 - Train Accuracies: All 0.5950 | Old 0.7721 | New 0.5060
2023-10-28 08:07:26.753 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 08:07:41.526 | INFO     | __main__:train:314 - Epoch: [56][0/1251]	 loss 4.69139	 cls_loss: 0.5581 cluster_loss: 1.3674 sup_con_loss: 0.5129 contrastive_loss: 5.2692 nll_loss: 0.0028 
2023-10-28 08:11:27.857 | INFO     | __main__:train:314 - Epoch: [56][100/1251]	 loss 4.61428	 cls_loss: 0.6407 cluster_loss: 1.2686 sup_con_loss: 0.4069 contrastive_loss: 5.2631 nll_loss: 0.0020 
2023-10-28 08:15:12.006 | INFO     | __main__:train:314 - Epoch: [56][200/1251]	 loss 4.58637	 cls_loss: 0.5523 cluster_loss: 1.3361 sup_con_loss: 0.2762 contrastive_loss: 5.2700 nll_loss: 0.0024 
2023-10-28 08:18:56.017 | INFO     | __main__:train:314 - Epoch: [56][300/1251]	 loss 4.56987	 cls_loss: 0.4771 cluster_loss: 1.2879 sup_con_loss: 0.3969 contrastive_loss: 5.2687 nll_loss: 0.0022 
2023-10-28 08:22:41.328 | INFO     | __main__:train:314 - Epoch: [56][400/1251]	 loss 4.51066	 cls_loss: 0.4072 cluster_loss: 1.3219 sup_con_loss: 0.2390 contrastive_loss: 5.2675 nll_loss: 0.0014 
2023-10-28 08:26:25.213 | INFO     | __main__:train:314 - Epoch: [56][500/1251]	 loss 4.62579	 cls_loss: 0.5514 cluster_loss: 1.3487 sup_con_loss: 0.3609 contrastive_loss: 5.2736 nll_loss: 0.0019 
2023-10-28 08:30:07.950 | INFO     | __main__:train:314 - Epoch: [56][600/1251]	 loss 4.64284	 cls_loss: 0.4386 cluster_loss: 1.3787 sup_con_loss: 0.4717 contrastive_loss: 5.2716 nll_loss: 0.0015 
2023-10-28 08:33:52.946 | INFO     | __main__:train:314 - Epoch: [56][700/1251]	 loss 4.55959	 cls_loss: 0.4821 cluster_loss: 1.3021 sup_con_loss: 0.3347 contrastive_loss: 5.2681 nll_loss: 0.0031 
2023-10-28 08:37:37.580 | INFO     | __main__:train:314 - Epoch: [56][800/1251]	 loss 4.45984	 cls_loss: 0.3405 cluster_loss: 1.2607 sup_con_loss: 0.2773 contrastive_loss: 5.2650 nll_loss: 0.0019 
2023-10-28 08:41:21.766 | INFO     | __main__:train:314 - Epoch: [56][900/1251]	 loss 4.74175	 cls_loss: 0.6512 cluster_loss: 1.3832 sup_con_loss: 0.5244 contrastive_loss: 5.2736 nll_loss: 0.0034 
2023-10-28 08:45:04.971 | INFO     | __main__:train:314 - Epoch: [56][1000/1251]	 loss 4.64474	 cls_loss: 0.5639 cluster_loss: 1.3818 sup_con_loss: 0.3411 contrastive_loss: 5.2739 nll_loss: 0.0018 
2023-10-28 08:48:48.706 | INFO     | __main__:train:314 - Epoch: [56][1100/1251]	 loss 4.74407	 cls_loss: 0.6269 cluster_loss: 1.3824 sup_con_loss: 0.5587 contrastive_loss: 5.2733 nll_loss: 0.0029 
2023-10-28 08:52:32.175 | INFO     | __main__:train:314 - Epoch: [56][1200/1251]	 loss 4.63237	 cls_loss: 0.4669 cluster_loss: 1.3620 sup_con_loss: 0.4486 contrastive_loss: 5.2691 nll_loss: 0.0018 
2023-10-28 08:54:23.868 | INFO     | __main__:train:319 - Train Epoch: 56 Avg Loss: 4.6398 
2023-10-28 08:54:23.878 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 09:12:06.392 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 56, Train ACC Unlabelled_v2: All 0.5975 | Old 0.7767 | New 0.5074
2023-10-28 09:12:06.577 | INFO     | __main__:main:205 - Train Accuracies: All 0.5975 | Old 0.7767 | New 0.5074
2023-10-28 09:12:10.342 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 09:12:23.118 | INFO     | __main__:train:314 - Epoch: [57][0/1251]	 loss 4.52703	 cls_loss: 0.4236 cluster_loss: 1.2926 sup_con_loss: 0.3242 contrastive_loss: 5.2644 nll_loss: 0.0032 
2023-10-28 09:16:06.078 | INFO     | __main__:train:314 - Epoch: [57][100/1251]	 loss 4.73329	 cls_loss: 0.6123 cluster_loss: 1.3797 sup_con_loss: 0.5498 contrastive_loss: 5.2721 nll_loss: 0.0029 
2023-10-28 09:19:50.438 | INFO     | __main__:train:314 - Epoch: [57][200/1251]	 loss 4.65173	 cls_loss: 0.4778 cluster_loss: 1.3822 sup_con_loss: 0.4512 contrastive_loss: 5.2683 nll_loss: 0.0038 
2023-10-28 09:23:35.084 | INFO     | __main__:train:314 - Epoch: [57][300/1251]	 loss 4.52082	 cls_loss: 0.4515 cluster_loss: 1.3061 sup_con_loss: 0.2506 contrastive_loss: 5.2677 nll_loss: 0.0021 
2023-10-28 09:27:19.250 | INFO     | __main__:train:314 - Epoch: [57][400/1251]	 loss 4.75904	 cls_loss: 0.7397 cluster_loss: 1.3748 sup_con_loss: 0.5057 contrastive_loss: 5.2739 nll_loss: 0.0015 
2023-10-28 09:31:02.487 | INFO     | __main__:train:314 - Epoch: [57][500/1251]	 loss 4.68823	 cls_loss: 0.5791 cluster_loss: 1.3826 sup_con_loss: 0.4452 contrastive_loss: 5.2754 nll_loss: 0.0020 
2023-10-28 09:34:47.802 | INFO     | __main__:train:314 - Epoch: [57][600/1251]	 loss 4.74942	 cls_loss: 0.6425 cluster_loss: 1.2928 sup_con_loss: 0.7315 contrastive_loss: 5.2702 nll_loss: 0.0026 
2023-10-28 09:38:36.125 | INFO     | __main__:train:314 - Epoch: [57][700/1251]	 loss 4.52964	 cls_loss: 0.4431 cluster_loss: 1.3265 sup_con_loss: 0.2460 contrastive_loss: 5.2682 nll_loss: 0.0019 
2023-10-28 09:42:19.380 | INFO     | __main__:train:314 - Epoch: [57][800/1251]	 loss 4.60595	 cls_loss: 0.4680 cluster_loss: 1.3196 sup_con_loss: 0.4585 contrastive_loss: 5.2655 nll_loss: 0.0014 
2023-10-28 09:46:03.641 | INFO     | __main__:train:314 - Epoch: [57][900/1251]	 loss 4.71780	 cls_loss: 0.5392 cluster_loss: 1.4268 sup_con_loss: 0.4884 contrastive_loss: 5.2733 nll_loss: 0.0031 
2023-10-28 09:49:47.837 | INFO     | __main__:train:314 - Epoch: [57][1000/1251]	 loss 4.61478	 cls_loss: 0.4628 cluster_loss: 1.3083 sup_con_loss: 0.5127 contrastive_loss: 5.2636 nll_loss: 0.0016 
2023-10-28 09:53:33.591 | INFO     | __main__:train:314 - Epoch: [57][1100/1251]	 loss 4.77054	 cls_loss: 0.6803 cluster_loss: 1.4249 sup_con_loss: 0.5057 contrastive_loss: 5.2741 nll_loss: 0.0011 
2023-10-28 09:57:19.339 | INFO     | __main__:train:314 - Epoch: [57][1200/1251]	 loss 4.55084	 cls_loss: 0.5187 cluster_loss: 1.2647 sup_con_loss: 0.3432 contrastive_loss: 5.2685 nll_loss: 0.0026 
2023-10-28 09:59:10.656 | INFO     | __main__:train:319 - Train Epoch: 57 Avg Loss: 4.6375 
2023-10-28 09:59:10.661 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 10:17:04.251 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 57, Train ACC Unlabelled_v2: All 0.5968 | Old 0.7771 | New 0.5062
2023-10-28 10:17:04.447 | INFO     | __main__:main:205 - Train Accuracies: All 0.5968 | Old 0.7771 | New 0.5062
2023-10-28 10:17:07.834 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 10:17:22.927 | INFO     | __main__:train:314 - Epoch: [58][0/1251]	 loss 4.67383	 cls_loss: 0.5672 cluster_loss: 1.3978 sup_con_loss: 0.3871 contrastive_loss: 5.2774 nll_loss: 0.0010 
2023-10-28 10:21:08.227 | INFO     | __main__:train:314 - Epoch: [58][100/1251]	 loss 4.73403	 cls_loss: 0.4827 cluster_loss: 1.4617 sup_con_loss: 0.5232 contrastive_loss: 5.2763 nll_loss: 0.0023 
2023-10-28 10:24:52.420 | INFO     | __main__:train:314 - Epoch: [58][200/1251]	 loss 4.74016	 cls_loss: 0.6059 cluster_loss: 1.3862 sup_con_loss: 0.5642 contrastive_loss: 5.2724 nll_loss: 0.0026 
2023-10-28 10:28:37.512 | INFO     | __main__:train:314 - Epoch: [58][300/1251]	 loss 4.60929	 cls_loss: 0.5270 cluster_loss: 1.3202 sup_con_loss: 0.3996 contrastive_loss: 5.2666 nll_loss: 0.0036 
2023-10-28 10:32:21.029 | INFO     | __main__:train:314 - Epoch: [58][400/1251]	 loss 4.62379	 cls_loss: 0.5151 cluster_loss: 1.3403 sup_con_loss: 0.4096 contrastive_loss: 5.2722 nll_loss: 0.0020 
2023-10-28 10:36:04.745 | INFO     | __main__:train:314 - Epoch: [58][500/1251]	 loss 4.66752	 cls_loss: 0.4932 cluster_loss: 1.3601 sup_con_loss: 0.5251 contrastive_loss: 5.2685 nll_loss: 0.0026 
2023-10-28 10:39:48.467 | INFO     | __main__:train:314 - Epoch: [58][600/1251]	 loss 4.68993	 cls_loss: 0.5944 cluster_loss: 1.3513 sup_con_loss: 0.4992 contrastive_loss: 5.2714 nll_loss: 0.0024 
2023-10-28 10:43:31.834 | INFO     | __main__:train:314 - Epoch: [58][700/1251]	 loss 4.67665	 cls_loss: 0.6282 cluster_loss: 1.3767 sup_con_loss: 0.3678 contrastive_loss: 5.2769 nll_loss: 0.0032 
2023-10-28 10:47:15.474 | INFO     | __main__:train:314 - Epoch: [58][800/1251]	 loss 4.63698	 cls_loss: 0.4877 cluster_loss: 1.3892 sup_con_loss: 0.3632 contrastive_loss: 5.2811 nll_loss: 0.0034 
2023-10-28 10:51:01.749 | INFO     | __main__:train:314 - Epoch: [58][900/1251]	 loss 4.63843	 cls_loss: 0.5261 cluster_loss: 1.3188 sup_con_loss: 0.4878 contrastive_loss: 5.2670 nll_loss: 0.0028 
2023-10-28 10:54:45.488 | INFO     | __main__:train:314 - Epoch: [58][1000/1251]	 loss 4.49783	 cls_loss: 0.3492 cluster_loss: 1.2686 sup_con_loss: 0.3657 contrastive_loss: 5.2632 nll_loss: 0.0020 
2023-10-28 10:58:28.701 | INFO     | __main__:train:314 - Epoch: [58][1100/1251]	 loss 4.54646	 cls_loss: 0.5979 cluster_loss: 1.2553 sup_con_loss: 0.2831 contrastive_loss: 5.2635 nll_loss: 0.0009 
2023-10-28 11:02:12.966 | INFO     | __main__:train:314 - Epoch: [58][1200/1251]	 loss 4.66028	 cls_loss: 0.5531 cluster_loss: 1.3248 sup_con_loss: 0.5105 contrastive_loss: 5.2696 nll_loss: 0.0017 
2023-10-28 11:04:04.865 | INFO     | __main__:train:319 - Train Epoch: 58 Avg Loss: 4.6358 
2023-10-28 11:04:04.873 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 11:22:21.110 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 58, Train ACC Unlabelled_v2: All 0.5965 | Old 0.7766 | New 0.5060
2023-10-28 11:22:21.305 | INFO     | __main__:main:205 - Train Accuracies: All 0.5965 | Old 0.7766 | New 0.5060
2023-10-28 11:22:25.828 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 11:22:40.946 | INFO     | __main__:train:314 - Epoch: [59][0/1251]	 loss 4.63245	 cls_loss: 0.5882 cluster_loss: 1.3325 sup_con_loss: 0.3822 contrastive_loss: 5.2673 nll_loss: 0.0029 
2023-10-28 11:26:24.825 | INFO     | __main__:train:314 - Epoch: [59][100/1251]	 loss 4.68059	 cls_loss: 0.6879 cluster_loss: 1.3532 sup_con_loss: 0.3800 contrastive_loss: 5.2697 nll_loss: 0.0019 
2023-10-28 11:30:09.427 | INFO     | __main__:train:314 - Epoch: [59][200/1251]	 loss 4.77519	 cls_loss: 0.6610 cluster_loss: 1.4387 sup_con_loss: 0.5063 contrastive_loss: 5.2742 nll_loss: 0.0032 
2023-10-28 11:33:51.968 | INFO     | __main__:train:314 - Epoch: [59][300/1251]	 loss 4.74174	 cls_loss: 0.5657 cluster_loss: 1.3896 sup_con_loss: 0.6026 contrastive_loss: 5.2727 nll_loss: 0.0023 
2023-10-28 11:37:36.214 | INFO     | __main__:train:314 - Epoch: [59][400/1251]	 loss 4.61650	 cls_loss: 0.4898 cluster_loss: 1.3558 sup_con_loss: 0.3878 contrastive_loss: 5.2712 nll_loss: 0.0018 
2023-10-28 11:41:19.935 | INFO     | __main__:train:314 - Epoch: [59][500/1251]	 loss 4.68216	 cls_loss: 0.5540 cluster_loss: 1.3455 sup_con_loss: 0.5347 contrastive_loss: 5.2665 nll_loss: 0.0033 
2023-10-28 11:45:07.434 | INFO     | __main__:train:314 - Epoch: [59][600/1251]	 loss 4.54564	 cls_loss: 0.4925 cluster_loss: 1.3177 sup_con_loss: 0.2534 contrastive_loss: 5.2715 nll_loss: 0.0016 
2023-10-28 11:48:50.953 | INFO     | __main__:train:314 - Epoch: [59][700/1251]	 loss 4.63390	 cls_loss: 0.5519 cluster_loss: 1.3249 sup_con_loss: 0.4352 contrastive_loss: 5.2704 nll_loss: 0.0014 
2023-10-28 11:52:34.700 | INFO     | __main__:train:314 - Epoch: [59][800/1251]	 loss 4.60545	 cls_loss: 0.5016 cluster_loss: 1.3457 sup_con_loss: 0.3567 contrastive_loss: 5.2755 nll_loss: 0.0013 
2023-10-28 11:56:19.091 | INFO     | __main__:train:314 - Epoch: [59][900/1251]	 loss 4.63485	 cls_loss: 0.5376 cluster_loss: 1.3471 sup_con_loss: 0.4155 contrastive_loss: 5.2677 nll_loss: 0.0016 
2023-10-28 12:00:01.852 | INFO     | __main__:train:314 - Epoch: [59][1000/1251]	 loss 4.62824	 cls_loss: 0.5253 cluster_loss: 1.3556 sup_con_loss: 0.3837 contrastive_loss: 5.2719 nll_loss: 0.0022 
2023-10-28 12:03:46.495 | INFO     | __main__:train:314 - Epoch: [59][1100/1251]	 loss 4.55595	 cls_loss: 0.4132 cluster_loss: 1.3062 sup_con_loss: 0.3901 contrastive_loss: 5.2653 nll_loss: 0.0034 
2023-10-28 12:07:29.757 | INFO     | __main__:train:314 - Epoch: [59][1200/1251]	 loss 4.51819	 cls_loss: 0.3985 cluster_loss: 1.3187 sup_con_loss: 0.2758 contrastive_loss: 5.2668 nll_loss: 0.0015 
2023-10-28 12:09:22.914 | INFO     | __main__:train:319 - Train Epoch: 59 Avg Loss: 4.6339 
2023-10-28 12:09:22.921 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 12:29:48.642 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 59, Train ACC Unlabelled_v2: All 0.5972 | Old 0.7753 | New 0.5076
2023-10-28 12:29:48.952 | INFO     | __main__:main:205 - Train Accuracies: All 0.5972 | Old 0.7753 | New 0.5076
2023-10-28 12:29:56.317 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 12:30:11.976 | INFO     | __main__:train:314 - Epoch: [60][0/1251]	 loss 4.55137	 cls_loss: 0.4174 cluster_loss: 1.2880 sup_con_loss: 0.4078 contrastive_loss: 5.2659 nll_loss: 0.0025 
2023-10-28 12:33:58.370 | INFO     | __main__:train:314 - Epoch: [60][100/1251]	 loss 4.66595	 cls_loss: 0.5813 cluster_loss: 1.3333 sup_con_loss: 0.4820 contrastive_loss: 5.2684 nll_loss: 0.0027 
2023-10-28 12:37:42.309 | INFO     | __main__:train:314 - Epoch: [60][200/1251]	 loss 4.59073	 cls_loss: 0.5496 cluster_loss: 1.3197 sup_con_loss: 0.3293 contrastive_loss: 5.2650 nll_loss: 0.0031 
2023-10-28 12:41:26.600 | INFO     | __main__:train:314 - Epoch: [60][300/1251]	 loss 4.55006	 cls_loss: 0.4782 cluster_loss: 1.2652 sup_con_loss: 0.3797 contrastive_loss: 5.2699 nll_loss: 0.0020 
2023-10-28 12:45:09.462 | INFO     | __main__:train:314 - Epoch: [60][400/1251]	 loss 4.52188	 cls_loss: 0.3470 cluster_loss: 1.3201 sup_con_loss: 0.3319 contrastive_loss: 5.2680 nll_loss: 0.0020 
2023-10-28 12:48:53.172 | INFO     | __main__:train:314 - Epoch: [60][500/1251]	 loss 4.67703	 cls_loss: 0.5497 cluster_loss: 1.3857 sup_con_loss: 0.4406 contrastive_loss: 5.2734 nll_loss: 0.0021 
2023-10-28 12:52:39.167 | INFO     | __main__:train:314 - Epoch: [60][600/1251]	 loss 4.63441	 cls_loss: 0.5110 cluster_loss: 1.3243 sup_con_loss: 0.4840 contrastive_loss: 5.2674 nll_loss: 0.0015 
2023-10-28 12:56:23.860 | INFO     | __main__:train:314 - Epoch: [60][700/1251]	 loss 4.82335	 cls_loss: 0.6087 cluster_loss: 1.4108 sup_con_loss: 0.7532 contrastive_loss: 5.2746 nll_loss: 0.0012 
2023-10-28 13:00:09.716 | INFO     | __main__:train:314 - Epoch: [60][800/1251]	 loss 4.55182	 cls_loss: 0.4222 cluster_loss: 1.2954 sup_con_loss: 0.3885 contrastive_loss: 5.2677 nll_loss: 0.0021 
2023-10-28 13:03:54.872 | INFO     | __main__:train:314 - Epoch: [60][900/1251]	 loss 4.57980	 cls_loss: 0.5240 cluster_loss: 1.2923 sup_con_loss: 0.3687 contrastive_loss: 5.2701 nll_loss: 0.0018 
2023-10-28 13:07:38.624 | INFO     | __main__:train:314 - Epoch: [60][1000/1251]	 loss 4.59655	 cls_loss: 0.5453 cluster_loss: 1.3115 sup_con_loss: 0.3709 contrastive_loss: 5.2635 nll_loss: 0.0021 
2023-10-28 13:11:22.684 | INFO     | __main__:train:314 - Epoch: [60][1100/1251]	 loss 4.54623	 cls_loss: 0.4834 cluster_loss: 1.3110 sup_con_loss: 0.2792 contrastive_loss: 5.2708 nll_loss: 0.0012 
2023-10-28 13:15:07.735 | INFO     | __main__:train:314 - Epoch: [60][1200/1251]	 loss 4.73753	 cls_loss: 0.5150 cluster_loss: 1.4451 sup_con_loss: 0.5224 contrastive_loss: 5.2805 nll_loss: 0.0028 
2023-10-28 13:16:59.203 | INFO     | __main__:train:319 - Train Epoch: 60 Avg Loss: 4.6303 
2023-10-28 13:16:59.212 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 13:34:44.138 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 60, Train ACC Unlabelled_v2: All 0.6003 | Old 0.7768 | New 0.5115
2023-10-28 13:34:44.335 | INFO     | __main__:main:205 - Train Accuracies: All 0.6003 | Old 0.7768 | New 0.5115
2023-10-28 13:34:47.554 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 13:35:01.729 | INFO     | __main__:train:314 - Epoch: [61][0/1251]	 loss 4.54838	 cls_loss: 0.3828 cluster_loss: 1.2918 sup_con_loss: 0.4360 contrastive_loss: 5.2620 nll_loss: 0.0019 
2023-10-28 13:38:46.940 | INFO     | __main__:train:314 - Epoch: [61][100/1251]	 loss 4.60099	 cls_loss: 0.5866 cluster_loss: 1.3268 sup_con_loss: 0.3089 contrastive_loss: 5.2660 nll_loss: 0.0023 
2023-10-28 13:42:32.981 | INFO     | __main__:train:314 - Epoch: [61][200/1251]	 loss 4.52876	 cls_loss: 0.3834 cluster_loss: 1.2947 sup_con_loss: 0.3661 contrastive_loss: 5.2650 nll_loss: 0.0027 
2023-10-28 13:46:17.450 | INFO     | __main__:train:314 - Epoch: [61][300/1251]	 loss 4.66385	 cls_loss: 0.5536 cluster_loss: 1.3522 sup_con_loss: 0.4695 contrastive_loss: 5.2689 nll_loss: 0.0021 
2023-10-28 13:50:02.493 | INFO     | __main__:train:314 - Epoch: [61][400/1251]	 loss 4.62356	 cls_loss: 0.4916 cluster_loss: 1.3548 sup_con_loss: 0.4156 contrastive_loss: 5.2671 nll_loss: 0.0018 
2023-10-28 13:53:46.733 | INFO     | __main__:train:314 - Epoch: [61][500/1251]	 loss 4.56886	 cls_loss: 0.4856 cluster_loss: 1.2965 sup_con_loss: 0.3718 contrastive_loss: 5.2687 nll_loss: 0.0014 
2023-10-28 13:57:32.381 | INFO     | __main__:train:314 - Epoch: [61][600/1251]	 loss 4.65404	 cls_loss: 0.4609 cluster_loss: 1.3802 sup_con_loss: 0.4639 contrastive_loss: 5.2754 nll_loss: 0.0042 
2023-10-28 14:01:18.086 | INFO     | __main__:train:314 - Epoch: [61][700/1251]	 loss 4.50612	 cls_loss: 0.4540 cluster_loss: 1.2834 sup_con_loss: 0.2536 contrastive_loss: 5.2643 nll_loss: 0.0025 
2023-10-28 14:05:00.868 | INFO     | __main__:train:314 - Epoch: [61][800/1251]	 loss 4.66675	 cls_loss: 0.6004 cluster_loss: 1.3800 sup_con_loss: 0.3716 contrastive_loss: 5.2723 nll_loss: 0.0025 
2023-10-28 14:08:45.061 | INFO     | __main__:train:314 - Epoch: [61][900/1251]	 loss 4.48369	 cls_loss: 0.4423 cluster_loss: 1.3008 sup_con_loss: 0.1678 contrastive_loss: 5.2646 nll_loss: 0.0027 
2023-10-28 14:12:29.494 | INFO     | __main__:train:314 - Epoch: [61][1000/1251]	 loss 4.65035	 cls_loss: 0.5405 cluster_loss: 1.3269 sup_con_loss: 0.4972 contrastive_loss: 5.2666 nll_loss: 0.0013 
2023-10-28 14:16:14.297 | INFO     | __main__:train:314 - Epoch: [61][1100/1251]	 loss 4.52691	 cls_loss: 0.4333 cluster_loss: 1.3047 sup_con_loss: 0.2912 contrastive_loss: 5.2666 nll_loss: 0.0020 
2023-10-28 14:19:58.842 | INFO     | __main__:train:314 - Epoch: [61][1200/1251]	 loss 4.72477	 cls_loss: 0.5421 cluster_loss: 1.3759 sup_con_loss: 0.6110 contrastive_loss: 5.2677 nll_loss: 0.0028 
2023-10-28 14:21:49.924 | INFO     | __main__:train:319 - Train Epoch: 61 Avg Loss: 4.6333 
2023-10-28 14:21:49.939 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 14:39:05.306 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 61, Train ACC Unlabelled_v2: All 0.5971 | Old 0.7766 | New 0.5069
2023-10-28 14:39:05.507 | INFO     | __main__:main:205 - Train Accuracies: All 0.5971 | Old 0.7766 | New 0.5069
2023-10-28 14:39:08.447 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 14:39:22.144 | INFO     | __main__:train:314 - Epoch: [62][0/1251]	 loss 4.56637	 cls_loss: 0.4583 cluster_loss: 1.3065 sup_con_loss: 0.3767 contrastive_loss: 5.2634 nll_loss: 0.0037 
2023-10-28 14:43:06.121 | INFO     | __main__:train:314 - Epoch: [62][100/1251]	 loss 4.68559	 cls_loss: 0.4212 cluster_loss: 1.4253 sup_con_loss: 0.5190 contrastive_loss: 5.2751 nll_loss: 0.0013 
2023-10-28 14:46:51.321 | INFO     | __main__:train:314 - Epoch: [62][200/1251]	 loss 4.47093	 cls_loss: 0.4499 cluster_loss: 1.2937 sup_con_loss: 0.1315 contrastive_loss: 5.2671 nll_loss: 0.0029 
2023-10-28 14:50:35.699 | INFO     | __main__:train:314 - Epoch: [62][300/1251]	 loss 4.65274	 cls_loss: 0.4724 cluster_loss: 1.3838 sup_con_loss: 0.4566 contrastive_loss: 5.2709 nll_loss: 0.0020 
2023-10-28 14:54:20.759 | INFO     | __main__:train:314 - Epoch: [62][400/1251]	 loss 4.67213	 cls_loss: 0.5526 cluster_loss: 1.3926 sup_con_loss: 0.4116 contrastive_loss: 5.2743 nll_loss: 0.0012 
2023-10-28 14:58:04.610 | INFO     | __main__:train:314 - Epoch: [62][500/1251]	 loss 4.76226	 cls_loss: 0.5248 cluster_loss: 1.4182 sup_con_loss: 0.6515 contrastive_loss: 5.2711 nll_loss: 0.0025 
2023-10-28 15:01:48.601 | INFO     | __main__:train:314 - Epoch: [62][600/1251]	 loss 4.65544	 cls_loss: 0.4876 cluster_loss: 1.3149 sup_con_loss: 0.5854 contrastive_loss: 5.2667 nll_loss: 0.0019 
2023-10-28 15:05:34.125 | INFO     | __main__:train:314 - Epoch: [62][700/1251]	 loss 4.66268	 cls_loss: 0.6171 cluster_loss: 1.3259 sup_con_loss: 0.4532 contrastive_loss: 5.2688 nll_loss: 0.0015 
2023-10-28 15:09:18.943 | INFO     | __main__:train:314 - Epoch: [62][800/1251]	 loss 4.51231	 cls_loss: 0.4257 cluster_loss: 1.2989 sup_con_loss: 0.2686 contrastive_loss: 5.2666 nll_loss: 0.0017 
2023-10-28 15:13:02.670 | INFO     | __main__:train:314 - Epoch: [62][900/1251]	 loss 4.68163	 cls_loss: 0.6638 cluster_loss: 1.3587 sup_con_loss: 0.3938 contrastive_loss: 5.2705 nll_loss: 0.0025 
2023-10-28 15:16:45.631 | INFO     | __main__:train:314 - Epoch: [62][1000/1251]	 loss 4.61101	 cls_loss: 0.4418 cluster_loss: 1.3482 sup_con_loss: 0.4425 contrastive_loss: 5.2682 nll_loss: 0.0009 
2023-10-28 15:20:29.370 | INFO     | __main__:train:314 - Epoch: [62][1100/1251]	 loss 4.61835	 cls_loss: 0.5390 cluster_loss: 1.3402 sup_con_loss: 0.3755 contrastive_loss: 5.2700 nll_loss: 0.0016 
2023-10-28 15:24:12.160 | INFO     | __main__:train:314 - Epoch: [62][1200/1251]	 loss 4.63612	 cls_loss: 0.5444 cluster_loss: 1.3210 sup_con_loss: 0.4604 contrastive_loss: 5.2680 nll_loss: 0.0017 
2023-10-28 15:26:03.361 | INFO     | __main__:train:319 - Train Epoch: 62 Avg Loss: 4.6325 
2023-10-28 15:26:03.367 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 15:43:30.560 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 62, Train ACC Unlabelled_v2: All 0.5979 | Old 0.7786 | New 0.5071
2023-10-28 15:43:30.589 | INFO     | __main__:main:205 - Train Accuracies: All 0.5979 | Old 0.7786 | New 0.5071
2023-10-28 15:43:33.780 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 15:43:49.630 | INFO     | __main__:train:314 - Epoch: [63][0/1251]	 loss 4.65574	 cls_loss: 0.5935 cluster_loss: 1.3647 sup_con_loss: 0.3841 contrastive_loss: 5.2686 nll_loss: 0.0020 
2023-10-28 15:47:34.304 | INFO     | __main__:train:314 - Epoch: [63][100/1251]	 loss 4.57678	 cls_loss: 0.5012 cluster_loss: 1.3230 sup_con_loss: 0.3303 contrastive_loss: 5.2675 nll_loss: 0.0019 
2023-10-28 15:51:17.792 | INFO     | __main__:train:314 - Epoch: [63][200/1251]	 loss 4.65008	 cls_loss: 0.4617 cluster_loss: 1.3211 sup_con_loss: 0.5819 contrastive_loss: 5.2685 nll_loss: 0.0016 
2023-10-28 15:55:01.530 | INFO     | __main__:train:314 - Epoch: [63][300/1251]	 loss 4.56820	 cls_loss: 0.4469 cluster_loss: 1.3013 sup_con_loss: 0.4027 contrastive_loss: 5.2651 nll_loss: 0.0027 
2023-10-28 15:58:44.841 | INFO     | __main__:train:314 - Epoch: [63][400/1251]	 loss 4.66025	 cls_loss: 0.5762 cluster_loss: 1.3454 sup_con_loss: 0.4445 contrastive_loss: 5.2701 nll_loss: 0.0029 
2023-10-28 16:02:29.500 | INFO     | __main__:train:314 - Epoch: [63][500/1251]	 loss 4.52213	 cls_loss: 0.3876 cluster_loss: 1.3282 sup_con_loss: 0.2743 contrastive_loss: 5.2687 nll_loss: 0.0025 
2023-10-28 16:06:13.192 | INFO     | __main__:train:314 - Epoch: [63][600/1251]	 loss 4.60323	 cls_loss: 0.5593 cluster_loss: 1.3476 sup_con_loss: 0.3007 contrastive_loss: 5.2679 nll_loss: 0.0022 
2023-10-28 16:09:59.769 | INFO     | __main__:train:314 - Epoch: [63][700/1251]	 loss 4.69934	 cls_loss: 0.4840 cluster_loss: 1.4206 sup_con_loss: 0.4987 contrastive_loss: 5.2747 nll_loss: 0.0035 
2023-10-28 16:13:44.208 | INFO     | __main__:train:314 - Epoch: [63][800/1251]	 loss 4.65193	 cls_loss: 0.5652 cluster_loss: 1.3414 sup_con_loss: 0.4445 contrastive_loss: 5.2670 nll_loss: 0.0030 
2023-10-28 16:17:28.826 | INFO     | __main__:train:314 - Epoch: [63][900/1251]	 loss 4.64328	 cls_loss: 0.4811 cluster_loss: 1.3385 sup_con_loss: 0.5080 contrastive_loss: 5.2688 nll_loss: 0.0023 
2023-10-28 16:21:12.792 | INFO     | __main__:train:314 - Epoch: [63][1000/1251]	 loss 4.71698	 cls_loss: 0.5614 cluster_loss: 1.3724 sup_con_loss: 0.5678 contrastive_loss: 5.2714 nll_loss: 0.0033 
2023-10-28 16:24:57.891 | INFO     | __main__:train:314 - Epoch: [63][1100/1251]	 loss 4.79688	 cls_loss: 0.7662 cluster_loss: 1.3324 sup_con_loss: 0.6698 contrastive_loss: 5.2718 nll_loss: 0.0015 
2023-10-28 16:28:43.075 | INFO     | __main__:train:314 - Epoch: [63][1200/1251]	 loss 4.68496	 cls_loss: 0.5759 cluster_loss: 1.3910 sup_con_loss: 0.4285 contrastive_loss: 5.2728 nll_loss: 0.0020 
2023-10-28 16:30:34.344 | INFO     | __main__:train:319 - Train Epoch: 63 Avg Loss: 4.6301 
2023-10-28 16:30:34.352 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 16:48:20.095 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 63, Train ACC Unlabelled_v2: All 0.5974 | Old 0.7765 | New 0.5074
2023-10-28 16:48:20.341 | INFO     | __main__:main:205 - Train Accuracies: All 0.5974 | Old 0.7765 | New 0.5074
2023-10-28 16:48:23.152 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 16:48:41.339 | INFO     | __main__:train:314 - Epoch: [64][0/1251]	 loss 4.57570	 cls_loss: 0.4792 cluster_loss: 1.3215 sup_con_loss: 0.3500 contrastive_loss: 5.2681 nll_loss: 0.0023 
2023-10-28 16:52:25.766 | INFO     | __main__:train:314 - Epoch: [64][100/1251]	 loss 4.70398	 cls_loss: 0.5639 cluster_loss: 1.3538 sup_con_loss: 0.5617 contrastive_loss: 5.2699 nll_loss: 0.0046 
2023-10-28 16:56:10.432 | INFO     | __main__:train:314 - Epoch: [64][200/1251]	 loss 4.63740	 cls_loss: 0.5130 cluster_loss: 1.3493 sup_con_loss: 0.4377 contrastive_loss: 5.2705 nll_loss: 0.0017 
2023-10-28 16:59:55.524 | INFO     | __main__:train:314 - Epoch: [64][300/1251]	 loss 4.47503	 cls_loss: 0.3812 cluster_loss: 1.3190 sup_con_loss: 0.1683 contrastive_loss: 5.2664 nll_loss: 0.0022 
2023-10-28 17:03:38.071 | INFO     | __main__:train:314 - Epoch: [64][400/1251]	 loss 4.59364	 cls_loss: 0.4479 cluster_loss: 1.4003 sup_con_loss: 0.2762 contrastive_loss: 5.2745 nll_loss: 0.0016 
2023-10-28 17:07:20.197 | INFO     | __main__:train:314 - Epoch: [64][500/1251]	 loss 4.66842	 cls_loss: 0.5750 cluster_loss: 1.3661 sup_con_loss: 0.4323 contrastive_loss: 5.2721 nll_loss: 0.0010 
2023-10-28 17:11:03.583 | INFO     | __main__:train:314 - Epoch: [64][600/1251]	 loss 4.56116	 cls_loss: 0.4335 cluster_loss: 1.3006 sup_con_loss: 0.3895 contrastive_loss: 5.2672 nll_loss: 0.0040 
2023-10-28 17:14:47.443 | INFO     | __main__:train:314 - Epoch: [64][700/1251]	 loss 4.58536	 cls_loss: 0.4633 cluster_loss: 1.3157 sup_con_loss: 0.3995 contrastive_loss: 5.2709 nll_loss: 0.0021 
2023-10-28 17:18:30.724 | INFO     | __main__:train:314 - Epoch: [64][800/1251]	 loss 4.66973	 cls_loss: 0.6422 cluster_loss: 1.2804 sup_con_loss: 0.5293 contrastive_loss: 5.2702 nll_loss: 0.0018 
2023-10-28 17:22:14.060 | INFO     | __main__:train:314 - Epoch: [64][900/1251]	 loss 4.65704	 cls_loss: 0.5997 cluster_loss: 1.3340 sup_con_loss: 0.4352 contrastive_loss: 5.2696 nll_loss: 0.0025 
2023-10-28 17:25:57.864 | INFO     | __main__:train:314 - Epoch: [64][1000/1251]	 loss 4.78910	 cls_loss: 0.5894 cluster_loss: 1.4626 sup_con_loss: 0.5731 contrastive_loss: 5.2773 nll_loss: 0.0013 
2023-10-28 17:29:42.436 | INFO     | __main__:train:314 - Epoch: [64][1100/1251]	 loss 4.62019	 cls_loss: 0.5200 cluster_loss: 1.3418 sup_con_loss: 0.4012 contrastive_loss: 5.2667 nll_loss: 0.0022 
2023-10-28 17:33:26.138 | INFO     | __main__:train:314 - Epoch: [64][1200/1251]	 loss 4.46519	 cls_loss: 0.4487 cluster_loss: 1.2713 sup_con_loss: 0.1664 contrastive_loss: 5.2642 nll_loss: 0.0019 
2023-10-28 17:35:17.373 | INFO     | __main__:train:319 - Train Epoch: 64 Avg Loss: 4.6290 
2023-10-28 17:35:17.381 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 17:52:54.952 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 64, Train ACC Unlabelled_v2: All 0.5978 | Old 0.7760 | New 0.5082
2023-10-28 17:52:55.285 | INFO     | __main__:main:205 - Train Accuracies: All 0.5978 | Old 0.7760 | New 0.5082
2023-10-28 17:52:58.262 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 17:53:15.051 | INFO     | __main__:train:314 - Epoch: [65][0/1251]	 loss 4.58267	 cls_loss: 0.4808 cluster_loss: 1.3266 sup_con_loss: 0.3604 contrastive_loss: 5.2678 nll_loss: 0.0019 
2023-10-28 17:57:00.163 | INFO     | __main__:train:314 - Epoch: [65][100/1251]	 loss 4.67592	 cls_loss: 0.5810 cluster_loss: 1.3439 sup_con_loss: 0.4964 contrastive_loss: 5.2679 nll_loss: 0.0012 
2023-10-28 18:00:44.986 | INFO     | __main__:train:314 - Epoch: [65][200/1251]	 loss 4.56302	 cls_loss: 0.3957 cluster_loss: 1.3319 sup_con_loss: 0.3755 contrastive_loss: 5.2695 nll_loss: 0.0022 
2023-10-28 18:04:30.777 | INFO     | __main__:train:314 - Epoch: [65][300/1251]	 loss 4.62265	 cls_loss: 0.5351 cluster_loss: 1.3171 sup_con_loss: 0.4317 contrastive_loss: 5.2701 nll_loss: 0.0026 
2023-10-28 18:08:15.890 | INFO     | __main__:train:314 - Epoch: [65][400/1251]	 loss 4.52290	 cls_loss: 0.4958 cluster_loss: 1.3192 sup_con_loss: 0.1914 contrastive_loss: 5.2667 nll_loss: 0.0015 
2023-10-28 18:12:00.347 | INFO     | __main__:train:314 - Epoch: [65][500/1251]	 loss 4.54565	 cls_loss: 0.4286 cluster_loss: 1.3736 sup_con_loss: 0.2068 contrastive_loss: 5.2748 nll_loss: 0.0019 
2023-10-28 18:15:45.916 | INFO     | __main__:train:314 - Epoch: [65][600/1251]	 loss 4.49983	 cls_loss: 0.4583 cluster_loss: 1.2805 sup_con_loss: 0.2433 contrastive_loss: 5.2619 nll_loss: 0.0018 
2023-10-28 18:19:32.419 | INFO     | __main__:train:314 - Epoch: [65][700/1251]	 loss 4.64829	 cls_loss: 0.5232 cluster_loss: 1.3647 sup_con_loss: 0.4242 contrastive_loss: 5.2729 nll_loss: 0.0022 
2023-10-28 18:23:17.053 | INFO     | __main__:train:314 - Epoch: [65][800/1251]	 loss 4.64777	 cls_loss: 0.5982 cluster_loss: 1.3748 sup_con_loss: 0.3285 contrastive_loss: 5.2732 nll_loss: 0.0022 
2023-10-28 18:27:01.106 | INFO     | __main__:train:314 - Epoch: [65][900/1251]	 loss 4.78387	 cls_loss: 0.5977 cluster_loss: 1.4618 sup_con_loss: 0.5482 contrastive_loss: 5.2775 nll_loss: 0.0023 
2023-10-28 18:30:46.207 | INFO     | __main__:train:314 - Epoch: [65][1000/1251]	 loss 4.60186	 cls_loss: 0.4759 cluster_loss: 1.3775 sup_con_loss: 0.3074 contrastive_loss: 5.2773 nll_loss: 0.0021 
2023-10-28 18:34:31.447 | INFO     | __main__:train:314 - Epoch: [65][1100/1251]	 loss 4.59116	 cls_loss: 0.4976 cluster_loss: 1.3690 sup_con_loss: 0.2774 contrastive_loss: 5.2739 nll_loss: 0.0020 
2023-10-28 18:38:15.795 | INFO     | __main__:train:314 - Epoch: [65][1200/1251]	 loss 4.66484	 cls_loss: 0.5959 cluster_loss: 1.3442 sup_con_loss: 0.4351 contrastive_loss: 5.2725 nll_loss: 0.0031 
2023-10-28 18:40:07.139 | INFO     | __main__:train:319 - Train Epoch: 65 Avg Loss: 4.6278 
2023-10-28 18:40:07.148 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 18:57:43.834 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 65, Train ACC Unlabelled_v2: All 0.5968 | Old 0.7781 | New 0.5057
2023-10-28 18:57:43.927 | INFO     | __main__:main:205 - Train Accuracies: All 0.5968 | Old 0.7781 | New 0.5057
2023-10-28 18:57:48.283 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 18:58:03.744 | INFO     | __main__:train:314 - Epoch: [66][0/1251]	 loss 4.53290	 cls_loss: 0.4582 cluster_loss: 1.3023 sup_con_loss: 0.2815 contrastive_loss: 5.2703 nll_loss: 0.0018 
2023-10-28 19:01:46.913 | INFO     | __main__:train:314 - Epoch: [66][100/1251]	 loss 4.65338	 cls_loss: 0.4875 cluster_loss: 1.3666 sup_con_loss: 0.4807 contrastive_loss: 5.2689 nll_loss: 0.0015 
2023-10-28 19:05:31.751 | INFO     | __main__:train:314 - Epoch: [66][200/1251]	 loss 4.68993	 cls_loss: 0.5199 cluster_loss: 1.3780 sup_con_loss: 0.5238 contrastive_loss: 5.2725 nll_loss: 0.0018 
2023-10-28 19:09:18.549 | INFO     | __main__:train:314 - Epoch: [66][300/1251]	 loss 4.54700	 cls_loss: 0.4290 cluster_loss: 1.3160 sup_con_loss: 0.3296 contrastive_loss: 5.2693 nll_loss: 0.0011 
2023-10-28 19:13:01.588 | INFO     | __main__:train:314 - Epoch: [66][400/1251]	 loss 4.63107	 cls_loss: 0.5329 cluster_loss: 1.3214 sup_con_loss: 0.4574 contrastive_loss: 5.2680 nll_loss: 0.0014 
2023-10-28 19:16:48.566 | INFO     | __main__:train:314 - Epoch: [66][500/1251]	 loss 4.57048	 cls_loss: 0.4394 cluster_loss: 1.3280 sup_con_loss: 0.3672 contrastive_loss: 5.2668 nll_loss: 0.0016 
2023-10-28 19:20:34.601 | INFO     | __main__:train:314 - Epoch: [66][600/1251]	 loss 4.63346	 cls_loss: 0.4633 cluster_loss: 1.3627 sup_con_loss: 0.4478 contrastive_loss: 5.2709 nll_loss: 0.0027 
2023-10-28 19:24:18.855 | INFO     | __main__:train:314 - Epoch: [66][700/1251]	 loss 4.53717	 cls_loss: 0.4474 cluster_loss: 1.3089 sup_con_loss: 0.3001 contrastive_loss: 5.2643 nll_loss: 0.0029 
2023-10-28 19:28:02.032 | INFO     | __main__:train:314 - Epoch: [66][800/1251]	 loss 4.78266	 cls_loss: 0.6167 cluster_loss: 1.4349 sup_con_loss: 0.5757 contrastive_loss: 5.2788 nll_loss: 0.0014 
2023-10-28 19:31:46.354 | INFO     | __main__:train:314 - Epoch: [66][900/1251]	 loss 4.58456	 cls_loss: 0.4627 cluster_loss: 1.3274 sup_con_loss: 0.3784 contrastive_loss: 5.2677 nll_loss: 0.0033 
2023-10-28 19:35:30.772 | INFO     | __main__:train:314 - Epoch: [66][1000/1251]	 loss 4.67491	 cls_loss: 0.6485 cluster_loss: 1.4123 sup_con_loss: 0.2850 contrastive_loss: 5.2721 nll_loss: 0.0033 
2023-10-28 19:39:16.421 | INFO     | __main__:train:314 - Epoch: [66][1100/1251]	 loss 4.77037	 cls_loss: 0.5449 cluster_loss: 1.4575 sup_con_loss: 0.5665 contrastive_loss: 5.2804 nll_loss: 0.0017 
2023-10-28 19:43:05.906 | INFO     | __main__:train:314 - Epoch: [66][1200/1251]	 loss 4.57230	 cls_loss: 0.3822 cluster_loss: 1.3619 sup_con_loss: 0.3582 contrastive_loss: 5.2709 nll_loss: 0.0018 
2023-10-28 19:44:57.796 | INFO     | __main__:train:319 - Train Epoch: 66 Avg Loss: 4.6266 
2023-10-28 19:44:57.806 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 20:02:18.178 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 66, Train ACC Unlabelled_v2: All 0.5982 | Old 0.7770 | New 0.5083
2023-10-28 20:02:18.397 | INFO     | __main__:main:205 - Train Accuracies: All 0.5982 | Old 0.7770 | New 0.5083
2023-10-28 20:02:21.369 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 20:02:35.802 | INFO     | __main__:train:314 - Epoch: [67][0/1251]	 loss 4.68156	 cls_loss: 0.5651 cluster_loss: 1.4043 sup_con_loss: 0.4064 contrastive_loss: 5.2725 nll_loss: 0.0016 
2023-10-28 20:06:20.734 | INFO     | __main__:train:314 - Epoch: [67][100/1251]	 loss 4.55619	 cls_loss: 0.4503 cluster_loss: 1.3003 sup_con_loss: 0.3714 contrastive_loss: 5.2621 nll_loss: 0.0030 
2023-10-28 20:10:05.695 | INFO     | __main__:train:314 - Epoch: [67][200/1251]	 loss 4.60933	 cls_loss: 0.5260 cluster_loss: 1.3078 sup_con_loss: 0.4335 contrastive_loss: 5.2650 nll_loss: 0.0012 
2023-10-28 20:13:49.430 | INFO     | __main__:train:314 - Epoch: [67][300/1251]	 loss 4.65567	 cls_loss: 0.5523 cluster_loss: 1.3130 sup_con_loss: 0.5191 contrastive_loss: 5.2698 nll_loss: 0.0019 
2023-10-28 20:17:32.801 | INFO     | __main__:train:314 - Epoch: [67][400/1251]	 loss 4.69284	 cls_loss: 0.5988 cluster_loss: 1.3543 sup_con_loss: 0.5035 contrastive_loss: 5.2693 nll_loss: 0.0017 
2023-10-28 20:21:17.769 | INFO     | __main__:train:314 - Epoch: [67][500/1251]	 loss 4.55073	 cls_loss: 0.5224 cluster_loss: 1.3142 sup_con_loss: 0.2489 contrastive_loss: 5.2681 nll_loss: 0.0023 
2023-10-28 20:25:01.252 | INFO     | __main__:train:314 - Epoch: [67][600/1251]	 loss 4.59794	 cls_loss: 0.4629 cluster_loss: 1.3735 sup_con_loss: 0.3349 contrastive_loss: 5.2665 nll_loss: 0.0028 
2023-10-28 20:28:46.008 | INFO     | __main__:train:314 - Epoch: [67][700/1251]	 loss 4.62673	 cls_loss: 0.4893 cluster_loss: 1.3232 sup_con_loss: 0.4845 contrastive_loss: 5.2666 nll_loss: 0.0025 
2023-10-28 20:32:28.624 | INFO     | __main__:train:314 - Epoch: [67][800/1251]	 loss 4.63567	 cls_loss: 0.4965 cluster_loss: 1.3551 sup_con_loss: 0.4390 contrastive_loss: 5.2691 nll_loss: 0.0025 
2023-10-28 20:36:13.814 | INFO     | __main__:train:314 - Epoch: [67][900/1251]	 loss 4.50880	 cls_loss: 0.4308 cluster_loss: 1.3205 sup_con_loss: 0.2106 contrastive_loss: 5.2667 nll_loss: 0.0026 
2023-10-28 20:39:58.944 | INFO     | __main__:train:314 - Epoch: [67][1000/1251]	 loss 4.57145	 cls_loss: 0.4283 cluster_loss: 1.3116 sup_con_loss: 0.4071 contrastive_loss: 5.2675 nll_loss: 0.0026 
2023-10-28 20:43:44.531 | INFO     | __main__:train:314 - Epoch: [67][1100/1251]	 loss 4.64817	 cls_loss: 0.5552 cluster_loss: 1.3478 sup_con_loss: 0.4259 contrastive_loss: 5.2692 nll_loss: 0.0038 
2023-10-28 20:47:28.215 | INFO     | __main__:train:314 - Epoch: [67][1200/1251]	 loss 4.55192	 cls_loss: 0.4788 cluster_loss: 1.2871 sup_con_loss: 0.3503 contrastive_loss: 5.2664 nll_loss: 0.0020 
2023-10-28 20:49:20.281 | INFO     | __main__:train:319 - Train Epoch: 67 Avg Loss: 4.6222 
2023-10-28 20:49:20.287 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 21:06:53.496 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 67, Train ACC Unlabelled_v2: All 0.5988 | Old 0.7750 | New 0.5102
2023-10-28 21:06:53.856 | INFO     | __main__:main:205 - Train Accuracies: All 0.5988 | Old 0.7750 | New 0.5102
2023-10-28 21:06:58.687 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 21:07:13.580 | INFO     | __main__:train:314 - Epoch: [68][0/1251]	 loss 4.61904	 cls_loss: 0.5706 cluster_loss: 1.3147 sup_con_loss: 0.3904 contrastive_loss: 5.2681 nll_loss: 0.0039 
2023-10-28 21:10:57.620 | INFO     | __main__:train:314 - Epoch: [68][100/1251]	 loss 4.56255	 cls_loss: 0.4567 cluster_loss: 1.3376 sup_con_loss: 0.3003 contrastive_loss: 5.2702 nll_loss: 0.0025 
2023-10-28 21:14:41.842 | INFO     | __main__:train:314 - Epoch: [68][200/1251]	 loss 4.66272	 cls_loss: 0.5689 cluster_loss: 1.3809 sup_con_loss: 0.3881 contrastive_loss: 5.2752 nll_loss: 0.0013 
2023-10-28 21:18:27.854 | INFO     | __main__:train:314 - Epoch: [68][300/1251]	 loss 4.59512	 cls_loss: 0.5088 cluster_loss: 1.3127 sup_con_loss: 0.3938 contrastive_loss: 5.2666 nll_loss: 0.0027 
2023-10-28 21:22:12.035 | INFO     | __main__:train:314 - Epoch: [68][400/1251]	 loss 4.60155	 cls_loss: 0.4892 cluster_loss: 1.3851 sup_con_loss: 0.2926 contrastive_loss: 5.2710 nll_loss: 0.0015 
2023-10-28 21:25:55.850 | INFO     | __main__:train:314 - Epoch: [68][500/1251]	 loss 4.57158	 cls_loss: 0.4619 cluster_loss: 1.3109 sup_con_loss: 0.3698 contrastive_loss: 5.2680 nll_loss: 0.0042 
2023-10-28 21:29:39.022 | INFO     | __main__:train:314 - Epoch: [68][600/1251]	 loss 4.57630	 cls_loss: 0.4559 cluster_loss: 1.3064 sup_con_loss: 0.4082 contrastive_loss: 5.2664 nll_loss: 0.0016 
2023-10-28 21:33:21.984 | INFO     | __main__:train:314 - Epoch: [68][700/1251]	 loss 4.54463	 cls_loss: 0.4567 cluster_loss: 1.3144 sup_con_loss: 0.2998 contrastive_loss: 5.2679 nll_loss: 0.0014 
2023-10-28 21:37:05.456 | INFO     | __main__:train:314 - Epoch: [68][800/1251]	 loss 4.59989	 cls_loss: 0.4814 cluster_loss: 1.3561 sup_con_loss: 0.3546 contrastive_loss: 5.2668 nll_loss: 0.0024 
2023-10-28 21:40:49.819 | INFO     | __main__:train:314 - Epoch: [68][900/1251]	 loss 4.79597	 cls_loss: 0.6648 cluster_loss: 1.4378 sup_con_loss: 0.5772 contrastive_loss: 5.2693 nll_loss: 0.0016 
2023-10-28 21:44:33.869 | INFO     | __main__:train:314 - Epoch: [68][1000/1251]	 loss 4.60629	 cls_loss: 0.4886 cluster_loss: 1.3501 sup_con_loss: 0.3677 contrastive_loss: 5.2721 nll_loss: 0.0022 
2023-10-28 21:48:18.113 | INFO     | __main__:train:314 - Epoch: [68][1100/1251]	 loss 4.75143	 cls_loss: 0.6000 cluster_loss: 1.3966 sup_con_loss: 0.5911 contrastive_loss: 5.2696 nll_loss: 0.0016 
2023-10-28 21:52:03.064 | INFO     | __main__:train:314 - Epoch: [68][1200/1251]	 loss 4.51901	 cls_loss: 0.3638 cluster_loss: 1.3022 sup_con_loss: 0.3417 contrastive_loss: 5.2671 nll_loss: 0.0021 
2023-10-28 21:53:55.112 | INFO     | __main__:train:319 - Train Epoch: 68 Avg Loss: 4.6204 
2023-10-28 21:53:55.116 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 22:11:38.918 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 68, Train ACC Unlabelled_v2: All 0.5985 | Old 0.7771 | New 0.5087
2023-10-28 22:11:39.132 | INFO     | __main__:main:205 - Train Accuracies: All 0.5985 | Old 0.7771 | New 0.5087
2023-10-28 22:11:42.862 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 22:11:55.998 | INFO     | __main__:train:314 - Epoch: [69][0/1251]	 loss 4.67989	 cls_loss: 0.6193 cluster_loss: 1.3513 sup_con_loss: 0.4502 contrastive_loss: 5.2689 nll_loss: 0.0025 
2023-10-28 22:15:41.751 | INFO     | __main__:train:314 - Epoch: [69][100/1251]	 loss 4.58958	 cls_loss: 0.4744 cluster_loss: 1.3297 sup_con_loss: 0.3714 contrastive_loss: 5.2710 nll_loss: 0.0031 
2023-10-28 22:19:26.980 | INFO     | __main__:train:314 - Epoch: [69][200/1251]	 loss 4.75244	 cls_loss: 0.5961 cluster_loss: 1.3654 sup_con_loss: 0.6489 contrastive_loss: 5.2735 nll_loss: 0.0014 
2023-10-28 22:23:10.372 | INFO     | __main__:train:314 - Epoch: [69][300/1251]	 loss 4.58772	 cls_loss: 0.4784 cluster_loss: 1.3652 sup_con_loss: 0.3089 contrastive_loss: 5.2667 nll_loss: 0.0015 
2023-10-28 22:26:53.763 | INFO     | __main__:train:314 - Epoch: [69][400/1251]	 loss 4.63687	 cls_loss: 0.5399 cluster_loss: 1.3344 sup_con_loss: 0.4352 contrastive_loss: 5.2707 nll_loss: 0.0022 
2023-10-28 22:30:37.789 | INFO     | __main__:train:314 - Epoch: [69][500/1251]	 loss 4.63337	 cls_loss: 0.5557 cluster_loss: 1.3620 sup_con_loss: 0.3635 contrastive_loss: 5.2695 nll_loss: 0.0012 
2023-10-28 22:34:23.238 | INFO     | __main__:train:314 - Epoch: [69][600/1251]	 loss 4.58442	 cls_loss: 0.4289 cluster_loss: 1.3269 sup_con_loss: 0.4195 contrastive_loss: 5.2650 nll_loss: 0.0027 
2023-10-28 22:38:10.810 | INFO     | __main__:train:314 - Epoch: [69][700/1251]	 loss 4.58464	 cls_loss: 0.4634 cluster_loss: 1.3385 sup_con_loss: 0.3535 contrastive_loss: 5.2709 nll_loss: 0.0026 
2023-10-28 22:41:54.612 | INFO     | __main__:train:314 - Epoch: [69][800/1251]	 loss 4.67147	 cls_loss: 0.5487 cluster_loss: 1.3460 sup_con_loss: 0.5077 contrastive_loss: 5.2684 nll_loss: 0.0024 
2023-10-28 22:45:38.157 | INFO     | __main__:train:314 - Epoch: [69][900/1251]	 loss 4.64892	 cls_loss: 0.5054 cluster_loss: 1.3689 sup_con_loss: 0.4338 contrastive_loss: 5.2743 nll_loss: 0.0021 
2023-10-28 22:49:22.020 | INFO     | __main__:train:314 - Epoch: [69][1000/1251]	 loss 4.56031	 cls_loss: 0.5225 cluster_loss: 1.2787 sup_con_loss: 0.3415 contrastive_loss: 5.2689 nll_loss: 0.0019 
2023-10-28 22:53:04.813 | INFO     | __main__:train:314 - Epoch: [69][1100/1251]	 loss 4.51121	 cls_loss: 0.4241 cluster_loss: 1.2767 sup_con_loss: 0.3076 contrastive_loss: 5.2661 nll_loss: 0.0023 
2023-10-28 22:56:48.990 | INFO     | __main__:train:314 - Epoch: [69][1200/1251]	 loss 4.69755	 cls_loss: 0.5749 cluster_loss: 1.3761 sup_con_loss: 0.4891 contrastive_loss: 5.2751 nll_loss: 0.0019 
2023-10-28 22:58:41.098 | INFO     | __main__:train:319 - Train Epoch: 69 Avg Loss: 4.6182 
2023-10-28 22:58:41.103 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-28 23:15:55.193 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 69, Train ACC Unlabelled_v2: All 0.5975 | Old 0.7764 | New 0.5076
2023-10-28 23:15:55.395 | INFO     | __main__:main:205 - Train Accuracies: All 0.5975 | Old 0.7764 | New 0.5076
2023-10-28 23:16:00.824 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-28 23:16:16.155 | INFO     | __main__:train:314 - Epoch: [70][0/1251]	 loss 4.58324	 cls_loss: 0.4783 cluster_loss: 1.3062 sup_con_loss: 0.4031 contrastive_loss: 5.2669 nll_loss: 0.0023 
2023-10-28 23:20:01.219 | INFO     | __main__:train:314 - Epoch: [70][100/1251]	 loss 4.54314	 cls_loss: 0.4747 cluster_loss: 1.2818 sup_con_loss: 0.3383 contrastive_loss: 5.2649 nll_loss: 0.0032 
2023-10-28 23:23:46.161 | INFO     | __main__:train:314 - Epoch: [70][200/1251]	 loss 4.63265	 cls_loss: 0.5706 cluster_loss: 1.3573 sup_con_loss: 0.3576 contrastive_loss: 5.2671 nll_loss: 0.0019 
2023-10-28 23:27:30.699 | INFO     | __main__:train:314 - Epoch: [70][300/1251]	 loss 4.73835	 cls_loss: 0.6544 cluster_loss: 1.4169 sup_con_loss: 0.4542 contrastive_loss: 5.2735 nll_loss: 0.0016 
2023-10-28 23:31:14.851 | INFO     | __main__:train:314 - Epoch: [70][400/1251]	 loss 4.64152	 cls_loss: 0.6012 cluster_loss: 1.3141 sup_con_loss: 0.4331 contrastive_loss: 5.2663 nll_loss: 0.0023 
2023-10-28 23:35:01.410 | INFO     | __main__:train:314 - Epoch: [70][500/1251]	 loss 4.60226	 cls_loss: 0.5543 cluster_loss: 1.3378 sup_con_loss: 0.3262 contrastive_loss: 5.2667 nll_loss: 0.0011 
2023-10-28 23:38:46.155 | INFO     | __main__:train:314 - Epoch: [70][600/1251]	 loss 4.59196	 cls_loss: 0.5493 cluster_loss: 1.3245 sup_con_loss: 0.3140 contrastive_loss: 5.2719 nll_loss: 0.0021 
2023-10-28 23:42:30.728 | INFO     | __main__:train:314 - Epoch: [70][700/1251]	 loss 4.62393	 cls_loss: 0.5322 cluster_loss: 1.3070 sup_con_loss: 0.4719 contrastive_loss: 5.2632 nll_loss: 0.0019 
2023-10-28 23:46:15.435 | INFO     | __main__:train:314 - Epoch: [70][800/1251]	 loss 4.63402	 cls_loss: 0.4803 cluster_loss: 1.2900 sup_con_loss: 0.5815 contrastive_loss: 5.2646 nll_loss: 0.0019 
2023-10-28 23:50:00.045 | INFO     | __main__:train:314 - Epoch: [70][900/1251]	 loss 4.68885	 cls_loss: 0.4340 cluster_loss: 1.3876 sup_con_loss: 0.5902 contrastive_loss: 5.2719 nll_loss: 0.0017 
2023-10-28 23:53:44.037 | INFO     | __main__:train:314 - Epoch: [70][1000/1251]	 loss 4.58356	 cls_loss: 0.5090 cluster_loss: 1.2927 sup_con_loss: 0.4038 contrastive_loss: 5.2636 nll_loss: 0.0024 
2023-10-28 23:57:28.283 | INFO     | __main__:train:314 - Epoch: [70][1100/1251]	 loss 4.58968	 cls_loss: 0.4953 cluster_loss: 1.2886 sup_con_loss: 0.4455 contrastive_loss: 5.2638 nll_loss: 0.0014 
2023-10-29 00:01:12.801 | INFO     | __main__:train:314 - Epoch: [70][1200/1251]	 loss 4.57100	 cls_loss: 0.4502 cluster_loss: 1.3372 sup_con_loss: 0.3316 contrastive_loss: 5.2700 nll_loss: 0.0028 
2023-10-29 00:03:05.630 | INFO     | __main__:train:319 - Train Epoch: 70 Avg Loss: 4.6193 
2023-10-29 00:03:05.635 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 00:20:24.924 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 70, Train ACC Unlabelled_v2: All 0.5998 | Old 0.7771 | New 0.5107
2023-10-29 00:20:25.234 | INFO     | __main__:main:205 - Train Accuracies: All 0.5998 | Old 0.7771 | New 0.5107
2023-10-29 00:20:30.473 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 00:20:44.953 | INFO     | __main__:train:314 - Epoch: [71][0/1251]	 loss 4.71073	 cls_loss: 0.5193 cluster_loss: 1.3377 sup_con_loss: 0.6635 contrastive_loss: 5.2694 nll_loss: 0.0021 
2023-10-29 00:24:31.307 | INFO     | __main__:train:314 - Epoch: [71][100/1251]	 loss 4.54739	 cls_loss: 0.4940 cluster_loss: 1.3188 sup_con_loss: 0.2580 contrastive_loss: 5.2687 nll_loss: 0.0024 
2023-10-29 00:28:16.107 | INFO     | __main__:train:314 - Epoch: [71][200/1251]	 loss 4.73311	 cls_loss: 0.5647 cluster_loss: 1.3527 sup_con_loss: 0.6561 contrastive_loss: 5.2683 nll_loss: 0.0021 
2023-10-29 00:32:00.571 | INFO     | __main__:train:314 - Epoch: [71][300/1251]	 loss 4.62825	 cls_loss: 0.5322 cluster_loss: 1.2955 sup_con_loss: 0.5017 contrastive_loss: 5.2652 nll_loss: 0.0019 
2023-10-29 00:35:45.087 | INFO     | __main__:train:314 - Epoch: [71][400/1251]	 loss 4.54818	 cls_loss: 0.3300 cluster_loss: 1.3398 sup_con_loss: 0.3871 contrastive_loss: 5.2676 nll_loss: 0.0024 
2023-10-29 00:39:29.555 | INFO     | __main__:train:314 - Epoch: [71][500/1251]	 loss 4.67187	 cls_loss: 0.6174 cluster_loss: 1.3794 sup_con_loss: 0.3710 contrastive_loss: 5.2736 nll_loss: 0.0015 
2023-10-29 00:43:14.872 | INFO     | __main__:train:314 - Epoch: [71][600/1251]	 loss 4.56800	 cls_loss: 0.4201 cluster_loss: 1.3219 sup_con_loss: 0.3880 contrastive_loss: 5.2645 nll_loss: 0.0040 
2023-10-29 00:47:00.137 | INFO     | __main__:train:314 - Epoch: [71][700/1251]	 loss 4.51460	 cls_loss: 0.4263 cluster_loss: 1.2862 sup_con_loss: 0.2997 contrastive_loss: 5.2653 nll_loss: 0.0020 
2023-10-29 00:50:46.217 | INFO     | __main__:train:314 - Epoch: [71][800/1251]	 loss 4.65239	 cls_loss: 0.5909 cluster_loss: 1.3761 sup_con_loss: 0.3406 contrastive_loss: 5.2759 nll_loss: 0.0026 
2023-10-29 00:54:30.034 | INFO     | __main__:train:314 - Epoch: [71][900/1251]	 loss 4.75261	 cls_loss: 0.6437 cluster_loss: 1.3778 sup_con_loss: 0.5806 contrastive_loss: 5.2704 nll_loss: 0.0028 
2023-10-29 00:58:14.572 | INFO     | __main__:train:314 - Epoch: [71][1000/1251]	 loss 4.62613	 cls_loss: 0.5509 cluster_loss: 1.3450 sup_con_loss: 0.3718 contrastive_loss: 5.2719 nll_loss: 0.0022 
2023-10-29 01:01:59.019 | INFO     | __main__:train:314 - Epoch: [71][1100/1251]	 loss 4.58969	 cls_loss: 0.3879 cluster_loss: 1.3527 sup_con_loss: 0.4243 contrastive_loss: 5.2681 nll_loss: 0.0019 
2023-10-29 01:05:44.113 | INFO     | __main__:train:314 - Epoch: [71][1200/1251]	 loss 4.56063	 cls_loss: 0.5032 cluster_loss: 1.3035 sup_con_loss: 0.3156 contrastive_loss: 5.2668 nll_loss: 0.0033 
2023-10-29 01:07:36.254 | INFO     | __main__:train:319 - Train Epoch: 71 Avg Loss: 4.6167 
2023-10-29 01:07:36.262 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 01:24:57.241 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 71, Train ACC Unlabelled_v2: All 0.6001 | Old 0.7763 | New 0.5115
2023-10-29 01:24:57.458 | INFO     | __main__:main:205 - Train Accuracies: All 0.6001 | Old 0.7763 | New 0.5115
2023-10-29 01:25:00.600 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 01:25:15.708 | INFO     | __main__:train:314 - Epoch: [72][0/1251]	 loss 4.55467	 cls_loss: 0.4019 cluster_loss: 1.3348 sup_con_loss: 0.3535 contrastive_loss: 5.2637 nll_loss: 0.0012 
2023-10-29 01:29:01.099 | INFO     | __main__:train:314 - Epoch: [72][100/1251]	 loss 4.50092	 cls_loss: 0.4033 cluster_loss: 1.3076 sup_con_loss: 0.2427 contrastive_loss: 5.2660 nll_loss: 0.0020 
2023-10-29 01:32:44.984 | INFO     | __main__:train:314 - Epoch: [72][200/1251]	 loss 4.69140	 cls_loss: 0.4852 cluster_loss: 1.3627 sup_con_loss: 0.5941 contrastive_loss: 5.2706 nll_loss: 0.0020 
2023-10-29 01:36:28.556 | INFO     | __main__:train:314 - Epoch: [72][300/1251]	 loss 4.62970	 cls_loss: 0.5158 cluster_loss: 1.3592 sup_con_loss: 0.3905 contrastive_loss: 5.2726 nll_loss: 0.0018 
2023-10-29 01:40:12.678 | INFO     | __main__:train:314 - Epoch: [72][400/1251]	 loss 4.63752	 cls_loss: 0.4888 cluster_loss: 1.3597 sup_con_loss: 0.4472 contrastive_loss: 5.2673 nll_loss: 0.0024 
2023-10-29 01:43:56.603 | INFO     | __main__:train:314 - Epoch: [72][500/1251]	 loss 4.53898	 cls_loss: 0.5064 cluster_loss: 1.2613 sup_con_loss: 0.3410 contrastive_loss: 5.2622 nll_loss: 0.0022 
2023-10-29 01:47:41.476 | INFO     | __main__:train:314 - Epoch: [72][600/1251]	 loss 4.75831	 cls_loss: 0.7377 cluster_loss: 1.3833 sup_con_loss: 0.4919 contrastive_loss: 5.2702 nll_loss: 0.0032 
2023-10-29 01:51:25.841 | INFO     | __main__:train:314 - Epoch: [72][700/1251]	 loss 4.63651	 cls_loss: 0.5537 cluster_loss: 1.3028 sup_con_loss: 0.4846 contrastive_loss: 5.2688 nll_loss: 0.0016 
2023-10-29 01:55:10.284 | INFO     | __main__:train:314 - Epoch: [72][800/1251]	 loss 4.59506	 cls_loss: 0.4900 cluster_loss: 1.3264 sup_con_loss: 0.3846 contrastive_loss: 5.2691 nll_loss: 0.0019 
2023-10-29 01:58:54.602 | INFO     | __main__:train:314 - Epoch: [72][900/1251]	 loss 4.64883	 cls_loss: 0.5840 cluster_loss: 1.3393 sup_con_loss: 0.4190 contrastive_loss: 5.2698 nll_loss: 0.0019 
2023-10-29 02:02:38.382 | INFO     | __main__:train:314 - Epoch: [72][1000/1251]	 loss 4.68010	 cls_loss: 0.6179 cluster_loss: 1.3230 sup_con_loss: 0.5091 contrastive_loss: 5.2663 nll_loss: 0.0027 
2023-10-29 02:06:23.197 | INFO     | __main__:train:314 - Epoch: [72][1100/1251]	 loss 4.53070	 cls_loss: 0.4525 cluster_loss: 1.3251 sup_con_loss: 0.2423 contrastive_loss: 5.2679 nll_loss: 0.0021 
2023-10-29 02:10:07.549 | INFO     | __main__:train:314 - Epoch: [72][1200/1251]	 loss 4.62248	 cls_loss: 0.5535 cluster_loss: 1.3498 sup_con_loss: 0.3561 contrastive_loss: 5.2686 nll_loss: 0.0021 
2023-10-29 02:11:59.725 | INFO     | __main__:train:319 - Train Epoch: 72 Avg Loss: 4.6153 
2023-10-29 02:11:59.734 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 02:29:14.205 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 72, Train ACC Unlabelled_v2: All 0.5994 | Old 0.7815 | New 0.5079
2023-10-29 02:29:14.476 | INFO     | __main__:main:205 - Train Accuracies: All 0.5994 | Old 0.7815 | New 0.5079
2023-10-29 02:29:18.963 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 02:29:33.428 | INFO     | __main__:train:314 - Epoch: [73][0/1251]	 loss 4.76047	 cls_loss: 0.6834 cluster_loss: 1.3562 sup_con_loss: 0.5927 contrastive_loss: 5.2744 nll_loss: 0.0039 
2023-10-29 02:33:19.038 | INFO     | __main__:train:314 - Epoch: [73][100/1251]	 loss 4.66900	 cls_loss: 0.5380 cluster_loss: 1.3575 sup_con_loss: 0.4938 contrastive_loss: 5.2677 nll_loss: 0.0015 
2023-10-29 02:37:02.572 | INFO     | __main__:train:314 - Epoch: [73][200/1251]	 loss 4.50622	 cls_loss: 0.3486 cluster_loss: 1.3001 sup_con_loss: 0.3252 contrastive_loss: 5.2658 nll_loss: 0.0026 
2023-10-29 02:40:47.467 | INFO     | __main__:train:314 - Epoch: [73][300/1251]	 loss 4.51921	 cls_loss: 0.3996 cluster_loss: 1.3009 sup_con_loss: 0.3147 contrastive_loss: 5.2630 nll_loss: 0.0027 
2023-10-29 02:44:31.417 | INFO     | __main__:train:314 - Epoch: [73][400/1251]	 loss 4.62685	 cls_loss: 0.5751 cluster_loss: 1.3219 sup_con_loss: 0.4028 contrastive_loss: 5.2672 nll_loss: 0.0016 
2023-10-29 02:48:19.472 | INFO     | __main__:train:314 - Epoch: [73][500/1251]	 loss 4.55949	 cls_loss: 0.3983 cluster_loss: 1.3435 sup_con_loss: 0.3425 contrastive_loss: 5.2683 nll_loss: 0.0026 
2023-10-29 02:52:03.879 | INFO     | __main__:train:314 - Epoch: [73][600/1251]	 loss 4.61725	 cls_loss: 0.4780 cluster_loss: 1.3539 sup_con_loss: 0.4128 contrastive_loss: 5.2681 nll_loss: 0.0012 
2023-10-29 02:55:47.246 | INFO     | __main__:train:314 - Epoch: [73][700/1251]	 loss 4.57537	 cls_loss: 0.3499 cluster_loss: 1.3518 sup_con_loss: 0.4221 contrastive_loss: 5.2694 nll_loss: 0.0014 
2023-10-29 02:59:30.522 | INFO     | __main__:train:314 - Epoch: [73][800/1251]	 loss 4.54033	 cls_loss: 0.4489 cluster_loss: 1.3001 sup_con_loss: 0.3275 contrastive_loss: 5.2628 nll_loss: 0.0027 
2023-10-29 03:03:14.075 | INFO     | __main__:train:314 - Epoch: [73][900/1251]	 loss 4.55430	 cls_loss: 0.4741 cluster_loss: 1.3372 sup_con_loss: 0.2539 contrastive_loss: 5.2725 nll_loss: 0.0032 
2023-10-29 03:06:59.127 | INFO     | __main__:train:314 - Epoch: [73][1000/1251]	 loss 4.81475	 cls_loss: 0.5461 cluster_loss: 1.4558 sup_con_loss: 0.7120 contrastive_loss: 5.2717 nll_loss: 0.0016 
2023-10-29 03:10:42.672 | INFO     | __main__:train:314 - Epoch: [73][1100/1251]	 loss 4.52151	 cls_loss: 0.4531 cluster_loss: 1.2854 sup_con_loss: 0.2977 contrastive_loss: 5.2636 nll_loss: 0.0019 
2023-10-29 03:14:27.516 | INFO     | __main__:train:314 - Epoch: [73][1200/1251]	 loss 4.70458	 cls_loss: 0.5802 cluster_loss: 1.4195 sup_con_loss: 0.4193 contrastive_loss: 5.2776 nll_loss: 0.0016 
2023-10-29 03:16:19.248 | INFO     | __main__:train:319 - Train Epoch: 73 Avg Loss: 4.6118 
2023-10-29 03:16:19.258 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 03:33:42.601 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 73, Train ACC Unlabelled_v2: All 0.6014 | Old 0.7785 | New 0.5123
2023-10-29 03:33:43.534 | INFO     | __main__:main:205 - Train Accuracies: All 0.6014 | Old 0.7785 | New 0.5123
2023-10-29 03:33:46.636 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 03:33:59.834 | INFO     | __main__:train:314 - Epoch: [74][0/1251]	 loss 4.67503	 cls_loss: 0.4387 cluster_loss: 1.4325 sup_con_loss: 0.4570 contrastive_loss: 5.2744 nll_loss: 0.0021 
2023-10-29 03:37:46.151 | INFO     | __main__:train:314 - Epoch: [74][100/1251]	 loss 4.66692	 cls_loss: 0.5624 cluster_loss: 1.3321 sup_con_loss: 0.5042 contrastive_loss: 5.2695 nll_loss: 0.0025 
2023-10-29 03:41:30.589 | INFO     | __main__:train:314 - Epoch: [74][200/1251]	 loss 4.63225	 cls_loss: 0.5654 cluster_loss: 1.2854 sup_con_loss: 0.5019 contrastive_loss: 5.2632 nll_loss: 0.0021 
2023-10-29 03:45:13.856 | INFO     | __main__:train:314 - Epoch: [74][300/1251]	 loss 4.55552	 cls_loss: 0.4147 cluster_loss: 1.3328 sup_con_loss: 0.3416 contrastive_loss: 5.2661 nll_loss: 0.0015 
2023-10-29 03:48:56.947 | INFO     | __main__:train:314 - Epoch: [74][400/1251]	 loss 4.61839	 cls_loss: 0.5842 cluster_loss: 1.2972 sup_con_loss: 0.4123 contrastive_loss: 5.2668 nll_loss: 0.0030 
2023-10-29 03:52:40.160 | INFO     | __main__:train:314 - Epoch: [74][500/1251]	 loss 4.57934	 cls_loss: 0.5729 cluster_loss: 1.3270 sup_con_loss: 0.2580 contrastive_loss: 5.2659 nll_loss: 0.0031 
2023-10-29 03:56:23.930 | INFO     | __main__:train:314 - Epoch: [74][600/1251]	 loss 4.59983	 cls_loss: 0.5222 cluster_loss: 1.3238 sup_con_loss: 0.3809 contrastive_loss: 5.2640 nll_loss: 0.0017 
2023-10-29 04:00:08.536 | INFO     | __main__:train:314 - Epoch: [74][700/1251]	 loss 4.59902	 cls_loss: 0.4617 cluster_loss: 1.3143 sup_con_loss: 0.4531 contrastive_loss: 5.2650 nll_loss: 0.0023 
2023-10-29 04:03:52.766 | INFO     | __main__:train:314 - Epoch: [74][800/1251]	 loss 4.66062	 cls_loss: 0.4098 cluster_loss: 1.4246 sup_con_loss: 0.4550 contrastive_loss: 5.2762 nll_loss: 0.0024 
2023-10-29 04:07:36.042 | INFO     | __main__:train:314 - Epoch: [74][900/1251]	 loss 4.55857	 cls_loss: 0.4932 cluster_loss: 1.3404 sup_con_loss: 0.2468 contrastive_loss: 5.2708 nll_loss: 0.0023 
2023-10-29 04:11:20.040 | INFO     | __main__:train:314 - Epoch: [74][1000/1251]	 loss 4.66210	 cls_loss: 0.5587 cluster_loss: 1.3902 sup_con_loss: 0.3856 contrastive_loss: 5.2703 nll_loss: 0.0023 
2023-10-29 04:15:03.972 | INFO     | __main__:train:314 - Epoch: [74][1100/1251]	 loss 4.63763	 cls_loss: 0.5800 cluster_loss: 1.3500 sup_con_loss: 0.3736 contrastive_loss: 5.2663 nll_loss: 0.0033 
2023-10-29 04:18:47.197 | INFO     | __main__:train:314 - Epoch: [74][1200/1251]	 loss 4.57438	 cls_loss: 0.5024 cluster_loss: 1.2989 sup_con_loss: 0.3630 contrastive_loss: 5.2695 nll_loss: 0.0020 
2023-10-29 04:20:38.461 | INFO     | __main__:train:319 - Train Epoch: 74 Avg Loss: 4.6106 
2023-10-29 04:20:38.464 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 04:37:58.741 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 74, Train ACC Unlabelled_v2: All 0.6010 | Old 0.7805 | New 0.5108
2023-10-29 04:37:58.939 | INFO     | __main__:main:205 - Train Accuracies: All 0.6010 | Old 0.7805 | New 0.5108
2023-10-29 04:38:03.850 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 04:38:18.373 | INFO     | __main__:train:314 - Epoch: [75][0/1251]	 loss 4.59275	 cls_loss: 0.4862 cluster_loss: 1.3195 sup_con_loss: 0.4078 contrastive_loss: 5.2624 nll_loss: 0.0016 
2023-10-29 04:42:02.416 | INFO     | __main__:train:314 - Epoch: [75][100/1251]	 loss 4.51107	 cls_loss: 0.4443 cluster_loss: 1.2968 sup_con_loss: 0.2512 contrastive_loss: 5.2658 nll_loss: 0.0020 
2023-10-29 04:45:46.697 | INFO     | __main__:train:314 - Epoch: [75][200/1251]	 loss 4.51447	 cls_loss: 0.4399 cluster_loss: 1.2789 sup_con_loss: 0.2966 contrastive_loss: 5.2659 nll_loss: 0.0026 
2023-10-29 04:49:29.835 | INFO     | __main__:train:314 - Epoch: [75][300/1251]	 loss 4.59166	 cls_loss: 0.4076 cluster_loss: 1.3744 sup_con_loss: 0.3701 contrastive_loss: 5.2685 nll_loss: 0.0016 
2023-10-29 04:53:14.249 | INFO     | __main__:train:314 - Epoch: [75][400/1251]	 loss 4.60014	 cls_loss: 0.5319 cluster_loss: 1.3239 sup_con_loss: 0.3668 contrastive_loss: 5.2666 nll_loss: 0.0017 
2023-10-29 04:56:58.721 | INFO     | __main__:train:314 - Epoch: [75][500/1251]	 loss 4.57828	 cls_loss: 0.4369 cluster_loss: 1.2812 sup_con_loss: 0.4809 contrastive_loss: 5.2655 nll_loss: 0.0017 
2023-10-29 05:00:41.472 | INFO     | __main__:train:314 - Epoch: [75][600/1251]	 loss 4.68942	 cls_loss: 0.5406 cluster_loss: 1.4023 sup_con_loss: 0.4536 contrastive_loss: 5.2739 nll_loss: 0.0019 
2023-10-29 05:04:26.811 | INFO     | __main__:train:314 - Epoch: [75][700/1251]	 loss 4.54181	 cls_loss: 0.4694 cluster_loss: 1.3233 sup_con_loss: 0.2565 contrastive_loss: 5.2703 nll_loss: 0.0019 
2023-10-29 05:08:10.808 | INFO     | __main__:train:314 - Epoch: [75][800/1251]	 loss 4.57590	 cls_loss: 0.5771 cluster_loss: 1.3151 sup_con_loss: 0.2679 contrastive_loss: 5.2661 nll_loss: 0.0023 
2023-10-29 05:11:55.488 | INFO     | __main__:train:314 - Epoch: [75][900/1251]	 loss 4.69518	 cls_loss: 0.4882 cluster_loss: 1.4308 sup_con_loss: 0.4697 contrastive_loss: 5.2730 nll_loss: 0.0024 
2023-10-29 05:15:40.450 | INFO     | __main__:train:314 - Epoch: [75][1000/1251]	 loss 4.65173	 cls_loss: 0.4289 cluster_loss: 1.3893 sup_con_loss: 0.4844 contrastive_loss: 5.2725 nll_loss: 0.0019 
2023-10-29 05:19:24.876 | INFO     | __main__:train:314 - Epoch: [75][1100/1251]	 loss 4.59881	 cls_loss: 0.4631 cluster_loss: 1.3498 sup_con_loss: 0.3769 contrastive_loss: 5.2685 nll_loss: 0.0029 
2023-10-29 05:23:08.797 | INFO     | __main__:train:314 - Epoch: [75][1200/1251]	 loss 4.64593	 cls_loss: 0.5219 cluster_loss: 1.3813 sup_con_loss: 0.3884 contrastive_loss: 5.2723 nll_loss: 0.0025 
2023-10-29 05:24:59.694 | INFO     | __main__:train:319 - Train Epoch: 75 Avg Loss: 4.6108 
2023-10-29 05:24:59.704 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 05:42:18.147 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 75, Train ACC Unlabelled_v2: All 0.6009 | Old 0.7799 | New 0.5109
2023-10-29 05:42:18.339 | INFO     | __main__:main:205 - Train Accuracies: All 0.6009 | Old 0.7799 | New 0.5109
2023-10-29 05:42:21.165 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 05:42:34.411 | INFO     | __main__:train:314 - Epoch: [76][0/1251]	 loss 4.59688	 cls_loss: 0.6400 cluster_loss: 1.2976 sup_con_loss: 0.2928 contrastive_loss: 5.2667 nll_loss: 0.0036 
2023-10-29 05:46:19.394 | INFO     | __main__:train:314 - Epoch: [76][100/1251]	 loss 4.60179	 cls_loss: 0.5538 cluster_loss: 1.2848 sup_con_loss: 0.4149 contrastive_loss: 5.2695 nll_loss: 0.0024 
2023-10-29 05:50:07.256 | INFO     | __main__:train:314 - Epoch: [76][200/1251]	 loss 4.64885	 cls_loss: 0.5069 cluster_loss: 1.3725 sup_con_loss: 0.4280 contrastive_loss: 5.2739 nll_loss: 0.0015 
2023-10-29 05:53:51.044 | INFO     | __main__:train:314 - Epoch: [76][300/1251]	 loss 4.59254	 cls_loss: 0.4629 cluster_loss: 1.3315 sup_con_loss: 0.3948 contrastive_loss: 5.2686 nll_loss: 0.0023 
2023-10-29 05:57:34.337 | INFO     | __main__:train:314 - Epoch: [76][400/1251]	 loss 4.67366	 cls_loss: 0.6262 cluster_loss: 1.3635 sup_con_loss: 0.4004 contrastive_loss: 5.2709 nll_loss: 0.0020 
2023-10-29 06:01:16.916 | INFO     | __main__:train:314 - Epoch: [76][500/1251]	 loss 4.53164	 cls_loss: 0.4136 cluster_loss: 1.3223 sup_con_loss: 0.2955 contrastive_loss: 5.2652 nll_loss: 0.0016 
2023-10-29 06:05:00.679 | INFO     | __main__:train:314 - Epoch: [76][600/1251]	 loss 4.60529	 cls_loss: 0.3844 cluster_loss: 1.3768 sup_con_loss: 0.4249 contrastive_loss: 5.2696 nll_loss: 0.0018 
2023-10-29 06:08:43.783 | INFO     | __main__:train:314 - Epoch: [76][700/1251]	 loss 4.50063	 cls_loss: 0.3756 cluster_loss: 1.2904 sup_con_loss: 0.2892 contrastive_loss: 5.2718 nll_loss: 0.0025 
2023-10-29 06:12:27.006 | INFO     | __main__:train:314 - Epoch: [76][800/1251]	 loss 4.63388	 cls_loss: 0.4491 cluster_loss: 1.3727 sup_con_loss: 0.4467 contrastive_loss: 5.2685 nll_loss: 0.0036 
2023-10-29 06:16:10.494 | INFO     | __main__:train:314 - Epoch: [76][900/1251]	 loss 4.64065	 cls_loss: 0.5539 cluster_loss: 1.3388 sup_con_loss: 0.4319 contrastive_loss: 5.2651 nll_loss: 0.0031 
2023-10-29 06:19:54.955 | INFO     | __main__:train:314 - Epoch: [76][1000/1251]	 loss 4.58423	 cls_loss: 0.5445 cluster_loss: 1.2995 sup_con_loss: 0.3544 contrastive_loss: 5.2654 nll_loss: 0.0024 
2023-10-29 06:23:38.370 | INFO     | __main__:train:314 - Epoch: [76][1100/1251]	 loss 4.49586	 cls_loss: 0.4416 cluster_loss: 1.2838 sup_con_loss: 0.2342 contrastive_loss: 5.2673 nll_loss: 0.0011 
2023-10-29 06:27:22.634 | INFO     | __main__:train:314 - Epoch: [76][1200/1251]	 loss 4.60093	 cls_loss: 0.4007 cluster_loss: 1.3306 sup_con_loss: 0.4906 contrastive_loss: 5.2656 nll_loss: 0.0015 
2023-10-29 06:29:14.304 | INFO     | __main__:train:319 - Train Epoch: 76 Avg Loss: 4.6069 
2023-10-29 06:29:14.313 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 06:46:37.409 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 76, Train ACC Unlabelled_v2: All 0.5995 | Old 0.7778 | New 0.5099
2023-10-29 06:46:37.620 | INFO     | __main__:main:205 - Train Accuracies: All 0.5995 | Old 0.7778 | New 0.5099
2023-10-29 06:46:40.732 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 06:46:56.636 | INFO     | __main__:train:314 - Epoch: [77][0/1251]	 loss 4.62819	 cls_loss: 0.5219 cluster_loss: 1.3833 sup_con_loss: 0.3364 contrastive_loss: 5.2715 nll_loss: 0.0022 
2023-10-29 06:50:44.513 | INFO     | __main__:train:314 - Epoch: [77][100/1251]	 loss 4.63636	 cls_loss: 0.4573 cluster_loss: 1.3563 sup_con_loss: 0.4837 contrastive_loss: 5.2668 nll_loss: 0.0020 
2023-10-29 06:54:30.527 | INFO     | __main__:train:314 - Epoch: [77][200/1251]	 loss 4.64111	 cls_loss: 0.5389 cluster_loss: 1.3651 sup_con_loss: 0.3834 contrastive_loss: 5.2755 nll_loss: 0.0019 
2023-10-29 06:58:24.082 | INFO     | __main__:train:314 - Epoch: [77][300/1251]	 loss 4.53834	 cls_loss: 0.4095 cluster_loss: 1.3080 sup_con_loss: 0.3424 contrastive_loss: 5.2663 nll_loss: 0.0019 
2023-10-29 07:02:16.890 | INFO     | __main__:train:314 - Epoch: [77][400/1251]	 loss 4.65749	 cls_loss: 0.5446 cluster_loss: 1.2994 sup_con_loss: 0.5580 contrastive_loss: 5.2682 nll_loss: 0.0026 
2023-10-29 07:06:08.003 | INFO     | __main__:train:314 - Epoch: [77][500/1251]	 loss 4.56621	 cls_loss: 0.4039 cluster_loss: 1.3646 sup_con_loss: 0.3129 contrastive_loss: 5.2706 nll_loss: 0.0024 
2023-10-29 07:09:52.486 | INFO     | __main__:train:314 - Epoch: [77][600/1251]	 loss 4.69384	 cls_loss: 0.5800 cluster_loss: 1.3896 sup_con_loss: 0.4595 contrastive_loss: 5.2670 nll_loss: 0.0032 
2023-10-29 07:13:41.468 | INFO     | __main__:train:314 - Epoch: [77][700/1251]	 loss 4.61212	 cls_loss: 0.4747 cluster_loss: 1.3398 sup_con_loss: 0.4295 contrastive_loss: 5.2672 nll_loss: 0.0011 
2023-10-29 07:17:25.747 | INFO     | __main__:train:314 - Epoch: [77][800/1251]	 loss 4.60792	 cls_loss: 0.5748 cluster_loss: 1.3061 sup_con_loss: 0.3771 contrastive_loss: 5.2673 nll_loss: 0.0021 
2023-10-29 07:21:12.443 | INFO     | __main__:train:314 - Epoch: [77][900/1251]	 loss 4.55744	 cls_loss: 0.5049 cluster_loss: 1.3438 sup_con_loss: 0.2296 contrastive_loss: 5.2692 nll_loss: 0.0019 
2023-10-29 07:24:57.176 | INFO     | __main__:train:314 - Epoch: [77][1000/1251]	 loss 4.59926	 cls_loss: 0.5382 cluster_loss: 1.3052 sup_con_loss: 0.3941 contrastive_loss: 5.2651 nll_loss: 0.0022 
2023-10-29 07:28:41.626 | INFO     | __main__:train:314 - Epoch: [77][1100/1251]	 loss 4.58273	 cls_loss: 0.4207 cluster_loss: 1.3369 sup_con_loss: 0.4010 contrastive_loss: 5.2685 nll_loss: 0.0016 
2023-10-29 07:32:29.422 | INFO     | __main__:train:314 - Epoch: [77][1200/1251]	 loss 4.63217	 cls_loss: 0.5825 cluster_loss: 1.3297 sup_con_loss: 0.3899 contrastive_loss: 5.2672 nll_loss: 0.0038 
2023-10-29 07:34:20.769 | INFO     | __main__:train:319 - Train Epoch: 77 Avg Loss: 4.6041 
2023-10-29 07:34:20.791 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 07:51:36.320 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 77, Train ACC Unlabelled_v2: All 0.6004 | Old 0.7795 | New 0.5103
2023-10-29 07:51:36.522 | INFO     | __main__:main:205 - Train Accuracies: All 0.6004 | Old 0.7795 | New 0.5103
2023-10-29 07:51:40.623 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 07:51:55.405 | INFO     | __main__:train:314 - Epoch: [78][0/1251]	 loss 4.61143	 cls_loss: 0.5153 cluster_loss: 1.3962 sup_con_loss: 0.2675 contrastive_loss: 5.2729 nll_loss: 0.0026 
2023-10-29 07:55:39.696 | INFO     | __main__:train:314 - Epoch: [78][100/1251]	 loss 4.49481	 cls_loss: 0.4178 cluster_loss: 1.2841 sup_con_loss: 0.2540 contrastive_loss: 5.2665 nll_loss: 0.0018 
2023-10-29 07:59:23.875 | INFO     | __main__:train:314 - Epoch: [78][200/1251]	 loss 4.65054	 cls_loss: 0.4938 cluster_loss: 1.3815 sup_con_loss: 0.4366 contrastive_loss: 5.2683 nll_loss: 0.0026 
2023-10-29 08:03:06.937 | INFO     | __main__:train:314 - Epoch: [78][300/1251]	 loss 4.66780	 cls_loss: 0.5129 cluster_loss: 1.3536 sup_con_loss: 0.5125 contrastive_loss: 5.2721 nll_loss: 0.0022 
2023-10-29 08:06:49.929 | INFO     | __main__:train:314 - Epoch: [78][400/1251]	 loss 4.69010	 cls_loss: 0.5631 cluster_loss: 1.3375 sup_con_loss: 0.5654 contrastive_loss: 5.2660 nll_loss: 0.0028 
2023-10-29 08:10:35.620 | INFO     | __main__:train:314 - Epoch: [78][500/1251]	 loss 4.57910	 cls_loss: 0.4442 cluster_loss: 1.3507 sup_con_loss: 0.3414 contrastive_loss: 5.2680 nll_loss: 0.0019 
2023-10-29 08:14:22.755 | INFO     | __main__:train:314 - Epoch: [78][600/1251]	 loss 4.53929	 cls_loss: 0.3684 cluster_loss: 1.3115 sup_con_loss: 0.3786 contrastive_loss: 5.2677 nll_loss: 0.0013 
2023-10-29 08:18:06.179 | INFO     | __main__:train:314 - Epoch: [78][700/1251]	 loss 4.64755	 cls_loss: 0.5095 cluster_loss: 1.3814 sup_con_loss: 0.4054 contrastive_loss: 5.2708 nll_loss: 0.0034 
2023-10-29 08:21:51.226 | INFO     | __main__:train:314 - Epoch: [78][800/1251]	 loss 4.65129	 cls_loss: 0.5415 cluster_loss: 1.3873 sup_con_loss: 0.3775 contrastive_loss: 5.2716 nll_loss: 0.0014 
2023-10-29 08:25:34.990 | INFO     | __main__:train:314 - Epoch: [78][900/1251]	 loss 4.65557	 cls_loss: 0.6327 cluster_loss: 1.3110 sup_con_loss: 0.4455 contrastive_loss: 5.2682 nll_loss: 0.0018 
2023-10-29 08:29:19.610 | INFO     | __main__:train:314 - Epoch: [78][1000/1251]	 loss 4.52786	 cls_loss: 0.4464 cluster_loss: 1.3264 sup_con_loss: 0.2339 contrastive_loss: 5.2704 nll_loss: 0.0019 
2023-10-29 08:33:02.309 | INFO     | __main__:train:314 - Epoch: [78][1100/1251]	 loss 4.47953	 cls_loss: 0.3801 cluster_loss: 1.2921 sup_con_loss: 0.2374 contrastive_loss: 5.2634 nll_loss: 0.0023 
2023-10-29 08:36:46.172 | INFO     | __main__:train:314 - Epoch: [78][1200/1251]	 loss 4.64911	 cls_loss: 0.4615 cluster_loss: 1.4064 sup_con_loss: 0.4194 contrastive_loss: 5.2694 nll_loss: 0.0015 
2023-10-29 08:38:37.598 | INFO     | __main__:train:319 - Train Epoch: 78 Avg Loss: 4.6049 
2023-10-29 08:38:37.608 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 08:55:46.906 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 78, Train ACC Unlabelled_v2: All 0.6019 | Old 0.7777 | New 0.5136
2023-10-29 08:55:47.098 | INFO     | __main__:main:205 - Train Accuracies: All 0.6019 | Old 0.7777 | New 0.5136
2023-10-29 08:55:51.014 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 08:56:09.272 | INFO     | __main__:train:314 - Epoch: [79][0/1251]	 loss 4.59458	 cls_loss: 0.4754 cluster_loss: 1.3800 sup_con_loss: 0.2921 contrastive_loss: 5.2720 nll_loss: 0.0021 
2023-10-29 08:59:56.000 | INFO     | __main__:train:314 - Epoch: [79][100/1251]	 loss 4.65739	 cls_loss: 0.4701 cluster_loss: 1.4227 sup_con_loss: 0.3931 contrastive_loss: 5.2727 nll_loss: 0.0032 
2023-10-29 09:03:41.390 | INFO     | __main__:train:314 - Epoch: [79][200/1251]	 loss 4.53854	 cls_loss: 0.4149 cluster_loss: 1.3053 sup_con_loss: 0.3334 contrastive_loss: 5.2714 nll_loss: 0.0018 
2023-10-29 09:07:26.110 | INFO     | __main__:train:314 - Epoch: [79][300/1251]	 loss 4.54051	 cls_loss: 0.4720 cluster_loss: 1.2874 sup_con_loss: 0.3286 contrastive_loss: 5.2642 nll_loss: 0.0017 
2023-10-29 09:11:10.205 | INFO     | __main__:train:314 - Epoch: [79][400/1251]	 loss 4.57168	 cls_loss: 0.4191 cluster_loss: 1.3187 sup_con_loss: 0.4088 contrastive_loss: 5.2649 nll_loss: 0.0026 
2023-10-29 09:14:55.478 | INFO     | __main__:train:314 - Epoch: [79][500/1251]	 loss 4.64460	 cls_loss: 0.5299 cluster_loss: 1.3344 sup_con_loss: 0.4723 contrastive_loss: 5.2686 nll_loss: 0.0019 
2023-10-29 09:18:39.652 | INFO     | __main__:train:314 - Epoch: [79][600/1251]	 loss 4.65785	 cls_loss: 0.4846 cluster_loss: 1.3478 sup_con_loss: 0.5286 contrastive_loss: 5.2683 nll_loss: 0.0028 
2023-10-29 09:22:24.172 | INFO     | __main__:train:314 - Epoch: [79][700/1251]	 loss 4.52162	 cls_loss: 0.4222 cluster_loss: 1.2686 sup_con_loss: 0.3498 contrastive_loss: 5.2694 nll_loss: 0.0017 
2023-10-29 09:26:07.316 | INFO     | __main__:train:314 - Epoch: [79][800/1251]	 loss 4.67292	 cls_loss: 0.5622 cluster_loss: 1.3744 sup_con_loss: 0.4454 contrastive_loss: 5.2686 nll_loss: 0.0023 
2023-10-29 09:29:51.237 | INFO     | __main__:train:314 - Epoch: [79][900/1251]	 loss 4.59590	 cls_loss: 0.4476 cluster_loss: 1.3786 sup_con_loss: 0.3260 contrastive_loss: 5.2718 nll_loss: 0.0024 
2023-10-29 09:33:36.015 | INFO     | __main__:train:314 - Epoch: [79][1000/1251]	 loss 4.61330	 cls_loss: 0.5169 cluster_loss: 1.3336 sup_con_loss: 0.4040 contrastive_loss: 5.2659 nll_loss: 0.0013 
2023-10-29 09:37:20.823 | INFO     | __main__:train:314 - Epoch: [79][1100/1251]	 loss 4.60627	 cls_loss: 0.4338 cluster_loss: 1.2980 sup_con_loss: 0.5348 contrastive_loss: 5.2619 nll_loss: 0.0033 
2023-10-29 09:41:05.895 | INFO     | __main__:train:314 - Epoch: [79][1200/1251]	 loss 4.56346	 cls_loss: 0.4311 cluster_loss: 1.3598 sup_con_loss: 0.2848 contrastive_loss: 5.2718 nll_loss: 0.0024 
2023-10-29 09:42:57.467 | INFO     | __main__:train:319 - Train Epoch: 79 Avg Loss: 4.6031 
2023-10-29 09:42:57.470 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 10:00:24.313 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 79, Train ACC Unlabelled_v2: All 0.6004 | Old 0.7797 | New 0.5102
2023-10-29 10:00:24.553 | INFO     | __main__:main:205 - Train Accuracies: All 0.6004 | Old 0.7797 | New 0.5102
2023-10-29 10:00:27.444 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 10:00:41.806 | INFO     | __main__:train:314 - Epoch: [80][0/1251]	 loss 4.57824	 cls_loss: 0.4138 cluster_loss: 1.3722 sup_con_loss: 0.3273 contrastive_loss: 5.2697 nll_loss: 0.0017 
2023-10-29 10:04:27.765 | INFO     | __main__:train:314 - Epoch: [80][100/1251]	 loss 4.58482	 cls_loss: 0.4473 cluster_loss: 1.4042 sup_con_loss: 0.2368 contrastive_loss: 5.2756 nll_loss: 0.0035 
2023-10-29 10:08:12.110 | INFO     | __main__:train:314 - Epoch: [80][200/1251]	 loss 4.58743	 cls_loss: 0.4144 cluster_loss: 1.3491 sup_con_loss: 0.3982 contrastive_loss: 5.2682 nll_loss: 0.0018 
2023-10-29 10:11:58.589 | INFO     | __main__:train:314 - Epoch: [80][300/1251]	 loss 4.48131	 cls_loss: 0.3928 cluster_loss: 1.2645 sup_con_loss: 0.2862 contrastive_loss: 5.2620 nll_loss: 0.0014 
2023-10-29 10:15:42.451 | INFO     | __main__:train:314 - Epoch: [80][400/1251]	 loss 4.59131	 cls_loss: 0.5061 cluster_loss: 1.3409 sup_con_loss: 0.3247 contrastive_loss: 5.2711 nll_loss: 0.0028 
2023-10-29 10:19:26.129 | INFO     | __main__:train:314 - Epoch: [80][500/1251]	 loss 4.66579	 cls_loss: 0.5234 cluster_loss: 1.3980 sup_con_loss: 0.4134 contrastive_loss: 5.2720 nll_loss: 0.0024 
2023-10-29 10:23:14.654 | INFO     | __main__:train:314 - Epoch: [80][600/1251]	 loss 4.71238	 cls_loss: 0.5527 cluster_loss: 1.4004 sup_con_loss: 0.5105 contrastive_loss: 5.2711 nll_loss: 0.0038 
2023-10-29 10:26:58.220 | INFO     | __main__:train:314 - Epoch: [80][700/1251]	 loss 4.56698	 cls_loss: 0.4115 cluster_loss: 1.3233 sup_con_loss: 0.3924 contrastive_loss: 5.2669 nll_loss: 0.0020 
2023-10-29 10:30:43.646 | INFO     | __main__:train:314 - Epoch: [80][800/1251]	 loss 4.60879	 cls_loss: 0.4951 cluster_loss: 1.3685 sup_con_loss: 0.3417 contrastive_loss: 5.2698 nll_loss: 0.0010 
2023-10-29 10:34:29.175 | INFO     | __main__:train:314 - Epoch: [80][900/1251]	 loss 4.60824	 cls_loss: 0.5059 cluster_loss: 1.3265 sup_con_loss: 0.4102 contrastive_loss: 5.2670 nll_loss: 0.0018 
2023-10-29 10:38:13.767 | INFO     | __main__:train:314 - Epoch: [80][1000/1251]	 loss 4.65408	 cls_loss: 0.4786 cluster_loss: 1.4290 sup_con_loss: 0.3680 contrastive_loss: 5.2725 nll_loss: 0.0018 
2023-10-29 10:42:00.337 | INFO     | __main__:train:314 - Epoch: [80][1100/1251]	 loss 4.61836	 cls_loss: 0.4452 cluster_loss: 1.2809 sup_con_loss: 0.5873 contrastive_loss: 5.2665 nll_loss: 0.0011 
2023-10-29 10:45:45.054 | INFO     | __main__:train:314 - Epoch: [80][1200/1251]	 loss 4.57611	 cls_loss: 0.4704 cluster_loss: 1.3286 sup_con_loss: 0.3539 contrastive_loss: 5.2657 nll_loss: 0.0014 
2023-10-29 10:47:36.370 | INFO     | __main__:train:319 - Train Epoch: 80 Avg Loss: 4.6019 
2023-10-29 10:47:36.378 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 11:05:10.929 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 80, Train ACC Unlabelled_v2: All 0.6009 | Old 0.7796 | New 0.5112
2023-10-29 11:05:11.187 | INFO     | __main__:main:205 - Train Accuracies: All 0.6009 | Old 0.7796 | New 0.5112
2023-10-29 11:05:14.232 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 11:05:27.336 | INFO     | __main__:train:314 - Epoch: [81][0/1251]	 loss 4.44508	 cls_loss: 0.3657 cluster_loss: 1.2650 sup_con_loss: 0.2036 contrastive_loss: 5.2648 nll_loss: 0.0014 
2023-10-29 11:09:13.262 | INFO     | __main__:train:314 - Epoch: [81][100/1251]	 loss 4.71380	 cls_loss: 0.5648 cluster_loss: 1.4097 sup_con_loss: 0.4833 contrastive_loss: 5.2757 nll_loss: 0.0015 
2023-10-29 11:12:57.534 | INFO     | __main__:train:314 - Epoch: [81][200/1251]	 loss 4.57497	 cls_loss: 0.4263 cluster_loss: 1.3452 sup_con_loss: 0.3608 contrastive_loss: 5.2681 nll_loss: 0.0008 
2023-10-29 11:16:42.089 | INFO     | __main__:train:314 - Epoch: [81][300/1251]	 loss 4.61320	 cls_loss: 0.4904 cluster_loss: 1.3530 sup_con_loss: 0.3818 contrastive_loss: 5.2697 nll_loss: 0.0032 
2023-10-29 11:20:25.674 | INFO     | __main__:train:314 - Epoch: [81][400/1251]	 loss 4.61407	 cls_loss: 0.4598 cluster_loss: 1.3295 sup_con_loss: 0.4681 contrastive_loss: 5.2667 nll_loss: 0.0018 
2023-10-29 11:24:13.090 | INFO     | __main__:train:314 - Epoch: [81][500/1251]	 loss 4.62091	 cls_loss: 0.5372 cluster_loss: 1.3124 sup_con_loss: 0.4484 contrastive_loss: 5.2631 nll_loss: 0.0018 
2023-10-29 11:27:56.579 | INFO     | __main__:train:314 - Epoch: [81][600/1251]	 loss 4.66761	 cls_loss: 0.5576 cluster_loss: 1.3535 sup_con_loss: 0.4770 contrastive_loss: 5.2680 nll_loss: 0.0015 
2023-10-29 11:31:42.217 | INFO     | __main__:train:314 - Epoch: [81][700/1251]	 loss 4.61462	 cls_loss: 0.5036 cluster_loss: 1.3505 sup_con_loss: 0.3786 contrastive_loss: 5.2702 nll_loss: 0.0024 
2023-10-29 11:35:27.479 | INFO     | __main__:train:314 - Epoch: [81][800/1251]	 loss 4.46988	 cls_loss: 0.3939 cluster_loss: 1.2378 sup_con_loss: 0.2939 contrastive_loss: 5.2655 nll_loss: 0.0020 
2023-10-29 11:39:13.139 | INFO     | __main__:train:314 - Epoch: [81][900/1251]	 loss 4.65279	 cls_loss: 0.4532 cluster_loss: 1.3966 sup_con_loss: 0.4392 contrastive_loss: 5.2765 nll_loss: 0.0029 
2023-10-29 11:42:57.535 | INFO     | __main__:train:314 - Epoch: [81][1000/1251]	 loss 4.56481	 cls_loss: 0.4419 cluster_loss: 1.3276 sup_con_loss: 0.3476 contrastive_loss: 5.2667 nll_loss: 0.0022 
2023-10-29 11:46:42.156 | INFO     | __main__:train:314 - Epoch: [81][1100/1251]	 loss 4.63085	 cls_loss: 0.5665 cluster_loss: 1.2798 sup_con_loss: 0.5071 contrastive_loss: 5.2618 nll_loss: 0.0031 
2023-10-29 11:50:29.223 | INFO     | __main__:train:314 - Epoch: [81][1200/1251]	 loss 4.61698	 cls_loss: 0.5280 cluster_loss: 1.3137 sup_con_loss: 0.4353 contrastive_loss: 5.2679 nll_loss: 0.0018 
2023-10-29 11:52:20.525 | INFO     | __main__:train:319 - Train Epoch: 81 Avg Loss: 4.5991 
2023-10-29 11:52:20.529 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 12:09:52.275 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 81, Train ACC Unlabelled_v2: All 0.6015 | Old 0.7731 | New 0.5152
2023-10-29 12:09:52.509 | INFO     | __main__:main:205 - Train Accuracies: All 0.6015 | Old 0.7731 | New 0.5152
2023-10-29 12:09:56.832 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 12:10:10.466 | INFO     | __main__:train:314 - Epoch: [82][0/1251]	 loss 4.65750	 cls_loss: 0.6569 cluster_loss: 1.3452 sup_con_loss: 0.3622 contrastive_loss: 5.2678 nll_loss: 0.0024 
2023-10-29 12:13:55.962 | INFO     | __main__:train:314 - Epoch: [82][100/1251]	 loss 4.62670	 cls_loss: 0.4428 cluster_loss: 1.3236 sup_con_loss: 0.5234 contrastive_loss: 5.2703 nll_loss: 0.0025 
2023-10-29 12:17:40.754 | INFO     | __main__:train:314 - Epoch: [82][200/1251]	 loss 4.66014	 cls_loss: 0.3728 cluster_loss: 1.3890 sup_con_loss: 0.5714 contrastive_loss: 5.2699 nll_loss: 0.0014 
2023-10-29 12:21:24.927 | INFO     | __main__:train:314 - Epoch: [82][300/1251]	 loss 4.68160	 cls_loss: 0.5541 cluster_loss: 1.3331 sup_con_loss: 0.5591 contrastive_loss: 5.2665 nll_loss: 0.0023 
2023-10-29 12:25:11.167 | INFO     | __main__:train:314 - Epoch: [82][400/1251]	 loss 4.62455	 cls_loss: 0.5135 cluster_loss: 1.3669 sup_con_loss: 0.3631 contrastive_loss: 5.2726 nll_loss: 0.0020 
2023-10-29 12:28:55.241 | INFO     | __main__:train:314 - Epoch: [82][500/1251]	 loss 4.50331	 cls_loss: 0.3795 cluster_loss: 1.3218 sup_con_loss: 0.2425 contrastive_loss: 5.2668 nll_loss: 0.0030 
2023-10-29 12:32:41.272 | INFO     | __main__:train:314 - Epoch: [82][600/1251]	 loss 4.48460	 cls_loss: 0.4371 cluster_loss: 1.2565 sup_con_loss: 0.2604 contrastive_loss: 5.2654 nll_loss: 0.0013 
2023-10-29 12:36:24.411 | INFO     | __main__:train:314 - Epoch: [82][700/1251]	 loss 4.55317	 cls_loss: 0.4586 cluster_loss: 1.2583 sup_con_loss: 0.4202 contrastive_loss: 5.2687 nll_loss: 0.0031 
2023-10-29 12:40:09.086 | INFO     | __main__:train:314 - Epoch: [82][800/1251]	 loss 4.62956	 cls_loss: 0.5816 cluster_loss: 1.2949 sup_con_loss: 0.4542 contrastive_loss: 5.2659 nll_loss: 0.0026 
2023-10-29 12:43:52.869 | INFO     | __main__:train:314 - Epoch: [82][900/1251]	 loss 4.53844	 cls_loss: 0.4389 cluster_loss: 1.3347 sup_con_loss: 0.2644 contrastive_loss: 5.2661 nll_loss: 0.0017 
2023-10-29 12:47:36.836 | INFO     | __main__:train:314 - Epoch: [82][1000/1251]	 loss 4.57589	 cls_loss: 0.4059 cluster_loss: 1.3469 sup_con_loss: 0.3691 contrastive_loss: 5.2729 nll_loss: 0.0018 
2023-10-29 12:51:21.394 | INFO     | __main__:train:314 - Epoch: [82][1100/1251]	 loss 4.61493	 cls_loss: 0.5195 cluster_loss: 1.3664 sup_con_loss: 0.3366 contrastive_loss: 5.2691 nll_loss: 0.0022 
2023-10-29 12:55:05.506 | INFO     | __main__:train:314 - Epoch: [82][1200/1251]	 loss 4.56684	 cls_loss: 0.4362 cluster_loss: 1.3564 sup_con_loss: 0.2992 contrastive_loss: 5.2698 nll_loss: 0.0025 
2023-10-29 12:56:57.518 | INFO     | __main__:train:319 - Train Epoch: 82 Avg Loss: 4.5990 
2023-10-29 12:56:57.524 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 13:14:22.786 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 82, Train ACC Unlabelled_v2: All 0.6011 | Old 0.7765 | New 0.5130
2023-10-29 13:14:23.476 | INFO     | __main__:main:205 - Train Accuracies: All 0.6011 | Old 0.7765 | New 0.5130
2023-10-29 13:14:28.315 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 13:14:42.074 | INFO     | __main__:train:314 - Epoch: [83][0/1251]	 loss 4.73012	 cls_loss: 0.5720 cluster_loss: 1.4393 sup_con_loss: 0.4617 contrastive_loss: 5.2788 nll_loss: 0.0016 
2023-10-29 13:18:26.998 | INFO     | __main__:train:314 - Epoch: [83][100/1251]	 loss 4.56954	 cls_loss: 0.4585 cluster_loss: 1.3476 sup_con_loss: 0.3073 contrastive_loss: 5.2686 nll_loss: 0.0010 
2023-10-29 13:22:11.700 | INFO     | __main__:train:314 - Epoch: [83][200/1251]	 loss 4.49899	 cls_loss: 0.4204 cluster_loss: 1.2598 sup_con_loss: 0.3060 contrastive_loss: 5.2681 nll_loss: 0.0016 
2023-10-29 13:25:56.350 | INFO     | __main__:train:314 - Epoch: [83][300/1251]	 loss 4.51125	 cls_loss: 0.3664 cluster_loss: 1.3325 sup_con_loss: 0.2604 contrastive_loss: 5.2672 nll_loss: 0.0020 
2023-10-29 13:29:41.437 | INFO     | __main__:train:314 - Epoch: [83][400/1251]	 loss 4.52935	 cls_loss: 0.4203 cluster_loss: 1.3061 sup_con_loss: 0.3064 contrastive_loss: 5.2674 nll_loss: 0.0022 
2023-10-29 13:33:26.177 | INFO     | __main__:train:314 - Epoch: [83][500/1251]	 loss 4.59002	 cls_loss: 0.4318 cluster_loss: 1.3379 sup_con_loss: 0.4098 contrastive_loss: 5.2669 nll_loss: 0.0023 
2023-10-29 13:37:09.992 | INFO     | __main__:train:314 - Epoch: [83][600/1251]	 loss 4.47619	 cls_loss: 0.4845 cluster_loss: 1.2409 sup_con_loss: 0.2210 contrastive_loss: 5.2637 nll_loss: 0.0012 
2023-10-29 13:40:54.459 | INFO     | __main__:train:314 - Epoch: [83][700/1251]	 loss 4.67684	 cls_loss: 0.5794 cluster_loss: 1.3845 sup_con_loss: 0.4171 contrastive_loss: 5.2714 nll_loss: 0.0018 
2023-10-29 13:44:38.947 | INFO     | __main__:train:314 - Epoch: [83][800/1251]	 loss 4.57735	 cls_loss: 0.4201 cluster_loss: 1.3521 sup_con_loss: 0.3543 contrastive_loss: 5.2697 nll_loss: 0.0021 
2023-10-29 13:48:25.452 | INFO     | __main__:train:314 - Epoch: [83][900/1251]	 loss 4.54981	 cls_loss: 0.4729 cluster_loss: 1.3045 sup_con_loss: 0.3197 contrastive_loss: 5.2653 nll_loss: 0.0020 
2023-10-29 13:52:10.287 | INFO     | __main__:train:314 - Epoch: [83][1000/1251]	 loss 4.64244	 cls_loss: 0.4902 cluster_loss: 1.3624 sup_con_loss: 0.4449 contrastive_loss: 5.2723 nll_loss: 0.0026 
2023-10-29 13:55:55.319 | INFO     | __main__:train:314 - Epoch: [83][1100/1251]	 loss 4.57021	 cls_loss: 0.4247 cluster_loss: 1.3231 sup_con_loss: 0.3818 contrastive_loss: 5.2715 nll_loss: 0.0014 
2023-10-29 13:59:38.534 | INFO     | __main__:train:314 - Epoch: [83][1200/1251]	 loss 4.63622	 cls_loss: 0.5218 cluster_loss: 1.2897 sup_con_loss: 0.5499 contrastive_loss: 5.2622 nll_loss: 0.0024 
2023-10-29 14:01:30.170 | INFO     | __main__:train:319 - Train Epoch: 83 Avg Loss: 4.5954 
2023-10-29 14:01:30.178 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 14:18:51.214 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 83, Train ACC Unlabelled_v2: All 0.6006 | Old 0.7757 | New 0.5125
2023-10-29 14:18:51.439 | INFO     | __main__:main:205 - Train Accuracies: All 0.6006 | Old 0.7757 | New 0.5125
2023-10-29 14:18:54.617 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 14:19:08.821 | INFO     | __main__:train:314 - Epoch: [84][0/1251]	 loss 4.51769	 cls_loss: 0.4513 cluster_loss: 1.3009 sup_con_loss: 0.2551 contrastive_loss: 5.2674 nll_loss: 0.0010 
2023-10-29 14:22:53.064 | INFO     | __main__:train:314 - Epoch: [84][100/1251]	 loss 4.64478	 cls_loss: 0.4619 cluster_loss: 1.3594 sup_con_loss: 0.4927 contrastive_loss: 5.2696 nll_loss: 0.0018 
2023-10-29 14:26:38.199 | INFO     | __main__:train:314 - Epoch: [84][200/1251]	 loss 4.55946	 cls_loss: 0.4251 cluster_loss: 1.3573 sup_con_loss: 0.2813 contrastive_loss: 5.2732 nll_loss: 0.0024 
2023-10-29 14:30:22.174 | INFO     | __main__:train:314 - Epoch: [84][300/1251]	 loss 4.50232	 cls_loss: 0.4109 cluster_loss: 1.3175 sup_con_loss: 0.2203 contrastive_loss: 5.2666 nll_loss: 0.0017 
2023-10-29 14:34:07.657 | INFO     | __main__:train:314 - Epoch: [84][400/1251]	 loss 4.49439	 cls_loss: 0.3845 cluster_loss: 1.3423 sup_con_loss: 0.1706 contrastive_loss: 5.2695 nll_loss: 0.0024 
2023-10-29 14:37:50.839 | INFO     | __main__:train:314 - Epoch: [84][500/1251]	 loss 4.58660	 cls_loss: 0.4837 cluster_loss: 1.3483 sup_con_loss: 0.3297 contrastive_loss: 5.2685 nll_loss: 0.0010 
2023-10-29 14:41:34.653 | INFO     | __main__:train:314 - Epoch: [84][600/1251]	 loss 4.61335	 cls_loss: 0.4621 cluster_loss: 1.4010 sup_con_loss: 0.3166 contrastive_loss: 5.2747 nll_loss: 0.0016 
2023-10-29 14:45:18.050 | INFO     | __main__:train:314 - Epoch: [84][700/1251]	 loss 4.58656	 cls_loss: 0.3809 cluster_loss: 1.3595 sup_con_loss: 0.4149 contrastive_loss: 5.2635 nll_loss: 0.0030 
2023-10-29 14:49:02.880 | INFO     | __main__:train:314 - Epoch: [84][800/1251]	 loss 4.50244	 cls_loss: 0.3942 cluster_loss: 1.3285 sup_con_loss: 0.2224 contrastive_loss: 5.2641 nll_loss: 0.0014 
2023-10-29 14:52:46.924 | INFO     | __main__:train:314 - Epoch: [84][900/1251]	 loss 4.64394	 cls_loss: 0.4808 cluster_loss: 1.3424 sup_con_loss: 0.5101 contrastive_loss: 5.2662 nll_loss: 0.0015 
2023-10-29 14:56:32.645 | INFO     | __main__:train:314 - Epoch: [84][1000/1251]	 loss 4.57063	 cls_loss: 0.4960 cluster_loss: 1.2977 sup_con_loss: 0.3636 contrastive_loss: 5.2687 nll_loss: 0.0016 
2023-10-29 15:00:16.369 | INFO     | __main__:train:314 - Epoch: [84][1100/1251]	 loss 4.52172	 cls_loss: 0.4837 cluster_loss: 1.3160 sup_con_loss: 0.1934 contrastive_loss: 5.2722 nll_loss: 0.0024 
2023-10-29 15:04:00.363 | INFO     | __main__:train:314 - Epoch: [84][1200/1251]	 loss 4.61503	 cls_loss: 0.4812 cluster_loss: 1.3661 sup_con_loss: 0.3802 contrastive_loss: 5.2669 nll_loss: 0.0021 
2023-10-29 15:05:52.079 | INFO     | __main__:train:319 - Train Epoch: 84 Avg Loss: 4.5922 
2023-10-29 15:05:52.085 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 15:23:44.324 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 84, Train ACC Unlabelled_v2: All 0.6007 | Old 0.7769 | New 0.5121
2023-10-29 15:23:44.574 | INFO     | __main__:main:205 - Train Accuracies: All 0.6007 | Old 0.7769 | New 0.5121
2023-10-29 15:23:48.686 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 15:24:01.988 | INFO     | __main__:train:314 - Epoch: [85][0/1251]	 loss 4.60845	 cls_loss: 0.5126 cluster_loss: 1.3040 sup_con_loss: 0.4441 contrastive_loss: 5.2672 nll_loss: 0.0023 
2023-10-29 15:27:46.104 | INFO     | __main__:train:314 - Epoch: [85][100/1251]	 loss 4.54085	 cls_loss: 0.4392 cluster_loss: 1.3343 sup_con_loss: 0.2679 contrastive_loss: 5.2686 nll_loss: 0.0015 
2023-10-29 15:31:29.656 | INFO     | __main__:train:314 - Epoch: [85][200/1251]	 loss 4.48590	 cls_loss: 0.3909 cluster_loss: 1.2878 sup_con_loss: 0.2523 contrastive_loss: 5.2638 nll_loss: 0.0022 
2023-10-29 15:35:15.755 | INFO     | __main__:train:314 - Epoch: [85][300/1251]	 loss 4.55202	 cls_loss: 0.4224 cluster_loss: 1.3010 sup_con_loss: 0.3791 contrastive_loss: 5.2666 nll_loss: 0.0025 
2023-10-29 15:38:59.327 | INFO     | __main__:train:314 - Epoch: [85][400/1251]	 loss 4.69020	 cls_loss: 0.5589 cluster_loss: 1.3621 sup_con_loss: 0.5194 contrastive_loss: 5.2695 nll_loss: 0.0022 
2023-10-29 15:42:43.921 | INFO     | __main__:train:314 - Epoch: [85][500/1251]	 loss 4.57482	 cls_loss: 0.4753 cluster_loss: 1.3347 sup_con_loss: 0.3375 contrastive_loss: 5.2633 nll_loss: 0.0016 
2023-10-29 15:46:29.046 | INFO     | __main__:train:314 - Epoch: [85][600/1251]	 loss 4.55351	 cls_loss: 0.4126 cluster_loss: 1.2996 sup_con_loss: 0.3924 contrastive_loss: 5.2661 nll_loss: 0.0040 
2023-10-29 15:50:13.160 | INFO     | __main__:train:314 - Epoch: [85][700/1251]	 loss 4.57167	 cls_loss: 0.4232 cluster_loss: 1.3415 sup_con_loss: 0.3658 contrastive_loss: 5.2648 nll_loss: 0.0014 
2023-10-29 15:53:57.839 | INFO     | __main__:train:314 - Epoch: [85][800/1251]	 loss 4.64218	 cls_loss: 0.5133 cluster_loss: 1.3643 sup_con_loss: 0.4193 contrastive_loss: 5.2720 nll_loss: 0.0021 
2023-10-29 15:57:41.285 | INFO     | __main__:train:314 - Epoch: [85][900/1251]	 loss 4.59252	 cls_loss: 0.4634 cluster_loss: 1.3595 sup_con_loss: 0.3437 contrastive_loss: 5.2693 nll_loss: 0.0013 
2023-10-29 16:01:25.094 | INFO     | __main__:train:314 - Epoch: [85][1000/1251]	 loss 4.60596	 cls_loss: 0.4579 cluster_loss: 1.3729 sup_con_loss: 0.3609 contrastive_loss: 5.2675 nll_loss: 0.0031 
2023-10-29 16:05:09.324 | INFO     | __main__:train:314 - Epoch: [85][1100/1251]	 loss 4.55991	 cls_loss: 0.5143 cluster_loss: 1.3409 sup_con_loss: 0.2334 contrastive_loss: 5.2667 nll_loss: 0.0033 
2023-10-29 16:08:53.177 | INFO     | __main__:train:314 - Epoch: [85][1200/1251]	 loss 4.66398	 cls_loss: 0.4761 cluster_loss: 1.3705 sup_con_loss: 0.5052 contrastive_loss: 5.2722 nll_loss: 0.0028 
2023-10-29 16:10:44.646 | INFO     | __main__:train:319 - Train Epoch: 85 Avg Loss: 4.5936 
2023-10-29 16:10:44.649 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 16:28:02.994 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 85, Train ACC Unlabelled_v2: All 0.6013 | Old 0.7751 | New 0.5139
2023-10-29 16:28:03.212 | INFO     | __main__:main:205 - Train Accuracies: All 0.6013 | Old 0.7751 | New 0.5139
2023-10-29 16:28:06.105 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 16:28:19.540 | INFO     | __main__:train:314 - Epoch: [86][0/1251]	 loss 4.59294	 cls_loss: 0.5612 cluster_loss: 1.3606 sup_con_loss: 0.2485 contrastive_loss: 5.2677 nll_loss: 0.0012 
2023-10-29 16:32:03.826 | INFO     | __main__:train:314 - Epoch: [86][100/1251]	 loss 4.53459	 cls_loss: 0.4163 cluster_loss: 1.2913 sup_con_loss: 0.3614 contrastive_loss: 5.2630 nll_loss: 0.0020 
2023-10-29 16:35:47.483 | INFO     | __main__:train:314 - Epoch: [86][200/1251]	 loss 4.53326	 cls_loss: 0.4579 cluster_loss: 1.3252 sup_con_loss: 0.2485 contrastive_loss: 5.2643 nll_loss: 0.0029 
2023-10-29 16:39:31.260 | INFO     | __main__:train:314 - Epoch: [86][300/1251]	 loss 4.60348	 cls_loss: 0.4977 cluster_loss: 1.3107 sup_con_loss: 0.4368 contrastive_loss: 5.2645 nll_loss: 0.0026 
2023-10-29 16:43:17.498 | INFO     | __main__:train:314 - Epoch: [86][400/1251]	 loss 4.62571	 cls_loss: 0.4106 cluster_loss: 1.3547 sup_con_loss: 0.5027 contrastive_loss: 5.2674 nll_loss: 0.0017 
2023-10-29 16:47:01.802 | INFO     | __main__:train:314 - Epoch: [86][500/1251]	 loss 4.54604	 cls_loss: 0.6066 cluster_loss: 1.2386 sup_con_loss: 0.3007 contrastive_loss: 5.2646 nll_loss: 0.0014 
2023-10-29 16:50:48.252 | INFO     | __main__:train:314 - Epoch: [86][600/1251]	 loss 4.65006	 cls_loss: 0.5986 cluster_loss: 1.3095 sup_con_loss: 0.4646 contrastive_loss: 5.2681 nll_loss: 0.0025 
2023-10-29 16:54:33.890 | INFO     | __main__:train:314 - Epoch: [86][700/1251]	 loss 4.57333	 cls_loss: 0.4234 cluster_loss: 1.2801 sup_con_loss: 0.4878 contrastive_loss: 5.2631 nll_loss: 0.0013 
2023-10-29 16:58:19.354 | INFO     | __main__:train:314 - Epoch: [86][800/1251]	 loss 4.55458	 cls_loss: 0.4815 cluster_loss: 1.2811 sup_con_loss: 0.3725 contrastive_loss: 5.2623 nll_loss: 0.0025 
2023-10-29 17:02:05.354 | INFO     | __main__:train:314 - Epoch: [86][900/1251]	 loss 4.62939	 cls_loss: 0.5148 cluster_loss: 1.3311 sup_con_loss: 0.4505 contrastive_loss: 5.2696 nll_loss: 0.0011 
2023-10-29 17:05:53.063 | INFO     | __main__:train:314 - Epoch: [86][1000/1251]	 loss 4.72963	 cls_loss: 0.5988 cluster_loss: 1.3748 sup_con_loss: 0.5704 contrastive_loss: 5.2703 nll_loss: 0.0011 
2023-10-29 17:09:39.517 | INFO     | __main__:train:314 - Epoch: [86][1100/1251]	 loss 4.62182	 cls_loss: 0.4100 cluster_loss: 1.3855 sup_con_loss: 0.4310 contrastive_loss: 5.2686 nll_loss: 0.0024 
2023-10-29 17:13:25.502 | INFO     | __main__:train:314 - Epoch: [86][1200/1251]	 loss 4.54862	 cls_loss: 0.4739 cluster_loss: 1.2729 sup_con_loss: 0.3704 contrastive_loss: 5.2668 nll_loss: 0.0023 
2023-10-29 17:15:17.277 | INFO     | __main__:train:319 - Train Epoch: 86 Avg Loss: 4.5878 
2023-10-29 17:15:17.282 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 17:33:04.870 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 86, Train ACC Unlabelled_v2: All 0.6019 | Old 0.7810 | New 0.5118
2023-10-29 17:33:05.121 | INFO     | __main__:main:205 - Train Accuracies: All 0.6019 | Old 0.7810 | New 0.5118
2023-10-29 17:33:08.049 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 17:33:22.441 | INFO     | __main__:train:314 - Epoch: [87][0/1251]	 loss 4.52014	 cls_loss: 0.3897 cluster_loss: 1.2807 sup_con_loss: 0.3610 contrastive_loss: 5.2645 nll_loss: 0.0030 
2023-10-29 17:37:09.535 | INFO     | __main__:train:314 - Epoch: [87][100/1251]	 loss 4.64762	 cls_loss: 0.5164 cluster_loss: 1.3198 sup_con_loss: 0.5199 contrastive_loss: 5.2689 nll_loss: 0.0022 
2023-10-29 17:40:56.430 | INFO     | __main__:train:314 - Epoch: [87][200/1251]	 loss 4.55326	 cls_loss: 0.3653 cluster_loss: 1.3275 sup_con_loss: 0.3889 contrastive_loss: 5.2691 nll_loss: 0.0015 
2023-10-29 17:44:41.735 | INFO     | __main__:train:314 - Epoch: [87][300/1251]	 loss 4.59846	 cls_loss: 0.4862 cluster_loss: 1.2994 sup_con_loss: 0.4503 contrastive_loss: 5.2684 nll_loss: 0.0016 
2023-10-29 17:48:27.266 | INFO     | __main__:train:314 - Epoch: [87][400/1251]	 loss 4.59143	 cls_loss: 0.4815 cluster_loss: 1.3339 sup_con_loss: 0.3733 contrastive_loss: 5.2675 nll_loss: 0.0013 
2023-10-29 17:52:12.745 | INFO     | __main__:train:314 - Epoch: [87][500/1251]	 loss 4.66580	 cls_loss: 0.5101 cluster_loss: 1.3597 sup_con_loss: 0.5019 contrastive_loss: 5.2709 nll_loss: 0.0017 
2023-10-29 17:55:56.789 | INFO     | __main__:train:314 - Epoch: [87][600/1251]	 loss 4.52252	 cls_loss: 0.4616 cluster_loss: 1.3040 sup_con_loss: 0.2491 contrastive_loss: 5.2676 nll_loss: 0.0023 
2023-10-29 17:59:41.187 | INFO     | __main__:train:314 - Epoch: [87][700/1251]	 loss 4.53600	 cls_loss: 0.3957 cluster_loss: 1.3187 sup_con_loss: 0.3295 contrastive_loss: 5.2663 nll_loss: 0.0020 
2023-10-29 18:03:25.850 | INFO     | __main__:train:314 - Epoch: [87][800/1251]	 loss 4.58484	 cls_loss: 0.4325 cluster_loss: 1.3380 sup_con_loss: 0.3960 contrastive_loss: 5.2670 nll_loss: 0.0015 
2023-10-29 18:07:10.326 | INFO     | __main__:train:314 - Epoch: [87][900/1251]	 loss 4.54255	 cls_loss: 0.4239 cluster_loss: 1.3233 sup_con_loss: 0.3083 contrastive_loss: 5.2685 nll_loss: 0.0016 
2023-10-29 18:10:54.468 | INFO     | __main__:train:314 - Epoch: [87][1000/1251]	 loss 4.59664	 cls_loss: 0.4070 cluster_loss: 1.3860 sup_con_loss: 0.3513 contrastive_loss: 5.2734 nll_loss: 0.0026 
2023-10-29 18:14:37.500 | INFO     | __main__:train:314 - Epoch: [87][1100/1251]	 loss 4.61160	 cls_loss: 0.4641 cluster_loss: 1.3246 sup_con_loss: 0.4653 contrastive_loss: 5.2674 nll_loss: 0.0014 
2023-10-29 18:18:24.597 | INFO     | __main__:train:314 - Epoch: [87][1200/1251]	 loss 4.51716	 cls_loss: 0.3701 cluster_loss: 1.2660 sup_con_loss: 0.4091 contrastive_loss: 5.2615 nll_loss: 0.0016 
2023-10-29 18:20:19.573 | INFO     | __main__:train:319 - Train Epoch: 87 Avg Loss: 4.5858 
2023-10-29 18:20:19.582 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 18:37:54.711 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 87, Train ACC Unlabelled_v2: All 0.6027 | Old 0.7797 | New 0.5138
2023-10-29 18:37:54.956 | INFO     | __main__:main:205 - Train Accuracies: All 0.6027 | Old 0.7797 | New 0.5138
2023-10-29 18:38:00.498 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 18:38:16.573 | INFO     | __main__:train:314 - Epoch: [88][0/1251]	 loss 4.49159	 cls_loss: 0.3588 cluster_loss: 1.3134 sup_con_loss: 0.2523 contrastive_loss: 5.2652 nll_loss: 0.0016 
2023-10-29 18:42:02.714 | INFO     | __main__:train:314 - Epoch: [88][100/1251]	 loss 4.51173	 cls_loss: 0.3600 cluster_loss: 1.3018 sup_con_loss: 0.3306 contrastive_loss: 5.2654 nll_loss: 0.0014 
2023-10-29 18:45:48.355 | INFO     | __main__:train:314 - Epoch: [88][200/1251]	 loss 4.54625	 cls_loss: 0.4231 cluster_loss: 1.2947 sup_con_loss: 0.3712 contrastive_loss: 5.2677 nll_loss: 0.0027 
2023-10-29 18:49:34.389 | INFO     | __main__:train:314 - Epoch: [88][300/1251]	 loss 4.59392	 cls_loss: 0.4709 cluster_loss: 1.3522 sup_con_loss: 0.3541 contrastive_loss: 5.2673 nll_loss: 0.0025 
2023-10-29 18:53:18.881 | INFO     | __main__:train:314 - Epoch: [88][400/1251]	 loss 4.48667	 cls_loss: 0.4334 cluster_loss: 1.3009 sup_con_loss: 0.1885 contrastive_loss: 5.2630 nll_loss: 0.0024 
2023-10-29 18:57:17.558 | INFO     | __main__:train:314 - Epoch: [88][500/1251]	 loss 4.51027	 cls_loss: 0.4263 cluster_loss: 1.3004 sup_con_loss: 0.2599 contrastive_loss: 5.2654 nll_loss: 0.0023 
2023-10-29 19:01:04.525 | INFO     | __main__:train:314 - Epoch: [88][600/1251]	 loss 4.62076	 cls_loss: 0.5058 cluster_loss: 1.3656 sup_con_loss: 0.3624 contrastive_loss: 5.2696 nll_loss: 0.0041 
2023-10-29 19:05:09.429 | INFO     | __main__:train:314 - Epoch: [88][700/1251]	 loss 4.52202	 cls_loss: 0.4136 cluster_loss: 1.3051 sup_con_loss: 0.2918 contrastive_loss: 5.2698 nll_loss: 0.0014 
2023-10-29 19:09:02.671 | INFO     | __main__:train:314 - Epoch: [88][800/1251]	 loss 4.56041	 cls_loss: 0.5039 cluster_loss: 1.2880 sup_con_loss: 0.3482 contrastive_loss: 5.2674 nll_loss: 0.0011 
2023-10-29 19:12:46.229 | INFO     | __main__:train:314 - Epoch: [88][900/1251]	 loss 4.61833	 cls_loss: 0.5186 cluster_loss: 1.3090 sup_con_loss: 0.4620 contrastive_loss: 5.2642 nll_loss: 0.0026 
2023-10-29 19:16:30.277 | INFO     | __main__:train:314 - Epoch: [88][1000/1251]	 loss 4.54230	 cls_loss: 0.4328 cluster_loss: 1.2974 sup_con_loss: 0.3489 contrastive_loss: 5.2672 nll_loss: 0.0017 
2023-10-29 19:20:16.674 | INFO     | __main__:train:314 - Epoch: [88][1100/1251]	 loss 4.54209	 cls_loss: 0.4048 cluster_loss: 1.3289 sup_con_loss: 0.3214 contrastive_loss: 5.2651 nll_loss: 0.0018 
2023-10-29 19:23:59.841 | INFO     | __main__:train:314 - Epoch: [88][1200/1251]	 loss 4.71498	 cls_loss: 0.5033 cluster_loss: 1.4088 sup_con_loss: 0.5540 contrastive_loss: 5.2733 nll_loss: 0.0016 
2023-10-29 19:25:52.417 | INFO     | __main__:train:319 - Train Epoch: 88 Avg Loss: 4.5840 
2023-10-29 19:25:52.425 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 19:43:25.634 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 88, Train ACC Unlabelled_v2: All 0.6037 | Old 0.7808 | New 0.5146
2023-10-29 19:43:26.261 | INFO     | __main__:main:205 - Train Accuracies: All 0.6037 | Old 0.7808 | New 0.5146
2023-10-29 19:43:29.545 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 19:43:45.018 | INFO     | __main__:train:314 - Epoch: [89][0/1251]	 loss 4.61368	 cls_loss: 0.4004 cluster_loss: 1.3867 sup_con_loss: 0.4137 contrastive_loss: 5.2707 nll_loss: 0.0015 
2023-10-29 19:47:29.070 | INFO     | __main__:train:314 - Epoch: [89][100/1251]	 loss 4.56852	 cls_loss: 0.4167 cluster_loss: 1.2641 sup_con_loss: 0.5026 contrastive_loss: 5.2658 nll_loss: 0.0023 
2023-10-29 19:51:13.644 | INFO     | __main__:train:314 - Epoch: [89][200/1251]	 loss 4.53625	 cls_loss: 0.3806 cluster_loss: 1.2910 sup_con_loss: 0.3966 contrastive_loss: 5.2632 nll_loss: 0.0040 
2023-10-29 19:54:59.811 | INFO     | __main__:train:314 - Epoch: [89][300/1251]	 loss 4.59009	 cls_loss: 0.4517 cluster_loss: 1.2873 sup_con_loss: 0.4902 contrastive_loss: 5.2630 nll_loss: 0.0027 
2023-10-29 19:58:43.462 | INFO     | __main__:train:314 - Epoch: [89][400/1251]	 loss 4.57349	 cls_loss: 0.4695 cluster_loss: 1.2831 sup_con_loss: 0.4340 contrastive_loss: 5.2633 nll_loss: 0.0021 
2023-10-29 20:02:28.694 | INFO     | __main__:train:314 - Epoch: [89][500/1251]	 loss 4.54392	 cls_loss: 0.4359 cluster_loss: 1.2784 sup_con_loss: 0.3928 contrastive_loss: 5.2632 nll_loss: 0.0018 
2023-10-29 20:06:13.941 | INFO     | __main__:train:314 - Epoch: [89][600/1251]	 loss 4.57764	 cls_loss: 0.4936 cluster_loss: 1.2831 sup_con_loss: 0.4208 contrastive_loss: 5.2650 nll_loss: 0.0013 
2023-10-29 20:09:57.749 | INFO     | __main__:train:314 - Epoch: [89][700/1251]	 loss 4.59371	 cls_loss: 0.4459 cluster_loss: 1.3245 sup_con_loss: 0.4383 contrastive_loss: 5.2647 nll_loss: 0.0013 
2023-10-29 20:13:41.959 | INFO     | __main__:train:314 - Epoch: [89][800/1251]	 loss 4.51941	 cls_loss: 0.4223 cluster_loss: 1.2791 sup_con_loss: 0.3289 contrastive_loss: 5.2661 nll_loss: 0.0021 
2023-10-29 20:17:26.828 | INFO     | __main__:train:314 - Epoch: [89][900/1251]	 loss 4.57308	 cls_loss: 0.4196 cluster_loss: 1.3407 sup_con_loss: 0.3667 contrastive_loss: 5.2677 nll_loss: 0.0024 
2023-10-29 20:21:11.963 | INFO     | __main__:train:314 - Epoch: [89][1000/1251]	 loss 4.47326	 cls_loss: 0.3471 cluster_loss: 1.2810 sup_con_loss: 0.2739 contrastive_loss: 5.2625 nll_loss: 0.0027 
2023-10-29 20:24:56.809 | INFO     | __main__:train:314 - Epoch: [89][1100/1251]	 loss 4.55326	 cls_loss: 0.4318 cluster_loss: 1.3031 sup_con_loss: 0.3714 contrastive_loss: 5.2664 nll_loss: 0.0020 
2023-10-29 20:28:42.933 | INFO     | __main__:train:314 - Epoch: [89][1200/1251]	 loss 4.51916	 cls_loss: 0.4005 cluster_loss: 1.2995 sup_con_loss: 0.3103 contrastive_loss: 5.2676 nll_loss: 0.0018 
2023-10-29 20:30:35.308 | INFO     | __main__:train:319 - Train Epoch: 89 Avg Loss: 4.5796 
2023-10-29 20:30:35.316 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 20:48:00.872 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 89, Train ACC Unlabelled_v2: All 0.6040 | Old 0.7804 | New 0.5153
2023-10-29 20:48:01.173 | INFO     | __main__:main:205 - Train Accuracies: All 0.6040 | Old 0.7804 | New 0.5153
2023-10-29 20:48:06.135 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 20:48:18.750 | INFO     | __main__:train:314 - Epoch: [90][0/1251]	 loss 4.52376	 cls_loss: 0.4301 cluster_loss: 1.3106 sup_con_loss: 0.2823 contrastive_loss: 5.2633 nll_loss: 0.0014 
2023-10-29 20:52:03.914 | INFO     | __main__:train:314 - Epoch: [90][100/1251]	 loss 4.53490	 cls_loss: 0.4182 cluster_loss: 1.3156 sup_con_loss: 0.3095 contrastive_loss: 5.2668 nll_loss: 0.0017 
2023-10-29 20:55:48.283 | INFO     | __main__:train:314 - Epoch: [90][200/1251]	 loss 4.72758	 cls_loss: 0.5799 cluster_loss: 1.3615 sup_con_loss: 0.6093 contrastive_loss: 5.2681 nll_loss: 0.0021 
2023-10-29 20:59:33.392 | INFO     | __main__:train:314 - Epoch: [90][300/1251]	 loss 4.57650	 cls_loss: 0.4445 cluster_loss: 1.3710 sup_con_loss: 0.2939 contrastive_loss: 5.2689 nll_loss: 0.0021 
2023-10-29 21:03:19.867 | INFO     | __main__:train:314 - Epoch: [90][400/1251]	 loss 4.64094	 cls_loss: 0.4978 cluster_loss: 1.2969 sup_con_loss: 0.5753 contrastive_loss: 5.2637 nll_loss: 0.0010 
2023-10-29 21:07:06.282 | INFO     | __main__:train:314 - Epoch: [90][500/1251]	 loss 4.51670	 cls_loss: 0.4425 cluster_loss: 1.2913 sup_con_loss: 0.2860 contrastive_loss: 5.2632 nll_loss: 0.0013 
2023-10-29 21:10:49.147 | INFO     | __main__:train:314 - Epoch: [90][600/1251]	 loss 4.53401	 cls_loss: 0.5698 cluster_loss: 1.2509 sup_con_loss: 0.2785 contrastive_loss: 5.2650 nll_loss: 0.0017 
2023-10-29 21:14:33.470 | INFO     | __main__:train:314 - Epoch: [90][700/1251]	 loss 4.54663	 cls_loss: 0.4058 cluster_loss: 1.3206 sup_con_loss: 0.3444 contrastive_loss: 5.2675 nll_loss: 0.0018 
2023-10-29 21:18:17.293 | INFO     | __main__:train:314 - Epoch: [90][800/1251]	 loss 4.60006	 cls_loss: 0.3897 cluster_loss: 1.3613 sup_con_loss: 0.4383 contrastive_loss: 5.2676 nll_loss: 0.0015 
2023-10-29 21:22:03.674 | INFO     | __main__:train:314 - Epoch: [90][900/1251]	 loss 4.59284	 cls_loss: 0.4185 cluster_loss: 1.3319 sup_con_loss: 0.4389 contrastive_loss: 5.2658 nll_loss: 0.0042 
2023-10-29 21:25:47.188 | INFO     | __main__:train:314 - Epoch: [90][1000/1251]	 loss 4.57571	 cls_loss: 0.4768 cluster_loss: 1.2986 sup_con_loss: 0.3930 contrastive_loss: 5.2705 nll_loss: 0.0014 
2023-10-29 21:29:31.560 | INFO     | __main__:train:314 - Epoch: [90][1100/1251]	 loss 4.55834	 cls_loss: 0.3855 cluster_loss: 1.3230 sup_con_loss: 0.3829 contrastive_loss: 5.2711 nll_loss: 0.0033 
2023-10-29 21:33:14.871 | INFO     | __main__:train:314 - Epoch: [90][1200/1251]	 loss 4.47594	 cls_loss: 0.4148 cluster_loss: 1.2934 sup_con_loss: 0.1893 contrastive_loss: 5.2645 nll_loss: 0.0019 
2023-10-29 21:35:07.080 | INFO     | __main__:train:319 - Train Epoch: 90 Avg Loss: 4.5818 
2023-10-29 21:35:07.084 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 21:52:32.402 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 90, Train ACC Unlabelled_v2: All 0.6027 | Old 0.7786 | New 0.5143
2023-10-29 21:52:32.620 | INFO     | __main__:main:205 - Train Accuracies: All 0.6027 | Old 0.7786 | New 0.5143
2023-10-29 21:52:37.174 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 21:52:52.689 | INFO     | __main__:train:314 - Epoch: [91][0/1251]	 loss 4.63138	 cls_loss: 0.4490 cluster_loss: 1.4091 sup_con_loss: 0.3558 contrastive_loss: 5.2784 nll_loss: 0.0029 
2023-10-29 21:56:41.361 | INFO     | __main__:train:314 - Epoch: [91][100/1251]	 loss 4.65577	 cls_loss: 0.4445 cluster_loss: 1.3904 sup_con_loss: 0.4764 contrastive_loss: 5.2719 nll_loss: 0.0030 
2023-10-29 22:00:25.376 | INFO     | __main__:train:314 - Epoch: [91][200/1251]	 loss 4.58698	 cls_loss: 0.4694 cluster_loss: 1.3291 sup_con_loss: 0.3818 contrastive_loss: 5.2664 nll_loss: 0.0020 
2023-10-29 22:04:10.539 | INFO     | __main__:train:314 - Epoch: [91][300/1251]	 loss 4.58679	 cls_loss: 0.4167 cluster_loss: 1.3463 sup_con_loss: 0.4056 contrastive_loss: 5.2656 nll_loss: 0.0013 
2023-10-29 22:07:58.473 | INFO     | __main__:train:314 - Epoch: [91][400/1251]	 loss 4.57133	 cls_loss: 0.3962 cluster_loss: 1.3259 sup_con_loss: 0.4151 contrastive_loss: 5.2667 nll_loss: 0.0022 
2023-10-29 22:11:45.298 | INFO     | __main__:train:314 - Epoch: [91][500/1251]	 loss 4.53146	 cls_loss: 0.4191 cluster_loss: 1.3009 sup_con_loss: 0.3313 contrastive_loss: 5.2644 nll_loss: 0.0013 
2023-10-29 22:15:29.926 | INFO     | __main__:train:314 - Epoch: [91][600/1251]	 loss 4.56429	 cls_loss: 0.5493 cluster_loss: 1.3214 sup_con_loss: 0.2486 contrastive_loss: 5.2689 nll_loss: 0.0013 
2023-10-29 22:19:15.041 | INFO     | __main__:train:314 - Epoch: [91][700/1251]	 loss 4.61086	 cls_loss: 0.4225 cluster_loss: 1.3537 sup_con_loss: 0.4440 contrastive_loss: 5.2700 nll_loss: 0.0021 
2023-10-29 22:22:58.087 | INFO     | __main__:train:314 - Epoch: [91][800/1251]	 loss 4.50421	 cls_loss: 0.4108 cluster_loss: 1.3147 sup_con_loss: 0.2296 contrastive_loss: 5.2675 nll_loss: 0.0017 
2023-10-29 22:26:42.932 | INFO     | __main__:train:314 - Epoch: [91][900/1251]	 loss 4.67242	 cls_loss: 0.4484 cluster_loss: 1.4373 sup_con_loss: 0.4288 contrastive_loss: 5.2760 nll_loss: 0.0017 
2023-10-29 22:30:27.188 | INFO     | __main__:train:314 - Epoch: [91][1000/1251]	 loss 4.61282	 cls_loss: 0.4228 cluster_loss: 1.3421 sup_con_loss: 0.4745 contrastive_loss: 5.2691 nll_loss: 0.0015 
2023-10-29 22:34:12.627 | INFO     | __main__:train:314 - Epoch: [91][1100/1251]	 loss 4.56299	 cls_loss: 0.4351 cluster_loss: 1.3017 sup_con_loss: 0.3994 contrastive_loss: 5.2657 nll_loss: 0.0021 
2023-10-29 22:37:56.409 | INFO     | __main__:train:314 - Epoch: [91][1200/1251]	 loss 4.63084	 cls_loss: 0.5097 cluster_loss: 1.2728 sup_con_loss: 0.5816 contrastive_loss: 5.2608 nll_loss: 0.0020 
2023-10-29 22:39:47.277 | INFO     | __main__:train:319 - Train Epoch: 91 Avg Loss: 4.5814 
2023-10-29 22:39:47.304 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-29 22:57:27.403 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 91, Train ACC Unlabelled_v2: All 0.6023 | Old 0.7772 | New 0.5144
2023-10-29 22:57:27.662 | INFO     | __main__:main:205 - Train Accuracies: All 0.6023 | Old 0.7772 | New 0.5144
2023-10-29 22:57:32.758 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-29 22:57:47.863 | INFO     | __main__:train:314 - Epoch: [92][0/1251]	 loss 4.54132	 cls_loss: 0.4166 cluster_loss: 1.3389 sup_con_loss: 0.2890 contrastive_loss: 5.2631 nll_loss: 0.0031 
2023-10-29 23:01:31.261 | INFO     | __main__:train:314 - Epoch: [92][100/1251]	 loss 4.59683	 cls_loss: 0.4595 cluster_loss: 1.3206 sup_con_loss: 0.4270 contrastive_loss: 5.2709 nll_loss: 0.0020 
2023-10-29 23:05:16.317 | INFO     | __main__:train:314 - Epoch: [92][200/1251]	 loss 4.57747	 cls_loss: 0.3972 cluster_loss: 1.3264 sup_con_loss: 0.4280 contrastive_loss: 5.2693 nll_loss: 0.0014 
2023-10-29 23:08:59.817 | INFO     | __main__:train:314 - Epoch: [92][300/1251]	 loss 4.54476	 cls_loss: 0.3991 cluster_loss: 1.3690 sup_con_loss: 0.2541 contrastive_loss: 5.2687 nll_loss: 0.0016 
2023-10-29 23:12:44.629 | INFO     | __main__:train:314 - Epoch: [92][400/1251]	 loss 4.56394	 cls_loss: 0.4330 cluster_loss: 1.3175 sup_con_loss: 0.3759 contrastive_loss: 5.2665 nll_loss: 0.0013 
2023-10-29 23:16:34.162 | INFO     | __main__:train:314 - Epoch: [92][500/1251]	 loss 4.66201	 cls_loss: 0.5342 cluster_loss: 1.3063 sup_con_loss: 0.5717 contrastive_loss: 5.2670 nll_loss: 0.0023 
2023-10-29 23:20:17.570 | INFO     | __main__:train:314 - Epoch: [92][600/1251]	 loss 4.51908	 cls_loss: 0.4497 cluster_loss: 1.2665 sup_con_loss: 0.3327 contrastive_loss: 5.2619 nll_loss: 0.0018 
2023-10-29 23:24:02.939 | INFO     | __main__:train:314 - Epoch: [92][700/1251]	 loss 4.52106	 cls_loss: 0.4203 cluster_loss: 1.2787 sup_con_loss: 0.3410 contrastive_loss: 5.2649 nll_loss: 0.0013 
2023-10-29 23:27:47.686 | INFO     | __main__:train:314 - Epoch: [92][800/1251]	 loss 4.56844	 cls_loss: 0.5233 cluster_loss: 1.3410 sup_con_loss: 0.2589 contrastive_loss: 5.2625 nll_loss: 0.0024 
2023-10-29 23:31:30.407 | INFO     | __main__:train:314 - Epoch: [92][900/1251]	 loss 4.59220	 cls_loss: 0.5600 cluster_loss: 1.2879 sup_con_loss: 0.3766 contrastive_loss: 5.2700 nll_loss: 0.0017 
2023-10-29 23:35:22.433 | INFO     | __main__:train:314 - Epoch: [92][1000/1251]	 loss 4.56063	 cls_loss: 0.4093 cluster_loss: 1.3483 sup_con_loss: 0.3238 contrastive_loss: 5.2721 nll_loss: 0.0008 
2023-10-29 23:39:07.234 | INFO     | __main__:train:314 - Epoch: [92][1100/1251]	 loss 4.59444	 cls_loss: 0.5113 cluster_loss: 1.3457 sup_con_loss: 0.3297 contrastive_loss: 5.2680 nll_loss: 0.0012 
2023-10-29 23:42:51.324 | INFO     | __main__:train:314 - Epoch: [92][1200/1251]	 loss 4.64401	 cls_loss: 0.5231 cluster_loss: 1.3119 sup_con_loss: 0.5219 contrastive_loss: 5.2677 nll_loss: 0.0015 
2023-10-29 23:44:44.777 | INFO     | __main__:train:319 - Train Epoch: 92 Avg Loss: 4.5732 
2023-10-29 23:44:44.780 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 00:02:39.139 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 92, Train ACC Unlabelled_v2: All 0.6029 | Old 0.7817 | New 0.5130
2023-10-30 00:02:39.399 | INFO     | __main__:main:205 - Train Accuracies: All 0.6029 | Old 0.7817 | New 0.5130
2023-10-30 00:02:42.918 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 00:03:00.374 | INFO     | __main__:train:314 - Epoch: [93][0/1251]	 loss 4.59344	 cls_loss: 0.4106 cluster_loss: 1.3667 sup_con_loss: 0.3817 contrastive_loss: 5.2712 nll_loss: 0.0015 
2023-10-30 00:06:44.981 | INFO     | __main__:train:314 - Epoch: [93][100/1251]	 loss 4.60944	 cls_loss: 0.4098 cluster_loss: 1.3769 sup_con_loss: 0.4090 contrastive_loss: 5.2713 nll_loss: 0.0015 
2023-10-30 00:10:30.447 | INFO     | __main__:train:314 - Epoch: [93][200/1251]	 loss 4.57702	 cls_loss: 0.4010 cluster_loss: 1.3323 sup_con_loss: 0.4115 contrastive_loss: 5.2681 nll_loss: 0.0024 
2023-10-30 00:14:14.836 | INFO     | __main__:train:314 - Epoch: [93][300/1251]	 loss 4.54782	 cls_loss: 0.4409 cluster_loss: 1.3111 sup_con_loss: 0.3362 contrastive_loss: 5.2619 nll_loss: 0.0034 
2023-10-30 00:18:00.260 | INFO     | __main__:train:314 - Epoch: [93][400/1251]	 loss 4.56550	 cls_loss: 0.3876 cluster_loss: 1.3662 sup_con_loss: 0.3280 contrastive_loss: 5.2703 nll_loss: 0.0013 
2023-10-30 00:21:46.279 | INFO     | __main__:train:314 - Epoch: [93][500/1251]	 loss 4.57180	 cls_loss: 0.4289 cluster_loss: 1.2872 sup_con_loss: 0.4501 contrastive_loss: 5.2700 nll_loss: 0.0020 
2023-10-30 00:25:30.453 | INFO     | __main__:train:314 - Epoch: [93][600/1251]	 loss 4.50561	 cls_loss: 0.3502 cluster_loss: 1.3094 sup_con_loss: 0.3028 contrastive_loss: 5.2655 nll_loss: 0.0034 
2023-10-30 00:29:15.882 | INFO     | __main__:train:314 - Epoch: [93][700/1251]	 loss 4.49335	 cls_loss: 0.3158 cluster_loss: 1.3002 sup_con_loss: 0.3275 contrastive_loss: 5.2628 nll_loss: 0.0023 
2023-10-30 00:33:02.017 | INFO     | __main__:train:314 - Epoch: [93][800/1251]	 loss 4.51699	 cls_loss: 0.4188 cluster_loss: 1.3246 sup_con_loss: 0.2376 contrastive_loss: 5.2681 nll_loss: 0.0020 
2023-10-30 00:36:44.999 | INFO     | __main__:train:314 - Epoch: [93][900/1251]	 loss 4.60469	 cls_loss: 0.4587 cluster_loss: 1.3162 sup_con_loss: 0.4680 contrastive_loss: 5.2653 nll_loss: 0.0024 
2023-10-30 00:40:31.047 | INFO     | __main__:train:314 - Epoch: [93][1000/1251]	 loss 4.53693	 cls_loss: 0.3766 cluster_loss: 1.2880 sup_con_loss: 0.4079 contrastive_loss: 5.2673 nll_loss: 0.0014 
2023-10-30 00:44:16.056 | INFO     | __main__:train:314 - Epoch: [93][1100/1251]	 loss 4.58416	 cls_loss: 0.4459 cluster_loss: 1.3075 sup_con_loss: 0.4450 contrastive_loss: 5.2633 nll_loss: 0.0014 
2023-10-30 00:48:00.724 | INFO     | __main__:train:314 - Epoch: [93][1200/1251]	 loss 4.47047	 cls_loss: 0.3370 cluster_loss: 1.2705 sup_con_loss: 0.3066 contrastive_loss: 5.2579 nll_loss: 0.0018 
2023-10-30 00:49:51.956 | INFO     | __main__:train:319 - Train Epoch: 93 Avg Loss: 4.5731 
2023-10-30 00:49:51.960 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 01:07:32.843 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 93, Train ACC Unlabelled_v2: All 0.6025 | Old 0.7781 | New 0.5143
2023-10-30 01:07:33.153 | INFO     | __main__:main:205 - Train Accuracies: All 0.6025 | Old 0.7781 | New 0.5143
2023-10-30 01:07:36.615 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 01:07:52.361 | INFO     | __main__:train:314 - Epoch: [94][0/1251]	 loss 4.59906	 cls_loss: 0.5459 cluster_loss: 1.3449 sup_con_loss: 0.3081 contrastive_loss: 5.2677 nll_loss: 0.0020 
2023-10-30 01:11:36.485 | INFO     | __main__:train:314 - Epoch: [94][100/1251]	 loss 4.60020	 cls_loss: 0.4139 cluster_loss: 1.3136 sup_con_loss: 0.5043 contrastive_loss: 5.2673 nll_loss: 0.0013 
2023-10-30 01:15:21.209 | INFO     | __main__:train:314 - Epoch: [94][200/1251]	 loss 4.56902	 cls_loss: 0.4275 cluster_loss: 1.3056 sup_con_loss: 0.4210 contrastive_loss: 5.2638 nll_loss: 0.0019 
2023-10-30 01:19:05.848 | INFO     | __main__:train:314 - Epoch: [94][300/1251]	 loss 4.54900	 cls_loss: 0.4072 cluster_loss: 1.2685 sup_con_loss: 0.4503 contrastive_loss: 5.2643 nll_loss: 0.0026 
2023-10-30 01:22:49.169 | INFO     | __main__:train:314 - Epoch: [94][400/1251]	 loss 4.45901	 cls_loss: 0.3667 cluster_loss: 1.2630 sup_con_loss: 0.2515 contrastive_loss: 5.2608 nll_loss: 0.0021 
2023-10-30 01:26:33.861 | INFO     | __main__:train:314 - Epoch: [94][500/1251]	 loss 4.60369	 cls_loss: 0.4755 cluster_loss: 1.2959 sup_con_loss: 0.4885 contrastive_loss: 5.2646 nll_loss: 0.0019 
2023-10-30 01:30:17.438 | INFO     | __main__:train:314 - Epoch: [94][600/1251]	 loss 4.53612	 cls_loss: 0.4306 cluster_loss: 1.3307 sup_con_loss: 0.2681 contrastive_loss: 5.2687 nll_loss: 0.0020 
2023-10-30 01:34:02.826 | INFO     | __main__:train:314 - Epoch: [94][700/1251]	 loss 4.55764	 cls_loss: 0.5469 cluster_loss: 1.2760 sup_con_loss: 0.3246 contrastive_loss: 5.2643 nll_loss: 0.0014 
2023-10-30 01:37:46.764 | INFO     | __main__:train:314 - Epoch: [94][800/1251]	 loss 4.65056	 cls_loss: 0.5183 cluster_loss: 1.3475 sup_con_loss: 0.4777 contrastive_loss: 5.2680 nll_loss: 0.0019 
2023-10-30 01:41:32.179 | INFO     | __main__:train:314 - Epoch: [94][900/1251]	 loss 4.53149	 cls_loss: 0.4009 cluster_loss: 1.3508 sup_con_loss: 0.2542 contrastive_loss: 5.2646 nll_loss: 0.0022 
2023-10-30 01:45:17.337 | INFO     | __main__:train:314 - Epoch: [94][1000/1251]	 loss 4.52522	 cls_loss: 0.4379 cluster_loss: 1.2752 sup_con_loss: 0.3447 contrastive_loss: 5.2622 nll_loss: 0.0020 
2023-10-30 01:49:01.452 | INFO     | __main__:train:314 - Epoch: [94][1100/1251]	 loss 4.49506	 cls_loss: 0.4295 cluster_loss: 1.2919 sup_con_loss: 0.2175 contrastive_loss: 5.2715 nll_loss: 0.0024 
2023-10-30 01:52:46.077 | INFO     | __main__:train:314 - Epoch: [94][1200/1251]	 loss 4.61722	 cls_loss: 0.4454 cluster_loss: 1.3548 sup_con_loss: 0.4338 contrastive_loss: 5.2729 nll_loss: 0.0015 
2023-10-30 01:54:38.758 | INFO     | __main__:train:319 - Train Epoch: 94 Avg Loss: 4.5722 
2023-10-30 01:54:38.763 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 02:11:58.084 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 94, Train ACC Unlabelled_v2: All 0.6036 | Old 0.7803 | New 0.5148
2023-10-30 02:11:58.423 | INFO     | __main__:main:205 - Train Accuracies: All 0.6036 | Old 0.7803 | New 0.5148
2023-10-30 02:12:01.358 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 02:12:15.829 | INFO     | __main__:train:314 - Epoch: [95][0/1251]	 loss 4.53607	 cls_loss: 0.4379 cluster_loss: 1.2841 sup_con_loss: 0.3565 contrastive_loss: 5.2646 nll_loss: 0.0013 
2023-10-30 02:15:59.870 | INFO     | __main__:train:314 - Epoch: [95][100/1251]	 loss 4.59639	 cls_loss: 0.4638 cluster_loss: 1.3657 sup_con_loss: 0.3405 contrastive_loss: 5.2703 nll_loss: 0.0014 
2023-10-30 02:19:46.603 | INFO     | __main__:train:314 - Epoch: [95][200/1251]	 loss 4.73077	 cls_loss: 0.5136 cluster_loss: 1.4356 sup_con_loss: 0.5376 contrastive_loss: 5.2733 nll_loss: 0.0021 
2023-10-30 02:23:30.821 | INFO     | __main__:train:314 - Epoch: [95][300/1251]	 loss 4.61539	 cls_loss: 0.5299 cluster_loss: 1.3303 sup_con_loss: 0.3988 contrastive_loss: 5.2649 nll_loss: 0.0034 
2023-10-30 02:27:16.762 | INFO     | __main__:train:314 - Epoch: [95][400/1251]	 loss 4.55956	 cls_loss: 0.4596 cluster_loss: 1.2958 sup_con_loss: 0.3826 contrastive_loss: 5.2626 nll_loss: 0.0018 
2023-10-30 02:31:02.514 | INFO     | __main__:train:314 - Epoch: [95][500/1251]	 loss 4.54504	 cls_loss: 0.3912 cluster_loss: 1.3840 sup_con_loss: 0.2307 contrastive_loss: 5.2714 nll_loss: 0.0014 
2023-10-30 02:34:46.655 | INFO     | __main__:train:314 - Epoch: [95][600/1251]	 loss 4.46939	 cls_loss: 0.3244 cluster_loss: 1.2964 sup_con_loss: 0.2573 contrastive_loss: 5.2642 nll_loss: 0.0014 
2023-10-30 02:38:31.917 | INFO     | __main__:train:314 - Epoch: [95][700/1251]	 loss 4.50562	 cls_loss: 0.3661 cluster_loss: 1.3255 sup_con_loss: 0.2594 contrastive_loss: 5.2657 nll_loss: 0.0025 
2023-10-30 02:42:21.717 | INFO     | __main__:train:314 - Epoch: [95][800/1251]	 loss 4.59394	 cls_loss: 0.4219 cluster_loss: 1.3843 sup_con_loss: 0.3425 contrastive_loss: 5.2688 nll_loss: 0.0019 
2023-10-30 02:46:06.834 | INFO     | __main__:train:314 - Epoch: [95][900/1251]	 loss 4.61398	 cls_loss: 0.5130 cluster_loss: 1.3117 sup_con_loss: 0.4403 contrastive_loss: 5.2708 nll_loss: 0.0017 
2023-10-30 02:49:52.765 | INFO     | __main__:train:314 - Epoch: [95][1000/1251]	 loss 4.70539	 cls_loss: 0.4440 cluster_loss: 1.5421 sup_con_loss: 0.3186 contrastive_loss: 5.2837 nll_loss: 0.0017 
2023-10-30 02:53:37.831 | INFO     | __main__:train:314 - Epoch: [95][1100/1251]	 loss 4.61009	 cls_loss: 0.4497 cluster_loss: 1.3417 sup_con_loss: 0.4362 contrastive_loss: 5.2704 nll_loss: 0.0022 
2023-10-30 02:57:24.505 | INFO     | __main__:train:314 - Epoch: [95][1200/1251]	 loss 4.48987	 cls_loss: 0.4585 cluster_loss: 1.3121 sup_con_loss: 0.1466 contrastive_loss: 5.2659 nll_loss: 0.0024 
2023-10-30 02:59:16.990 | INFO     | __main__:train:319 - Train Epoch: 95 Avg Loss: 4.5720 
2023-10-30 02:59:16.997 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 03:16:35.680 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 95, Train ACC Unlabelled_v2: All 0.6025 | Old 0.7798 | New 0.5135
2023-10-30 03:16:35.891 | INFO     | __main__:main:205 - Train Accuracies: All 0.6025 | Old 0.7798 | New 0.5135
2023-10-30 03:16:39.529 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 03:16:53.451 | INFO     | __main__:train:314 - Epoch: [96][0/1251]	 loss 4.61390	 cls_loss: 0.4403 cluster_loss: 1.3484 sup_con_loss: 0.4503 contrastive_loss: 5.2688 nll_loss: 0.0010 
2023-10-30 03:20:37.764 | INFO     | __main__:train:314 - Epoch: [96][100/1251]	 loss 4.66227	 cls_loss: 0.4825 cluster_loss: 1.3714 sup_con_loss: 0.5012 contrastive_loss: 5.2683 nll_loss: 0.0022 
2023-10-30 03:24:22.782 | INFO     | __main__:train:314 - Epoch: [96][200/1251]	 loss 4.72049	 cls_loss: 0.4579 cluster_loss: 1.3976 sup_con_loss: 0.6375 contrastive_loss: 5.2689 nll_loss: 0.0039 
2023-10-30 03:28:07.385 | INFO     | __main__:train:314 - Epoch: [96][300/1251]	 loss 4.59496	 cls_loss: 0.4806 cluster_loss: 1.3655 sup_con_loss: 0.3301 contrastive_loss: 5.2644 nll_loss: 0.0018 
2023-10-30 03:32:00.935 | INFO     | __main__:train:314 - Epoch: [96][400/1251]	 loss 4.51380	 cls_loss: 0.3798 cluster_loss: 1.2986 sup_con_loss: 0.3189 contrastive_loss: 5.2661 nll_loss: 0.0022 
2023-10-30 03:35:44.477 | INFO     | __main__:train:314 - Epoch: [96][500/1251]	 loss 4.57215	 cls_loss: 0.3614 cluster_loss: 1.3523 sup_con_loss: 0.3956 contrastive_loss: 5.2706 nll_loss: 0.0023 
2023-10-30 03:39:37.086 | INFO     | __main__:train:314 - Epoch: [96][600/1251]	 loss 4.59736	 cls_loss: 0.4801 cluster_loss: 1.3467 sup_con_loss: 0.3668 contrastive_loss: 5.2654 nll_loss: 0.0031 
2023-10-30 03:43:21.389 | INFO     | __main__:train:314 - Epoch: [96][700/1251]	 loss 4.55860	 cls_loss: 0.3768 cluster_loss: 1.3042 sup_con_loss: 0.4443 contrastive_loss: 5.2641 nll_loss: 0.0018 
2023-10-30 03:47:05.108 | INFO     | __main__:train:314 - Epoch: [96][800/1251]	 loss 4.63916	 cls_loss: 0.4225 cluster_loss: 1.3319 sup_con_loss: 0.5685 contrastive_loss: 5.2677 nll_loss: 0.0026 
2023-10-30 03:50:51.532 | INFO     | __main__:train:314 - Epoch: [96][900/1251]	 loss 4.61301	 cls_loss: 0.4961 cluster_loss: 1.3551 sup_con_loss: 0.3724 contrastive_loss: 5.2727 nll_loss: 0.0010 
2023-10-30 03:54:37.893 | INFO     | __main__:train:314 - Epoch: [96][1000/1251]	 loss 4.49865	 cls_loss: 0.4329 cluster_loss: 1.2393 sup_con_loss: 0.3355 contrastive_loss: 5.2649 nll_loss: 0.0019 
2023-10-30 03:58:24.000 | INFO     | __main__:train:314 - Epoch: [96][1100/1251]	 loss 4.63950	 cls_loss: 0.4489 cluster_loss: 1.3753 sup_con_loss: 0.4616 contrastive_loss: 5.2695 nll_loss: 0.0017 
2023-10-30 04:02:09.749 | INFO     | __main__:train:314 - Epoch: [96][1200/1251]	 loss 4.54079	 cls_loss: 0.4575 cluster_loss: 1.2946 sup_con_loss: 0.3300 contrastive_loss: 5.2636 nll_loss: 0.0023 
2023-10-30 04:04:01.474 | INFO     | __main__:train:319 - Train Epoch: 96 Avg Loss: 4.5657 
2023-10-30 04:04:01.510 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 04:21:58.341 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 96, Train ACC Unlabelled_v2: All 0.6053 | Old 0.7809 | New 0.5170
2023-10-30 04:21:58.592 | INFO     | __main__:main:205 - Train Accuracies: All 0.6053 | Old 0.7809 | New 0.5170
2023-10-30 04:22:03.657 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 04:22:16.933 | INFO     | __main__:train:314 - Epoch: [97][0/1251]	 loss 4.53419	 cls_loss: 0.4780 cluster_loss: 1.2813 sup_con_loss: 0.3068 contrastive_loss: 5.2688 nll_loss: 0.0019 
2023-10-30 04:26:02.261 | INFO     | __main__:train:314 - Epoch: [97][100/1251]	 loss 4.69166	 cls_loss: 0.5418 cluster_loss: 1.4113 sup_con_loss: 0.4339 contrastive_loss: 5.2764 nll_loss: 0.0031 
2023-10-30 04:29:46.638 | INFO     | __main__:train:314 - Epoch: [97][200/1251]	 loss 4.53053	 cls_loss: 0.3971 cluster_loss: 1.2591 sup_con_loss: 0.4308 contrastive_loss: 5.2608 nll_loss: 0.0028 
2023-10-30 04:33:31.898 | INFO     | __main__:train:314 - Epoch: [97][300/1251]	 loss 4.54557	 cls_loss: 0.4571 cluster_loss: 1.3346 sup_con_loss: 0.2637 contrastive_loss: 5.2684 nll_loss: 0.0013 
2023-10-30 04:37:15.972 | INFO     | __main__:train:314 - Epoch: [97][400/1251]	 loss 4.53545	 cls_loss: 0.3187 cluster_loss: 1.3309 sup_con_loss: 0.3757 contrastive_loss: 5.2691 nll_loss: 0.0024 
2023-10-30 04:40:59.748 | INFO     | __main__:train:314 - Epoch: [97][500/1251]	 loss 4.50947	 cls_loss: 0.3966 cluster_loss: 1.2790 sup_con_loss: 0.3393 contrastive_loss: 5.2595 nll_loss: 0.0020 
2023-10-30 04:44:43.777 | INFO     | __main__:train:314 - Epoch: [97][600/1251]	 loss 4.51225	 cls_loss: 0.4490 cluster_loss: 1.2775 sup_con_loss: 0.2909 contrastive_loss: 5.2627 nll_loss: 0.0021 
2023-10-30 04:48:28.310 | INFO     | __main__:train:314 - Epoch: [97][700/1251]	 loss 4.59101	 cls_loss: 0.4508 cluster_loss: 1.3223 sup_con_loss: 0.4273 contrastive_loss: 5.2659 nll_loss: 0.0013 
2023-10-30 04:52:13.526 | INFO     | __main__:train:314 - Epoch: [97][800/1251]	 loss 4.57281	 cls_loss: 0.5235 cluster_loss: 1.3197 sup_con_loss: 0.3028 contrastive_loss: 5.2663 nll_loss: 0.0027 
2023-10-30 04:55:58.554 | INFO     | __main__:train:314 - Epoch: [97][900/1251]	 loss 4.58513	 cls_loss: 0.3709 cluster_loss: 1.3649 sup_con_loss: 0.4023 contrastive_loss: 5.2712 nll_loss: 0.0011 
2023-10-30 04:59:42.373 | INFO     | __main__:train:314 - Epoch: [97][1000/1251]	 loss 4.51281	 cls_loss: 0.3941 cluster_loss: 1.2939 sup_con_loss: 0.3136 contrastive_loss: 5.2660 nll_loss: 0.0011 
2023-10-30 05:03:24.296 | INFO     | __main__:train:314 - Epoch: [97][1100/1251]	 loss 4.59114	 cls_loss: 0.4252 cluster_loss: 1.3752 sup_con_loss: 0.3410 contrastive_loss: 5.2699 nll_loss: 0.0036 
2023-10-30 05:07:07.619 | INFO     | __main__:train:314 - Epoch: [97][1200/1251]	 loss 4.45920	 cls_loss: 0.3127 cluster_loss: 1.2868 sup_con_loss: 0.2609 contrastive_loss: 5.2625 nll_loss: 0.0014 
2023-10-30 05:08:58.978 | INFO     | __main__:train:319 - Train Epoch: 97 Avg Loss: 4.5624 
2023-10-30 05:08:58.989 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 05:26:55.134 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 97, Train ACC Unlabelled_v2: All 0.6055 | Old 0.7816 | New 0.5169
2023-10-30 05:26:55.380 | INFO     | __main__:main:205 - Train Accuracies: All 0.6055 | Old 0.7816 | New 0.5169
2023-10-30 05:27:00.317 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 05:27:13.417 | INFO     | __main__:train:314 - Epoch: [98][0/1251]	 loss 4.48341	 cls_loss: 0.3811 cluster_loss: 1.2584 sup_con_loss: 0.3128 contrastive_loss: 5.2627 nll_loss: 0.0018 
2023-10-30 05:30:58.765 | INFO     | __main__:train:314 - Epoch: [98][100/1251]	 loss 4.46077	 cls_loss: 0.3996 cluster_loss: 1.2606 sup_con_loss: 0.2204 contrastive_loss: 5.2634 nll_loss: 0.0032 
2023-10-30 05:34:42.498 | INFO     | __main__:train:314 - Epoch: [98][200/1251]	 loss 4.55091	 cls_loss: 0.4651 cluster_loss: 1.2624 sup_con_loss: 0.4231 contrastive_loss: 5.2581 nll_loss: 0.0018 
2023-10-30 05:38:28.220 | INFO     | __main__:train:314 - Epoch: [98][300/1251]	 loss 4.53111	 cls_loss: 0.4039 cluster_loss: 1.3237 sup_con_loss: 0.2958 contrastive_loss: 5.2674 nll_loss: 0.0020 
2023-10-30 05:42:13.054 | INFO     | __main__:train:314 - Epoch: [98][400/1251]	 loss 4.59306	 cls_loss: 0.4810 cluster_loss: 1.3200 sup_con_loss: 0.4017 contrastive_loss: 5.2679 nll_loss: 0.0020 
2023-10-30 05:45:56.623 | INFO     | __main__:train:314 - Epoch: [98][500/1251]	 loss 4.55364	 cls_loss: 0.4756 cluster_loss: 1.3058 sup_con_loss: 0.3198 contrastive_loss: 5.2702 nll_loss: 0.0009 
2023-10-30 05:49:41.169 | INFO     | __main__:train:314 - Epoch: [98][600/1251]	 loss 4.57349	 cls_loss: 0.4324 cluster_loss: 1.3202 sup_con_loss: 0.4034 contrastive_loss: 5.2633 nll_loss: 0.0017 
2023-10-30 05:53:25.437 | INFO     | __main__:train:314 - Epoch: [98][700/1251]	 loss 4.57873	 cls_loss: 0.4416 cluster_loss: 1.3306 sup_con_loss: 0.3801 contrastive_loss: 5.2674 nll_loss: 0.0024 
2023-10-30 05:57:10.153 | INFO     | __main__:train:314 - Epoch: [98][800/1251]	 loss 4.52861	 cls_loss: 0.4455 cluster_loss: 1.3046 sup_con_loss: 0.2868 contrastive_loss: 5.2664 nll_loss: 0.0012 
2023-10-30 06:00:53.643 | INFO     | __main__:train:314 - Epoch: [98][900/1251]	 loss 4.54340	 cls_loss: 0.4720 cluster_loss: 1.3165 sup_con_loss: 0.2868 contrastive_loss: 5.2622 nll_loss: 0.0016 
2023-10-30 06:04:38.258 | INFO     | __main__:train:314 - Epoch: [98][1000/1251]	 loss 4.51508	 cls_loss: 0.3962 cluster_loss: 1.2717 sup_con_loss: 0.3593 contrastive_loss: 5.2643 nll_loss: 0.0023 
2023-10-30 06:08:23.152 | INFO     | __main__:train:314 - Epoch: [98][1100/1251]	 loss 4.58672	 cls_loss: 0.4678 cluster_loss: 1.3321 sup_con_loss: 0.3777 contrastive_loss: 5.2667 nll_loss: 0.0016 
2023-10-30 06:12:06.056 | INFO     | __main__:train:314 - Epoch: [98][1200/1251]	 loss 4.58691	 cls_loss: 0.4833 cluster_loss: 1.2959 sup_con_loss: 0.4408 contrastive_loss: 5.2604 nll_loss: 0.0019 
2023-10-30 06:13:58.040 | INFO     | __main__:train:319 - Train Epoch: 98 Avg Loss: 4.5601 
2023-10-30 06:13:58.078 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 06:31:44.994 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 98, Train ACC Unlabelled_v2: All 0.6050 | Old 0.7783 | New 0.5178
2023-10-30 06:31:45.238 | INFO     | __main__:main:205 - Train Accuracies: All 0.6050 | Old 0.7783 | New 0.5178
2023-10-30 06:31:50.312 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 06:32:04.463 | INFO     | __main__:train:314 - Epoch: [99][0/1251]	 loss 4.69808	 cls_loss: 0.4607 cluster_loss: 1.4006 sup_con_loss: 0.5630 contrastive_loss: 5.2728 nll_loss: 0.0021 
2023-10-30 06:35:51.127 | INFO     | __main__:train:314 - Epoch: [99][100/1251]	 loss 4.61905	 cls_loss: 0.4806 cluster_loss: 1.3576 sup_con_loss: 0.4043 contrastive_loss: 5.2692 nll_loss: 0.0019 
2023-10-30 06:39:35.493 | INFO     | __main__:train:314 - Epoch: [99][200/1251]	 loss 4.63293	 cls_loss: 0.5738 cluster_loss: 1.3238 sup_con_loss: 0.4088 contrastive_loss: 5.2716 nll_loss: 0.0020 
2023-10-30 06:43:19.800 | INFO     | __main__:train:314 - Epoch: [99][300/1251]	 loss 4.58456	 cls_loss: 0.3845 cluster_loss: 1.3213 sup_con_loss: 0.4753 contrastive_loss: 5.2656 nll_loss: 0.0021 
2023-10-30 06:47:04.414 | INFO     | __main__:train:314 - Epoch: [99][400/1251]	 loss 4.50679	 cls_loss: 0.4100 cluster_loss: 1.2748 sup_con_loss: 0.3112 contrastive_loss: 5.2665 nll_loss: 0.0026 
2023-10-30 06:50:48.891 | INFO     | __main__:train:314 - Epoch: [99][500/1251]	 loss 4.77098	 cls_loss: 0.5188 cluster_loss: 1.4645 sup_con_loss: 0.5896 contrastive_loss: 5.2759 nll_loss: 0.0018 
2023-10-30 06:54:34.280 | INFO     | __main__:train:314 - Epoch: [99][600/1251]	 loss 4.68580	 cls_loss: 0.4105 cluster_loss: 1.4526 sup_con_loss: 0.4774 contrastive_loss: 5.2749 nll_loss: 0.0021 
2023-10-30 06:58:18.612 | INFO     | __main__:train:314 - Epoch: [99][700/1251]	 loss 4.53554	 cls_loss: 0.4751 cluster_loss: 1.2802 sup_con_loss: 0.3222 contrastive_loss: 5.2637 nll_loss: 0.0029 
2023-10-30 07:02:03.064 | INFO     | __main__:train:314 - Epoch: [99][800/1251]	 loss 4.50260	 cls_loss: 0.3469 cluster_loss: 1.3210 sup_con_loss: 0.2758 contrastive_loss: 5.2684 nll_loss: 0.0015 
2023-10-30 07:05:47.502 | INFO     | __main__:train:314 - Epoch: [99][900/1251]	 loss 4.54231	 cls_loss: 0.4176 cluster_loss: 1.2924 sup_con_loss: 0.3772 contrastive_loss: 5.2661 nll_loss: 0.0011 
2023-10-30 07:09:32.243 | INFO     | __main__:train:314 - Epoch: [99][1000/1251]	 loss 4.55299	 cls_loss: 0.3924 cluster_loss: 1.3234 sup_con_loss: 0.3698 contrastive_loss: 5.2685 nll_loss: 0.0015 
2023-10-30 07:13:15.988 | INFO     | __main__:train:314 - Epoch: [99][1100/1251]	 loss 4.57404	 cls_loss: 0.4582 cluster_loss: 1.2988 sup_con_loss: 0.4147 contrastive_loss: 5.2656 nll_loss: 0.0017 
2023-10-30 07:17:11.664 | INFO     | __main__:train:314 - Epoch: [99][1200/1251]	 loss 4.42222	 cls_loss: 0.3290 cluster_loss: 1.2428 sup_con_loss: 0.2252 contrastive_loss: 5.2605 nll_loss: 0.0011 
2023-10-30 07:19:03.272 | INFO     | __main__:train:319 - Train Epoch: 99 Avg Loss: 4.5584 
2023-10-30 07:19:03.283 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 07:36:43.080 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 99, Train ACC Unlabelled_v2: All 0.6046 | Old 0.7792 | New 0.5169
2023-10-30 07:36:43.610 | INFO     | __main__:main:205 - Train Accuracies: All 0.6046 | Old 0.7792 | New 0.5169
2023-10-30 07:36:46.760 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 07:37:01.396 | INFO     | __main__:train:314 - Epoch: [100][0/1251]	 loss 4.55200	 cls_loss: 0.3702 cluster_loss: 1.3329 sup_con_loss: 0.3751 contrastive_loss: 5.2663 nll_loss: 0.0017 
2023-10-30 07:40:45.778 | INFO     | __main__:train:314 - Epoch: [100][100/1251]	 loss 4.48766	 cls_loss: 0.4286 cluster_loss: 1.2690 sup_con_loss: 0.2512 contrastive_loss: 5.2649 nll_loss: 0.0027 
2023-10-30 07:44:29.372 | INFO     | __main__:train:314 - Epoch: [100][200/1251]	 loss 4.53937	 cls_loss: 0.3801 cluster_loss: 1.3533 sup_con_loss: 0.2930 contrastive_loss: 5.2662 nll_loss: 0.0011 
2023-10-30 07:48:13.659 | INFO     | __main__:train:314 - Epoch: [100][300/1251]	 loss 4.53744	 cls_loss: 0.3655 cluster_loss: 1.2879 sup_con_loss: 0.4268 contrastive_loss: 5.2617 nll_loss: 0.0029 
2023-10-30 07:51:59.269 | INFO     | __main__:train:314 - Epoch: [100][400/1251]	 loss 4.55203	 cls_loss: 0.4944 cluster_loss: 1.3434 sup_con_loss: 0.2278 contrastive_loss: 5.2683 nll_loss: 0.0016 
2023-10-30 07:55:42.264 | INFO     | __main__:train:314 - Epoch: [100][500/1251]	 loss 4.56873	 cls_loss: 0.4939 cluster_loss: 1.3158 sup_con_loss: 0.3338 contrastive_loss: 5.2641 nll_loss: 0.0021 
2023-10-30 07:59:25.964 | INFO     | __main__:train:314 - Epoch: [100][600/1251]	 loss 4.56270	 cls_loss: 0.5147 cluster_loss: 1.2735 sup_con_loss: 0.3768 contrastive_loss: 5.2645 nll_loss: 0.0010 
2023-10-30 08:03:09.791 | INFO     | __main__:train:314 - Epoch: [100][700/1251]	 loss 4.63832	 cls_loss: 0.4336 cluster_loss: 1.3406 sup_con_loss: 0.5464 contrastive_loss: 5.2652 nll_loss: 0.0015 
2023-10-30 08:06:53.592 | INFO     | __main__:train:314 - Epoch: [100][800/1251]	 loss 4.47250	 cls_loss: 0.3397 cluster_loss: 1.2633 sup_con_loss: 0.3128 contrastive_loss: 5.2634 nll_loss: 0.0017 
2023-10-30 08:10:36.799 | INFO     | __main__:train:314 - Epoch: [100][900/1251]	 loss 4.55436	 cls_loss: 0.3813 cluster_loss: 1.2825 sup_con_loss: 0.4689 contrastive_loss: 5.2636 nll_loss: 0.0018 
2023-10-30 08:14:21.372 | INFO     | __main__:train:314 - Epoch: [100][1000/1251]	 loss 4.62609	 cls_loss: 0.3696 cluster_loss: 1.3755 sup_con_loss: 0.5068 contrastive_loss: 5.2657 nll_loss: 0.0026 
2023-10-30 08:18:06.619 | INFO     | __main__:train:314 - Epoch: [100][1100/1251]	 loss 4.69191	 cls_loss: 0.5057 cluster_loss: 1.4075 sup_con_loss: 0.4908 contrastive_loss: 5.2725 nll_loss: 0.0011 
2023-10-30 08:21:51.436 | INFO     | __main__:train:314 - Epoch: [100][1200/1251]	 loss 4.61720	 cls_loss: 0.4931 cluster_loss: 1.3452 sup_con_loss: 0.4158 contrastive_loss: 5.2668 nll_loss: 0.0013 
2023-10-30 08:23:42.671 | INFO     | __main__:train:319 - Train Epoch: 100 Avg Loss: 4.5572 
2023-10-30 08:23:42.679 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 08:41:41.363 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 100, Train ACC Unlabelled_v2: All 0.6060 | Old 0.7828 | New 0.5172
2023-10-30 08:41:41.597 | INFO     | __main__:main:205 - Train Accuracies: All 0.6060 | Old 0.7828 | New 0.5172
2023-10-30 08:41:45.444 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 08:41:58.993 | INFO     | __main__:train:314 - Epoch: [101][0/1251]	 loss 4.66956	 cls_loss: 0.4999 cluster_loss: 1.3684 sup_con_loss: 0.5083 contrastive_loss: 5.2699 nll_loss: 0.0018 
2023-10-30 08:45:42.917 | INFO     | __main__:train:314 - Epoch: [101][100/1251]	 loss 4.51934	 cls_loss: 0.3695 cluster_loss: 1.3213 sup_con_loss: 0.3034 contrastive_loss: 5.2647 nll_loss: 0.0029 
2023-10-30 08:49:26.115 | INFO     | __main__:train:314 - Epoch: [101][200/1251]	 loss 4.65899	 cls_loss: 0.4656 cluster_loss: 1.3863 sup_con_loss: 0.4783 contrastive_loss: 5.2702 nll_loss: 0.0019 
2023-10-30 08:53:09.350 | INFO     | __main__:train:314 - Epoch: [101][300/1251]	 loss 4.53577	 cls_loss: 0.3865 cluster_loss: 1.2759 sup_con_loss: 0.4241 contrastive_loss: 5.2630 nll_loss: 0.0018 
2023-10-30 08:56:56.893 | INFO     | __main__:train:314 - Epoch: [101][400/1251]	 loss 4.42965	 cls_loss: 0.3636 cluster_loss: 1.2663 sup_con_loss: 0.1528 contrastive_loss: 5.2676 nll_loss: 0.0019 
2023-10-30 09:00:40.209 | INFO     | __main__:train:314 - Epoch: [101][500/1251]	 loss 4.45449	 cls_loss: 0.3629 cluster_loss: 1.2376 sup_con_loss: 0.2895 contrastive_loss: 5.2628 nll_loss: 0.0009 
2023-10-30 09:04:23.953 | INFO     | __main__:train:314 - Epoch: [101][600/1251]	 loss 4.48681	 cls_loss: 0.3415 cluster_loss: 1.2751 sup_con_loss: 0.3316 contrastive_loss: 5.2632 nll_loss: 0.0013 
2023-10-30 09:08:06.787 | INFO     | __main__:train:314 - Epoch: [101][700/1251]	 loss 4.50402	 cls_loss: 0.4101 cluster_loss: 1.3012 sup_con_loss: 0.2646 contrastive_loss: 5.2636 nll_loss: 0.0008 
2023-10-30 09:11:50.947 | INFO     | __main__:train:314 - Epoch: [101][800/1251]	 loss 4.51766	 cls_loss: 0.4142 cluster_loss: 1.3172 sup_con_loss: 0.2645 contrastive_loss: 5.2652 nll_loss: 0.0016 
2023-10-30 09:15:34.132 | INFO     | __main__:train:314 - Epoch: [101][900/1251]	 loss 4.57051	 cls_loss: 0.4210 cluster_loss: 1.3338 sup_con_loss: 0.3786 contrastive_loss: 5.2646 nll_loss: 0.0017 
2023-10-30 09:19:20.323 | INFO     | __main__:train:314 - Epoch: [101][1000/1251]	 loss 4.49408	 cls_loss: 0.4089 cluster_loss: 1.2747 sup_con_loss: 0.2855 contrastive_loss: 5.2624 nll_loss: 0.0019 
2023-10-30 09:23:03.117 | INFO     | __main__:train:314 - Epoch: [101][1100/1251]	 loss 4.55789	 cls_loss: 0.3856 cluster_loss: 1.3185 sup_con_loss: 0.4042 contrastive_loss: 5.2648 nll_loss: 0.0023 
2023-10-30 09:26:47.971 | INFO     | __main__:train:314 - Epoch: [101][1200/1251]	 loss 4.63010	 cls_loss: 0.5554 cluster_loss: 1.3115 sup_con_loss: 0.4529 contrastive_loss: 5.2667 nll_loss: 0.0013 
2023-10-30 09:28:39.241 | INFO     | __main__:train:319 - Train Epoch: 101 Avg Loss: 4.5543 
2023-10-30 09:28:39.248 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 09:46:50.401 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 101, Train ACC Unlabelled_v2: All 0.6037 | Old 0.7783 | New 0.5159
2023-10-30 09:46:50.459 | INFO     | __main__:main:205 - Train Accuracies: All 0.6037 | Old 0.7783 | New 0.5159
2023-10-30 09:46:53.216 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 09:47:06.968 | INFO     | __main__:train:314 - Epoch: [102][0/1251]	 loss 4.56128	 cls_loss: 0.4802 cluster_loss: 1.3285 sup_con_loss: 0.2995 contrastive_loss: 5.2658 nll_loss: 0.0021 
2023-10-30 09:50:53.610 | INFO     | __main__:train:314 - Epoch: [102][100/1251]	 loss 4.50251	 cls_loss: 0.4699 cluster_loss: 1.2735 sup_con_loss: 0.2544 contrastive_loss: 5.2619 nll_loss: 0.0010 
2023-10-30 09:54:36.661 | INFO     | __main__:train:314 - Epoch: [102][200/1251]	 loss 4.56254	 cls_loss: 0.4432 cluster_loss: 1.3084 sup_con_loss: 0.3778 contrastive_loss: 5.2662 nll_loss: 0.0017 
2023-10-30 09:58:20.491 | INFO     | __main__:train:314 - Epoch: [102][300/1251]	 loss 4.55394	 cls_loss: 0.3602 cluster_loss: 1.3059 sup_con_loss: 0.4329 contrastive_loss: 5.2705 nll_loss: 0.0017 
2023-10-30 10:02:06.275 | INFO     | __main__:train:314 - Epoch: [102][400/1251]	 loss 4.64583	 cls_loss: 0.4409 cluster_loss: 1.3447 sup_con_loss: 0.5498 contrastive_loss: 5.2662 nll_loss: 0.0021 
2023-10-30 10:06:01.658 | INFO     | __main__:train:314 - Epoch: [102][500/1251]	 loss 4.53718	 cls_loss: 0.4230 cluster_loss: 1.3138 sup_con_loss: 0.3197 contrastive_loss: 5.2632 nll_loss: 0.0022 
2023-10-30 10:09:47.795 | INFO     | __main__:train:314 - Epoch: [102][600/1251]	 loss 4.54599	 cls_loss: 0.4082 cluster_loss: 1.2946 sup_con_loss: 0.3939 contrastive_loss: 5.2634 nll_loss: 0.0025 
2023-10-30 10:13:31.523 | INFO     | __main__:train:314 - Epoch: [102][700/1251]	 loss 4.49605	 cls_loss: 0.4098 cluster_loss: 1.2818 sup_con_loss: 0.2701 contrastive_loss: 5.2659 nll_loss: 0.0021 
2023-10-30 10:17:27.685 | INFO     | __main__:train:314 - Epoch: [102][800/1251]	 loss 4.58366	 cls_loss: 0.4057 cluster_loss: 1.3451 sup_con_loss: 0.4051 contrastive_loss: 5.2674 nll_loss: 0.0018 
2023-10-30 10:21:11.990 | INFO     | __main__:train:314 - Epoch: [102][900/1251]	 loss 4.62351	 cls_loss: 0.4769 cluster_loss: 1.3990 sup_con_loss: 0.3301 contrastive_loss: 5.2772 nll_loss: 0.0016 
2023-10-30 10:24:56.643 | INFO     | __main__:train:314 - Epoch: [102][1000/1251]	 loss 4.52582	 cls_loss: 0.3938 cluster_loss: 1.2797 sup_con_loss: 0.3751 contrastive_loss: 5.2657 nll_loss: 0.0022 
2023-10-30 10:28:41.804 | INFO     | __main__:train:314 - Epoch: [102][1100/1251]	 loss 4.54495	 cls_loss: 0.4078 cluster_loss: 1.3187 sup_con_loss: 0.3451 contrastive_loss: 5.2645 nll_loss: 0.0024 
2023-10-30 10:32:26.378 | INFO     | __main__:train:314 - Epoch: [102][1200/1251]	 loss 4.55905	 cls_loss: 0.3798 cluster_loss: 1.3610 sup_con_loss: 0.3267 contrastive_loss: 5.2688 nll_loss: 0.0024 
2023-10-30 10:34:17.329 | INFO     | __main__:train:319 - Train Epoch: 102 Avg Loss: 4.5528 
2023-10-30 10:34:17.337 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 10:54:59.626 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 102, Train ACC Unlabelled_v2: All 0.6071 | Old 0.7814 | New 0.5194
2023-10-30 10:54:59.882 | INFO     | __main__:main:205 - Train Accuracies: All 0.6071 | Old 0.7814 | New 0.5194
2023-10-30 10:55:02.627 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 10:55:19.370 | INFO     | __main__:train:314 - Epoch: [103][0/1251]	 loss 4.51255	 cls_loss: 0.4086 cluster_loss: 1.2761 sup_con_loss: 0.3315 contrastive_loss: 5.2629 nll_loss: 0.0032 
2023-10-30 10:59:06.487 | INFO     | __main__:train:314 - Epoch: [103][100/1251]	 loss 4.64197	 cls_loss: 0.4919 cluster_loss: 1.3927 sup_con_loss: 0.3920 contrastive_loss: 5.2705 nll_loss: 0.0014 
2023-10-30 11:02:51.921 | INFO     | __main__:train:314 - Epoch: [103][200/1251]	 loss 4.44593	 cls_loss: 0.3302 cluster_loss: 1.2654 sup_con_loss: 0.2457 contrastive_loss: 5.2618 nll_loss: 0.0017 
2023-10-30 11:06:37.608 | INFO     | __main__:train:314 - Epoch: [103][300/1251]	 loss 4.55381	 cls_loss: 0.3716 cluster_loss: 1.3280 sup_con_loss: 0.3844 contrastive_loss: 5.2688 nll_loss: 0.0013 
2023-10-30 11:10:23.583 | INFO     | __main__:train:314 - Epoch: [103][400/1251]	 loss 4.51635	 cls_loss: 0.4612 cluster_loss: 1.2433 sup_con_loss: 0.3550 contrastive_loss: 5.2624 nll_loss: 0.0020 
2023-10-30 11:15:50.031 | INFO     | __main__:train:314 - Epoch: [103][500/1251]	 loss 4.54568	 cls_loss: 0.4220 cluster_loss: 1.2665 sup_con_loss: 0.4325 contrastive_loss: 5.2647 nll_loss: 0.0013 
2023-10-30 11:19:53.873 | INFO     | __main__:train:314 - Epoch: [103][600/1251]	 loss 4.57394	 cls_loss: 0.3637 cluster_loss: 1.3498 sup_con_loss: 0.4049 contrastive_loss: 5.2699 nll_loss: 0.0022 
2023-10-30 11:23:47.644 | INFO     | __main__:train:314 - Epoch: [103][700/1251]	 loss 4.53177	 cls_loss: 0.3495 cluster_loss: 1.2970 sup_con_loss: 0.4128 contrastive_loss: 5.2614 nll_loss: 0.0020 
2023-10-30 11:27:48.350 | INFO     | __main__:train:314 - Epoch: [103][800/1251]	 loss 4.49017	 cls_loss: 0.4037 cluster_loss: 1.2648 sup_con_loss: 0.3020 contrastive_loss: 5.2616 nll_loss: 0.0011 
2023-10-30 11:31:47.876 | INFO     | __main__:train:314 - Epoch: [103][900/1251]	 loss 4.46124	 cls_loss: 0.3412 cluster_loss: 1.2901 sup_con_loss: 0.2293 contrastive_loss: 5.2626 nll_loss: 0.0023 
2023-10-30 11:35:41.491 | INFO     | __main__:train:314 - Epoch: [103][1000/1251]	 loss 4.54166	 cls_loss: 0.4237 cluster_loss: 1.3042 sup_con_loss: 0.3521 contrastive_loss: 5.2631 nll_loss: 0.0014 
2023-10-30 11:39:47.410 | INFO     | __main__:train:314 - Epoch: [103][1100/1251]	 loss 4.62514	 cls_loss: 0.5306 cluster_loss: 1.3389 sup_con_loss: 0.4164 contrastive_loss: 5.2639 nll_loss: 0.0018 
2023-10-30 11:44:19.296 | INFO     | __main__:train:314 - Epoch: [103][1200/1251]	 loss 4.57552	 cls_loss: 0.4485 cluster_loss: 1.3414 sup_con_loss: 0.3494 contrastive_loss: 5.2660 nll_loss: 0.0015 
2023-10-30 11:46:40.298 | INFO     | __main__:train:319 - Train Epoch: 103 Avg Loss: 4.5490 
2023-10-30 11:46:40.305 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 12:37:34.567 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 103, Train ACC Unlabelled_v2: All 0.6064 | Old 0.7815 | New 0.5185
2023-10-30 12:37:35.010 | INFO     | __main__:main:205 - Train Accuracies: All 0.6064 | Old 0.7815 | New 0.5185
2023-10-30 12:37:40.140 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 12:38:04.802 | INFO     | __main__:train:314 - Epoch: [104][0/1251]	 loss 4.51460	 cls_loss: 0.3328 cluster_loss: 1.3187 sup_con_loss: 0.3264 contrastive_loss: 5.2673 nll_loss: 0.0030 
2023-10-30 12:42:37.016 | INFO     | __main__:train:314 - Epoch: [104][100/1251]	 loss 4.52173	 cls_loss: 0.3923 cluster_loss: 1.2769 sup_con_loss: 0.3739 contrastive_loss: 5.2657 nll_loss: 0.0009 
2023-10-30 12:46:25.845 | INFO     | __main__:train:314 - Epoch: [104][200/1251]	 loss 4.51621	 cls_loss: 0.3411 cluster_loss: 1.2980 sup_con_loss: 0.3716 contrastive_loss: 5.2636 nll_loss: 0.0018 
2023-10-30 12:50:36.581 | INFO     | __main__:train:314 - Epoch: [104][300/1251]	 loss 4.59333	 cls_loss: 0.4264 cluster_loss: 1.3162 sup_con_loss: 0.4713 contrastive_loss: 5.2645 nll_loss: 0.0017 
2023-10-30 12:54:24.923 | INFO     | __main__:train:314 - Epoch: [104][400/1251]	 loss 4.51711	 cls_loss: 0.4256 cluster_loss: 1.2897 sup_con_loss: 0.2987 contrastive_loss: 5.2653 nll_loss: 0.0028 
2023-10-30 12:58:26.296 | INFO     | __main__:train:314 - Epoch: [104][500/1251]	 loss 4.57175	 cls_loss: 0.4658 cluster_loss: 1.2932 sup_con_loss: 0.4104 contrastive_loss: 5.2667 nll_loss: 0.0011 
2023-10-30 13:02:35.551 | INFO     | __main__:train:314 - Epoch: [104][600/1251]	 loss 4.50976	 cls_loss: 0.3780 cluster_loss: 1.2849 sup_con_loss: 0.3356 contrastive_loss: 5.2653 nll_loss: 0.0024 
2023-10-30 13:06:26.708 | INFO     | __main__:train:314 - Epoch: [104][700/1251]	 loss 4.56507	 cls_loss: 0.3727 cluster_loss: 1.3760 sup_con_loss: 0.3262 contrastive_loss: 5.2694 nll_loss: 0.0009 
2023-10-30 13:10:12.990 | INFO     | __main__:train:314 - Epoch: [104][800/1251]	 loss 4.63867	 cls_loss: 0.4584 cluster_loss: 1.3204 sup_con_loss: 0.5684 contrastive_loss: 5.2619 nll_loss: 0.0008 
2023-10-30 13:14:01.232 | INFO     | __main__:train:314 - Epoch: [104][900/1251]	 loss 4.52436	 cls_loss: 0.3410 cluster_loss: 1.2846 sup_con_loss: 0.4214 contrastive_loss: 5.2633 nll_loss: 0.0014 
2023-10-30 13:17:46.222 | INFO     | __main__:train:314 - Epoch: [104][1000/1251]	 loss 4.51283	 cls_loss: 0.4862 cluster_loss: 1.2388 sup_con_loss: 0.3266 contrastive_loss: 5.2644 nll_loss: 0.0013 
2023-10-30 13:21:49.249 | INFO     | __main__:train:314 - Epoch: [104][1100/1251]	 loss 4.56939	 cls_loss: 0.3767 cluster_loss: 1.3301 sup_con_loss: 0.4190 contrastive_loss: 5.2671 nll_loss: 0.0027 
2023-10-30 13:26:03.452 | INFO     | __main__:train:314 - Epoch: [104][1200/1251]	 loss 4.60352	 cls_loss: 0.3805 cluster_loss: 1.3904 sup_con_loss: 0.3922 contrastive_loss: 5.2723 nll_loss: 0.0023 
2023-10-30 13:29:12.703 | INFO     | __main__:train:319 - Train Epoch: 104 Avg Loss: 4.5462 
2023-10-30 13:29:12.714 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 14:04:59.690 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 104, Train ACC Unlabelled_v2: All 0.6058 | Old 0.7822 | New 0.5171
2023-10-30 14:04:59.727 | INFO     | __main__:main:205 - Train Accuracies: All 0.6058 | Old 0.7822 | New 0.5171
2023-10-30 14:05:03.064 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 14:05:24.770 | INFO     | __main__:train:314 - Epoch: [105][0/1251]	 loss 4.51275	 cls_loss: 0.4564 cluster_loss: 1.2944 sup_con_loss: 0.2452 contrastive_loss: 5.2671 nll_loss: 0.0022 
2023-10-30 14:09:20.028 | INFO     | __main__:train:314 - Epoch: [105][100/1251]	 loss 4.52217	 cls_loss: 0.4247 cluster_loss: 1.2537 sup_con_loss: 0.3918 contrastive_loss: 5.2619 nll_loss: 0.0013 
2023-10-30 14:13:03.940 | INFO     | __main__:train:314 - Epoch: [105][200/1251]	 loss 4.57872	 cls_loss: 0.4315 cluster_loss: 1.3871 sup_con_loss: 0.2755 contrastive_loss: 5.2720 nll_loss: 0.0029 
2023-10-30 14:16:49.848 | INFO     | __main__:train:314 - Epoch: [105][300/1251]	 loss 4.50992	 cls_loss: 0.4381 cluster_loss: 1.3022 sup_con_loss: 0.2424 contrastive_loss: 5.2661 nll_loss: 0.0024 
2023-10-30 14:20:36.109 | INFO     | __main__:train:314 - Epoch: [105][400/1251]	 loss 4.53889	 cls_loss: 0.4114 cluster_loss: 1.3250 sup_con_loss: 0.3062 contrastive_loss: 5.2680 nll_loss: 0.0023 
2023-10-30 14:24:46.137 | INFO     | __main__:train:314 - Epoch: [105][500/1251]	 loss 4.53126	 cls_loss: 0.4357 cluster_loss: 1.3263 sup_con_loss: 0.2632 contrastive_loss: 5.2659 nll_loss: 0.0017 
2023-10-30 14:28:36.472 | INFO     | __main__:train:314 - Epoch: [105][600/1251]	 loss 4.58613	 cls_loss: 0.5352 cluster_loss: 1.3129 sup_con_loss: 0.3340 contrastive_loss: 5.2699 nll_loss: 0.0031 
2023-10-30 14:32:22.767 | INFO     | __main__:train:314 - Epoch: [105][700/1251]	 loss 4.48365	 cls_loss: 0.3719 cluster_loss: 1.2987 sup_con_loss: 0.2505 contrastive_loss: 5.2609 nll_loss: 0.0021 
2023-10-30 14:36:09.818 | INFO     | __main__:train:314 - Epoch: [105][800/1251]	 loss 4.52863	 cls_loss: 0.3315 cluster_loss: 1.3592 sup_con_loss: 0.2967 contrastive_loss: 5.2663 nll_loss: 0.0022 
2023-10-30 14:40:03.815 | INFO     | __main__:train:314 - Epoch: [105][900/1251]	 loss 4.53292	 cls_loss: 0.3853 cluster_loss: 1.3363 sup_con_loss: 0.2981 contrastive_loss: 5.2666 nll_loss: 0.0019 
2023-10-30 14:43:46.222 | INFO     | __main__:train:314 - Epoch: [105][1000/1251]	 loss 4.60031	 cls_loss: 0.4670 cluster_loss: 1.3546 sup_con_loss: 0.3608 contrastive_loss: 5.2751 nll_loss: 0.0013 
2023-10-30 14:47:31.523 | INFO     | __main__:train:314 - Epoch: [105][1100/1251]	 loss 4.54700	 cls_loss: 0.4229 cluster_loss: 1.3052 sup_con_loss: 0.3600 contrastive_loss: 5.2674 nll_loss: 0.0008 
2023-10-30 14:51:19.062 | INFO     | __main__:train:314 - Epoch: [105][1200/1251]	 loss 4.68169	 cls_loss: 0.5908 cluster_loss: 1.3725 sup_con_loss: 0.4436 contrastive_loss: 5.2694 nll_loss: 0.0024 
2023-10-30 14:53:15.101 | INFO     | __main__:train:319 - Train Epoch: 105 Avg Loss: 4.5429 
2023-10-30 14:53:15.110 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 15:22:02.258 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 105, Train ACC Unlabelled_v2: All 0.6058 | Old 0.7807 | New 0.5178
2023-10-30 15:22:02.455 | INFO     | __main__:main:205 - Train Accuracies: All 0.6058 | Old 0.7807 | New 0.5178
2023-10-30 15:22:06.512 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 15:22:33.815 | INFO     | __main__:train:314 - Epoch: [106][0/1251]	 loss 4.51686	 cls_loss: 0.3909 cluster_loss: 1.3149 sup_con_loss: 0.2924 contrastive_loss: 5.2626 nll_loss: 0.0023 
2023-10-30 15:26:20.529 | INFO     | __main__:train:314 - Epoch: [106][100/1251]	 loss 4.54572	 cls_loss: 0.4234 cluster_loss: 1.3378 sup_con_loss: 0.2920 contrastive_loss: 5.2685 nll_loss: 0.0012 
2023-10-30 15:30:08.377 | INFO     | __main__:train:314 - Epoch: [106][200/1251]	 loss 4.51439	 cls_loss: 0.3845 cluster_loss: 1.3170 sup_con_loss: 0.2857 contrastive_loss: 5.2655 nll_loss: 0.0012 
2023-10-30 15:33:56.844 | INFO     | __main__:train:314 - Epoch: [106][300/1251]	 loss 4.48269	 cls_loss: 0.3609 cluster_loss: 1.2682 sup_con_loss: 0.3198 contrastive_loss: 5.2590 nll_loss: 0.0017 
2023-10-30 15:37:42.736 | INFO     | __main__:train:314 - Epoch: [106][400/1251]	 loss 4.58117	 cls_loss: 0.4237 cluster_loss: 1.3242 sup_con_loss: 0.4208 contrastive_loss: 5.2664 nll_loss: 0.0017 
2023-10-30 15:41:30.585 | INFO     | __main__:train:314 - Epoch: [106][500/1251]	 loss 4.49975	 cls_loss: 0.3141 cluster_loss: 1.3066 sup_con_loss: 0.3305 contrastive_loss: 5.2660 nll_loss: 0.0020 
2023-10-30 15:45:45.394 | INFO     | __main__:train:314 - Epoch: [106][600/1251]	 loss 4.58096	 cls_loss: 0.4229 cluster_loss: 1.3124 sup_con_loss: 0.4474 contrastive_loss: 5.2644 nll_loss: 0.0014 
2023-10-30 15:49:40.583 | INFO     | __main__:train:314 - Epoch: [106][700/1251]	 loss 4.51638	 cls_loss: 0.3881 cluster_loss: 1.3042 sup_con_loss: 0.3076 contrastive_loss: 5.2675 nll_loss: 0.0013 
2023-10-30 15:53:31.889 | INFO     | __main__:train:314 - Epoch: [106][800/1251]	 loss 4.45513	 cls_loss: 0.3464 cluster_loss: 1.3126 sup_con_loss: 0.1592 contrastive_loss: 5.2665 nll_loss: 0.0018 
2023-10-30 15:57:21.939 | INFO     | __main__:train:314 - Epoch: [106][900/1251]	 loss 4.51229	 cls_loss: 0.3552 cluster_loss: 1.2724 sup_con_loss: 0.3958 contrastive_loss: 5.2622 nll_loss: 0.0020 
2023-10-30 16:01:21.420 | INFO     | __main__:train:314 - Epoch: [106][1000/1251]	 loss 4.44896	 cls_loss: 0.3802 cluster_loss: 1.2099 sup_con_loss: 0.3211 contrastive_loss: 5.2557 nll_loss: 0.0009 
2023-10-30 16:05:05.287 | INFO     | __main__:train:314 - Epoch: [106][1100/1251]	 loss 4.51668	 cls_loss: 0.4050 cluster_loss: 1.3224 sup_con_loss: 0.2569 contrastive_loss: 5.2658 nll_loss: 0.0027 
2023-10-30 16:08:50.529 | INFO     | __main__:train:314 - Epoch: [106][1200/1251]	 loss 4.57837	 cls_loss: 0.4526 cluster_loss: 1.3073 sup_con_loss: 0.4176 contrastive_loss: 5.2646 nll_loss: 0.0021 
2023-10-30 16:10:44.604 | INFO     | __main__:train:319 - Train Epoch: 106 Avg Loss: 4.5411 
2023-10-30 16:10:44.612 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 16:44:52.818 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 106, Train ACC Unlabelled_v2: All 0.6047 | Old 0.7787 | New 0.5172
2023-10-30 16:44:53.032 | INFO     | __main__:main:205 - Train Accuracies: All 0.6047 | Old 0.7787 | New 0.5172
2023-10-30 16:44:56.209 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 16:45:18.817 | INFO     | __main__:train:314 - Epoch: [107][0/1251]	 loss 4.51961	 cls_loss: 0.3321 cluster_loss: 1.2901 sup_con_loss: 0.4054 contrastive_loss: 5.2624 nll_loss: 0.0024 
2023-10-30 16:49:18.505 | INFO     | __main__:train:314 - Epoch: [107][100/1251]	 loss 4.52186	 cls_loss: 0.3418 cluster_loss: 1.3747 sup_con_loss: 0.2385 contrastive_loss: 5.2681 nll_loss: 0.0010 
2023-10-30 16:53:04.463 | INFO     | __main__:train:314 - Epoch: [107][200/1251]	 loss 4.51130	 cls_loss: 0.4070 cluster_loss: 1.2899 sup_con_loss: 0.3073 contrastive_loss: 5.2636 nll_loss: 0.0015 
2023-10-30 16:56:52.940 | INFO     | __main__:train:314 - Epoch: [107][300/1251]	 loss 4.56028	 cls_loss: 0.4511 cluster_loss: 1.3543 sup_con_loss: 0.2709 contrastive_loss: 5.2697 nll_loss: 0.0020 
2023-10-30 17:00:37.823 | INFO     | __main__:train:314 - Epoch: [107][400/1251]	 loss 4.45743	 cls_loss: 0.3424 cluster_loss: 1.2808 sup_con_loss: 0.2393 contrastive_loss: 5.2610 nll_loss: 0.0016 
2023-10-30 17:04:28.580 | INFO     | __main__:train:314 - Epoch: [107][500/1251]	 loss 4.58019	 cls_loss: 0.4900 cluster_loss: 1.3126 sup_con_loss: 0.3661 contrastive_loss: 5.2688 nll_loss: 0.0026 
2023-10-30 17:08:18.562 | INFO     | __main__:train:314 - Epoch: [107][600/1251]	 loss 4.48062	 cls_loss: 0.3432 cluster_loss: 1.2708 sup_con_loss: 0.3169 contrastive_loss: 5.2640 nll_loss: 0.0019 
2023-10-30 17:12:06.094 | INFO     | __main__:train:314 - Epoch: [107][700/1251]	 loss 4.56499	 cls_loss: 0.4582 cluster_loss: 1.3042 sup_con_loss: 0.3740 contrastive_loss: 5.2669 nll_loss: 0.0025 
2023-10-30 17:15:56.952 | INFO     | __main__:train:314 - Epoch: [107][800/1251]	 loss 4.53378	 cls_loss: 0.4933 cluster_loss: 1.3017 sup_con_loss: 0.2604 contrastive_loss: 5.2650 nll_loss: 0.0016 
2023-10-30 17:20:25.150 | INFO     | __main__:train:314 - Epoch: [107][900/1251]	 loss 4.56828	 cls_loss: 0.3869 cluster_loss: 1.3502 sup_con_loss: 0.3718 contrastive_loss: 5.2668 nll_loss: 0.0017 
2023-10-30 17:25:00.024 | INFO     | __main__:train:314 - Epoch: [107][1000/1251]	 loss 4.48602	 cls_loss: 0.4327 cluster_loss: 1.2837 sup_con_loss: 0.2135 contrastive_loss: 5.2659 nll_loss: 0.0026 
2023-10-30 17:29:06.289 | INFO     | __main__:train:314 - Epoch: [107][1100/1251]	 loss 4.62283	 cls_loss: 0.4377 cluster_loss: 1.2996 sup_con_loss: 0.5739 contrastive_loss: 5.2645 nll_loss: 0.0021 
2023-10-30 17:33:00.213 | INFO     | __main__:train:314 - Epoch: [107][1200/1251]	 loss 4.50123	 cls_loss: 0.3668 cluster_loss: 1.3364 sup_con_loss: 0.2188 contrastive_loss: 5.2708 nll_loss: 0.0016 
2023-10-30 17:35:20.271 | INFO     | __main__:train:319 - Train Epoch: 107 Avg Loss: 4.5397 
2023-10-30 17:35:20.334 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 18:25:25.881 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 107, Train ACC Unlabelled_v2: All 0.6061 | Old 0.7809 | New 0.5182
2023-10-30 18:25:26.417 | INFO     | __main__:main:205 - Train Accuracies: All 0.6061 | Old 0.7809 | New 0.5182
2023-10-30 18:25:57.136 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 18:26:35.892 | INFO     | __main__:train:314 - Epoch: [108][0/1251]	 loss 4.42514	 cls_loss: 0.2882 cluster_loss: 1.2567 sup_con_loss: 0.2380 contrastive_loss: 5.2631 nll_loss: 0.0031 
2023-10-30 18:33:22.278 | INFO     | __main__:train:314 - Epoch: [108][100/1251]	 loss 4.55720	 cls_loss: 0.3577 cluster_loss: 1.3190 sup_con_loss: 0.4282 contrastive_loss: 5.2664 nll_loss: 0.0016 
2023-10-30 18:38:34.184 | INFO     | __main__:train:314 - Epoch: [108][200/1251]	 loss 4.47459	 cls_loss: 0.3029 cluster_loss: 1.2956 sup_con_loss: 0.2995 contrastive_loss: 5.2613 nll_loss: 0.0018 
2023-10-30 18:43:17.758 | INFO     | __main__:train:314 - Epoch: [108][300/1251]	 loss 4.61336	 cls_loss: 0.3523 cluster_loss: 1.3945 sup_con_loss: 0.4384 contrastive_loss: 5.2751 nll_loss: 0.0014 
2023-10-30 18:47:46.290 | INFO     | __main__:train:314 - Epoch: [108][400/1251]	 loss 4.54615	 cls_loss: 0.4322 cluster_loss: 1.3302 sup_con_loss: 0.2946 contrastive_loss: 5.2677 nll_loss: 0.0032 
2023-10-30 18:52:14.497 | INFO     | __main__:train:314 - Epoch: [108][500/1251]	 loss 4.54742	 cls_loss: 0.4653 cluster_loss: 1.3324 sup_con_loss: 0.2584 contrastive_loss: 5.2708 nll_loss: 0.0020 
2023-10-30 18:59:29.920 | INFO     | __main__:train:314 - Epoch: [108][600/1251]	 loss 4.50791	 cls_loss: 0.4045 cluster_loss: 1.2563 sup_con_loss: 0.3619 contrastive_loss: 5.2638 nll_loss: 0.0016 
2023-10-30 19:05:12.910 | INFO     | __main__:train:314 - Epoch: [108][700/1251]	 loss 4.51863	 cls_loss: 0.4193 cluster_loss: 1.3065 sup_con_loss: 0.2830 contrastive_loss: 5.2635 nll_loss: 0.0023 
2023-10-30 19:09:50.225 | INFO     | __main__:train:314 - Epoch: [108][800/1251]	 loss 4.53935	 cls_loss: 0.4248 cluster_loss: 1.2620 sup_con_loss: 0.4254 contrastive_loss: 5.2610 nll_loss: 0.0018 
2023-10-30 19:13:59.916 | INFO     | __main__:train:314 - Epoch: [108][900/1251]	 loss 4.51205	 cls_loss: 0.3455 cluster_loss: 1.3400 sup_con_loss: 0.2652 contrastive_loss: 5.2712 nll_loss: 0.0010 
2023-10-30 19:17:45.961 | INFO     | __main__:train:314 - Epoch: [108][1000/1251]	 loss 4.60562	 cls_loss: 0.4917 cluster_loss: 1.2923 sup_con_loss: 0.4861 contrastive_loss: 5.2649 nll_loss: 0.0012 
2023-10-30 19:21:39.698 | INFO     | __main__:train:314 - Epoch: [108][1100/1251]	 loss 4.60361	 cls_loss: 0.4675 cluster_loss: 1.3117 sup_con_loss: 0.4564 contrastive_loss: 5.2683 nll_loss: 0.0032 
2023-10-30 19:25:29.938 | INFO     | __main__:train:314 - Epoch: [108][1200/1251]	 loss 4.50059	 cls_loss: 0.3240 cluster_loss: 1.3675 sup_con_loss: 0.1932 contrastive_loss: 5.2748 nll_loss: 0.0020 
2023-10-30 19:27:25.190 | INFO     | __main__:train:319 - Train Epoch: 108 Avg Loss: 4.5371 
2023-10-30 19:27:25.194 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 19:55:51.576 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 108, Train ACC Unlabelled_v2: All 0.6061 | Old 0.7815 | New 0.5180
2023-10-30 19:55:51.610 | INFO     | __main__:main:205 - Train Accuracies: All 0.6061 | Old 0.7815 | New 0.5180
2023-10-30 19:55:54.493 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 19:56:10.286 | INFO     | __main__:train:314 - Epoch: [109][0/1251]	 loss 4.56459	 cls_loss: 0.3945 cluster_loss: 1.3347 sup_con_loss: 0.3813 contrastive_loss: 5.2679 nll_loss: 0.0014 
2023-10-30 20:00:07.098 | INFO     | __main__:train:314 - Epoch: [109][100/1251]	 loss 4.55064	 cls_loss: 0.3959 cluster_loss: 1.2891 sup_con_loss: 0.4368 contrastive_loss: 5.2605 nll_loss: 0.0019 
2023-10-30 20:03:53.793 | INFO     | __main__:train:314 - Epoch: [109][200/1251]	 loss 4.53504	 cls_loss: 0.4439 cluster_loss: 1.3056 sup_con_loss: 0.3027 contrastive_loss: 5.2663 nll_loss: 0.0020 
2023-10-30 20:07:44.431 | INFO     | __main__:train:314 - Epoch: [109][300/1251]	 loss 4.56941	 cls_loss: 0.3659 cluster_loss: 1.3484 sup_con_loss: 0.4008 contrastive_loss: 5.2645 nll_loss: 0.0027 
2023-10-30 20:11:39.197 | INFO     | __main__:train:314 - Epoch: [109][400/1251]	 loss 4.56150	 cls_loss: 0.4242 cluster_loss: 1.2410 sup_con_loss: 0.5332 contrastive_loss: 5.2583 nll_loss: 0.0019 
2023-10-30 20:15:24.264 | INFO     | __main__:train:314 - Epoch: [109][500/1251]	 loss 4.49812	 cls_loss: 0.3905 cluster_loss: 1.3310 sup_con_loss: 0.2008 contrastive_loss: 5.2679 nll_loss: 0.0019 
2023-10-30 20:19:08.656 | INFO     | __main__:train:314 - Epoch: [109][600/1251]	 loss 4.52498	 cls_loss: 0.4969 cluster_loss: 1.2461 sup_con_loss: 0.3376 contrastive_loss: 5.2635 nll_loss: 0.0017 
2023-10-30 20:22:58.877 | INFO     | __main__:train:314 - Epoch: [109][700/1251]	 loss 4.44497	 cls_loss: 0.3957 cluster_loss: 1.2626 sup_con_loss: 0.1792 contrastive_loss: 5.2626 nll_loss: 0.0024 
2023-10-30 20:26:46.535 | INFO     | __main__:train:314 - Epoch: [109][800/1251]	 loss 4.55195	 cls_loss: 0.3780 cluster_loss: 1.2811 sup_con_loss: 0.4669 contrastive_loss: 5.2645 nll_loss: 0.0016 
2023-10-30 20:30:30.308 | INFO     | __main__:train:314 - Epoch: [109][900/1251]	 loss 4.47002	 cls_loss: 0.3712 cluster_loss: 1.2524 sup_con_loss: 0.2938 contrastive_loss: 5.2628 nll_loss: 0.0024 
2023-10-30 20:34:13.746 | INFO     | __main__:train:314 - Epoch: [109][1000/1251]	 loss 4.52844	 cls_loss: 0.3548 cluster_loss: 1.2805 sup_con_loss: 0.4308 contrastive_loss: 5.2617 nll_loss: 0.0011 
2023-10-30 20:37:58.266 | INFO     | __main__:train:314 - Epoch: [109][1100/1251]	 loss 4.51985	 cls_loss: 0.3441 cluster_loss: 1.3285 sup_con_loss: 0.3234 contrastive_loss: 5.2631 nll_loss: 0.0017 
2023-10-30 20:41:44.925 | INFO     | __main__:train:314 - Epoch: [109][1200/1251]	 loss 4.55360	 cls_loss: 0.3528 cluster_loss: 1.3705 sup_con_loss: 0.3220 contrastive_loss: 5.2684 nll_loss: 0.0022 
2023-10-30 20:43:36.422 | INFO     | __main__:train:319 - Train Epoch: 109 Avg Loss: 4.5338 
2023-10-30 20:43:36.430 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 21:09:29.475 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 109, Train ACC Unlabelled_v2: All 0.6055 | Old 0.7805 | New 0.5175
2023-10-30 21:09:29.700 | INFO     | __main__:main:205 - Train Accuracies: All 0.6055 | Old 0.7805 | New 0.5175
2023-10-30 21:09:33.280 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 21:09:49.948 | INFO     | __main__:train:314 - Epoch: [110][0/1251]	 loss 4.57551	 cls_loss: 0.4588 cluster_loss: 1.3487 sup_con_loss: 0.3154 contrastive_loss: 5.2704 nll_loss: 0.0021 
2023-10-30 21:13:38.607 | INFO     | __main__:train:314 - Epoch: [110][100/1251]	 loss 4.52644	 cls_loss: 0.4940 cluster_loss: 1.2513 sup_con_loss: 0.3276 contrastive_loss: 5.2672 nll_loss: 0.0019 
2023-10-30 21:17:25.349 | INFO     | __main__:train:314 - Epoch: [110][200/1251]	 loss 4.63112	 cls_loss: 0.4600 cluster_loss: 1.3893 sup_con_loss: 0.3982 contrastive_loss: 5.2714 nll_loss: 0.0013 
2023-10-30 21:21:13.841 | INFO     | __main__:train:314 - Epoch: [110][300/1251]	 loss 4.56654	 cls_loss: 0.4123 cluster_loss: 1.3210 sup_con_loss: 0.4008 contrastive_loss: 5.2644 nll_loss: 0.0014 
2023-10-30 21:24:56.899 | INFO     | __main__:train:314 - Epoch: [110][400/1251]	 loss 4.46978	 cls_loss: 0.4331 cluster_loss: 1.2703 sup_con_loss: 0.2008 contrastive_loss: 5.2625 nll_loss: 0.0016 
2023-10-30 21:28:43.219 | INFO     | __main__:train:314 - Epoch: [110][500/1251]	 loss 4.48284	 cls_loss: 0.3236 cluster_loss: 1.3153 sup_con_loss: 0.2624 contrastive_loss: 5.2632 nll_loss: 0.0017 
2023-10-30 21:32:38.609 | INFO     | __main__:train:314 - Epoch: [110][600/1251]	 loss 4.56370	 cls_loss: 0.4461 cluster_loss: 1.3018 sup_con_loss: 0.3936 contrastive_loss: 5.2640 nll_loss: 0.0021 
2023-10-30 21:36:25.679 | INFO     | __main__:train:314 - Epoch: [110][700/1251]	 loss 4.44751	 cls_loss: 0.3322 cluster_loss: 1.2151 sup_con_loss: 0.3450 contrastive_loss: 5.2600 nll_loss: 0.0017 
2023-10-30 21:40:13.170 | INFO     | __main__:train:314 - Epoch: [110][800/1251]	 loss 4.47154	 cls_loss: 0.3347 cluster_loss: 1.2692 sup_con_loss: 0.2998 contrastive_loss: 5.2661 nll_loss: 0.0015 
2023-10-30 21:44:05.897 | INFO     | __main__:train:314 - Epoch: [110][900/1251]	 loss 4.55732	 cls_loss: 0.4333 cluster_loss: 1.3597 sup_con_loss: 0.2693 contrastive_loss: 5.2713 nll_loss: 0.0013 
2023-10-30 21:47:51.061 | INFO     | __main__:train:314 - Epoch: [110][1000/1251]	 loss 4.47132	 cls_loss: 0.3433 cluster_loss: 1.2542 sup_con_loss: 0.3280 contrastive_loss: 5.2595 nll_loss: 0.0024 
2023-10-30 21:51:35.544 | INFO     | __main__:train:314 - Epoch: [110][1100/1251]	 loss 4.50114	 cls_loss: 0.3333 cluster_loss: 1.2725 sup_con_loss: 0.3867 contrastive_loss: 5.2620 nll_loss: 0.0018 
2023-10-30 21:55:22.171 | INFO     | __main__:train:314 - Epoch: [110][1200/1251]	 loss 4.48915	 cls_loss: 0.4260 cluster_loss: 1.2802 sup_con_loss: 0.2348 contrastive_loss: 5.2674 nll_loss: 0.0019 
2023-10-30 21:57:15.075 | INFO     | __main__:train:319 - Train Epoch: 110 Avg Loss: 4.5280 
2023-10-30 21:57:15.099 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 22:18:38.299 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 110, Train ACC Unlabelled_v2: All 0.6070 | Old 0.7798 | New 0.5201
2023-10-30 22:18:38.777 | INFO     | __main__:main:205 - Train Accuracies: All 0.6070 | Old 0.7798 | New 0.5201
2023-10-30 22:18:42.509 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 22:18:56.130 | INFO     | __main__:train:314 - Epoch: [111][0/1251]	 loss 4.53882	 cls_loss: 0.3784 cluster_loss: 1.3346 sup_con_loss: 0.3288 contrastive_loss: 5.2654 nll_loss: 0.0013 
2023-10-30 22:22:41.623 | INFO     | __main__:train:314 - Epoch: [111][100/1251]	 loss 4.60903	 cls_loss: 0.4210 cluster_loss: 1.3772 sup_con_loss: 0.3935 contrastive_loss: 5.2725 nll_loss: 0.0016 
2023-10-30 22:26:26.921 | INFO     | __main__:train:314 - Epoch: [111][200/1251]	 loss 4.53849	 cls_loss: 0.4307 cluster_loss: 1.2682 sup_con_loss: 0.4060 contrastive_loss: 5.2604 nll_loss: 0.0021 
2023-10-30 22:30:13.370 | INFO     | __main__:train:314 - Epoch: [111][300/1251]	 loss 4.53863	 cls_loss: 0.4092 cluster_loss: 1.3185 sup_con_loss: 0.3325 contrastive_loss: 5.2614 nll_loss: 0.0021 
2023-10-30 22:34:01.812 | INFO     | __main__:train:314 - Epoch: [111][400/1251]	 loss 4.61567	 cls_loss: 0.5859 cluster_loss: 1.2922 sup_con_loss: 0.4287 contrastive_loss: 5.2598 nll_loss: 0.0018 
2023-10-30 22:37:45.979 | INFO     | __main__:train:314 - Epoch: [111][500/1251]	 loss 4.53903	 cls_loss: 0.3221 cluster_loss: 1.3179 sup_con_loss: 0.4127 contrastive_loss: 5.2670 nll_loss: 0.0016 
2023-10-30 22:41:28.686 | INFO     | __main__:train:314 - Epoch: [111][600/1251]	 loss 4.62022	 cls_loss: 0.4805 cluster_loss: 1.3527 sup_con_loss: 0.4159 contrastive_loss: 5.2709 nll_loss: 0.0011 
2023-10-30 22:45:18.198 | INFO     | __main__:train:314 - Epoch: [111][700/1251]	 loss 4.61504	 cls_loss: 0.4605 cluster_loss: 1.3840 sup_con_loss: 0.3577 contrastive_loss: 5.2723 nll_loss: 0.0020 
2023-10-30 22:49:04.092 | INFO     | __main__:train:314 - Epoch: [111][800/1251]	 loss 4.50213	 cls_loss: 0.3819 cluster_loss: 1.3014 sup_con_loss: 0.2808 contrastive_loss: 5.2656 nll_loss: 0.0017 
2023-10-30 22:52:48.618 | INFO     | __main__:train:314 - Epoch: [111][900/1251]	 loss 4.51997	 cls_loss: 0.5009 cluster_loss: 1.2906 sup_con_loss: 0.2351 contrastive_loss: 5.2648 nll_loss: 0.0014 
2023-10-30 22:56:35.801 | INFO     | __main__:train:314 - Epoch: [111][1000/1251]	 loss 4.48901	 cls_loss: 0.3744 cluster_loss: 1.2813 sup_con_loss: 0.2860 contrastive_loss: 5.2668 nll_loss: 0.0015 
2023-10-30 23:00:22.141 | INFO     | __main__:train:314 - Epoch: [111][1100/1251]	 loss 4.55840	 cls_loss: 0.3762 cluster_loss: 1.2864 sup_con_loss: 0.4847 contrastive_loss: 5.2605 nll_loss: 0.0016 
2023-10-30 23:04:05.586 | INFO     | __main__:train:314 - Epoch: [111][1200/1251]	 loss 4.47900	 cls_loss: 0.3657 cluster_loss: 1.2844 sup_con_loss: 0.2659 contrastive_loss: 5.2644 nll_loss: 0.0012 
2023-10-30 23:06:00.744 | INFO     | __main__:train:319 - Train Epoch: 111 Avg Loss: 4.5329 
2023-10-30 23:06:00.844 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-30 23:28:14.048 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 111, Train ACC Unlabelled_v2: All 0.6072 | Old 0.7809 | New 0.5198
2023-10-30 23:28:14.100 | INFO     | __main__:main:205 - Train Accuracies: All 0.6072 | Old 0.7809 | New 0.5198
2023-10-30 23:28:16.757 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-30 23:28:32.139 | INFO     | __main__:train:314 - Epoch: [112][0/1251]	 loss 4.62737	 cls_loss: 0.3734 cluster_loss: 1.3780 sup_con_loss: 0.4961 contrastive_loss: 5.2699 nll_loss: 0.0019 
2023-10-30 23:32:16.731 | INFO     | __main__:train:314 - Epoch: [112][100/1251]	 loss 4.55307	 cls_loss: 0.3567 cluster_loss: 1.3175 sup_con_loss: 0.4190 contrastive_loss: 5.2667 nll_loss: 0.0018 
2023-10-30 23:36:01.067 | INFO     | __main__:train:314 - Epoch: [112][200/1251]	 loss 4.55080	 cls_loss: 0.4105 cluster_loss: 1.3212 sup_con_loss: 0.3557 contrastive_loss: 5.2643 nll_loss: 0.0020 
2023-10-30 23:39:54.325 | INFO     | __main__:train:314 - Epoch: [112][300/1251]	 loss 4.52161	 cls_loss: 0.4920 cluster_loss: 1.2554 sup_con_loss: 0.3200 contrastive_loss: 5.2599 nll_loss: 0.0025 
2023-10-30 23:43:46.715 | INFO     | __main__:train:314 - Epoch: [112][400/1251]	 loss 4.51327	 cls_loss: 0.3413 cluster_loss: 1.2843 sup_con_loss: 0.3937 contrastive_loss: 5.2614 nll_loss: 0.0013 
2023-10-30 23:47:29.755 | INFO     | __main__:train:314 - Epoch: [112][500/1251]	 loss 4.49009	 cls_loss: 0.3186 cluster_loss: 1.2927 sup_con_loss: 0.3296 contrastive_loss: 5.2637 nll_loss: 0.0015 
2023-10-30 23:51:16.062 | INFO     | __main__:train:314 - Epoch: [112][600/1251]	 loss 4.65690	 cls_loss: 0.4028 cluster_loss: 1.4234 sup_con_loss: 0.4624 contrastive_loss: 5.2724 nll_loss: 0.0019 
2023-10-30 23:54:59.859 | INFO     | __main__:train:314 - Epoch: [112][700/1251]	 loss 4.50004	 cls_loss: 0.3436 cluster_loss: 1.3109 sup_con_loss: 0.2958 contrastive_loss: 5.2665 nll_loss: 0.0009 
2023-10-30 23:58:47.593 | INFO     | __main__:train:314 - Epoch: [112][800/1251]	 loss 4.52585	 cls_loss: 0.4032 cluster_loss: 1.3155 sup_con_loss: 0.3055 contrastive_loss: 5.2619 nll_loss: 0.0025 
2023-10-31 00:02:31.320 | INFO     | __main__:train:314 - Epoch: [112][900/1251]	 loss 4.49960	 cls_loss: 0.3974 cluster_loss: 1.3122 sup_con_loss: 0.2321 contrastive_loss: 5.2658 nll_loss: 0.0036 
2023-10-31 00:06:19.470 | INFO     | __main__:train:314 - Epoch: [112][1000/1251]	 loss 4.54466	 cls_loss: 0.4860 cluster_loss: 1.3185 sup_con_loss: 0.2594 contrastive_loss: 5.2673 nll_loss: 0.0030 
2023-10-31 00:10:09.759 | INFO     | __main__:train:314 - Epoch: [112][1100/1251]	 loss 4.51443	 cls_loss: 0.4038 cluster_loss: 1.3072 sup_con_loss: 0.2863 contrastive_loss: 5.2630 nll_loss: 0.0023 
2023-10-31 00:14:02.491 | INFO     | __main__:train:314 - Epoch: [112][1200/1251]	 loss 4.54704	 cls_loss: 0.5111 cluster_loss: 1.2357 sup_con_loss: 0.4066 contrastive_loss: 5.2616 nll_loss: 0.0026 
2023-10-31 00:15:53.407 | INFO     | __main__:train:319 - Train Epoch: 112 Avg Loss: 4.5225 
2023-10-31 00:15:53.411 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 00:36:03.814 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 112, Train ACC Unlabelled_v2: All 0.6062 | Old 0.7795 | New 0.5192
2023-10-31 00:36:04.046 | INFO     | __main__:main:205 - Train Accuracies: All 0.6062 | Old 0.7795 | New 0.5192
2023-10-31 00:36:07.332 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 00:36:22.834 | INFO     | __main__:train:314 - Epoch: [113][0/1251]	 loss 4.51997	 cls_loss: 0.3731 cluster_loss: 1.2950 sup_con_loss: 0.3548 contrastive_loss: 5.2640 nll_loss: 0.0018 
2023-10-31 00:40:09.959 | INFO     | __main__:train:314 - Epoch: [113][100/1251]	 loss 4.44701	 cls_loss: 0.3033 cluster_loss: 1.2904 sup_con_loss: 0.2280 contrastive_loss: 5.2619 nll_loss: 0.0020 
2023-10-31 00:43:56.593 | INFO     | __main__:train:314 - Epoch: [113][200/1251]	 loss 4.47044	 cls_loss: 0.2977 cluster_loss: 1.3030 sup_con_loss: 0.2789 contrastive_loss: 5.2602 nll_loss: 0.0026 
2023-10-31 00:47:41.636 | INFO     | __main__:train:314 - Epoch: [113][300/1251]	 loss 4.53745	 cls_loss: 0.4559 cluster_loss: 1.3224 sup_con_loss: 0.2701 contrastive_loss: 5.2646 nll_loss: 0.0018 
2023-10-31 00:51:24.533 | INFO     | __main__:train:314 - Epoch: [113][400/1251]	 loss 4.54971	 cls_loss: 0.3503 cluster_loss: 1.3308 sup_con_loss: 0.3876 contrastive_loss: 5.2681 nll_loss: 0.0022 
2023-10-31 00:55:13.768 | INFO     | __main__:train:314 - Epoch: [113][500/1251]	 loss 4.52087	 cls_loss: 0.3303 cluster_loss: 1.3125 sup_con_loss: 0.3682 contrastive_loss: 5.2635 nll_loss: 0.0020 
2023-10-31 00:59:01.407 | INFO     | __main__:train:314 - Epoch: [113][600/1251]	 loss 4.48367	 cls_loss: 0.3479 cluster_loss: 1.2558 sup_con_loss: 0.3547 contrastive_loss: 5.2612 nll_loss: 0.0017 
2023-10-31 01:02:46.789 | INFO     | __main__:train:314 - Epoch: [113][700/1251]	 loss 4.51909	 cls_loss: 0.3790 cluster_loss: 1.2956 sup_con_loss: 0.3488 contrastive_loss: 5.2637 nll_loss: 0.0008 
2023-10-31 01:06:32.336 | INFO     | __main__:train:314 - Epoch: [113][800/1251]	 loss 4.53702	 cls_loss: 0.3690 cluster_loss: 1.2833 sup_con_loss: 0.4337 contrastive_loss: 5.2620 nll_loss: 0.0016 
2023-10-31 01:10:19.293 | INFO     | __main__:train:314 - Epoch: [113][900/1251]	 loss 4.53330	 cls_loss: 0.2983 cluster_loss: 1.3547 sup_con_loss: 0.3422 contrastive_loss: 5.2712 nll_loss: 0.0023 
2023-10-31 01:14:10.101 | INFO     | __main__:train:314 - Epoch: [113][1000/1251]	 loss 4.47357	 cls_loss: 0.3387 cluster_loss: 1.2744 sup_con_loss: 0.3004 contrastive_loss: 5.2615 nll_loss: 0.0015 
2023-10-31 01:18:01.684 | INFO     | __main__:train:314 - Epoch: [113][1100/1251]	 loss 4.52860	 cls_loss: 0.3951 cluster_loss: 1.3064 sup_con_loss: 0.3339 contrastive_loss: 5.2648 nll_loss: 0.0021 
2023-10-31 01:21:48.391 | INFO     | __main__:train:314 - Epoch: [113][1200/1251]	 loss 4.49113	 cls_loss: 0.3956 cluster_loss: 1.2884 sup_con_loss: 0.2712 contrastive_loss: 5.2600 nll_loss: 0.0013 
2023-10-31 01:23:46.111 | INFO     | __main__:train:319 - Train Epoch: 113 Avg Loss: 4.5230 
2023-10-31 01:23:46.120 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 01:44:58.565 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 113, Train ACC Unlabelled_v2: All 0.6066 | Old 0.7805 | New 0.5192
2023-10-31 01:44:58.807 | INFO     | __main__:main:205 - Train Accuracies: All 0.6066 | Old 0.7805 | New 0.5192
2023-10-31 01:45:01.524 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 01:45:17.444 | INFO     | __main__:train:314 - Epoch: [114][0/1251]	 loss 4.52750	 cls_loss: 0.3952 cluster_loss: 1.3351 sup_con_loss: 0.2740 contrastive_loss: 5.2662 nll_loss: 0.0024 
2023-10-31 01:49:02.655 | INFO     | __main__:train:314 - Epoch: [114][100/1251]	 loss 4.47123	 cls_loss: 0.3034 cluster_loss: 1.2851 sup_con_loss: 0.3036 contrastive_loss: 5.2650 nll_loss: 0.0012 
2023-10-31 01:52:49.400 | INFO     | __main__:train:314 - Epoch: [114][200/1251]	 loss 4.60963	 cls_loss: 0.4092 cluster_loss: 1.3628 sup_con_loss: 0.4429 contrastive_loss: 5.2674 nll_loss: 0.0018 
2023-10-31 01:56:37.440 | INFO     | __main__:train:314 - Epoch: [114][300/1251]	 loss 4.53575	 cls_loss: 0.3586 cluster_loss: 1.2584 sup_con_loss: 0.4868 contrastive_loss: 5.2620 nll_loss: 0.0016 
2023-10-31 02:00:23.399 | INFO     | __main__:train:314 - Epoch: [114][400/1251]	 loss 4.49760	 cls_loss: 0.3678 cluster_loss: 1.2757 sup_con_loss: 0.3359 contrastive_loss: 5.2625 nll_loss: 0.0015 
2023-10-31 02:04:13.543 | INFO     | __main__:train:314 - Epoch: [114][500/1251]	 loss 4.53444	 cls_loss: 0.4471 cluster_loss: 1.2975 sup_con_loss: 0.3222 contrastive_loss: 5.2615 nll_loss: 0.0018 
2023-10-31 02:08:08.179 | INFO     | __main__:train:314 - Epoch: [114][600/1251]	 loss 4.47180	 cls_loss: 0.3482 cluster_loss: 1.2639 sup_con_loss: 0.3049 contrastive_loss: 5.2607 nll_loss: 0.0023 
2023-10-31 02:11:54.634 | INFO     | __main__:train:314 - Epoch: [114][700/1251]	 loss 4.47335	 cls_loss: 0.3503 cluster_loss: 1.2891 sup_con_loss: 0.2586 contrastive_loss: 5.2616 nll_loss: 0.0023 
2023-10-31 02:16:10.283 | INFO     | __main__:train:314 - Epoch: [114][800/1251]	 loss 4.42150	 cls_loss: 0.2761 cluster_loss: 1.2765 sup_con_loss: 0.2124 contrastive_loss: 5.2604 nll_loss: 0.0016 
2023-10-31 02:19:57.573 | INFO     | __main__:train:314 - Epoch: [114][900/1251]	 loss 4.52674	 cls_loss: 0.3170 cluster_loss: 1.3199 sup_con_loss: 0.3895 contrastive_loss: 5.2627 nll_loss: 0.0008 
2023-10-31 02:23:40.940 | INFO     | __main__:train:314 - Epoch: [114][1000/1251]	 loss 4.54551	 cls_loss: 0.3495 cluster_loss: 1.2831 sup_con_loss: 0.4746 contrastive_loss: 5.2637 nll_loss: 0.0016 
2023-10-31 02:27:24.529 | INFO     | __main__:train:314 - Epoch: [114][1100/1251]	 loss 4.46941	 cls_loss: 0.3531 cluster_loss: 1.2652 sup_con_loss: 0.2975 contrastive_loss: 5.2589 nll_loss: 0.0010 
2023-10-31 02:31:07.285 | INFO     | __main__:train:314 - Epoch: [114][1200/1251]	 loss 4.53811	 cls_loss: 0.3967 cluster_loss: 1.3422 sup_con_loss: 0.2878 contrastive_loss: 5.2683 nll_loss: 0.0017 
2023-10-31 02:32:58.520 | INFO     | __main__:train:319 - Train Epoch: 114 Avg Loss: 4.5187 
2023-10-31 02:32:58.525 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 02:52:29.202 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 114, Train ACC Unlabelled_v2: All 0.6070 | Old 0.7790 | New 0.5206
2023-10-31 02:52:29.464 | INFO     | __main__:main:205 - Train Accuracies: All 0.6070 | Old 0.7790 | New 0.5206
2023-10-31 02:52:32.604 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 02:52:48.607 | INFO     | __main__:train:314 - Epoch: [115][0/1251]	 loss 4.47019	 cls_loss: 0.3685 cluster_loss: 1.2870 sup_con_loss: 0.2378 contrastive_loss: 5.2622 nll_loss: 0.0010 
2023-10-31 02:56:31.291 | INFO     | __main__:train:314 - Epoch: [115][100/1251]	 loss 4.55282	 cls_loss: 0.3761 cluster_loss: 1.3033 sup_con_loss: 0.4250 contrastive_loss: 5.2681 nll_loss: 0.0010 
2023-10-31 03:00:23.909 | INFO     | __main__:train:314 - Epoch: [115][200/1251]	 loss 4.47668	 cls_loss: 0.3561 cluster_loss: 1.2878 sup_con_loss: 0.2637 contrastive_loss: 5.2626 nll_loss: 0.0019 
2023-10-31 03:04:09.909 | INFO     | __main__:train:314 - Epoch: [115][300/1251]	 loss 4.53910	 cls_loss: 0.4088 cluster_loss: 1.3386 sup_con_loss: 0.2844 contrastive_loss: 5.2672 nll_loss: 0.0027 
2023-10-31 03:07:53.499 | INFO     | __main__:train:314 - Epoch: [115][400/1251]	 loss 4.44894	 cls_loss: 0.2979 cluster_loss: 1.2609 sup_con_loss: 0.2971 contrastive_loss: 5.2596 nll_loss: 0.0024 
2023-10-31 03:11:42.024 | INFO     | __main__:train:314 - Epoch: [115][500/1251]	 loss 4.53049	 cls_loss: 0.3815 cluster_loss: 1.2844 sup_con_loss: 0.3985 contrastive_loss: 5.2633 nll_loss: 0.0014 
2023-10-31 03:15:26.899 | INFO     | __main__:train:314 - Epoch: [115][600/1251]	 loss 4.53045	 cls_loss: 0.4764 cluster_loss: 1.3123 sup_con_loss: 0.2520 contrastive_loss: 5.2635 nll_loss: 0.0012 
2023-10-31 03:19:11.320 | INFO     | __main__:train:314 - Epoch: [115][700/1251]	 loss 4.44131	 cls_loss: 0.3319 cluster_loss: 1.2661 sup_con_loss: 0.2285 contrastive_loss: 5.2621 nll_loss: 0.0018 
2023-10-31 03:22:55.736 | INFO     | __main__:train:314 - Epoch: [115][800/1251]	 loss 4.44981	 cls_loss: 0.2943 cluster_loss: 1.2594 sup_con_loss: 0.3103 contrastive_loss: 5.2590 nll_loss: 0.0013 
2023-10-31 03:26:41.317 | INFO     | __main__:train:314 - Epoch: [115][900/1251]	 loss 4.56963	 cls_loss: 0.4169 cluster_loss: 1.3077 sup_con_loss: 0.4249 contrastive_loss: 5.2666 nll_loss: 0.0017 
2023-10-31 03:30:25.689 | INFO     | __main__:train:314 - Epoch: [115][1000/1251]	 loss 4.48116	 cls_loss: 0.3842 cluster_loss: 1.2748 sup_con_loss: 0.2678 contrastive_loss: 5.2656 nll_loss: 0.0017 
2023-10-31 03:34:08.948 | INFO     | __main__:train:314 - Epoch: [115][1100/1251]	 loss 4.45963	 cls_loss: 0.3629 cluster_loss: 1.2467 sup_con_loss: 0.2838 contrastive_loss: 5.2620 nll_loss: 0.0026 
2023-10-31 03:37:54.430 | INFO     | __main__:train:314 - Epoch: [115][1200/1251]	 loss 4.50352	 cls_loss: 0.3433 cluster_loss: 1.2976 sup_con_loss: 0.3344 contrastive_loss: 5.2633 nll_loss: 0.0018 
2023-10-31 03:39:46.694 | INFO     | __main__:train:319 - Train Epoch: 115 Avg Loss: 4.5150 
2023-10-31 03:39:46.699 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 03:59:25.026 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 115, Train ACC Unlabelled_v2: All 0.6074 | Old 0.7799 | New 0.5208
2023-10-31 03:59:25.210 | INFO     | __main__:main:205 - Train Accuracies: All 0.6074 | Old 0.7799 | New 0.5208
2023-10-31 03:59:29.661 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 03:59:44.044 | INFO     | __main__:train:314 - Epoch: [116][0/1251]	 loss 4.61987	 cls_loss: 0.3795 cluster_loss: 1.3751 sup_con_loss: 0.4819 contrastive_loss: 5.2670 nll_loss: 0.0011 
2023-10-31 04:03:28.028 | INFO     | __main__:train:314 - Epoch: [116][100/1251]	 loss 4.53798	 cls_loss: 0.4094 cluster_loss: 1.3270 sup_con_loss: 0.3068 contrastive_loss: 5.2673 nll_loss: 0.0010 
2023-10-31 04:07:13.931 | INFO     | __main__:train:314 - Epoch: [116][200/1251]	 loss 4.50148	 cls_loss: 0.3189 cluster_loss: 1.2962 sup_con_loss: 0.3571 contrastive_loss: 5.2632 nll_loss: 0.0013 
2023-10-31 04:11:00.547 | INFO     | __main__:train:314 - Epoch: [116][300/1251]	 loss 4.59030	 cls_loss: 0.4856 cluster_loss: 1.3042 sup_con_loss: 0.4258 contrastive_loss: 5.2650 nll_loss: 0.0014 
2023-10-31 04:14:44.741 | INFO     | __main__:train:314 - Epoch: [116][400/1251]	 loss 4.54389	 cls_loss: 0.3841 cluster_loss: 1.3016 sup_con_loss: 0.4111 contrastive_loss: 5.2588 nll_loss: 0.0014 
2023-10-31 04:18:34.594 | INFO     | __main__:train:314 - Epoch: [116][500/1251]	 loss 4.60351	 cls_loss: 0.4504 cluster_loss: 1.2905 sup_con_loss: 0.5345 contrastive_loss: 5.2595 nll_loss: 0.0013 
2023-10-31 04:22:35.048 | INFO     | __main__:train:314 - Epoch: [116][600/1251]	 loss 4.56623	 cls_loss: 0.4189 cluster_loss: 1.2898 sup_con_loss: 0.4472 contrastive_loss: 5.2648 nll_loss: 0.0026 
2023-10-31 04:26:20.015 | INFO     | __main__:train:314 - Epoch: [116][700/1251]	 loss 4.50587	 cls_loss: 0.3360 cluster_loss: 1.3078 sup_con_loss: 0.3328 contrastive_loss: 5.2621 nll_loss: 0.0013 
2023-10-31 04:30:04.806 | INFO     | __main__:train:314 - Epoch: [116][800/1251]	 loss 4.46658	 cls_loss: 0.2871 cluster_loss: 1.2718 sup_con_loss: 0.3340 contrastive_loss: 5.2617 nll_loss: 0.0024 
2023-10-31 04:33:50.344 | INFO     | __main__:train:314 - Epoch: [116][900/1251]	 loss 4.54542	 cls_loss: 0.3709 cluster_loss: 1.3080 sup_con_loss: 0.4063 contrastive_loss: 5.2628 nll_loss: 0.0024 
2023-10-31 04:37:35.845 | INFO     | __main__:train:314 - Epoch: [116][1000/1251]	 loss 4.53471	 cls_loss: 0.3843 cluster_loss: 1.3223 sup_con_loss: 0.3282 contrastive_loss: 5.2681 nll_loss: 0.0016 
2023-10-31 04:41:23.306 | INFO     | __main__:train:314 - Epoch: [116][1100/1251]	 loss 4.58008	 cls_loss: 0.3678 cluster_loss: 1.3485 sup_con_loss: 0.4252 contrastive_loss: 5.2668 nll_loss: 0.0026 
2023-10-31 04:45:06.538 | INFO     | __main__:train:314 - Epoch: [116][1200/1251]	 loss 4.60707	 cls_loss: 0.4270 cluster_loss: 1.3404 sup_con_loss: 0.4615 contrastive_loss: 5.2661 nll_loss: 0.0019 
2023-10-31 04:46:59.435 | INFO     | __main__:train:319 - Train Epoch: 116 Avg Loss: 4.5149 
2023-10-31 04:46:59.490 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 05:06:41.599 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 116, Train ACC Unlabelled_v2: All 0.6079 | Old 0.7823 | New 0.5202
2023-10-31 05:06:41.809 | INFO     | __main__:main:205 - Train Accuracies: All 0.6079 | Old 0.7823 | New 0.5202
2023-10-31 05:06:45.169 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 05:06:59.400 | INFO     | __main__:train:314 - Epoch: [117][0/1251]	 loss 4.53918	 cls_loss: 0.3124 cluster_loss: 1.3142 sup_con_loss: 0.4297 contrastive_loss: 5.2665 nll_loss: 0.0020 
2023-10-31 05:10:43.889 | INFO     | __main__:train:314 - Epoch: [117][100/1251]	 loss 4.53469	 cls_loss: 0.3272 cluster_loss: 1.3585 sup_con_loss: 0.3139 contrastive_loss: 5.2704 nll_loss: 0.0016 
2023-10-31 05:14:27.066 | INFO     | __main__:train:314 - Epoch: [117][200/1251]	 loss 4.51918	 cls_loss: 0.3520 cluster_loss: 1.3024 sup_con_loss: 0.3634 contrastive_loss: 5.2643 nll_loss: 0.0005 
2023-10-31 05:18:09.135 | INFO     | __main__:train:314 - Epoch: [117][300/1251]	 loss 4.54973	 cls_loss: 0.4262 cluster_loss: 1.2742 sup_con_loss: 0.4326 contrastive_loss: 5.2616 nll_loss: 0.0009 
2023-10-31 05:21:58.248 | INFO     | __main__:train:314 - Epoch: [117][400/1251]	 loss 4.50732	 cls_loss: 0.3982 cluster_loss: 1.2962 sup_con_loss: 0.3008 contrastive_loss: 5.2585 nll_loss: 0.0021 
2023-10-31 05:25:43.029 | INFO     | __main__:train:314 - Epoch: [117][500/1251]	 loss 4.56694	 cls_loss: 0.4536 cluster_loss: 1.2847 sup_con_loss: 0.4320 contrastive_loss: 5.2619 nll_loss: 0.0017 
2023-10-31 05:29:38.394 | INFO     | __main__:train:314 - Epoch: [117][600/1251]	 loss 4.46865	 cls_loss: 0.3404 cluster_loss: 1.2604 sup_con_loss: 0.3179 contrastive_loss: 5.2577 nll_loss: 0.0014 
2023-10-31 05:33:24.486 | INFO     | __main__:train:314 - Epoch: [117][700/1251]	 loss 4.52764	 cls_loss: 0.3083 cluster_loss: 1.3653 sup_con_loss: 0.2991 contrastive_loss: 5.2713 nll_loss: 0.0013 
2023-10-31 05:37:09.796 | INFO     | __main__:train:314 - Epoch: [117][800/1251]	 loss 4.54181	 cls_loss: 0.3233 cluster_loss: 1.3533 sup_con_loss: 0.3412 contrastive_loss: 5.2742 nll_loss: 0.0014 
2023-10-31 05:40:54.128 | INFO     | __main__:train:314 - Epoch: [117][900/1251]	 loss 4.46828	 cls_loss: 0.2671 cluster_loss: 1.2748 sup_con_loss: 0.3553 contrastive_loss: 5.2612 nll_loss: 0.0020 
2023-10-31 05:44:44.005 | INFO     | __main__:train:314 - Epoch: [117][1000/1251]	 loss 4.51123	 cls_loss: 0.3903 cluster_loss: 1.2523 sup_con_loss: 0.4037 contrastive_loss: 5.2587 nll_loss: 0.0012 
2023-10-31 05:48:27.992 | INFO     | __main__:train:314 - Epoch: [117][1100/1251]	 loss 4.51389	 cls_loss: 0.3321 cluster_loss: 1.3075 sup_con_loss: 0.3549 contrastive_loss: 5.2657 nll_loss: 0.0009 
2023-10-31 05:52:11.296 | INFO     | __main__:train:314 - Epoch: [117][1200/1251]	 loss 4.51037	 cls_loss: 0.3281 cluster_loss: 1.3226 sup_con_loss: 0.3162 contrastive_loss: 5.2653 nll_loss: 0.0027 
2023-10-31 05:54:03.385 | INFO     | __main__:train:319 - Train Epoch: 117 Avg Loss: 4.5081 
2023-10-31 05:54:03.393 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 06:12:16.417 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 117, Train ACC Unlabelled_v2: All 0.6089 | Old 0.7833 | New 0.5212
2023-10-31 06:12:16.637 | INFO     | __main__:main:205 - Train Accuracies: All 0.6089 | Old 0.7833 | New 0.5212
2023-10-31 06:12:20.012 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 06:12:32.344 | INFO     | __main__:train:314 - Epoch: [118][0/1251]	 loss 4.53889	 cls_loss: 0.4203 cluster_loss: 1.3139 sup_con_loss: 0.3250 contrastive_loss: 5.2650 nll_loss: 0.0017 
2023-10-31 06:16:17.086 | INFO     | __main__:train:314 - Epoch: [118][100/1251]	 loss 4.48923	 cls_loss: 0.3327 cluster_loss: 1.3404 sup_con_loss: 0.2227 contrastive_loss: 5.2635 nll_loss: 0.0023 
2023-10-31 06:20:01.286 | INFO     | __main__:train:314 - Epoch: [118][200/1251]	 loss 4.59391	 cls_loss: 0.4490 cluster_loss: 1.3240 sup_con_loss: 0.4361 contrastive_loss: 5.2647 nll_loss: 0.0015 
2023-10-31 06:23:48.874 | INFO     | __main__:train:314 - Epoch: [118][300/1251]	 loss 4.55084	 cls_loss: 0.2815 cluster_loss: 1.3371 sup_con_loss: 0.4527 contrastive_loss: 5.2647 nll_loss: 0.0027 
2023-10-31 06:27:32.272 | INFO     | __main__:train:314 - Epoch: [118][400/1251]	 loss 4.38849	 cls_loss: 0.3071 cluster_loss: 1.1982 sup_con_loss: 0.2357 contrastive_loss: 5.2588 nll_loss: 0.0015 
2023-10-31 06:31:14.840 | INFO     | __main__:train:314 - Epoch: [118][500/1251]	 loss 4.56821	 cls_loss: 0.4273 cluster_loss: 1.3003 sup_con_loss: 0.4356 contrastive_loss: 5.2610 nll_loss: 0.0013 
2023-10-31 06:34:58.778 | INFO     | __main__:train:314 - Epoch: [118][600/1251]	 loss 4.55117	 cls_loss: 0.3612 cluster_loss: 1.3138 sup_con_loss: 0.4235 contrastive_loss: 5.2643 nll_loss: 0.0007 
2023-10-31 06:38:43.938 | INFO     | __main__:train:314 - Epoch: [118][700/1251]	 loss 4.47272	 cls_loss: 0.4462 cluster_loss: 1.2755 sup_con_loss: 0.1768 contrastive_loss: 5.2683 nll_loss: 0.0012 
2023-10-31 06:42:29.395 | INFO     | __main__:train:314 - Epoch: [118][800/1251]	 loss 4.41026	 cls_loss: 0.2977 cluster_loss: 1.2294 sup_con_loss: 0.2468 contrastive_loss: 5.2605 nll_loss: 0.0012 
2023-10-31 06:46:13.086 | INFO     | __main__:train:314 - Epoch: [118][900/1251]	 loss 4.49499	 cls_loss: 0.2901 cluster_loss: 1.3350 sup_con_loss: 0.2842 contrastive_loss: 5.2686 nll_loss: 0.0016 
2023-10-31 06:49:58.042 | INFO     | __main__:train:314 - Epoch: [118][1000/1251]	 loss 4.54662	 cls_loss: 0.3577 cluster_loss: 1.3089 sup_con_loss: 0.4177 contrastive_loss: 5.2648 nll_loss: 0.0023 
2023-10-31 06:53:42.198 | INFO     | __main__:train:314 - Epoch: [118][1100/1251]	 loss 4.50247	 cls_loss: 0.2991 cluster_loss: 1.3071 sup_con_loss: 0.3517 contrastive_loss: 5.2659 nll_loss: 0.0023 
2023-10-31 06:57:27.779 | INFO     | __main__:train:314 - Epoch: [118][1200/1251]	 loss 4.50092	 cls_loss: 0.4385 cluster_loss: 1.3164 sup_con_loss: 0.1943 contrastive_loss: 5.2646 nll_loss: 0.0018 
2023-10-31 06:59:19.497 | INFO     | __main__:train:319 - Train Epoch: 118 Avg Loss: 4.5106 
2023-10-31 06:59:19.505 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 07:17:16.733 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 118, Train ACC Unlabelled_v2: All 0.6104 | Old 0.7811 | New 0.5246
2023-10-31 07:17:16.905 | INFO     | __main__:main:205 - Train Accuracies: All 0.6104 | Old 0.7811 | New 0.5246
2023-10-31 07:17:19.802 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 07:17:34.368 | INFO     | __main__:train:314 - Epoch: [119][0/1251]	 loss 4.56424	 cls_loss: 0.3996 cluster_loss: 1.3374 sup_con_loss: 0.3710 contrastive_loss: 5.2661 nll_loss: 0.0023 
2023-10-31 07:21:20.135 | INFO     | __main__:train:314 - Epoch: [119][100/1251]	 loss 4.44143	 cls_loss: 0.3664 cluster_loss: 1.2388 sup_con_loss: 0.2509 contrastive_loss: 5.2596 nll_loss: 0.0014 
2023-10-31 07:25:04.187 | INFO     | __main__:train:314 - Epoch: [119][200/1251]	 loss 4.60746	 cls_loss: 0.3799 cluster_loss: 1.3675 sup_con_loss: 0.4600 contrastive_loss: 5.2664 nll_loss: 0.0014 
2023-10-31 07:28:48.331 | INFO     | __main__:train:314 - Epoch: [119][300/1251]	 loss 4.48219	 cls_loss: 0.3330 cluster_loss: 1.2617 sup_con_loss: 0.3567 contrastive_loss: 5.2595 nll_loss: 0.0020 
2023-10-31 07:32:32.286 | INFO     | __main__:train:314 - Epoch: [119][400/1251]	 loss 4.50459	 cls_loss: 0.3620 cluster_loss: 1.3127 sup_con_loss: 0.2859 contrastive_loss: 5.2662 nll_loss: 0.0015 
2023-10-31 07:36:14.958 | INFO     | __main__:train:314 - Epoch: [119][500/1251]	 loss 4.48306	 cls_loss: 0.3082 cluster_loss: 1.2715 sup_con_loss: 0.3657 contrastive_loss: 5.2603 nll_loss: 0.0016 
2023-10-31 07:39:58.206 | INFO     | __main__:train:314 - Epoch: [119][600/1251]	 loss 4.55034	 cls_loss: 0.4051 cluster_loss: 1.2915 sup_con_loss: 0.4165 contrastive_loss: 5.2640 nll_loss: 0.0017 
2023-10-31 07:43:42.474 | INFO     | __main__:train:314 - Epoch: [119][700/1251]	 loss 4.43376	 cls_loss: 0.2723 cluster_loss: 1.2794 sup_con_loss: 0.2384 contrastive_loss: 5.2643 nll_loss: 0.0016 
2023-10-31 07:47:25.992 | INFO     | __main__:train:314 - Epoch: [119][800/1251]	 loss 4.63747	 cls_loss: 0.4448 cluster_loss: 1.3742 sup_con_loss: 0.4638 contrastive_loss: 5.2682 nll_loss: 0.0019 
2023-10-31 07:51:11.560 | INFO     | __main__:train:314 - Epoch: [119][900/1251]	 loss 4.46976	 cls_loss: 0.3285 cluster_loss: 1.2989 sup_con_loss: 0.2530 contrastive_loss: 5.2622 nll_loss: 0.0015 
2023-10-31 07:54:55.612 | INFO     | __main__:train:314 - Epoch: [119][1000/1251]	 loss 4.38197	 cls_loss: 0.2994 cluster_loss: 1.2421 sup_con_loss: 0.1428 contrastive_loss: 5.2590 nll_loss: 0.0015 
2023-10-31 07:58:39.928 | INFO     | __main__:train:314 - Epoch: [119][1100/1251]	 loss 4.40847	 cls_loss: 0.3354 cluster_loss: 1.2187 sup_con_loss: 0.2246 contrastive_loss: 5.2584 nll_loss: 0.0023 
2023-10-31 08:02:24.658 | INFO     | __main__:train:314 - Epoch: [119][1200/1251]	 loss 4.48129	 cls_loss: 0.3724 cluster_loss: 1.2640 sup_con_loss: 0.3070 contrastive_loss: 5.2620 nll_loss: 0.0016 
2023-10-31 08:04:17.222 | INFO     | __main__:train:319 - Train Epoch: 119 Avg Loss: 4.5072 
2023-10-31 08:04:17.231 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 08:21:53.283 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 119, Train ACC Unlabelled_v2: All 0.6088 | Old 0.7802 | New 0.5226
2023-10-31 08:21:53.465 | INFO     | __main__:main:205 - Train Accuracies: All 0.6088 | Old 0.7802 | New 0.5226
2023-10-31 08:21:57.625 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 08:22:15.513 | INFO     | __main__:train:314 - Epoch: [120][0/1251]	 loss 4.47859	 cls_loss: 0.3363 cluster_loss: 1.2761 sup_con_loss: 0.3193 contrastive_loss: 5.2591 nll_loss: 0.0012 
2023-10-31 08:26:01.762 | INFO     | __main__:train:314 - Epoch: [120][100/1251]	 loss 4.59099	 cls_loss: 0.4292 cluster_loss: 1.3124 sup_con_loss: 0.4735 contrastive_loss: 5.2612 nll_loss: 0.0022 
2023-10-31 08:29:46.433 | INFO     | __main__:train:314 - Epoch: [120][200/1251]	 loss 4.53030	 cls_loss: 0.3918 cluster_loss: 1.3206 sup_con_loss: 0.3221 contrastive_loss: 5.2624 nll_loss: 0.0014 
2023-10-31 08:33:30.278 | INFO     | __main__:train:314 - Epoch: [120][300/1251]	 loss 4.57918	 cls_loss: 0.3505 cluster_loss: 1.3771 sup_con_loss: 0.3924 contrastive_loss: 5.2652 nll_loss: 0.0016 
2023-10-31 08:37:13.181 | INFO     | __main__:train:314 - Epoch: [120][400/1251]	 loss 4.48021	 cls_loss: 0.3525 cluster_loss: 1.2905 sup_con_loss: 0.2755 contrastive_loss: 5.2611 nll_loss: 0.0018 
2023-10-31 08:40:57.450 | INFO     | __main__:train:314 - Epoch: [120][500/1251]	 loss 4.40846	 cls_loss: 0.2672 cluster_loss: 1.2203 sup_con_loss: 0.2923 contrastive_loss: 5.2573 nll_loss: 0.0022 
2023-10-31 08:44:43.470 | INFO     | __main__:train:314 - Epoch: [120][600/1251]	 loss 4.48399	 cls_loss: 0.4817 cluster_loss: 1.2522 sup_con_loss: 0.2274 contrastive_loss: 5.2620 nll_loss: 0.0015 
2023-10-31 08:48:27.800 | INFO     | __main__:train:314 - Epoch: [120][700/1251]	 loss 4.44568	 cls_loss: 0.2991 cluster_loss: 1.3379 sup_con_loss: 0.1308 contrastive_loss: 5.2680 nll_loss: 0.0014 
2023-10-31 08:52:10.453 | INFO     | __main__:train:314 - Epoch: [120][800/1251]	 loss 4.53194	 cls_loss: 0.3069 cluster_loss: 1.3550 sup_con_loss: 0.3285 contrastive_loss: 5.2707 nll_loss: 0.0029 
2023-10-31 08:55:53.651 | INFO     | __main__:train:314 - Epoch: [120][900/1251]	 loss 4.41036	 cls_loss: 0.2780 cluster_loss: 1.2432 sup_con_loss: 0.2445 contrastive_loss: 5.2571 nll_loss: 0.0023 
2023-10-31 08:59:37.540 | INFO     | __main__:train:314 - Epoch: [120][1000/1251]	 loss 4.49754	 cls_loss: 0.3313 cluster_loss: 1.3288 sup_con_loss: 0.2598 contrastive_loss: 5.2694 nll_loss: 0.0018 
2023-10-31 09:03:21.690 | INFO     | __main__:train:314 - Epoch: [120][1100/1251]	 loss 4.47097	 cls_loss: 0.2918 cluster_loss: 1.2772 sup_con_loss: 0.3284 contrastive_loss: 5.2650 nll_loss: 0.0015 
2023-10-31 09:07:08.014 | INFO     | __main__:train:314 - Epoch: [120][1200/1251]	 loss 4.59453	 cls_loss: 0.3579 cluster_loss: 1.3426 sup_con_loss: 0.4838 contrastive_loss: 5.2703 nll_loss: 0.0015 
2023-10-31 09:08:59.152 | INFO     | __main__:train:319 - Train Epoch: 120 Avg Loss: 4.5008 
2023-10-31 09:08:59.158 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 09:26:56.363 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 120, Train ACC Unlabelled_v2: All 0.6092 | Old 0.7822 | New 0.5222
2023-10-31 09:26:56.668 | INFO     | __main__:main:205 - Train Accuracies: All 0.6092 | Old 0.7822 | New 0.5222
2023-10-31 09:27:01.387 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 09:27:15.470 | INFO     | __main__:train:314 - Epoch: [121][0/1251]	 loss 4.57328	 cls_loss: 0.3227 cluster_loss: 1.3483 sup_con_loss: 0.4541 contrastive_loss: 5.2676 nll_loss: 0.0011 
2023-10-31 09:30:59.648 | INFO     | __main__:train:314 - Epoch: [121][100/1251]	 loss 4.57996	 cls_loss: 0.4039 cluster_loss: 1.2717 sup_con_loss: 0.5388 contrastive_loss: 5.2637 nll_loss: 0.0019 
2023-10-31 09:34:42.400 | INFO     | __main__:train:314 - Epoch: [121][200/1251]	 loss 4.53248	 cls_loss: 0.3654 cluster_loss: 1.3000 sup_con_loss: 0.3894 contrastive_loss: 5.2636 nll_loss: 0.0020 
2023-10-31 09:38:26.155 | INFO     | __main__:train:314 - Epoch: [121][300/1251]	 loss 4.52961	 cls_loss: 0.3248 cluster_loss: 1.3488 sup_con_loss: 0.3266 contrastive_loss: 5.2661 nll_loss: 0.0019 
2023-10-31 09:42:10.590 | INFO     | __main__:train:314 - Epoch: [121][400/1251]	 loss 4.43552	 cls_loss: 0.2776 cluster_loss: 1.2774 sup_con_loss: 0.2407 contrastive_loss: 5.2642 nll_loss: 0.0021 
2023-10-31 09:45:53.144 | INFO     | __main__:train:314 - Epoch: [121][500/1251]	 loss 4.52770	 cls_loss: 0.3494 cluster_loss: 1.3223 sup_con_loss: 0.3430 contrastive_loss: 5.2670 nll_loss: 0.0023 
2023-10-31 09:49:38.307 | INFO     | __main__:train:314 - Epoch: [121][600/1251]	 loss 4.54730	 cls_loss: 0.2907 cluster_loss: 1.3596 sup_con_loss: 0.3959 contrastive_loss: 5.2633 nll_loss: 0.0021 
2023-10-31 09:53:24.573 | INFO     | __main__:train:314 - Epoch: [121][700/1251]	 loss 4.46914	 cls_loss: 0.3399 cluster_loss: 1.2600 sup_con_loss: 0.3083 contrastive_loss: 5.2613 nll_loss: 0.0034 
2023-10-31 09:57:08.472 | INFO     | __main__:train:314 - Epoch: [121][800/1251]	 loss 4.46910	 cls_loss: 0.3489 cluster_loss: 1.3128 sup_con_loss: 0.2008 contrastive_loss: 5.2634 nll_loss: 0.0022 
2023-10-31 10:00:56.543 | INFO     | __main__:train:314 - Epoch: [121][900/1251]	 loss 4.49876	 cls_loss: 0.3043 cluster_loss: 1.3231 sup_con_loss: 0.3074 contrastive_loss: 5.2670 nll_loss: 0.0011 
2023-10-31 10:04:40.996 | INFO     | __main__:train:314 - Epoch: [121][1000/1251]	 loss 4.37255	 cls_loss: 0.3254 cluster_loss: 1.1913 sup_con_loss: 0.1898 contrastive_loss: 5.2570 nll_loss: 0.0009 
2023-10-31 10:08:26.142 | INFO     | __main__:train:314 - Epoch: [121][1100/1251]	 loss 4.42485	 cls_loss: 0.3397 cluster_loss: 1.2297 sup_con_loss: 0.2488 contrastive_loss: 5.2588 nll_loss: 0.0013 
2023-10-31 10:12:13.927 | INFO     | __main__:train:314 - Epoch: [121][1200/1251]	 loss 4.43409	 cls_loss: 0.2810 cluster_loss: 1.2642 sup_con_loss: 0.2657 contrastive_loss: 5.2619 nll_loss: 0.0008 
2023-10-31 10:14:05.053 | INFO     | __main__:train:319 - Train Epoch: 121 Avg Loss: 4.4997 
2023-10-31 10:14:05.062 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 10:34:13.683 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 121, Train ACC Unlabelled_v2: All 0.6089 | Old 0.7800 | New 0.5229
2023-10-31 10:34:14.036 | INFO     | __main__:main:205 - Train Accuracies: All 0.6089 | Old 0.7800 | New 0.5229
2023-10-31 10:34:17.639 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 10:34:32.975 | INFO     | __main__:train:314 - Epoch: [122][0/1251]	 loss 4.48014	 cls_loss: 0.3139 cluster_loss: 1.2670 sup_con_loss: 0.3669 contrastive_loss: 5.2579 nll_loss: 0.0007 
2023-10-31 10:38:16.934 | INFO     | __main__:train:314 - Epoch: [122][100/1251]	 loss 4.45531	 cls_loss: 0.3043 cluster_loss: 1.2623 sup_con_loss: 0.3026 contrastive_loss: 5.2633 nll_loss: 0.0012 
2023-10-31 10:42:00.397 | INFO     | __main__:train:314 - Epoch: [122][200/1251]	 loss 4.48241	 cls_loss: 0.3249 cluster_loss: 1.2973 sup_con_loss: 0.2876 contrastive_loss: 5.2664 nll_loss: 0.0016 
2023-10-31 10:45:46.219 | INFO     | __main__:train:314 - Epoch: [122][300/1251]	 loss 4.53318	 cls_loss: 0.3320 cluster_loss: 1.2960 sup_con_loss: 0.4264 contrastive_loss: 5.2664 nll_loss: 0.0022 
2023-10-31 10:49:30.880 | INFO     | __main__:train:314 - Epoch: [122][400/1251]	 loss 4.50424	 cls_loss: 0.3267 cluster_loss: 1.2908 sup_con_loss: 0.3658 contrastive_loss: 5.2634 nll_loss: 0.0016 
2023-10-31 10:53:13.979 | INFO     | __main__:train:314 - Epoch: [122][500/1251]	 loss 4.56732	 cls_loss: 0.3633 cluster_loss: 1.3593 sup_con_loss: 0.3717 contrastive_loss: 5.2675 nll_loss: 0.0027 
2023-10-31 10:56:59.213 | INFO     | __main__:train:314 - Epoch: [122][600/1251]	 loss 4.48482	 cls_loss: 0.3516 cluster_loss: 1.2850 sup_con_loss: 0.3057 contrastive_loss: 5.2587 nll_loss: 0.0013 
2023-10-31 11:00:45.539 | INFO     | __main__:train:314 - Epoch: [122][700/1251]	 loss 4.43299	 cls_loss: 0.3001 cluster_loss: 1.2631 sup_con_loss: 0.2434 contrastive_loss: 5.2613 nll_loss: 0.0019 
2023-10-31 11:04:29.053 | INFO     | __main__:train:314 - Epoch: [122][800/1251]	 loss 4.50570	 cls_loss: 0.3572 cluster_loss: 1.2892 sup_con_loss: 0.3352 contrastive_loss: 5.2678 nll_loss: 0.0013 
2023-10-31 11:08:14.624 | INFO     | __main__:train:314 - Epoch: [122][900/1251]	 loss 4.46922	 cls_loss: 0.4107 cluster_loss: 1.2663 sup_con_loss: 0.2247 contrastive_loss: 5.2641 nll_loss: 0.0020 
2023-10-31 11:12:01.201 | INFO     | __main__:train:314 - Epoch: [122][1000/1251]	 loss 4.45042	 cls_loss: 0.3246 cluster_loss: 1.2568 sup_con_loss: 0.2835 contrastive_loss: 5.2599 nll_loss: 0.0018 
2023-10-31 11:15:46.894 | INFO     | __main__:train:314 - Epoch: [122][1100/1251]	 loss 4.48346	 cls_loss: 0.3584 cluster_loss: 1.2739 sup_con_loss: 0.3071 contrastive_loss: 5.2632 nll_loss: 0.0014 
2023-10-31 11:19:30.684 | INFO     | __main__:train:314 - Epoch: [122][1200/1251]	 loss 4.56953	 cls_loss: 0.4116 cluster_loss: 1.2914 sup_con_loss: 0.4747 contrastive_loss: 5.2591 nll_loss: 0.0015 
2023-10-31 11:21:23.686 | INFO     | __main__:train:319 - Train Epoch: 122 Avg Loss: 4.4989 
2023-10-31 11:21:23.703 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 11:41:40.474 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 122, Train ACC Unlabelled_v2: All 0.6110 | Old 0.7831 | New 0.5245
2023-10-31 11:41:40.701 | INFO     | __main__:main:205 - Train Accuracies: All 0.6110 | Old 0.7831 | New 0.5245
2023-10-31 11:41:44.392 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 11:41:58.975 | INFO     | __main__:train:314 - Epoch: [123][0/1251]	 loss 4.43300	 cls_loss: 0.3010 cluster_loss: 1.2474 sup_con_loss: 0.2742 contrastive_loss: 5.2606 nll_loss: 0.0015 
2023-10-31 11:45:45.611 | INFO     | __main__:train:314 - Epoch: [123][100/1251]	 loss 4.35814	 cls_loss: 0.2490 cluster_loss: 1.2188 sup_con_loss: 0.1709 contrastive_loss: 5.2578 nll_loss: 0.0014 
2023-10-31 11:49:29.656 | INFO     | __main__:train:314 - Epoch: [123][200/1251]	 loss 4.45475	 cls_loss: 0.3470 cluster_loss: 1.2432 sup_con_loss: 0.2978 contrastive_loss: 5.2616 nll_loss: 0.0010 
2023-10-31 11:53:12.195 | INFO     | __main__:train:314 - Epoch: [123][300/1251]	 loss 4.54501	 cls_loss: 0.4978 cluster_loss: 1.2608 sup_con_loss: 0.3689 contrastive_loss: 5.2634 nll_loss: 0.0009 
2023-10-31 11:56:56.474 | INFO     | __main__:train:314 - Epoch: [123][400/1251]	 loss 4.51350	 cls_loss: 0.3864 cluster_loss: 1.2748 sup_con_loss: 0.3655 contrastive_loss: 5.2621 nll_loss: 0.0013 
2023-10-31 12:00:41.724 | INFO     | __main__:train:314 - Epoch: [123][500/1251]	 loss 4.43506	 cls_loss: 0.3149 cluster_loss: 1.2732 sup_con_loss: 0.2132 contrastive_loss: 5.2624 nll_loss: 0.0021 
2023-10-31 12:04:26.166 | INFO     | __main__:train:314 - Epoch: [123][600/1251]	 loss 4.51759	 cls_loss: 0.3867 cluster_loss: 1.3089 sup_con_loss: 0.3039 contrastive_loss: 5.2665 nll_loss: 0.0019 
2023-10-31 12:08:09.938 | INFO     | __main__:train:314 - Epoch: [123][700/1251]	 loss 4.48174	 cls_loss: 0.3458 cluster_loss: 1.2758 sup_con_loss: 0.3155 contrastive_loss: 5.2613 nll_loss: 0.0012 
2023-10-31 12:11:54.563 | INFO     | __main__:train:314 - Epoch: [123][800/1251]	 loss 4.50655	 cls_loss: 0.3502 cluster_loss: 1.2498 sup_con_loss: 0.4350 contrastive_loss: 5.2587 nll_loss: 0.0013 
2023-10-31 12:15:37.242 | INFO     | __main__:train:314 - Epoch: [123][900/1251]	 loss 4.44235	 cls_loss: 0.3093 cluster_loss: 1.2390 sup_con_loss: 0.3028 contrastive_loss: 5.2632 nll_loss: 0.0017 
2023-10-31 12:19:20.836 | INFO     | __main__:train:314 - Epoch: [123][1000/1251]	 loss 4.37848	 cls_loss: 0.2916 cluster_loss: 1.2184 sup_con_loss: 0.1858 contrastive_loss: 5.2584 nll_loss: 0.0014 
2023-10-31 12:23:05.954 | INFO     | __main__:train:314 - Epoch: [123][1100/1251]	 loss 4.53012	 cls_loss: 0.3309 cluster_loss: 1.3469 sup_con_loss: 0.3258 contrastive_loss: 5.2644 nll_loss: 0.0030 
2023-10-31 12:26:48.675 | INFO     | __main__:train:314 - Epoch: [123][1200/1251]	 loss 4.52555	 cls_loss: 0.3298 cluster_loss: 1.3305 sup_con_loss: 0.3488 contrastive_loss: 5.2639 nll_loss: 0.0017 
2023-10-31 12:28:40.286 | INFO     | __main__:train:319 - Train Epoch: 123 Avg Loss: 4.4933 
2023-10-31 12:28:40.302 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 12:47:47.614 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 123, Train ACC Unlabelled_v2: All 0.6104 | Old 0.7818 | New 0.5243
2023-10-31 12:47:48.070 | INFO     | __main__:main:205 - Train Accuracies: All 0.6104 | Old 0.7818 | New 0.5243
2023-10-31 12:47:51.378 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 12:48:04.847 | INFO     | __main__:train:314 - Epoch: [124][0/1251]	 loss 4.46938	 cls_loss: 0.2974 cluster_loss: 1.2676 sup_con_loss: 0.3483 contrastive_loss: 5.2593 nll_loss: 0.0009 
2023-10-31 12:51:52.572 | INFO     | __main__:train:314 - Epoch: [124][100/1251]	 loss 4.54853	 cls_loss: 0.4086 cluster_loss: 1.2686 sup_con_loss: 0.4542 contrastive_loss: 5.2633 nll_loss: 0.0008 
2023-10-31 12:55:35.234 | INFO     | __main__:train:314 - Epoch: [124][200/1251]	 loss 4.38931	 cls_loss: 0.2646 cluster_loss: 1.2608 sup_con_loss: 0.1589 contrastive_loss: 5.2604 nll_loss: 0.0023 
2023-10-31 12:59:18.987 | INFO     | __main__:train:314 - Epoch: [124][300/1251]	 loss 4.52143	 cls_loss: 0.4028 cluster_loss: 1.3127 sup_con_loss: 0.2999 contrastive_loss: 5.2626 nll_loss: 0.0016 
2023-10-31 13:03:06.121 | INFO     | __main__:train:314 - Epoch: [124][400/1251]	 loss 4.54257	 cls_loss: 0.3621 cluster_loss: 1.2942 sup_con_loss: 0.4269 contrastive_loss: 5.2671 nll_loss: 0.0016 
2023-10-31 13:06:52.525 | INFO     | __main__:train:314 - Epoch: [124][500/1251]	 loss 4.54952	 cls_loss: 0.3537 cluster_loss: 1.3179 sup_con_loss: 0.4098 contrastive_loss: 5.2682 nll_loss: 0.0013 
2023-10-31 13:10:36.756 | INFO     | __main__:train:314 - Epoch: [124][600/1251]	 loss 4.46152	 cls_loss: 0.3235 cluster_loss: 1.2633 sup_con_loss: 0.3028 contrastive_loss: 5.2614 nll_loss: 0.0012 
2023-10-31 13:14:20.627 | INFO     | __main__:train:314 - Epoch: [124][700/1251]	 loss 4.44990	 cls_loss: 0.3206 cluster_loss: 1.2776 sup_con_loss: 0.2457 contrastive_loss: 5.2606 nll_loss: 0.0019 
2023-10-31 13:18:04.560 | INFO     | __main__:train:314 - Epoch: [124][800/1251]	 loss 4.55153	 cls_loss: 0.4498 cluster_loss: 1.2943 sup_con_loss: 0.3736 contrastive_loss: 5.2619 nll_loss: 0.0018 
2023-10-31 13:21:50.342 | INFO     | __main__:train:314 - Epoch: [124][900/1251]	 loss 4.53700	 cls_loss: 0.3626 cluster_loss: 1.3322 sup_con_loss: 0.3400 contrastive_loss: 5.2684 nll_loss: 0.0007 
2023-10-31 13:25:35.406 | INFO     | __main__:train:314 - Epoch: [124][1000/1251]	 loss 4.54763	 cls_loss: 0.3853 cluster_loss: 1.2775 sup_con_loss: 0.4547 contrastive_loss: 5.2630 nll_loss: 0.0023 
2023-10-31 13:29:22.204 | INFO     | __main__:train:314 - Epoch: [124][1100/1251]	 loss 4.55864	 cls_loss: 0.3102 cluster_loss: 1.3650 sup_con_loss: 0.3883 contrastive_loss: 5.2685 nll_loss: 0.0024 
2023-10-31 13:33:10.355 | INFO     | __main__:train:314 - Epoch: [124][1200/1251]	 loss 4.56479	 cls_loss: 0.4119 cluster_loss: 1.3164 sup_con_loss: 0.4046 contrastive_loss: 5.2637 nll_loss: 0.0019 
2023-10-31 13:35:03.456 | INFO     | __main__:train:319 - Train Epoch: 124 Avg Loss: 4.4935 
2023-10-31 13:35:03.825 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 14:00:53.438 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 124, Train ACC Unlabelled_v2: All 0.6102 | Old 0.7849 | New 0.5224
2023-10-31 14:00:56.602 | INFO     | __main__:main:205 - Train Accuracies: All 0.6102 | Old 0.7849 | New 0.5224
2023-10-31 14:01:04.755 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 14:01:41.199 | INFO     | __main__:train:314 - Epoch: [125][0/1251]	 loss 4.47647	 cls_loss: 0.3032 cluster_loss: 1.2712 sup_con_loss: 0.3477 contrastive_loss: 5.2631 nll_loss: 0.0014 
2023-10-31 14:05:25.833 | INFO     | __main__:train:314 - Epoch: [125][100/1251]	 loss 4.45687	 cls_loss: 0.2771 cluster_loss: 1.2868 sup_con_loss: 0.2942 contrastive_loss: 5.2609 nll_loss: 0.0009 
2023-10-31 14:09:09.081 | INFO     | __main__:train:314 - Epoch: [125][200/1251]	 loss 4.51495	 cls_loss: 0.3885 cluster_loss: 1.2766 sup_con_loss: 0.3629 contrastive_loss: 5.2612 nll_loss: 0.0024 
2023-10-31 14:13:02.841 | INFO     | __main__:train:314 - Epoch: [125][300/1251]	 loss 4.40902	 cls_loss: 0.2922 cluster_loss: 1.2544 sup_con_loss: 0.1979 contrastive_loss: 5.2627 nll_loss: 0.0014 
2023-10-31 14:16:55.945 | INFO     | __main__:train:314 - Epoch: [125][400/1251]	 loss 4.58043	 cls_loss: 0.3436 cluster_loss: 1.3384 sup_con_loss: 0.4815 contrastive_loss: 5.2624 nll_loss: 0.0012 
2023-10-31 14:21:31.859 | INFO     | __main__:train:314 - Epoch: [125][500/1251]	 loss 4.37792	 cls_loss: 0.2294 cluster_loss: 1.2459 sup_con_loss: 0.1941 contrastive_loss: 5.2588 nll_loss: 0.0017 
2023-10-31 14:25:16.103 | INFO     | __main__:train:314 - Epoch: [125][600/1251]	 loss 4.51147	 cls_loss: 0.2855 cluster_loss: 1.2986 sup_con_loss: 0.4136 contrastive_loss: 5.2636 nll_loss: 0.0014 
2023-10-31 14:29:00.316 | INFO     | __main__:train:314 - Epoch: [125][700/1251]	 loss 4.49175	 cls_loss: 0.3069 cluster_loss: 1.3350 sup_con_loss: 0.2643 contrastive_loss: 5.2664 nll_loss: 0.0009 
2023-10-31 14:32:44.734 | INFO     | __main__:train:314 - Epoch: [125][800/1251]	 loss 4.41811	 cls_loss: 0.3787 cluster_loss: 1.2252 sup_con_loss: 0.2015 contrastive_loss: 5.2568 nll_loss: 0.0017 
2023-10-31 14:36:30.896 | INFO     | __main__:train:314 - Epoch: [125][900/1251]	 loss 4.56299	 cls_loss: 0.3273 cluster_loss: 1.3493 sup_con_loss: 0.4205 contrastive_loss: 5.2666 nll_loss: 0.0009 
2023-10-31 14:40:14.891 | INFO     | __main__:train:314 - Epoch: [125][1000/1251]	 loss 4.50255	 cls_loss: 0.3341 cluster_loss: 1.3166 sup_con_loss: 0.2957 contrastive_loss: 5.2689 nll_loss: 0.0016 
2023-10-31 14:43:57.858 | INFO     | __main__:train:314 - Epoch: [125][1100/1251]	 loss 4.44542	 cls_loss: 0.3267 cluster_loss: 1.2544 sup_con_loss: 0.2717 contrastive_loss: 5.2607 nll_loss: 0.0012 
2023-10-31 14:47:47.298 | INFO     | __main__:train:314 - Epoch: [125][1200/1251]	 loss 4.46049	 cls_loss: 0.2644 cluster_loss: 1.2875 sup_con_loss: 0.3203 contrastive_loss: 5.2584 nll_loss: 0.0010 
2023-10-31 14:49:38.911 | INFO     | __main__:train:319 - Train Epoch: 125 Avg Loss: 4.4883 
2023-10-31 14:49:38.917 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 15:08:44.202 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 125, Train ACC Unlabelled_v2: All 0.6114 | Old 0.7825 | New 0.5254
2023-10-31 15:08:44.445 | INFO     | __main__:main:205 - Train Accuracies: All 0.6114 | Old 0.7825 | New 0.5254
2023-10-31 15:08:47.442 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 15:09:02.381 | INFO     | __main__:train:314 - Epoch: [126][0/1251]	 loss 4.56838	 cls_loss: 0.3141 cluster_loss: 1.3070 sup_con_loss: 0.5329 contrastive_loss: 5.2623 nll_loss: 0.0019 
2023-10-31 15:12:46.992 | INFO     | __main__:train:314 - Epoch: [126][100/1251]	 loss 4.43301	 cls_loss: 0.3118 cluster_loss: 1.2475 sup_con_loss: 0.2689 contrastive_loss: 5.2582 nll_loss: 0.0011 
2023-10-31 15:16:31.068 | INFO     | __main__:train:314 - Epoch: [126][200/1251]	 loss 4.51298	 cls_loss: 0.3692 cluster_loss: 1.2959 sup_con_loss: 0.3419 contrastive_loss: 5.2606 nll_loss: 0.0024 
2023-10-31 15:20:13.433 | INFO     | __main__:train:314 - Epoch: [126][300/1251]	 loss 4.38899	 cls_loss: 0.2719 cluster_loss: 1.2438 sup_con_loss: 0.1883 contrastive_loss: 5.2588 nll_loss: 0.0013 
2023-10-31 15:24:00.518 | INFO     | __main__:train:314 - Epoch: [126][400/1251]	 loss 4.44636	 cls_loss: 0.3506 cluster_loss: 1.2457 sup_con_loss: 0.2652 contrastive_loss: 5.2600 nll_loss: 0.0021 
2023-10-31 15:27:46.027 | INFO     | __main__:train:314 - Epoch: [126][500/1251]	 loss 4.53322	 cls_loss: 0.3190 cluster_loss: 1.3066 sup_con_loss: 0.4314 contrastive_loss: 5.2616 nll_loss: 0.0012 
2023-10-31 15:31:35.818 | INFO     | __main__:train:314 - Epoch: [126][600/1251]	 loss 4.50753	 cls_loss: 0.3136 cluster_loss: 1.2784 sup_con_loss: 0.4112 contrastive_loss: 5.2636 nll_loss: 0.0016 
2023-10-31 15:35:20.010 | INFO     | __main__:train:314 - Epoch: [126][700/1251]	 loss 4.39555	 cls_loss: 0.2663 cluster_loss: 1.2357 sup_con_loss: 0.2252 contrastive_loss: 5.2599 nll_loss: 0.0014 
2023-10-31 15:39:05.573 | INFO     | __main__:train:314 - Epoch: [126][800/1251]	 loss 4.63690	 cls_loss: 0.3640 cluster_loss: 1.3974 sup_con_loss: 0.5002 contrastive_loss: 5.2668 nll_loss: 0.0027 
2023-10-31 15:42:46.765 | INFO     | __main__:train:314 - Epoch: [126][900/1251]	 loss 4.52958	 cls_loss: 0.3448 cluster_loss: 1.3428 sup_con_loss: 0.3176 contrastive_loss: 5.2670 nll_loss: 0.0013 
2023-10-31 15:46:30.057 | INFO     | __main__:train:314 - Epoch: [126][1000/1251]	 loss 4.44775	 cls_loss: 0.3014 cluster_loss: 1.2587 sup_con_loss: 0.2959 contrastive_loss: 5.2595 nll_loss: 0.0019 
2023-10-31 15:50:12.640 | INFO     | __main__:train:314 - Epoch: [126][1100/1251]	 loss 4.60912	 cls_loss: 0.3915 cluster_loss: 1.3637 sup_con_loss: 0.4584 contrastive_loss: 5.2660 nll_loss: 0.0023 
2023-10-31 15:53:57.811 | INFO     | __main__:train:314 - Epoch: [126][1200/1251]	 loss 4.52716	 cls_loss: 0.3265 cluster_loss: 1.3173 sup_con_loss: 0.3872 contrastive_loss: 5.2599 nll_loss: 0.0022 
2023-10-31 15:55:49.311 | INFO     | __main__:train:319 - Train Epoch: 126 Avg Loss: 4.4872 
2023-10-31 15:55:49.314 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 16:17:14.143 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 126, Train ACC Unlabelled_v2: All 0.6110 | Old 0.7823 | New 0.5249
2023-10-31 16:17:14.326 | INFO     | __main__:main:205 - Train Accuracies: All 0.6110 | Old 0.7823 | New 0.5249
2023-10-31 16:17:17.280 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 16:17:32.124 | INFO     | __main__:train:314 - Epoch: [127][0/1251]	 loss 4.48001	 cls_loss: 0.3776 cluster_loss: 1.2494 sup_con_loss: 0.3200 contrastive_loss: 5.2635 nll_loss: 0.0025 
2023-10-31 16:21:18.908 | INFO     | __main__:train:314 - Epoch: [127][100/1251]	 loss 4.45421	 cls_loss: 0.3415 cluster_loss: 1.2693 sup_con_loss: 0.2539 contrastive_loss: 5.2615 nll_loss: 0.0008 
2023-10-31 16:25:03.350 | INFO     | __main__:train:314 - Epoch: [127][200/1251]	 loss 4.57730	 cls_loss: 0.3640 cluster_loss: 1.3884 sup_con_loss: 0.3428 contrastive_loss: 5.2711 nll_loss: 0.0013 
2023-10-31 16:29:19.284 | INFO     | __main__:train:314 - Epoch: [127][300/1251]	 loss 4.51567	 cls_loss: 0.3013 cluster_loss: 1.3251 sup_con_loss: 0.3620 contrastive_loss: 5.2620 nll_loss: 0.0019 
2023-10-31 16:33:15.833 | INFO     | __main__:train:314 - Epoch: [127][400/1251]	 loss 4.45885	 cls_loss: 0.3042 cluster_loss: 1.2575 sup_con_loss: 0.3256 contrastive_loss: 5.2595 nll_loss: 0.0023 
2023-10-31 16:37:10.377 | INFO     | __main__:train:314 - Epoch: [127][500/1251]	 loss 4.45139	 cls_loss: 0.3648 cluster_loss: 1.2355 sup_con_loss: 0.2878 contrastive_loss: 5.2589 nll_loss: 0.0016 
2023-10-31 16:40:57.562 | INFO     | __main__:train:314 - Epoch: [127][600/1251]	 loss 4.47672	 cls_loss: 0.2798 cluster_loss: 1.3075 sup_con_loss: 0.2998 contrastive_loss: 5.2643 nll_loss: 0.0022 
2023-10-31 16:44:41.467 | INFO     | __main__:train:314 - Epoch: [127][700/1251]	 loss 4.46475	 cls_loss: 0.2981 cluster_loss: 1.3285 sup_con_loss: 0.2095 contrastive_loss: 5.2660 nll_loss: 0.0007 
2023-10-31 16:48:26.398 | INFO     | __main__:train:314 - Epoch: [127][800/1251]	 loss 4.50625	 cls_loss: 0.3009 cluster_loss: 1.3223 sup_con_loss: 0.3401 contrastive_loss: 5.2639 nll_loss: 0.0009 
2023-10-31 16:52:15.596 | INFO     | __main__:train:314 - Epoch: [127][900/1251]	 loss 4.53241	 cls_loss: 0.3586 cluster_loss: 1.2690 sup_con_loss: 0.4612 contrastive_loss: 5.2603 nll_loss: 0.0014 
2023-10-31 16:55:59.345 | INFO     | __main__:train:314 - Epoch: [127][1000/1251]	 loss 4.50580	 cls_loss: 0.3322 cluster_loss: 1.2767 sup_con_loss: 0.3936 contrastive_loss: 5.2611 nll_loss: 0.0022 
2023-10-31 16:59:44.342 | INFO     | __main__:train:314 - Epoch: [127][1100/1251]	 loss 4.38105	 cls_loss: 0.3271 cluster_loss: 1.2152 sup_con_loss: 0.1690 contrastive_loss: 5.2559 nll_loss: 0.0012 
2023-10-31 17:03:28.969 | INFO     | __main__:train:314 - Epoch: [127][1200/1251]	 loss 4.47775	 cls_loss: 0.2757 cluster_loss: 1.2860 sup_con_loss: 0.3579 contrastive_loss: 5.2607 nll_loss: 0.0006 
2023-10-31 17:05:23.988 | INFO     | __main__:train:319 - Train Epoch: 127 Avg Loss: 4.4845 
2023-10-31 17:05:23.992 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 17:24:33.526 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 127, Train ACC Unlabelled_v2: All 0.6113 | Old 0.7842 | New 0.5244
2023-10-31 17:24:33.569 | INFO     | __main__:main:205 - Train Accuracies: All 0.6113 | Old 0.7842 | New 0.5244
2023-10-31 17:24:36.278 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 17:24:51.198 | INFO     | __main__:train:314 - Epoch: [128][0/1251]	 loss 4.48148	 cls_loss: 0.3326 cluster_loss: 1.2662 sup_con_loss: 0.3496 contrastive_loss: 5.2584 nll_loss: 0.0017 
2023-10-31 17:28:36.941 | INFO     | __main__:train:314 - Epoch: [128][100/1251]	 loss 4.52338	 cls_loss: 0.2904 cluster_loss: 1.2915 sup_con_loss: 0.4585 contrastive_loss: 5.2624 nll_loss: 0.0013 
2023-10-31 17:32:21.147 | INFO     | __main__:train:314 - Epoch: [128][200/1251]	 loss 4.45354	 cls_loss: 0.3510 cluster_loss: 1.2889 sup_con_loss: 0.1907 contrastive_loss: 5.2695 nll_loss: 0.0010 
2023-10-31 17:36:11.469 | INFO     | __main__:train:314 - Epoch: [128][300/1251]	 loss 4.42243	 cls_loss: 0.2890 cluster_loss: 1.2637 sup_con_loss: 0.2271 contrastive_loss: 5.2602 nll_loss: 0.0013 
2023-10-31 17:39:53.908 | INFO     | __main__:train:314 - Epoch: [128][400/1251]	 loss 4.51111	 cls_loss: 0.3228 cluster_loss: 1.3129 sup_con_loss: 0.3402 contrastive_loss: 5.2674 nll_loss: 0.0018 
2023-10-31 17:43:37.895 | INFO     | __main__:train:314 - Epoch: [128][500/1251]	 loss 4.38471	 cls_loss: 0.2682 cluster_loss: 1.2434 sup_con_loss: 0.1782 contrastive_loss: 5.2591 nll_loss: 0.0018 
2023-10-31 17:47:22.684 | INFO     | __main__:train:314 - Epoch: [128][600/1251]	 loss 4.47466	 cls_loss: 0.2678 cluster_loss: 1.2882 sup_con_loss: 0.3482 contrastive_loss: 5.2627 nll_loss: 0.0010 
2023-10-31 17:51:15.586 | INFO     | __main__:train:314 - Epoch: [128][700/1251]	 loss 4.46833	 cls_loss: 0.3621 cluster_loss: 1.2084 sup_con_loss: 0.3927 contrastive_loss: 5.2583 nll_loss: 0.0007 
2023-10-31 17:55:01.241 | INFO     | __main__:train:314 - Epoch: [128][800/1251]	 loss 4.57628	 cls_loss: 0.3390 cluster_loss: 1.3581 sup_con_loss: 0.4290 contrastive_loss: 5.2658 nll_loss: 0.0019 
2023-10-31 17:58:48.845 | INFO     | __main__:train:314 - Epoch: [128][900/1251]	 loss 4.49172	 cls_loss: 0.3309 cluster_loss: 1.2912 sup_con_loss: 0.3241 contrastive_loss: 5.2627 nll_loss: 0.0025 
2023-10-31 18:02:32.443 | INFO     | __main__:train:314 - Epoch: [128][1000/1251]	 loss 4.54361	 cls_loss: 0.3444 cluster_loss: 1.3288 sup_con_loss: 0.3838 contrastive_loss: 5.2674 nll_loss: 0.0012 
2023-10-31 18:06:16.681 | INFO     | __main__:train:314 - Epoch: [128][1100/1251]	 loss 4.45127	 cls_loss: 0.3154 cluster_loss: 1.2682 sup_con_loss: 0.2747 contrastive_loss: 5.2607 nll_loss: 0.0010 
2023-10-31 18:10:03.782 | INFO     | __main__:train:314 - Epoch: [128][1200/1251]	 loss 4.44169	 cls_loss: 0.3129 cluster_loss: 1.1904 sup_con_loss: 0.4032 contrastive_loss: 5.2548 nll_loss: 0.0017 
2023-10-31 18:11:56.229 | INFO     | __main__:train:319 - Train Epoch: 128 Avg Loss: 4.4811 
2023-10-31 18:11:56.239 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 18:30:42.691 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 128, Train ACC Unlabelled_v2: All 0.6109 | Old 0.7838 | New 0.5241
2023-10-31 18:30:42.768 | INFO     | __main__:main:205 - Train Accuracies: All 0.6109 | Old 0.7838 | New 0.5241
2023-10-31 18:30:45.491 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 18:31:01.474 | INFO     | __main__:train:314 - Epoch: [129][0/1251]	 loss 4.42221	 cls_loss: 0.2985 cluster_loss: 1.1945 sup_con_loss: 0.3494 contrastive_loss: 5.2579 nll_loss: 0.0014 
2023-10-31 18:34:48.334 | INFO     | __main__:train:314 - Epoch: [129][100/1251]	 loss 4.47328	 cls_loss: 0.3161 cluster_loss: 1.2851 sup_con_loss: 0.2970 contrastive_loss: 5.2648 nll_loss: 0.0013 
2023-10-31 18:38:33.863 | INFO     | __main__:train:314 - Epoch: [129][200/1251]	 loss 4.40123	 cls_loss: 0.2613 cluster_loss: 1.2608 sup_con_loss: 0.2022 contrastive_loss: 5.2595 nll_loss: 0.0008 
2023-10-31 18:42:18.708 | INFO     | __main__:train:314 - Epoch: [129][300/1251]	 loss 4.52046	 cls_loss: 0.3700 cluster_loss: 1.2679 sup_con_loss: 0.4150 contrastive_loss: 5.2619 nll_loss: 0.0013 
2023-10-31 18:46:02.089 | INFO     | __main__:train:314 - Epoch: [129][400/1251]	 loss 4.45447	 cls_loss: 0.3057 cluster_loss: 1.2579 sup_con_loss: 0.3100 contrastive_loss: 5.2605 nll_loss: 0.0020 
2023-10-31 18:49:46.139 | INFO     | __main__:train:314 - Epoch: [129][500/1251]	 loss 4.48001	 cls_loss: 0.2844 cluster_loss: 1.3213 sup_con_loss: 0.2703 contrastive_loss: 5.2700 nll_loss: 0.0015 
2023-10-31 18:53:30.917 | INFO     | __main__:train:314 - Epoch: [129][600/1251]	 loss 4.44680	 cls_loss: 0.2551 cluster_loss: 1.2595 sup_con_loss: 0.3410 contrastive_loss: 5.2594 nll_loss: 0.0009 
2023-10-31 18:57:21.671 | INFO     | __main__:train:314 - Epoch: [129][700/1251]	 loss 4.47777	 cls_loss: 0.2997 cluster_loss: 1.2640 sup_con_loss: 0.3717 contrastive_loss: 5.2609 nll_loss: 0.0016 
2023-10-31 19:01:04.505 | INFO     | __main__:train:314 - Epoch: [129][800/1251]	 loss 4.49899	 cls_loss: 0.2892 cluster_loss: 1.2881 sup_con_loss: 0.3939 contrastive_loss: 5.2629 nll_loss: 0.0018 
2023-10-31 19:04:47.372 | INFO     | __main__:train:314 - Epoch: [129][900/1251]	 loss 4.51377	 cls_loss: 0.3240 cluster_loss: 1.3120 sup_con_loss: 0.3554 contrastive_loss: 5.2639 nll_loss: 0.0017 
2023-10-31 19:08:35.820 | INFO     | __main__:train:314 - Epoch: [129][1000/1251]	 loss 4.48565	 cls_loss: 0.3611 cluster_loss: 1.2801 sup_con_loss: 0.2998 contrastive_loss: 5.2630 nll_loss: 0.0013 
2023-10-31 19:12:23.121 | INFO     | __main__:train:314 - Epoch: [129][1100/1251]	 loss 4.59725	 cls_loss: 0.3520 cluster_loss: 1.3490 sup_con_loss: 0.4980 contrastive_loss: 5.2647 nll_loss: 0.0008 
2023-10-31 19:16:55.832 | INFO     | __main__:train:314 - Epoch: [129][1200/1251]	 loss 4.39984	 cls_loss: 0.2982 cluster_loss: 1.2143 sup_con_loss: 0.2437 contrastive_loss: 5.2613 nll_loss: 0.0011 
2023-10-31 19:18:47.493 | INFO     | __main__:train:319 - Train Epoch: 129 Avg Loss: 4.4789 
2023-10-31 19:18:47.514 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 19:37:33.066 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 129, Train ACC Unlabelled_v2: All 0.6114 | Old 0.7835 | New 0.5249
2023-10-31 19:37:33.108 | INFO     | __main__:main:205 - Train Accuracies: All 0.6114 | Old 0.7835 | New 0.5249
2023-10-31 19:37:36.340 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 19:37:54.260 | INFO     | __main__:train:314 - Epoch: [130][0/1251]	 loss 4.45154	 cls_loss: 0.3157 cluster_loss: 1.2450 sup_con_loss: 0.3192 contrastive_loss: 5.2598 nll_loss: 0.0012 
2023-10-31 19:41:38.690 | INFO     | __main__:train:314 - Epoch: [130][100/1251]	 loss 4.38160	 cls_loss: 0.2659 cluster_loss: 1.2402 sup_con_loss: 0.1804 contrastive_loss: 5.2589 nll_loss: 0.0010 
2023-10-31 19:45:22.252 | INFO     | __main__:train:314 - Epoch: [130][200/1251]	 loss 4.43478	 cls_loss: 0.3156 cluster_loss: 1.2378 sup_con_loss: 0.2872 contrastive_loss: 5.2584 nll_loss: 0.0012 
2023-10-31 19:49:04.824 | INFO     | __main__:train:314 - Epoch: [130][300/1251]	 loss 4.57400	 cls_loss: 0.4017 cluster_loss: 1.3191 sup_con_loss: 0.4359 contrastive_loss: 5.2644 nll_loss: 0.0016 
2023-10-31 19:52:49.497 | INFO     | __main__:train:314 - Epoch: [130][400/1251]	 loss 4.44037	 cls_loss: 0.2893 cluster_loss: 1.2438 sup_con_loss: 0.3154 contrastive_loss: 5.2598 nll_loss: 0.0014 
2023-10-31 19:56:34.762 | INFO     | __main__:train:314 - Epoch: [130][500/1251]	 loss 4.52230	 cls_loss: 0.3161 cluster_loss: 1.3380 sup_con_loss: 0.3326 contrastive_loss: 5.2677 nll_loss: 0.0016 
2023-10-31 20:00:19.267 | INFO     | __main__:train:314 - Epoch: [130][600/1251]	 loss 4.47908	 cls_loss: 0.3337 cluster_loss: 1.2803 sup_con_loss: 0.3091 contrastive_loss: 5.2633 nll_loss: 0.0008 
2023-10-31 20:04:02.880 | INFO     | __main__:train:314 - Epoch: [130][700/1251]	 loss 4.49570	 cls_loss: 0.3243 cluster_loss: 1.3004 sup_con_loss: 0.3256 contrastive_loss: 5.2647 nll_loss: 0.0009 
2023-10-31 20:07:45.593 | INFO     | __main__:train:314 - Epoch: [130][800/1251]	 loss 4.48869	 cls_loss: 0.3694 cluster_loss: 1.2794 sup_con_loss: 0.2974 contrastive_loss: 5.2649 nll_loss: 0.0015 
2023-10-31 20:11:29.015 | INFO     | __main__:train:314 - Epoch: [130][900/1251]	 loss 4.49388	 cls_loss: 0.2833 cluster_loss: 1.3459 sup_con_loss: 0.2739 contrastive_loss: 5.2642 nll_loss: 0.0023 
2023-10-31 20:15:13.061 | INFO     | __main__:train:314 - Epoch: [130][1000/1251]	 loss 4.52420	 cls_loss: 0.3861 cluster_loss: 1.2973 sup_con_loss: 0.3511 contrastive_loss: 5.2643 nll_loss: 0.0011 
2023-10-31 20:18:57.167 | INFO     | __main__:train:314 - Epoch: [130][1100/1251]	 loss 4.54253	 cls_loss: 0.2925 cluster_loss: 1.2861 sup_con_loss: 0.5253 contrastive_loss: 5.2594 nll_loss: 0.0017 
2023-10-31 20:22:43.792 | INFO     | __main__:train:314 - Epoch: [130][1200/1251]	 loss 4.48695	 cls_loss: 0.2981 cluster_loss: 1.2990 sup_con_loss: 0.3340 contrastive_loss: 5.2619 nll_loss: 0.0011 
2023-10-31 20:24:37.622 | INFO     | __main__:train:319 - Train Epoch: 130 Avg Loss: 4.4727 
2023-10-31 20:24:37.626 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 20:42:26.289 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 130, Train ACC Unlabelled_v2: All 0.6114 | Old 0.7821 | New 0.5256
2023-10-31 20:42:26.444 | INFO     | __main__:main:205 - Train Accuracies: All 0.6114 | Old 0.7821 | New 0.5256
2023-10-31 20:42:29.464 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 20:42:44.800 | INFO     | __main__:train:314 - Epoch: [131][0/1251]	 loss 4.42614	 cls_loss: 0.2852 cluster_loss: 1.2377 sup_con_loss: 0.2887 contrastive_loss: 5.2612 nll_loss: 0.0010 
2023-10-31 20:46:27.426 | INFO     | __main__:train:314 - Epoch: [131][100/1251]	 loss 4.45280	 cls_loss: 0.3290 cluster_loss: 1.2364 sup_con_loss: 0.3268 contrastive_loss: 5.2598 nll_loss: 0.0008 
2023-10-31 20:50:11.172 | INFO     | __main__:train:314 - Epoch: [131][200/1251]	 loss 4.50167	 cls_loss: 0.2640 cluster_loss: 1.3395 sup_con_loss: 0.3298 contrastive_loss: 5.2646 nll_loss: 0.0011 
2023-10-31 20:53:54.396 | INFO     | __main__:train:314 - Epoch: [131][300/1251]	 loss 4.51235	 cls_loss: 0.3371 cluster_loss: 1.2834 sup_con_loss: 0.3887 contrastive_loss: 5.2656 nll_loss: 0.0014 
2023-10-31 20:57:37.632 | INFO     | __main__:train:314 - Epoch: [131][400/1251]	 loss 4.56998	 cls_loss: 0.3272 cluster_loss: 1.3445 sup_con_loss: 0.4502 contrastive_loss: 5.2659 nll_loss: 0.0011 
2023-10-31 21:01:21.102 | INFO     | __main__:train:314 - Epoch: [131][500/1251]	 loss 4.49698	 cls_loss: 0.3682 cluster_loss: 1.3093 sup_con_loss: 0.2670 contrastive_loss: 5.2657 nll_loss: 0.0009 
2023-10-31 21:05:05.348 | INFO     | __main__:train:314 - Epoch: [131][600/1251]	 loss 4.46271	 cls_loss: 0.3052 cluster_loss: 1.2862 sup_con_loss: 0.2790 contrastive_loss: 5.2640 nll_loss: 0.0006 
2023-10-31 21:08:50.578 | INFO     | __main__:train:314 - Epoch: [131][700/1251]	 loss 4.43714	 cls_loss: 0.3128 cluster_loss: 1.2485 sup_con_loss: 0.2704 contrastive_loss: 5.2616 nll_loss: 0.0015 
2023-10-31 21:12:34.896 | INFO     | __main__:train:314 - Epoch: [131][800/1251]	 loss 4.51799	 cls_loss: 0.2960 cluster_loss: 1.3467 sup_con_loss: 0.3244 contrastive_loss: 5.2673 nll_loss: 0.0017 
2023-10-31 21:16:19.864 | INFO     | __main__:train:314 - Epoch: [131][900/1251]	 loss 4.47064	 cls_loss: 0.3105 cluster_loss: 1.2498 sup_con_loss: 0.3659 contrastive_loss: 5.2613 nll_loss: 0.0016 
2023-10-31 21:20:43.163 | INFO     | __main__:train:314 - Epoch: [131][1000/1251]	 loss 4.48561	 cls_loss: 0.2928 cluster_loss: 1.2636 sup_con_loss: 0.4061 contrastive_loss: 5.2584 nll_loss: 0.0017 
2023-10-31 21:25:08.420 | INFO     | __main__:train:314 - Epoch: [131][1100/1251]	 loss 4.42722	 cls_loss: 0.3051 cluster_loss: 1.2415 sup_con_loss: 0.2628 contrastive_loss: 5.2610 nll_loss: 0.0018 
2023-10-31 21:28:50.670 | INFO     | __main__:train:314 - Epoch: [131][1200/1251]	 loss 4.43525	 cls_loss: 0.3335 cluster_loss: 1.2331 sup_con_loss: 0.2768 contrastive_loss: 5.2598 nll_loss: 0.0013 
2023-10-31 21:30:42.347 | INFO     | __main__:train:319 - Train Epoch: 131 Avg Loss: 4.4716 
2023-10-31 21:30:42.385 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 21:54:02.393 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 131, Train ACC Unlabelled_v2: All 0.6127 | Old 0.7823 | New 0.5275
2023-10-31 21:54:02.599 | INFO     | __main__:main:205 - Train Accuracies: All 0.6127 | Old 0.7823 | New 0.5275
2023-10-31 21:54:05.994 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 21:54:21.586 | INFO     | __main__:train:314 - Epoch: [132][0/1251]	 loss 4.44155	 cls_loss: 0.3331 cluster_loss: 1.2561 sup_con_loss: 0.2478 contrastive_loss: 5.2625 nll_loss: 0.0011 
2023-10-31 21:58:05.483 | INFO     | __main__:train:314 - Epoch: [132][100/1251]	 loss 4.46857	 cls_loss: 0.2746 cluster_loss: 1.2835 sup_con_loss: 0.3341 contrastive_loss: 5.2609 nll_loss: 0.0016 
2023-10-31 22:01:52.823 | INFO     | __main__:train:314 - Epoch: [132][200/1251]	 loss 4.43411	 cls_loss: 0.2632 cluster_loss: 1.2346 sup_con_loss: 0.3468 contrastive_loss: 5.2561 nll_loss: 0.0016 
2023-10-31 22:05:35.850 | INFO     | __main__:train:314 - Epoch: [132][300/1251]	 loss 4.56193	 cls_loss: 0.3205 cluster_loss: 1.3474 sup_con_loss: 0.4270 contrastive_loss: 5.2666 nll_loss: 0.0013 
2023-10-31 22:09:19.403 | INFO     | __main__:train:314 - Epoch: [132][400/1251]	 loss 4.45440	 cls_loss: 0.2819 cluster_loss: 1.2724 sup_con_loss: 0.3081 contrastive_loss: 5.2603 nll_loss: 0.0017 
2023-10-31 22:13:04.355 | INFO     | __main__:train:314 - Epoch: [132][500/1251]	 loss 4.41786	 cls_loss: 0.2735 cluster_loss: 1.2385 sup_con_loss: 0.2827 contrastive_loss: 5.2569 nll_loss: 0.0012 
2023-10-31 22:16:48.057 | INFO     | __main__:train:314 - Epoch: [132][600/1251]	 loss 4.46668	 cls_loss: 0.3421 cluster_loss: 1.2958 sup_con_loss: 0.2349 contrastive_loss: 5.2643 nll_loss: 0.0007 
2023-10-31 22:20:34.398 | INFO     | __main__:train:314 - Epoch: [132][700/1251]	 loss 4.53207	 cls_loss: 0.3348 cluster_loss: 1.2728 sup_con_loss: 0.4692 contrastive_loss: 5.2648 nll_loss: 0.0012 
2023-10-31 22:24:35.236 | INFO     | __main__:train:314 - Epoch: [132][800/1251]	 loss 4.41618	 cls_loss: 0.2680 cluster_loss: 1.2673 sup_con_loss: 0.2201 contrastive_loss: 5.2615 nll_loss: 0.0017 
2023-10-31 22:28:55.739 | INFO     | __main__:train:314 - Epoch: [132][900/1251]	 loss 4.42680	 cls_loss: 0.2992 cluster_loss: 1.2529 sup_con_loss: 0.2545 contrastive_loss: 5.2579 nll_loss: 0.0010 
2023-10-31 22:32:50.512 | INFO     | __main__:train:314 - Epoch: [132][1000/1251]	 loss 4.49123	 cls_loss: 0.3665 cluster_loss: 1.2910 sup_con_loss: 0.2799 contrastive_loss: 5.2679 nll_loss: 0.0017 
2023-10-31 22:36:42.783 | INFO     | __main__:train:314 - Epoch: [132][1100/1251]	 loss 4.44657	 cls_loss: 0.2611 cluster_loss: 1.2325 sup_con_loss: 0.3801 contrastive_loss: 5.2619 nll_loss: 0.0008 
2023-10-31 22:40:25.591 | INFO     | __main__:train:314 - Epoch: [132][1200/1251]	 loss 4.48734	 cls_loss: 0.3496 cluster_loss: 1.2672 sup_con_loss: 0.3475 contrastive_loss: 5.2592 nll_loss: 0.0012 
2023-10-31 22:42:18.213 | INFO     | __main__:train:319 - Train Epoch: 132 Avg Loss: 4.4665 
2023-10-31 22:42:18.996 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-10-31 23:02:22.913 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 132, Train ACC Unlabelled_v2: All 0.6134 | Old 0.7852 | New 0.5270
2023-10-31 23:02:22.940 | INFO     | __main__:main:205 - Train Accuracies: All 0.6134 | Old 0.7852 | New 0.5270
2023-10-31 23:02:26.359 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-10-31 23:02:39.790 | INFO     | __main__:train:314 - Epoch: [133][0/1251]	 loss 4.49656	 cls_loss: 0.3465 cluster_loss: 1.2795 sup_con_loss: 0.3353 contrastive_loss: 5.2675 nll_loss: 0.0023 
2023-10-31 23:06:24.731 | INFO     | __main__:train:314 - Epoch: [133][100/1251]	 loss 4.51409	 cls_loss: 0.3037 cluster_loss: 1.3057 sup_con_loss: 0.3904 contrastive_loss: 5.2630 nll_loss: 0.0015 
2023-10-31 23:10:11.841 | INFO     | __main__:train:314 - Epoch: [133][200/1251]	 loss 4.49535	 cls_loss: 0.2998 cluster_loss: 1.3167 sup_con_loss: 0.3182 contrastive_loss: 5.2641 nll_loss: 0.0015 
2023-10-31 23:13:56.312 | INFO     | __main__:train:314 - Epoch: [133][300/1251]	 loss 4.42482	 cls_loss: 0.3016 cluster_loss: 1.2452 sup_con_loss: 0.2570 contrastive_loss: 5.2597 nll_loss: 0.0011 
2023-10-31 23:17:39.520 | INFO     | __main__:train:314 - Epoch: [133][400/1251]	 loss 4.47935	 cls_loss: 0.3335 cluster_loss: 1.2874 sup_con_loss: 0.2965 contrastive_loss: 5.2632 nll_loss: 0.0010 
2023-10-31 23:21:23.125 | INFO     | __main__:train:314 - Epoch: [133][500/1251]	 loss 4.44609	 cls_loss: 0.2824 cluster_loss: 1.2667 sup_con_loss: 0.2909 contrastive_loss: 5.2617 nll_loss: 0.0020 
2023-10-31 23:25:07.559 | INFO     | __main__:train:314 - Epoch: [133][600/1251]	 loss 4.52263	 cls_loss: 0.3525 cluster_loss: 1.3243 sup_con_loss: 0.3265 contrastive_loss: 5.2662 nll_loss: 0.0011 
2023-10-31 23:28:51.036 | INFO     | __main__:train:314 - Epoch: [133][700/1251]	 loss 4.53775	 cls_loss: 0.3311 cluster_loss: 1.3036 sup_con_loss: 0.4340 contrastive_loss: 5.2625 nll_loss: 0.0020 
2023-10-31 23:32:36.182 | INFO     | __main__:train:314 - Epoch: [133][800/1251]	 loss 4.46970	 cls_loss: 0.3623 cluster_loss: 1.2984 sup_con_loss: 0.2137 contrastive_loss: 5.2642 nll_loss: 0.0024 
2023-10-31 23:36:46.470 | INFO     | __main__:train:314 - Epoch: [133][900/1251]	 loss 4.53503	 cls_loss: 0.3184 cluster_loss: 1.2935 sup_con_loss: 0.4671 contrastive_loss: 5.2584 nll_loss: 0.0014 
2023-10-31 23:41:03.328 | INFO     | __main__:train:314 - Epoch: [133][1000/1251]	 loss 4.38445	 cls_loss: 0.2833 cluster_loss: 1.2137 sup_con_loss: 0.2246 contrastive_loss: 5.2570 nll_loss: 0.0007 
2023-10-31 23:45:12.853 | INFO     | __main__:train:314 - Epoch: [133][1100/1251]	 loss 4.39890	 cls_loss: 0.2489 cluster_loss: 1.2538 sup_con_loss: 0.2172 contrastive_loss: 5.2597 nll_loss: 0.0019 
2023-10-31 23:49:00.175 | INFO     | __main__:train:314 - Epoch: [133][1200/1251]	 loss 4.39488	 cls_loss: 0.2684 cluster_loss: 1.2711 sup_con_loss: 0.1514 contrastive_loss: 5.2629 nll_loss: 0.0008 
2023-10-31 23:50:51.725 | INFO     | __main__:train:319 - Train Epoch: 133 Avg Loss: 4.4672 
2023-10-31 23:50:51.734 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 00:11:18.097 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 133, Train ACC Unlabelled_v2: All 0.6126 | Old 0.7812 | New 0.5279
2023-11-01 00:11:18.295 | INFO     | __main__:main:205 - Train Accuracies: All 0.6126 | Old 0.7812 | New 0.5279
2023-11-01 00:11:22.650 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 00:11:38.342 | INFO     | __main__:train:314 - Epoch: [134][0/1251]	 loss 4.37521	 cls_loss: 0.2787 cluster_loss: 1.2006 sup_con_loss: 0.2221 contrastive_loss: 5.2569 nll_loss: 0.0026 
2023-11-01 00:15:22.010 | INFO     | __main__:train:314 - Epoch: [134][100/1251]	 loss 4.44050	 cls_loss: 0.3039 cluster_loss: 1.2531 sup_con_loss: 0.2835 contrastive_loss: 5.2603 nll_loss: 0.0012 
2023-11-01 00:19:06.834 | INFO     | __main__:train:314 - Epoch: [134][200/1251]	 loss 4.48248	 cls_loss: 0.4108 cluster_loss: 1.2226 sup_con_loss: 0.3535 contrastive_loss: 5.2587 nll_loss: 0.0021 
2023-11-01 00:22:55.602 | INFO     | __main__:train:314 - Epoch: [134][300/1251]	 loss 4.45329	 cls_loss: 0.3333 cluster_loss: 1.2915 sup_con_loss: 0.2185 contrastive_loss: 5.2605 nll_loss: 0.0014 
2023-11-01 00:26:48.019 | INFO     | __main__:train:314 - Epoch: [134][400/1251]	 loss 4.51890	 cls_loss: 0.3180 cluster_loss: 1.2756 sup_con_loss: 0.4552 contrastive_loss: 5.2583 nll_loss: 0.0013 
2023-11-01 00:30:32.937 | INFO     | __main__:train:314 - Epoch: [134][500/1251]	 loss 4.51412	 cls_loss: 0.3433 cluster_loss: 1.2830 sup_con_loss: 0.3952 contrastive_loss: 5.2619 nll_loss: 0.0015 
2023-11-01 00:34:18.011 | INFO     | __main__:train:314 - Epoch: [134][600/1251]	 loss 4.45173	 cls_loss: 0.2969 cluster_loss: 1.2760 sup_con_loss: 0.2800 contrastive_loss: 5.2602 nll_loss: 0.0013 
2023-11-01 00:38:02.121 | INFO     | __main__:train:314 - Epoch: [134][700/1251]	 loss 4.45731	 cls_loss: 0.3253 cluster_loss: 1.2568 sup_con_loss: 0.3011 contrastive_loss: 5.2619 nll_loss: 0.0009 
2023-11-01 00:41:48.040 | INFO     | __main__:train:314 - Epoch: [134][800/1251]	 loss 4.35676	 cls_loss: 0.2576 cluster_loss: 1.1978 sup_con_loss: 0.1980 contrastive_loss: 5.2582 nll_loss: 0.0009 
2023-11-01 00:45:34.010 | INFO     | __main__:train:314 - Epoch: [134][900/1251]	 loss 4.47951	 cls_loss: 0.3369 cluster_loss: 1.2226 sup_con_loss: 0.4224 contrastive_loss: 5.2575 nll_loss: 0.0017 
2023-11-01 00:49:17.440 | INFO     | __main__:train:314 - Epoch: [134][1000/1251]	 loss 4.47947	 cls_loss: 0.2380 cluster_loss: 1.2970 sup_con_loss: 0.3769 contrastive_loss: 5.2610 nll_loss: 0.0015 
2023-11-01 00:53:00.536 | INFO     | __main__:train:314 - Epoch: [134][1100/1251]	 loss 4.46560	 cls_loss: 0.2853 cluster_loss: 1.2702 sup_con_loss: 0.3432 contrastive_loss: 5.2588 nll_loss: 0.0018 
2023-11-01 00:56:45.462 | INFO     | __main__:train:314 - Epoch: [134][1200/1251]	 loss 4.50803	 cls_loss: 0.3117 cluster_loss: 1.3106 sup_con_loss: 0.3590 contrastive_loss: 5.2621 nll_loss: 0.0010 
2023-11-01 00:58:36.943 | INFO     | __main__:train:319 - Train Epoch: 134 Avg Loss: 4.4617 
2023-11-01 00:58:36.948 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 01:18:10.979 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 134, Train ACC Unlabelled_v2: All 0.6129 | Old 0.7837 | New 0.5271
2023-11-01 01:18:11.442 | INFO     | __main__:main:205 - Train Accuracies: All 0.6129 | Old 0.7837 | New 0.5271
2023-11-01 01:18:14.596 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 01:18:34.411 | INFO     | __main__:train:314 - Epoch: [135][0/1251]	 loss 4.44865	 cls_loss: 0.3584 cluster_loss: 1.2433 sup_con_loss: 0.2660 contrastive_loss: 5.2628 nll_loss: 0.0011 
2023-11-01 01:22:24.270 | INFO     | __main__:train:314 - Epoch: [135][100/1251]	 loss 4.49962	 cls_loss: 0.3291 cluster_loss: 1.2797 sup_con_loss: 0.3749 contrastive_loss: 5.2617 nll_loss: 0.0013 
2023-11-01 01:26:06.821 | INFO     | __main__:train:314 - Epoch: [135][200/1251]	 loss 4.50285	 cls_loss: 0.2536 cluster_loss: 1.3445 sup_con_loss: 0.3324 contrastive_loss: 5.2652 nll_loss: 0.0014 
2023-11-01 01:29:50.809 | INFO     | __main__:train:314 - Epoch: [135][300/1251]	 loss 4.48306	 cls_loss: 0.2815 cluster_loss: 1.2546 sup_con_loss: 0.4277 contrastive_loss: 5.2581 nll_loss: 0.0016 
2023-11-01 01:33:35.048 | INFO     | __main__:train:314 - Epoch: [135][400/1251]	 loss 4.44330	 cls_loss: 0.2782 cluster_loss: 1.3051 sup_con_loss: 0.2092 contrastive_loss: 5.2659 nll_loss: 0.0015 
2023-11-01 01:37:19.718 | INFO     | __main__:train:314 - Epoch: [135][500/1251]	 loss 4.43809	 cls_loss: 0.2454 cluster_loss: 1.2531 sup_con_loss: 0.3396 contrastive_loss: 5.2578 nll_loss: 0.0013 
2023-11-01 01:41:04.716 | INFO     | __main__:train:314 - Epoch: [135][600/1251]	 loss 4.46027	 cls_loss: 0.3184 cluster_loss: 1.2646 sup_con_loss: 0.3016 contrastive_loss: 5.2613 nll_loss: 0.0014 
2023-11-01 01:44:47.778 | INFO     | __main__:train:314 - Epoch: [135][700/1251]	 loss 4.48290	 cls_loss: 0.3148 cluster_loss: 1.2597 sup_con_loss: 0.3821 contrastive_loss: 5.2596 nll_loss: 0.0015 
2023-11-01 01:48:31.689 | INFO     | __main__:train:314 - Epoch: [135][800/1251]	 loss 4.42349	 cls_loss: 0.2661 cluster_loss: 1.2599 sup_con_loss: 0.2608 contrastive_loss: 5.2602 nll_loss: 0.0010 
2023-11-01 01:52:14.249 | INFO     | __main__:train:314 - Epoch: [135][900/1251]	 loss 4.46217	 cls_loss: 0.3763 cluster_loss: 1.2355 sup_con_loss: 0.3038 contrastive_loss: 5.2608 nll_loss: 0.0015 
2023-11-01 01:55:57.741 | INFO     | __main__:train:314 - Epoch: [135][1000/1251]	 loss 4.53052	 cls_loss: 0.3584 cluster_loss: 1.3156 sup_con_loss: 0.3685 contrastive_loss: 5.2599 nll_loss: 0.0020 
2023-11-01 01:59:41.102 | INFO     | __main__:train:314 - Epoch: [135][1100/1251]	 loss 4.42891	 cls_loss: 0.3082 cluster_loss: 1.2446 sup_con_loss: 0.2602 contrastive_loss: 5.2596 nll_loss: 0.0023 
2023-11-01 02:03:25.188 | INFO     | __main__:train:314 - Epoch: [135][1200/1251]	 loss 4.44313	 cls_loss: 0.2876 cluster_loss: 1.2531 sup_con_loss: 0.3056 contrastive_loss: 5.2613 nll_loss: 0.0011 
2023-11-01 02:05:16.807 | INFO     | __main__:train:319 - Train Epoch: 135 Avg Loss: 4.4611 
2023-11-01 02:05:16.814 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 02:23:58.126 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 135, Train ACC Unlabelled_v2: All 0.6130 | Old 0.7835 | New 0.5272
2023-11-01 02:23:58.170 | INFO     | __main__:main:205 - Train Accuracies: All 0.6130 | Old 0.7835 | New 0.5272
2023-11-01 02:24:02.722 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 02:24:15.832 | INFO     | __main__:train:314 - Epoch: [136][0/1251]	 loss 4.39449	 cls_loss: 0.2968 cluster_loss: 1.2322 sup_con_loss: 0.1991 contrastive_loss: 5.2584 nll_loss: 0.0020 
2023-11-01 02:28:01.537 | INFO     | __main__:train:314 - Epoch: [136][100/1251]	 loss 4.40917	 cls_loss: 0.3136 cluster_loss: 1.2411 sup_con_loss: 0.2030 contrastive_loss: 5.2621 nll_loss: 0.0013 
2023-11-01 02:31:45.371 | INFO     | __main__:train:314 - Epoch: [136][200/1251]	 loss 4.46821	 cls_loss: 0.2757 cluster_loss: 1.3096 sup_con_loss: 0.2834 contrastive_loss: 5.2616 nll_loss: 0.0012 
2023-11-01 02:35:29.775 | INFO     | __main__:train:314 - Epoch: [136][300/1251]	 loss 4.52778	 cls_loss: 0.4125 cluster_loss: 1.2962 sup_con_loss: 0.3436 contrastive_loss: 5.2612 nll_loss: 0.0008 
2023-11-01 02:39:17.078 | INFO     | __main__:train:314 - Epoch: [136][400/1251]	 loss 4.43451	 cls_loss: 0.3073 cluster_loss: 1.2886 sup_con_loss: 0.1869 contrastive_loss: 5.2659 nll_loss: 0.0011 
2023-11-01 02:42:59.377 | INFO     | __main__:train:314 - Epoch: [136][500/1251]	 loss 4.39026	 cls_loss: 0.3092 cluster_loss: 1.2151 sup_con_loss: 0.2031 contrastive_loss: 5.2615 nll_loss: 0.0012 
2023-11-01 02:46:43.813 | INFO     | __main__:train:314 - Epoch: [136][600/1251]	 loss 4.48913	 cls_loss: 0.2641 cluster_loss: 1.2957 sup_con_loss: 0.3809 contrastive_loss: 5.2611 nll_loss: 0.0014 
2023-11-01 02:50:28.401 | INFO     | __main__:train:314 - Epoch: [136][700/1251]	 loss 4.46090	 cls_loss: 0.3393 cluster_loss: 1.2658 sup_con_loss: 0.2692 contrastive_loss: 5.2671 nll_loss: 0.0016 
2023-11-01 02:54:11.157 | INFO     | __main__:train:314 - Epoch: [136][800/1251]	 loss 4.48599	 cls_loss: 0.3674 cluster_loss: 1.2392 sup_con_loss: 0.3782 contrastive_loss: 5.2577 nll_loss: 0.0021 
2023-11-01 02:57:53.495 | INFO     | __main__:train:314 - Epoch: [136][900/1251]	 loss 4.43406	 cls_loss: 0.2550 cluster_loss: 1.2733 sup_con_loss: 0.2701 contrastive_loss: 5.2639 nll_loss: 0.0011 
2023-11-01 03:01:42.718 | INFO     | __main__:train:314 - Epoch: [136][1000/1251]	 loss 4.40356	 cls_loss: 0.2887 cluster_loss: 1.2453 sup_con_loss: 0.2079 contrastive_loss: 5.2581 nll_loss: 0.0026 
2023-11-01 03:05:27.138 | INFO     | __main__:train:314 - Epoch: [136][1100/1251]	 loss 4.51203	 cls_loss: 0.2932 cluster_loss: 1.2867 sup_con_loss: 0.4346 contrastive_loss: 5.2608 nll_loss: 0.0014 
2023-11-01 03:09:15.303 | INFO     | __main__:train:314 - Epoch: [136][1200/1251]	 loss 4.40848	 cls_loss: 0.2666 cluster_loss: 1.2415 sup_con_loss: 0.2526 contrastive_loss: 5.2600 nll_loss: 0.0008 
2023-11-01 03:11:06.979 | INFO     | __main__:train:319 - Train Epoch: 136 Avg Loss: 4.4581 
2023-11-01 03:11:06.986 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 03:29:49.069 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 136, Train ACC Unlabelled_v2: All 0.6126 | Old 0.7834 | New 0.5267
2023-11-01 03:29:49.255 | INFO     | __main__:main:205 - Train Accuracies: All 0.6126 | Old 0.7834 | New 0.5267
2023-11-01 03:29:52.925 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 03:30:07.357 | INFO     | __main__:train:314 - Epoch: [137][0/1251]	 loss 4.51534	 cls_loss: 0.3667 cluster_loss: 1.2812 sup_con_loss: 0.3821 contrastive_loss: 5.2608 nll_loss: 0.0010 
2023-11-01 03:33:54.019 | INFO     | __main__:train:314 - Epoch: [137][100/1251]	 loss 4.46507	 cls_loss: 0.2699 cluster_loss: 1.3042 sup_con_loss: 0.2908 contrastive_loss: 5.2602 nll_loss: 0.0020 
2023-11-01 03:37:39.968 | INFO     | __main__:train:314 - Epoch: [137][200/1251]	 loss 4.45172	 cls_loss: 0.3400 cluster_loss: 1.2316 sup_con_loss: 0.3224 contrastive_loss: 5.2580 nll_loss: 0.0016 
2023-11-01 03:41:25.401 | INFO     | __main__:train:314 - Epoch: [137][300/1251]	 loss 4.54266	 cls_loss: 0.3385 cluster_loss: 1.3374 sup_con_loss: 0.3770 contrastive_loss: 5.2641 nll_loss: 0.0012 
2023-11-01 03:45:08.113 | INFO     | __main__:train:314 - Epoch: [137][400/1251]	 loss 4.42404	 cls_loss: 0.2660 cluster_loss: 1.2799 sup_con_loss: 0.2156 contrastive_loss: 5.2648 nll_loss: 0.0014 
2023-11-01 03:48:56.314 | INFO     | __main__:train:314 - Epoch: [137][500/1251]	 loss 4.49029	 cls_loss: 0.2560 cluster_loss: 1.2827 sup_con_loss: 0.4125 contrastive_loss: 5.2632 nll_loss: 0.0015 
2023-11-01 03:52:40.445 | INFO     | __main__:train:314 - Epoch: [137][600/1251]	 loss 4.57703	 cls_loss: 0.4003 cluster_loss: 1.3593 sup_con_loss: 0.3683 contrastive_loss: 5.2658 nll_loss: 0.0017 
2023-11-01 03:56:23.961 | INFO     | __main__:train:314 - Epoch: [137][700/1251]	 loss 4.37527	 cls_loss: 0.3249 cluster_loss: 1.1942 sup_con_loss: 0.1908 contrastive_loss: 5.2567 nll_loss: 0.0017 
2023-11-01 04:00:09.217 | INFO     | __main__:train:314 - Epoch: [137][800/1251]	 loss 4.50316	 cls_loss: 0.3140 cluster_loss: 1.3174 sup_con_loss: 0.3280 contrastive_loss: 5.2630 nll_loss: 0.0012 
2023-11-01 04:03:51.758 | INFO     | __main__:train:314 - Epoch: [137][900/1251]	 loss 4.49331	 cls_loss: 0.3000 cluster_loss: 1.2764 sup_con_loss: 0.3891 contrastive_loss: 5.2629 nll_loss: 0.0016 
2023-11-01 04:07:35.465 | INFO     | __main__:train:314 - Epoch: [137][1000/1251]	 loss 4.39998	 cls_loss: 0.2625 cluster_loss: 1.2252 sup_con_loss: 0.2671 contrastive_loss: 5.2569 nll_loss: 0.0013 
2023-11-01 04:11:18.262 | INFO     | __main__:train:314 - Epoch: [137][1100/1251]	 loss 4.42729	 cls_loss: 0.3346 cluster_loss: 1.2081 sup_con_loss: 0.3102 contrastive_loss: 5.2540 nll_loss: 0.0013 
2023-11-01 04:15:01.788 | INFO     | __main__:train:314 - Epoch: [137][1200/1251]	 loss 4.44832	 cls_loss: 0.2900 cluster_loss: 1.2376 sup_con_loss: 0.3458 contrastive_loss: 5.2606 nll_loss: 0.0020 
2023-11-01 04:16:55.069 | INFO     | __main__:train:319 - Train Epoch: 137 Avg Loss: 4.4531 
2023-11-01 04:16:55.075 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 04:35:00.993 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 137, Train ACC Unlabelled_v2: All 0.6132 | Old 0.7832 | New 0.5277
2023-11-01 04:35:01.339 | INFO     | __main__:main:205 - Train Accuracies: All 0.6132 | Old 0.7832 | New 0.5277
2023-11-01 04:35:05.631 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 04:35:20.987 | INFO     | __main__:train:314 - Epoch: [138][0/1251]	 loss 4.45357	 cls_loss: 0.2860 cluster_loss: 1.2488 sup_con_loss: 0.3513 contrastive_loss: 5.2572 nll_loss: 0.0016 
2023-11-01 04:39:04.918 | INFO     | __main__:train:314 - Epoch: [138][100/1251]	 loss 4.47572	 cls_loss: 0.2515 cluster_loss: 1.2670 sup_con_loss: 0.4122 contrastive_loss: 5.2589 nll_loss: 0.0016 
2023-11-01 04:42:50.343 | INFO     | __main__:train:314 - Epoch: [138][200/1251]	 loss 4.44142	 cls_loss: 0.3125 cluster_loss: 1.2773 sup_con_loss: 0.2308 contrastive_loss: 5.2601 nll_loss: 0.0020 
2023-11-01 04:46:35.641 | INFO     | __main__:train:314 - Epoch: [138][300/1251]	 loss 4.43886	 cls_loss: 0.3459 cluster_loss: 1.2623 sup_con_loss: 0.2135 contrastive_loss: 5.2643 nll_loss: 0.0008 
2023-11-01 04:50:19.727 | INFO     | __main__:train:314 - Epoch: [138][400/1251]	 loss 4.46174	 cls_loss: 0.3453 cluster_loss: 1.2753 sup_con_loss: 0.2555 contrastive_loss: 5.2635 nll_loss: 0.0012 
2023-11-01 04:54:04.562 | INFO     | __main__:train:314 - Epoch: [138][500/1251]	 loss 4.42388	 cls_loss: 0.2497 cluster_loss: 1.2484 sup_con_loss: 0.3029 contrastive_loss: 5.2588 nll_loss: 0.0008 
2023-11-01 04:57:47.266 | INFO     | __main__:train:314 - Epoch: [138][600/1251]	 loss 4.40252	 cls_loss: 0.2865 cluster_loss: 1.2269 sup_con_loss: 0.2466 contrastive_loss: 5.2578 nll_loss: 0.0008 
2023-11-01 05:01:30.214 | INFO     | __main__:train:314 - Epoch: [138][700/1251]	 loss 4.52779	 cls_loss: 0.3144 cluster_loss: 1.3499 sup_con_loss: 0.3377 contrastive_loss: 5.2635 nll_loss: 0.0009 
2023-11-01 05:05:14.506 | INFO     | __main__:train:314 - Epoch: [138][800/1251]	 loss 4.50957	 cls_loss: 0.3630 cluster_loss: 1.3188 sup_con_loss: 0.2957 contrastive_loss: 5.2626 nll_loss: 0.0011 
2023-11-01 05:08:59.389 | INFO     | __main__:train:314 - Epoch: [138][900/1251]	 loss 4.40626	 cls_loss: 0.2614 cluster_loss: 1.2389 sup_con_loss: 0.2558 contrastive_loss: 5.2601 nll_loss: 0.0008 
2023-11-01 05:12:44.459 | INFO     | __main__:train:314 - Epoch: [138][1000/1251]	 loss 4.45664	 cls_loss: 0.2427 cluster_loss: 1.2811 sup_con_loss: 0.3342 contrastive_loss: 5.2634 nll_loss: 0.0008 
2023-11-01 05:16:27.669 | INFO     | __main__:train:314 - Epoch: [138][1100/1251]	 loss 4.45634	 cls_loss: 0.2808 cluster_loss: 1.2885 sup_con_loss: 0.2827 contrastive_loss: 5.2614 nll_loss: 0.0017 
2023-11-01 05:20:11.416 | INFO     | __main__:train:314 - Epoch: [138][1200/1251]	 loss 4.46204	 cls_loss: 0.2478 cluster_loss: 1.3288 sup_con_loss: 0.2478 contrastive_loss: 5.2677 nll_loss: 0.0009 
2023-11-01 05:22:02.674 | INFO     | __main__:train:319 - Train Epoch: 138 Avg Loss: 4.4532 
2023-11-01 05:22:02.682 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 05:41:28.178 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 138, Train ACC Unlabelled_v2: All 0.6135 | Old 0.7837 | New 0.5280
2023-11-01 05:41:28.370 | INFO     | __main__:main:205 - Train Accuracies: All 0.6135 | Old 0.7837 | New 0.5280
2023-11-01 05:41:32.639 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 05:41:47.152 | INFO     | __main__:train:314 - Epoch: [139][0/1251]	 loss 4.43189	 cls_loss: 0.3238 cluster_loss: 1.2637 sup_con_loss: 0.2152 contrastive_loss: 5.2626 nll_loss: 0.0011 
2023-11-01 05:45:30.646 | INFO     | __main__:train:314 - Epoch: [139][100/1251]	 loss 4.43583	 cls_loss: 0.2843 cluster_loss: 1.2521 sup_con_loss: 0.2957 contrastive_loss: 5.2574 nll_loss: 0.0017 
2023-11-01 05:49:14.620 | INFO     | __main__:train:314 - Epoch: [139][200/1251]	 loss 4.51505	 cls_loss: 0.3215 cluster_loss: 1.3214 sup_con_loss: 0.3406 contrastive_loss: 5.2665 nll_loss: 0.0012 
2023-11-01 05:52:58.363 | INFO     | __main__:train:314 - Epoch: [139][300/1251]	 loss 4.47061	 cls_loss: 0.2956 cluster_loss: 1.2705 sup_con_loss: 0.3429 contrastive_loss: 5.2614 nll_loss: 0.0014 
2023-11-01 05:56:54.449 | INFO     | __main__:train:314 - Epoch: [139][400/1251]	 loss 4.44045	 cls_loss: 0.3262 cluster_loss: 1.2643 sup_con_loss: 0.2352 contrastive_loss: 5.2622 nll_loss: 0.0017 
2023-11-01 06:00:42.408 | INFO     | __main__:train:314 - Epoch: [139][500/1251]	 loss 4.42578	 cls_loss: 0.2976 cluster_loss: 1.2452 sup_con_loss: 0.2667 contrastive_loss: 5.2577 nll_loss: 0.0014 
2023-11-01 06:04:38.225 | INFO     | __main__:train:314 - Epoch: [139][600/1251]	 loss 4.49241	 cls_loss: 0.2802 cluster_loss: 1.2716 sup_con_loss: 0.4205 contrastive_loss: 5.2612 nll_loss: 0.0008 
2023-11-01 06:08:22.897 | INFO     | __main__:train:314 - Epoch: [139][700/1251]	 loss 4.40389	 cls_loss: 0.2441 cluster_loss: 1.2307 sup_con_loss: 0.2793 contrastive_loss: 5.2593 nll_loss: 0.0022 
2023-11-01 06:12:05.916 | INFO     | __main__:train:314 - Epoch: [139][800/1251]	 loss 4.44151	 cls_loss: 0.2825 cluster_loss: 1.2825 sup_con_loss: 0.2537 contrastive_loss: 5.2597 nll_loss: 0.0014 
2023-11-01 06:15:49.250 | INFO     | __main__:train:314 - Epoch: [139][900/1251]	 loss 4.45657	 cls_loss: 0.2503 cluster_loss: 1.2517 sup_con_loss: 0.3848 contrastive_loss: 5.2603 nll_loss: 0.0015 
2023-11-01 06:19:32.558 | INFO     | __main__:train:314 - Epoch: [139][1000/1251]	 loss 4.32148	 cls_loss: 0.2910 cluster_loss: 1.1922 sup_con_loss: 0.0778 contrastive_loss: 5.2559 nll_loss: 0.0011 
2023-11-01 06:23:15.468 | INFO     | __main__:train:314 - Epoch: [139][1100/1251]	 loss 4.42767	 cls_loss: 0.2752 cluster_loss: 1.2530 sup_con_loss: 0.2747 contrastive_loss: 5.2597 nll_loss: 0.0019 
2023-11-01 06:26:58.401 | INFO     | __main__:train:314 - Epoch: [139][1200/1251]	 loss 4.46829	 cls_loss: 0.2899 cluster_loss: 1.2761 sup_con_loss: 0.3297 contrastive_loss: 5.2623 nll_loss: 0.0015 
2023-11-01 06:28:49.652 | INFO     | __main__:train:319 - Train Epoch: 139 Avg Loss: 4.4490 
2023-11-01 06:28:49.654 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 06:47:01.530 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 139, Train ACC Unlabelled_v2: All 0.6142 | Old 0.7847 | New 0.5286
2023-11-01 06:47:01.579 | INFO     | __main__:main:205 - Train Accuracies: All 0.6142 | Old 0.7847 | New 0.5286
2023-11-01 06:47:04.370 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 06:47:19.267 | INFO     | __main__:train:314 - Epoch: [140][0/1251]	 loss 4.46320	 cls_loss: 0.3009 cluster_loss: 1.2625 sup_con_loss: 0.3433 contrastive_loss: 5.2557 nll_loss: 0.0009 
2023-11-01 06:51:03.540 | INFO     | __main__:train:314 - Epoch: [140][100/1251]	 loss 4.42666	 cls_loss: 0.2131 cluster_loss: 1.2835 sup_con_loss: 0.2749 contrastive_loss: 5.2618 nll_loss: 0.0014 
2023-11-01 06:54:46.588 | INFO     | __main__:train:314 - Epoch: [140][200/1251]	 loss 4.38794	 cls_loss: 0.3046 cluster_loss: 1.2327 sup_con_loss: 0.1746 contrastive_loss: 5.2578 nll_loss: 0.0014 
2023-11-01 06:58:30.045 | INFO     | __main__:train:314 - Epoch: [140][300/1251]	 loss 4.43127	 cls_loss: 0.2910 cluster_loss: 1.2482 sup_con_loss: 0.2802 contrastive_loss: 5.2592 nll_loss: 0.0015 
2023-11-01 07:02:14.089 | INFO     | __main__:train:314 - Epoch: [140][400/1251]	 loss 4.42340	 cls_loss: 0.2556 cluster_loss: 1.2429 sup_con_loss: 0.3018 contrastive_loss: 5.2602 nll_loss: 0.0012 
2023-11-01 07:05:58.008 | INFO     | __main__:train:314 - Epoch: [140][500/1251]	 loss 4.47409	 cls_loss: 0.2470 cluster_loss: 1.2890 sup_con_loss: 0.3704 contrastive_loss: 5.2601 nll_loss: 0.0011 
2023-11-01 07:09:42.896 | INFO     | __main__:train:314 - Epoch: [140][600/1251]	 loss 4.42203	 cls_loss: 0.2656 cluster_loss: 1.2461 sup_con_loss: 0.2850 contrastive_loss: 5.2587 nll_loss: 0.0012 
2023-11-01 07:13:27.763 | INFO     | __main__:train:314 - Epoch: [140][700/1251]	 loss 4.49565	 cls_loss: 0.2657 cluster_loss: 1.3226 sup_con_loss: 0.3414 contrastive_loss: 5.2653 nll_loss: 0.0010 
2023-11-01 07:17:10.721 | INFO     | __main__:train:314 - Epoch: [140][800/1251]	 loss 4.41986	 cls_loss: 0.2804 cluster_loss: 1.2613 sup_con_loss: 0.2304 contrastive_loss: 5.2607 nll_loss: 0.0018 
2023-11-01 07:20:54.992 | INFO     | __main__:train:314 - Epoch: [140][900/1251]	 loss 4.39279	 cls_loss: 0.2693 cluster_loss: 1.2510 sup_con_loss: 0.1801 contrastive_loss: 5.2623 nll_loss: 0.0019 
2023-11-01 07:24:41.452 | INFO     | __main__:train:314 - Epoch: [140][1000/1251]	 loss 4.52292	 cls_loss: 0.2884 cluster_loss: 1.3102 sup_con_loss: 0.4283 contrastive_loss: 5.2610 nll_loss: 0.0008 
2023-11-01 07:28:26.108 | INFO     | __main__:train:314 - Epoch: [140][1100/1251]	 loss 4.55995	 cls_loss: 0.3222 cluster_loss: 1.3141 sup_con_loss: 0.4874 contrastive_loss: 5.2637 nll_loss: 0.0010 
2023-11-01 07:32:11.479 | INFO     | __main__:train:314 - Epoch: [140][1200/1251]	 loss 4.49490	 cls_loss: 0.4062 cluster_loss: 1.2789 sup_con_loss: 0.2891 contrastive_loss: 5.2602 nll_loss: 0.0012 
2023-11-01 07:34:03.270 | INFO     | __main__:train:319 - Train Epoch: 140 Avg Loss: 4.4450 
2023-11-01 07:34:03.276 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 07:51:47.381 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 140, Train ACC Unlabelled_v2: All 0.6144 | Old 0.7837 | New 0.5294
2023-11-01 07:51:47.558 | INFO     | __main__:main:205 - Train Accuracies: All 0.6144 | Old 0.7837 | New 0.5294
2023-11-01 07:51:50.229 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 07:52:05.278 | INFO     | __main__:train:314 - Epoch: [141][0/1251]	 loss 4.41271	 cls_loss: 0.2736 cluster_loss: 1.2191 sup_con_loss: 0.3015 contrastive_loss: 5.2590 nll_loss: 0.0007 
2023-11-01 07:55:48.768 | INFO     | __main__:train:314 - Epoch: [141][100/1251]	 loss 4.49371	 cls_loss: 0.3109 cluster_loss: 1.2317 sup_con_loss: 0.4729 contrastive_loss: 5.2587 nll_loss: 0.0006 
2023-11-01 07:59:35.635 | INFO     | __main__:train:314 - Epoch: [141][200/1251]	 loss 4.40258	 cls_loss: 0.2707 cluster_loss: 1.2325 sup_con_loss: 0.2517 contrastive_loss: 5.2569 nll_loss: 0.0016 
2023-11-01 08:03:19.583 | INFO     | __main__:train:314 - Epoch: [141][300/1251]	 loss 4.46217	 cls_loss: 0.2559 cluster_loss: 1.2801 sup_con_loss: 0.3408 contrastive_loss: 5.2604 nll_loss: 0.0020 
2023-11-01 08:07:03.367 | INFO     | __main__:train:314 - Epoch: [141][400/1251]	 loss 4.46206	 cls_loss: 0.2760 cluster_loss: 1.2497 sup_con_loss: 0.3797 contrastive_loss: 5.2593 nll_loss: 0.0017 
2023-11-01 08:10:47.592 | INFO     | __main__:train:314 - Epoch: [141][500/1251]	 loss 4.42108	 cls_loss: 0.2897 cluster_loss: 1.2431 sup_con_loss: 0.2648 contrastive_loss: 5.2589 nll_loss: 0.0006 
2023-11-01 08:14:32.304 | INFO     | __main__:train:314 - Epoch: [141][600/1251]	 loss 4.46179	 cls_loss: 0.2942 cluster_loss: 1.2762 sup_con_loss: 0.3072 contrastive_loss: 5.2608 nll_loss: 0.0022 
2023-11-01 08:18:16.739 | INFO     | __main__:train:314 - Epoch: [141][700/1251]	 loss 4.43807	 cls_loss: 0.3060 cluster_loss: 1.2641 sup_con_loss: 0.2472 contrastive_loss: 5.2617 nll_loss: 0.0027 
2023-11-01 08:22:01.973 | INFO     | __main__:train:314 - Epoch: [141][800/1251]	 loss 4.45005	 cls_loss: 0.2776 cluster_loss: 1.2917 sup_con_loss: 0.2535 contrastive_loss: 5.2666 nll_loss: 0.0013 
2023-11-01 08:25:48.318 | INFO     | __main__:train:314 - Epoch: [141][900/1251]	 loss 4.38278	 cls_loss: 0.2917 cluster_loss: 1.2408 sup_con_loss: 0.1563 contrastive_loss: 5.2592 nll_loss: 0.0010 
2023-11-01 08:29:31.963 | INFO     | __main__:train:314 - Epoch: [141][1000/1251]	 loss 4.40507	 cls_loss: 0.2643 cluster_loss: 1.2644 sup_con_loss: 0.1974 contrastive_loss: 5.2604 nll_loss: 0.0023 
2023-11-01 08:33:15.937 | INFO     | __main__:train:314 - Epoch: [141][1100/1251]	 loss 4.43375	 cls_loss: 0.2483 cluster_loss: 1.2623 sup_con_loss: 0.2966 contrastive_loss: 5.2633 nll_loss: 0.0014 
2023-11-01 08:37:01.049 | INFO     | __main__:train:314 - Epoch: [141][1200/1251]	 loss 4.49283	 cls_loss: 0.2583 cluster_loss: 1.3147 sup_con_loss: 0.3585 contrastive_loss: 5.2628 nll_loss: 0.0016 
2023-11-01 08:38:54.094 | INFO     | __main__:train:319 - Train Epoch: 141 Avg Loss: 4.4419 
2023-11-01 08:38:54.109 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 08:56:50.811 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 141, Train ACC Unlabelled_v2: All 0.6153 | Old 0.7851 | New 0.5299
2023-11-01 08:56:51.011 | INFO     | __main__:main:205 - Train Accuracies: All 0.6153 | Old 0.7851 | New 0.5299
2023-11-01 08:56:54.012 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 08:57:09.501 | INFO     | __main__:train:314 - Epoch: [142][0/1251]	 loss 4.43588	 cls_loss: 0.2699 cluster_loss: 1.2701 sup_con_loss: 0.2727 contrastive_loss: 5.2604 nll_loss: 0.0012 
2023-11-01 09:00:52.228 | INFO     | __main__:train:314 - Epoch: [142][100/1251]	 loss 4.41776	 cls_loss: 0.2895 cluster_loss: 1.2213 sup_con_loss: 0.2895 contrastive_loss: 5.2617 nll_loss: 0.0012 
2023-11-01 09:04:35.222 | INFO     | __main__:train:314 - Epoch: [142][200/1251]	 loss 4.53967	 cls_loss: 0.2934 cluster_loss: 1.3102 sup_con_loss: 0.4687 contrastive_loss: 5.2614 nll_loss: 0.0014 
2023-11-01 09:08:20.444 | INFO     | __main__:train:314 - Epoch: [142][300/1251]	 loss 4.40964	 cls_loss: 0.2634 cluster_loss: 1.2250 sup_con_loss: 0.2928 contrastive_loss: 5.2580 nll_loss: 0.0010 
2023-11-01 09:12:04.031 | INFO     | __main__:train:314 - Epoch: [142][400/1251]	 loss 4.47166	 cls_loss: 0.3016 cluster_loss: 1.3114 sup_con_loss: 0.2491 contrastive_loss: 5.2700 nll_loss: 0.0010 
2023-11-01 09:15:47.822 | INFO     | __main__:train:314 - Epoch: [142][500/1251]	 loss 4.39026	 cls_loss: 0.3206 cluster_loss: 1.2318 sup_con_loss: 0.1667 contrastive_loss: 5.2591 nll_loss: 0.0006 
2023-11-01 09:19:31.816 | INFO     | __main__:train:314 - Epoch: [142][600/1251]	 loss 4.43106	 cls_loss: 0.3166 cluster_loss: 1.2140 sup_con_loss: 0.3205 contrastive_loss: 5.2581 nll_loss: 0.0012 
2023-11-01 09:23:14.377 | INFO     | __main__:train:314 - Epoch: [142][700/1251]	 loss 4.44558	 cls_loss: 0.2672 cluster_loss: 1.2723 sup_con_loss: 0.2944 contrastive_loss: 5.2628 nll_loss: 0.0013 
2023-11-01 09:26:59.865 | INFO     | __main__:train:314 - Epoch: [142][800/1251]	 loss 4.47707	 cls_loss: 0.2493 cluster_loss: 1.3067 sup_con_loss: 0.3364 contrastive_loss: 5.2638 nll_loss: 0.0012 
2023-11-01 09:30:45.483 | INFO     | __main__:train:314 - Epoch: [142][900/1251]	 loss 4.47617	 cls_loss: 0.2684 cluster_loss: 1.2828 sup_con_loss: 0.3689 contrastive_loss: 5.2592 nll_loss: 0.0008 
2023-11-01 09:34:36.610 | INFO     | __main__:train:314 - Epoch: [142][1000/1251]	 loss 4.39427	 cls_loss: 0.2423 cluster_loss: 1.2228 sup_con_loss: 0.2709 contrastive_loss: 5.2589 nll_loss: 0.0015 
2023-11-01 09:38:47.277 | INFO     | __main__:train:314 - Epoch: [142][1100/1251]	 loss 4.49460	 cls_loss: 0.2698 cluster_loss: 1.2797 sup_con_loss: 0.4247 contrastive_loss: 5.2596 nll_loss: 0.0010 
2023-11-01 09:42:31.623 | INFO     | __main__:train:314 - Epoch: [142][1200/1251]	 loss 4.41401	 cls_loss: 0.2470 cluster_loss: 1.2487 sup_con_loss: 0.2729 contrastive_loss: 5.2591 nll_loss: 0.0020 
2023-11-01 09:44:27.084 | INFO     | __main__:train:319 - Train Epoch: 142 Avg Loss: 4.4402 
2023-11-01 09:44:27.093 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 10:04:26.057 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 142, Train ACC Unlabelled_v2: All 0.6150 | Old 0.7851 | New 0.5295
2023-11-01 10:04:26.533 | INFO     | __main__:main:205 - Train Accuracies: All 0.6150 | Old 0.7851 | New 0.5295
2023-11-01 10:04:29.530 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 10:04:43.415 | INFO     | __main__:train:314 - Epoch: [143][0/1251]	 loss 4.33958	 cls_loss: 0.2499 cluster_loss: 1.2147 sup_con_loss: 0.1247 contrastive_loss: 5.2576 nll_loss: 0.0015 
2023-11-01 10:08:26.606 | INFO     | __main__:train:314 - Epoch: [143][100/1251]	 loss 4.33584	 cls_loss: 0.2339 cluster_loss: 1.1842 sup_con_loss: 0.1915 contrastive_loss: 5.2555 nll_loss: 0.0011 
2023-11-01 10:12:10.836 | INFO     | __main__:train:314 - Epoch: [143][200/1251]	 loss 4.44199	 cls_loss: 0.2871 cluster_loss: 1.2553 sup_con_loss: 0.3062 contrastive_loss: 5.2578 nll_loss: 0.0008 
2023-11-01 10:15:55.281 | INFO     | __main__:train:314 - Epoch: [143][300/1251]	 loss 4.48797	 cls_loss: 0.3030 cluster_loss: 1.2627 sup_con_loss: 0.3919 contrastive_loss: 5.2661 nll_loss: 0.0010 
2023-11-01 10:19:38.529 | INFO     | __main__:train:314 - Epoch: [143][400/1251]	 loss 4.38489	 cls_loss: 0.2328 cluster_loss: 1.2271 sup_con_loss: 0.2421 contrastive_loss: 5.2617 nll_loss: 0.0009 
2023-11-01 10:23:25.141 | INFO     | __main__:train:314 - Epoch: [143][500/1251]	 loss 4.38081	 cls_loss: 0.2482 cluster_loss: 1.2275 sup_con_loss: 0.2194 contrastive_loss: 5.2582 nll_loss: 0.0014 
2023-11-01 10:27:08.460 | INFO     | __main__:train:314 - Epoch: [143][600/1251]	 loss 4.37669	 cls_loss: 0.2286 cluster_loss: 1.2455 sup_con_loss: 0.1880 contrastive_loss: 5.2604 nll_loss: 0.0020 
2023-11-01 10:30:52.839 | INFO     | __main__:train:314 - Epoch: [143][700/1251]	 loss 4.40667	 cls_loss: 0.2514 cluster_loss: 1.2464 sup_con_loss: 0.2507 contrastive_loss: 5.2608 nll_loss: 0.0012 
2023-11-01 10:34:36.849 | INFO     | __main__:train:314 - Epoch: [143][800/1251]	 loss 4.43353	 cls_loss: 0.2695 cluster_loss: 1.2578 sup_con_loss: 0.2918 contrastive_loss: 5.2599 nll_loss: 0.0006 
2023-11-01 10:38:21.280 | INFO     | __main__:train:314 - Epoch: [143][900/1251]	 loss 4.48597	 cls_loss: 0.3437 cluster_loss: 1.3093 sup_con_loss: 0.2678 contrastive_loss: 5.2623 nll_loss: 0.0004 
2023-11-01 10:42:05.773 | INFO     | __main__:train:314 - Epoch: [143][1000/1251]	 loss 4.40749	 cls_loss: 0.3037 cluster_loss: 1.2620 sup_con_loss: 0.1743 contrastive_loss: 5.2600 nll_loss: 0.0009 
2023-11-01 10:45:50.433 | INFO     | __main__:train:314 - Epoch: [143][1100/1251]	 loss 4.46762	 cls_loss: 0.2834 cluster_loss: 1.3300 sup_con_loss: 0.2218 contrastive_loss: 5.2689 nll_loss: 0.0015 
2023-11-01 10:49:37.577 | INFO     | __main__:train:314 - Epoch: [143][1200/1251]	 loss 4.44215	 cls_loss: 0.2659 cluster_loss: 1.2685 sup_con_loss: 0.2892 contrastive_loss: 5.2636 nll_loss: 0.0020 
2023-11-01 10:51:30.415 | INFO     | __main__:train:319 - Train Epoch: 143 Avg Loss: 4.4373 
2023-11-01 10:51:30.417 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 11:09:08.676 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 143, Train ACC Unlabelled_v2: All 0.6148 | Old 0.7855 | New 0.5290
2023-11-01 11:09:08.910 | INFO     | __main__:main:205 - Train Accuracies: All 0.6148 | Old 0.7855 | New 0.5290
2023-11-01 11:09:11.895 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 11:09:25.044 | INFO     | __main__:train:314 - Epoch: [144][0/1251]	 loss 4.43043	 cls_loss: 0.3286 cluster_loss: 1.2231 sup_con_loss: 0.2863 contrastive_loss: 5.2592 nll_loss: 0.0017 
2023-11-01 11:13:10.185 | INFO     | __main__:train:314 - Epoch: [144][100/1251]	 loss 4.43005	 cls_loss: 0.2645 cluster_loss: 1.2428 sup_con_loss: 0.3078 contrastive_loss: 5.2624 nll_loss: 0.0014 
2023-11-01 11:16:56.268 | INFO     | __main__:train:314 - Epoch: [144][200/1251]	 loss 4.45474	 cls_loss: 0.2241 cluster_loss: 1.2923 sup_con_loss: 0.3305 contrastive_loss: 5.2608 nll_loss: 0.0012 
2023-11-01 11:20:40.035 | INFO     | __main__:train:314 - Epoch: [144][300/1251]	 loss 4.43172	 cls_loss: 0.2738 cluster_loss: 1.2574 sup_con_loss: 0.2842 contrastive_loss: 5.2582 nll_loss: 0.0013 
2023-11-01 11:24:22.846 | INFO     | __main__:train:314 - Epoch: [144][400/1251]	 loss 4.40786	 cls_loss: 0.2474 cluster_loss: 1.2607 sup_con_loss: 0.2280 contrastive_loss: 5.2622 nll_loss: 0.0016 
2023-11-01 11:28:14.170 | INFO     | __main__:train:314 - Epoch: [144][500/1251]	 loss 4.38889	 cls_loss: 0.2501 cluster_loss: 1.2226 sup_con_loss: 0.2452 contrastive_loss: 5.2608 nll_loss: 0.0013 
2023-11-01 11:31:56.999 | INFO     | __main__:train:314 - Epoch: [144][600/1251]	 loss 4.41679	 cls_loss: 0.2953 cluster_loss: 1.2300 sup_con_loss: 0.2731 contrastive_loss: 5.2572 nll_loss: 0.0012 
2023-11-01 11:35:43.993 | INFO     | __main__:train:314 - Epoch: [144][700/1251]	 loss 4.42940	 cls_loss: 0.2663 cluster_loss: 1.2531 sup_con_loss: 0.2892 contrastive_loss: 5.2611 nll_loss: 0.0007 
2023-11-01 11:39:27.898 | INFO     | __main__:train:314 - Epoch: [144][800/1251]	 loss 4.41994	 cls_loss: 0.2723 cluster_loss: 1.2376 sup_con_loss: 0.2907 contrastive_loss: 5.2579 nll_loss: 0.0008 
2023-11-01 11:43:12.621 | INFO     | __main__:train:314 - Epoch: [144][900/1251]	 loss 4.40632	 cls_loss: 0.2984 cluster_loss: 1.2079 sup_con_loss: 0.2784 contrastive_loss: 5.2591 nll_loss: 0.0009 
2023-11-01 11:46:57.201 | INFO     | __main__:train:314 - Epoch: [144][1000/1251]	 loss 4.42245	 cls_loss: 0.2685 cluster_loss: 1.2693 sup_con_loss: 0.2319 contrastive_loss: 5.2615 nll_loss: 0.0023 
2023-11-01 11:50:41.257 | INFO     | __main__:train:314 - Epoch: [144][1100/1251]	 loss 4.39895	 cls_loss: 0.2779 cluster_loss: 1.2237 sup_con_loss: 0.2442 contrastive_loss: 5.2614 nll_loss: 0.0009 
2023-11-01 11:54:24.638 | INFO     | __main__:train:314 - Epoch: [144][1200/1251]	 loss 4.52572	 cls_loss: 0.2416 cluster_loss: 1.3674 sup_con_loss: 0.3608 contrastive_loss: 5.2693 nll_loss: 0.0010 
2023-11-01 11:56:16.390 | INFO     | __main__:train:319 - Train Epoch: 144 Avg Loss: 4.4347 
2023-11-01 11:56:16.398 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 12:14:26.101 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 144, Train ACC Unlabelled_v2: All 0.6154 | Old 0.7859 | New 0.5298
2023-11-01 12:14:26.311 | INFO     | __main__:main:205 - Train Accuracies: All 0.6154 | Old 0.7859 | New 0.5298
2023-11-01 12:14:31.254 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 12:14:48.534 | INFO     | __main__:train:314 - Epoch: [145][0/1251]	 loss 4.39803	 cls_loss: 0.2170 cluster_loss: 1.2450 sup_con_loss: 0.2734 contrastive_loss: 5.2554 nll_loss: 0.0011 
2023-11-01 12:18:34.951 | INFO     | __main__:train:314 - Epoch: [145][100/1251]	 loss 4.44840	 cls_loss: 0.2912 cluster_loss: 1.2271 sup_con_loss: 0.3775 contrastive_loss: 5.2546 nll_loss: 0.0012 
2023-11-01 12:22:19.987 | INFO     | __main__:train:314 - Epoch: [145][200/1251]	 loss 4.44068	 cls_loss: 0.2839 cluster_loss: 1.2396 sup_con_loss: 0.3342 contrastive_loss: 5.2569 nll_loss: 0.0017 
2023-11-01 12:26:02.968 | INFO     | __main__:train:314 - Epoch: [145][300/1251]	 loss 4.49413	 cls_loss: 0.2564 cluster_loss: 1.3090 sup_con_loss: 0.3828 contrastive_loss: 5.2591 nll_loss: 0.0011 
2023-11-01 12:29:47.587 | INFO     | __main__:train:314 - Epoch: [145][400/1251]	 loss 4.45949	 cls_loss: 0.3445 cluster_loss: 1.2660 sup_con_loss: 0.2686 contrastive_loss: 5.2627 nll_loss: 0.0013 
2023-11-01 12:33:31.799 | INFO     | __main__:train:314 - Epoch: [145][500/1251]	 loss 4.43744	 cls_loss: 0.2735 cluster_loss: 1.2424 sup_con_loss: 0.3292 contrastive_loss: 5.2585 nll_loss: 0.0009 
2023-11-01 12:37:16.607 | INFO     | __main__:train:314 - Epoch: [145][600/1251]	 loss 4.42737	 cls_loss: 0.2820 cluster_loss: 1.2288 sup_con_loss: 0.3141 contrastive_loss: 5.2595 nll_loss: 0.0014 
2023-11-01 12:41:00.419 | INFO     | __main__:train:314 - Epoch: [145][700/1251]	 loss 4.39428	 cls_loss: 0.2274 cluster_loss: 1.2551 sup_con_loss: 0.2239 contrastive_loss: 5.2618 nll_loss: 0.0003 
2023-11-01 12:44:47.152 | INFO     | __main__:train:314 - Epoch: [145][800/1251]	 loss 4.34988	 cls_loss: 0.2421 cluster_loss: 1.2108 sup_con_loss: 0.1697 contrastive_loss: 5.2583 nll_loss: 0.0008 
2023-11-01 12:48:33.268 | INFO     | __main__:train:314 - Epoch: [145][900/1251]	 loss 4.43978	 cls_loss: 0.3003 cluster_loss: 1.2413 sup_con_loss: 0.3086 contrastive_loss: 5.2599 nll_loss: 0.0009 
2023-11-01 12:52:16.629 | INFO     | __main__:train:314 - Epoch: [145][1000/1251]	 loss 4.43928	 cls_loss: 0.2899 cluster_loss: 1.2163 sup_con_loss: 0.3687 contrastive_loss: 5.2561 nll_loss: 0.0017 
2023-11-01 12:56:00.234 | INFO     | __main__:train:314 - Epoch: [145][1100/1251]	 loss 4.41052	 cls_loss: 0.2842 cluster_loss: 1.2198 sup_con_loss: 0.2816 contrastive_loss: 5.2594 nll_loss: 0.0010 
2023-11-01 12:59:43.996 | INFO     | __main__:train:314 - Epoch: [145][1200/1251]	 loss 4.41453	 cls_loss: 0.2441 cluster_loss: 1.2398 sup_con_loss: 0.3010 contrastive_loss: 5.2568 nll_loss: 0.0010 
2023-11-01 13:01:36.848 | INFO     | __main__:train:319 - Train Epoch: 145 Avg Loss: 4.4327 
2023-11-01 13:01:36.870 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 13:19:55.549 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 145, Train ACC Unlabelled_v2: All 0.6169 | Old 0.7867 | New 0.5315
2023-11-01 13:19:55.777 | INFO     | __main__:main:205 - Train Accuracies: All 0.6169 | Old 0.7867 | New 0.5315
2023-11-01 13:19:59.989 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 13:20:15.007 | INFO     | __main__:train:314 - Epoch: [146][0/1251]	 loss 4.35827	 cls_loss: 0.2691 cluster_loss: 1.2071 sup_con_loss: 0.1790 contrastive_loss: 5.2551 nll_loss: 0.0010 
2023-11-01 13:23:58.751 | INFO     | __main__:train:314 - Epoch: [146][100/1251]	 loss 4.38877	 cls_loss: 0.2603 cluster_loss: 1.2270 sup_con_loss: 0.2312 contrastive_loss: 5.2590 nll_loss: 0.0009 
2023-11-01 13:27:43.056 | INFO     | __main__:train:314 - Epoch: [146][200/1251]	 loss 4.50875	 cls_loss: 0.3051 cluster_loss: 1.3254 sup_con_loss: 0.3399 contrastive_loss: 5.2618 nll_loss: 0.0013 
2023-11-01 13:31:29.475 | INFO     | __main__:train:314 - Epoch: [146][300/1251]	 loss 4.45998	 cls_loss: 0.2528 cluster_loss: 1.2716 sup_con_loss: 0.3533 contrastive_loss: 5.2612 nll_loss: 0.0015 
2023-11-01 13:35:12.220 | INFO     | __main__:train:314 - Epoch: [146][400/1251]	 loss 4.37732	 cls_loss: 0.2868 cluster_loss: 1.2201 sup_con_loss: 0.1889 contrastive_loss: 5.2568 nll_loss: 0.0008 
2023-11-01 13:40:06.841 | INFO     | __main__:train:314 - Epoch: [146][500/1251]	 loss 4.37665	 cls_loss: 0.2391 cluster_loss: 1.2163 sup_con_loss: 0.2410 contrastive_loss: 5.2562 nll_loss: 0.0015 
2023-11-01 13:43:56.056 | INFO     | __main__:train:314 - Epoch: [146][600/1251]	 loss 4.51721	 cls_loss: 0.1961 cluster_loss: 1.3503 sup_con_loss: 0.4207 contrastive_loss: 5.2661 nll_loss: 0.0007 
2023-11-01 13:47:39.595 | INFO     | __main__:train:314 - Epoch: [146][700/1251]	 loss 4.41403	 cls_loss: 0.2726 cluster_loss: 1.2392 sup_con_loss: 0.2724 contrastive_loss: 5.2559 nll_loss: 0.0015 
2023-11-01 13:51:24.181 | INFO     | __main__:train:314 - Epoch: [146][800/1251]	 loss 4.49775	 cls_loss: 0.3261 cluster_loss: 1.2956 sup_con_loss: 0.3452 contrastive_loss: 5.2604 nll_loss: 0.0014 
2023-11-01 13:55:08.676 | INFO     | __main__:train:314 - Epoch: [146][900/1251]	 loss 4.41150	 cls_loss: 0.2260 cluster_loss: 1.2466 sup_con_loss: 0.2921 contrastive_loss: 5.2589 nll_loss: 0.0016 
2023-11-01 13:58:53.459 | INFO     | __main__:train:314 - Epoch: [146][1000/1251]	 loss 4.42914	 cls_loss: 0.2471 cluster_loss: 1.2838 sup_con_loss: 0.2423 contrastive_loss: 5.2627 nll_loss: 0.0026 
2023-11-01 14:02:38.785 | INFO     | __main__:train:314 - Epoch: [146][1100/1251]	 loss 4.42633	 cls_loss: 0.2736 cluster_loss: 1.2776 sup_con_loss: 0.2313 contrastive_loss: 5.2588 nll_loss: 0.0009 
2023-11-01 14:06:28.232 | INFO     | __main__:train:314 - Epoch: [146][1200/1251]	 loss 4.45271	 cls_loss: 0.2644 cluster_loss: 1.2609 sup_con_loss: 0.3460 contrastive_loss: 5.2579 nll_loss: 0.0019 
2023-11-01 14:08:19.707 | INFO     | __main__:train:319 - Train Epoch: 146 Avg Loss: 4.4305 
2023-11-01 14:08:19.735 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 14:27:08.487 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 146, Train ACC Unlabelled_v2: All 0.6157 | Old 0.7873 | New 0.5295
2023-11-01 14:27:08.767 | INFO     | __main__:main:205 - Train Accuracies: All 0.6157 | Old 0.7873 | New 0.5295
2023-11-01 14:27:12.720 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 14:27:28.435 | INFO     | __main__:train:314 - Epoch: [147][0/1251]	 loss 4.48689	 cls_loss: 0.2739 cluster_loss: 1.2839 sup_con_loss: 0.3826 contrastive_loss: 5.2631 nll_loss: 0.0016 
2023-11-01 14:31:13.419 | INFO     | __main__:train:314 - Epoch: [147][100/1251]	 loss 4.45577	 cls_loss: 0.2949 cluster_loss: 1.2817 sup_con_loss: 0.2832 contrastive_loss: 5.2607 nll_loss: 0.0009 
2023-11-01 14:34:59.616 | INFO     | __main__:train:314 - Epoch: [147][200/1251]	 loss 4.49083	 cls_loss: 0.2704 cluster_loss: 1.2495 sup_con_loss: 0.4720 contrastive_loss: 5.2582 nll_loss: 0.0010 
2023-11-01 14:38:43.528 | INFO     | __main__:train:314 - Epoch: [147][300/1251]	 loss 4.40940	 cls_loss: 0.2437 cluster_loss: 1.2314 sup_con_loss: 0.3074 contrastive_loss: 5.2540 nll_loss: 0.0011 
2023-11-01 14:42:26.042 | INFO     | __main__:train:314 - Epoch: [147][400/1251]	 loss 4.43734	 cls_loss: 0.2289 cluster_loss: 1.2932 sup_con_loss: 0.2712 contrastive_loss: 5.2625 nll_loss: 0.0011 
2023-11-01 14:46:11.520 | INFO     | __main__:train:314 - Epoch: [147][500/1251]	 loss 4.40527	 cls_loss: 0.2465 cluster_loss: 1.2387 sup_con_loss: 0.2700 contrastive_loss: 5.2587 nll_loss: 0.0012 
2023-11-01 14:49:54.285 | INFO     | __main__:train:314 - Epoch: [147][600/1251]	 loss 4.41754	 cls_loss: 0.2425 cluster_loss: 1.2586 sup_con_loss: 0.2702 contrastive_loss: 5.2596 nll_loss: 0.0012 
2023-11-01 14:53:38.134 | INFO     | __main__:train:314 - Epoch: [147][700/1251]	 loss 4.45452	 cls_loss: 0.2651 cluster_loss: 1.2519 sup_con_loss: 0.3661 contrastive_loss: 5.2590 nll_loss: 0.0015 
2023-11-01 14:57:19.990 | INFO     | __main__:train:314 - Epoch: [147][800/1251]	 loss 4.47177	 cls_loss: 0.2907 cluster_loss: 1.2747 sup_con_loss: 0.3535 contrastive_loss: 5.2570 nll_loss: 0.0007 
2023-11-01 15:01:04.931 | INFO     | __main__:train:314 - Epoch: [147][900/1251]	 loss 4.46451	 cls_loss: 0.3088 cluster_loss: 1.2959 sup_con_loss: 0.2589 contrastive_loss: 5.2645 nll_loss: 0.0016 
2023-11-01 15:04:50.187 | INFO     | __main__:train:314 - Epoch: [147][1000/1251]	 loss 4.40979	 cls_loss: 0.2694 cluster_loss: 1.2396 sup_con_loss: 0.2559 contrastive_loss: 5.2600 nll_loss: 0.0011 
2023-11-01 15:08:34.103 | INFO     | __main__:train:314 - Epoch: [147][1100/1251]	 loss 4.39266	 cls_loss: 0.2626 cluster_loss: 1.2329 sup_con_loss: 0.2246 contrastive_loss: 5.2596 nll_loss: 0.0020 
2023-11-01 15:12:18.594 | INFO     | __main__:train:314 - Epoch: [147][1200/1251]	 loss 4.37080	 cls_loss: 0.2586 cluster_loss: 1.2072 sup_con_loss: 0.2220 contrastive_loss: 5.2565 nll_loss: 0.0012 
2023-11-01 15:14:10.071 | INFO     | __main__:train:319 - Train Epoch: 147 Avg Loss: 4.4256 
2023-11-01 15:14:10.075 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 15:34:48.072 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 147, Train ACC Unlabelled_v2: All 0.6161 | Old 0.7858 | New 0.5308
2023-11-01 15:34:48.365 | INFO     | __main__:main:205 - Train Accuracies: All 0.6161 | Old 0.7858 | New 0.5308
2023-11-01 15:34:51.815 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 15:35:07.819 | INFO     | __main__:train:314 - Epoch: [148][0/1251]	 loss 4.39954	 cls_loss: 0.2558 cluster_loss: 1.2401 sup_con_loss: 0.2413 contrastive_loss: 5.2593 nll_loss: 0.0010 
2023-11-01 15:38:52.841 | INFO     | __main__:train:314 - Epoch: [148][100/1251]	 loss 4.49653	 cls_loss: 0.2582 cluster_loss: 1.3369 sup_con_loss: 0.3203 contrastive_loss: 5.2672 nll_loss: 0.0014 
2023-11-01 15:42:40.491 | INFO     | __main__:train:314 - Epoch: [148][200/1251]	 loss 4.45451	 cls_loss: 0.2589 cluster_loss: 1.2667 sup_con_loss: 0.3492 contrastive_loss: 5.2580 nll_loss: 0.0006 
2023-11-01 15:46:28.746 | INFO     | __main__:train:314 - Epoch: [148][300/1251]	 loss 4.47426	 cls_loss: 0.3873 cluster_loss: 1.2760 sup_con_loss: 0.2499 contrastive_loss: 5.2627 nll_loss: 0.0011 
2023-11-01 15:53:49.168 | INFO     | __main__:train:314 - Epoch: [148][400/1251]	 loss 4.44664	 cls_loss: 0.2485 cluster_loss: 1.2591 sup_con_loss: 0.3519 contrastive_loss: 5.2563 nll_loss: 0.0015 
2023-11-01 15:59:41.177 | INFO     | __main__:train:314 - Epoch: [148][500/1251]	 loss 4.41093	 cls_loss: 0.2546 cluster_loss: 1.2370 sup_con_loss: 0.2868 contrastive_loss: 5.2564 nll_loss: 0.0007 
2023-11-01 16:03:29.620 | INFO     | __main__:train:314 - Epoch: [148][600/1251]	 loss 4.46387	 cls_loss: 0.2968 cluster_loss: 1.2461 sup_con_loss: 0.3754 contrastive_loss: 5.2578 nll_loss: 0.0010 
2023-11-01 16:07:20.718 | INFO     | __main__:train:314 - Epoch: [148][700/1251]	 loss 4.40474	 cls_loss: 0.2298 cluster_loss: 1.2113 sup_con_loss: 0.3376 contrastive_loss: 5.2574 nll_loss: 0.0015 
2023-11-01 16:11:10.524 | INFO     | __main__:train:314 - Epoch: [148][800/1251]	 loss 4.43897	 cls_loss: 0.2223 cluster_loss: 1.2839 sup_con_loss: 0.3113 contrastive_loss: 5.2570 nll_loss: 0.0006 
2023-11-01 16:15:20.738 | INFO     | __main__:train:314 - Epoch: [148][900/1251]	 loss 4.40097	 cls_loss: 0.2827 cluster_loss: 1.2153 sup_con_loss: 0.2618 contrastive_loss: 5.2601 nll_loss: 0.0014 
2023-11-01 16:19:13.111 | INFO     | __main__:train:314 - Epoch: [148][1000/1251]	 loss 4.47356	 cls_loss: 0.2907 cluster_loss: 1.2877 sup_con_loss: 0.3256 contrastive_loss: 5.2616 nll_loss: 0.0008 
2023-11-01 16:23:00.474 | INFO     | __main__:train:314 - Epoch: [148][1100/1251]	 loss 4.40076	 cls_loss: 0.2768 cluster_loss: 1.1867 sup_con_loss: 0.3304 contrastive_loss: 5.2554 nll_loss: 0.0009 
2023-11-01 16:26:46.133 | INFO     | __main__:train:314 - Epoch: [148][1200/1251]	 loss 4.44502	 cls_loss: 0.2440 cluster_loss: 1.2586 sup_con_loss: 0.3523 contrastive_loss: 5.2574 nll_loss: 0.0009 
2023-11-01 16:28:37.889 | INFO     | __main__:train:319 - Train Epoch: 148 Avg Loss: 4.4239 
2023-11-01 16:28:37.894 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 16:49:52.092 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 148, Train ACC Unlabelled_v2: All 0.6168 | Old 0.7872 | New 0.5311
2023-11-01 16:49:53.121 | INFO     | __main__:main:205 - Train Accuracies: All 0.6168 | Old 0.7872 | New 0.5311
2023-11-01 16:49:58.825 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 16:50:37.719 | INFO     | __main__:train:314 - Epoch: [149][0/1251]	 loss 4.43033	 cls_loss: 0.2997 cluster_loss: 1.2279 sup_con_loss: 0.3084 contrastive_loss: 5.2592 nll_loss: 0.0009 
2023-11-01 16:54:36.475 | INFO     | __main__:train:314 - Epoch: [149][100/1251]	 loss 4.38210	 cls_loss: 0.2999 cluster_loss: 1.2115 sup_con_loss: 0.1998 contrastive_loss: 5.2596 nll_loss: 0.0010 
2023-11-01 16:58:21.856 | INFO     | __main__:train:314 - Epoch: [149][200/1251]	 loss 4.40926	 cls_loss: 0.2401 cluster_loss: 1.2329 sup_con_loss: 0.3037 contrastive_loss: 5.2565 nll_loss: 0.0008 
2023-11-01 17:02:06.240 | INFO     | __main__:train:314 - Epoch: [149][300/1251]	 loss 4.45045	 cls_loss: 0.2843 cluster_loss: 1.2602 sup_con_loss: 0.3217 contrastive_loss: 5.2589 nll_loss: 0.0009 
2023-11-01 17:05:50.356 | INFO     | __main__:train:314 - Epoch: [149][400/1251]	 loss 4.50987	 cls_loss: 0.2915 cluster_loss: 1.3067 sup_con_loss: 0.3826 contrastive_loss: 5.2667 nll_loss: 0.0012 
2023-11-01 17:09:36.635 | INFO     | __main__:train:314 - Epoch: [149][500/1251]	 loss 4.49180	 cls_loss: 0.2979 cluster_loss: 1.2648 sup_con_loss: 0.4140 contrastive_loss: 5.2608 nll_loss: 0.0010 
2023-11-01 17:13:22.986 | INFO     | __main__:train:314 - Epoch: [149][600/1251]	 loss 4.45503	 cls_loss: 0.2548 cluster_loss: 1.2878 sup_con_loss: 0.3021 contrastive_loss: 5.2647 nll_loss: 0.0010 
2023-11-01 17:17:06.268 | INFO     | __main__:train:314 - Epoch: [149][700/1251]	 loss 4.40930	 cls_loss: 0.2623 cluster_loss: 1.2279 sup_con_loss: 0.2783 contrastive_loss: 5.2622 nll_loss: 0.0015 
2023-11-01 17:20:49.613 | INFO     | __main__:train:314 - Epoch: [149][800/1251]	 loss 4.45863	 cls_loss: 0.3128 cluster_loss: 1.3082 sup_con_loss: 0.2153 contrastive_loss: 5.2655 nll_loss: 0.0009 
2023-11-01 17:24:33.356 | INFO     | __main__:train:314 - Epoch: [149][900/1251]	 loss 4.48242	 cls_loss: 0.3116 cluster_loss: 1.2872 sup_con_loss: 0.3285 contrastive_loss: 5.2617 nll_loss: 0.0016 
2023-11-01 17:28:17.739 | INFO     | __main__:train:314 - Epoch: [149][1000/1251]	 loss 4.37831	 cls_loss: 0.2421 cluster_loss: 1.1984 sup_con_loss: 0.2720 contrastive_loss: 5.2584 nll_loss: 0.0015 
2023-11-01 17:32:03.501 | INFO     | __main__:train:314 - Epoch: [149][1100/1251]	 loss 4.42102	 cls_loss: 0.2755 cluster_loss: 1.2522 sup_con_loss: 0.2585 contrastive_loss: 5.2607 nll_loss: 0.0007 
2023-11-01 17:35:46.537 | INFO     | __main__:train:314 - Epoch: [149][1200/1251]	 loss 4.34153	 cls_loss: 0.2752 cluster_loss: 1.2129 sup_con_loss: 0.1094 contrastive_loss: 5.2578 nll_loss: 0.0010 
2023-11-01 17:37:38.448 | INFO     | __main__:train:319 - Train Epoch: 149 Avg Loss: 4.4221 
2023-11-01 17:37:38.454 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 17:57:01.356 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 149, Train ACC Unlabelled_v2: All 0.6175 | Old 0.7863 | New 0.5326
2023-11-01 17:57:01.643 | INFO     | __main__:main:205 - Train Accuracies: All 0.6175 | Old 0.7863 | New 0.5326
2023-11-01 17:57:04.626 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 17:57:18.177 | INFO     | __main__:train:314 - Epoch: [150][0/1251]	 loss 4.39736	 cls_loss: 0.2822 cluster_loss: 1.2083 sup_con_loss: 0.2739 contrastive_loss: 5.2560 nll_loss: 0.0009 
2023-11-01 18:01:01.632 | INFO     | __main__:train:314 - Epoch: [150][100/1251]	 loss 4.43658	 cls_loss: 0.2552 cluster_loss: 1.2705 sup_con_loss: 0.2899 contrastive_loss: 5.2592 nll_loss: 0.0014 
2023-11-01 18:04:44.593 | INFO     | __main__:train:314 - Epoch: [150][200/1251]	 loss 4.40772	 cls_loss: 0.2808 cluster_loss: 1.2227 sup_con_loss: 0.2756 contrastive_loss: 5.2569 nll_loss: 0.0012 
2023-11-01 18:08:26.447 | INFO     | __main__:train:314 - Epoch: [150][300/1251]	 loss 4.41053	 cls_loss: 0.2734 cluster_loss: 1.1998 sup_con_loss: 0.3388 contrastive_loss: 5.2542 nll_loss: 0.0012 
2023-11-01 18:12:11.263 | INFO     | __main__:train:314 - Epoch: [150][400/1251]	 loss 4.39191	 cls_loss: 0.2657 cluster_loss: 1.2273 sup_con_loss: 0.2386 contrastive_loss: 5.2549 nll_loss: 0.0019 
2023-11-01 18:16:00.375 | INFO     | __main__:train:314 - Epoch: [150][500/1251]	 loss 4.39346	 cls_loss: 0.2668 cluster_loss: 1.2400 sup_con_loss: 0.2097 contrastive_loss: 5.2599 nll_loss: 0.0018 
2023-11-01 18:19:48.727 | INFO     | __main__:train:314 - Epoch: [150][600/1251]	 loss 4.49470	 cls_loss: 0.2973 cluster_loss: 1.2973 sup_con_loss: 0.3593 contrastive_loss: 5.2621 nll_loss: 0.0013 
2023-11-01 18:23:31.748 | INFO     | __main__:train:314 - Epoch: [150][700/1251]	 loss 4.39351	 cls_loss: 0.2660 cluster_loss: 1.2272 sup_con_loss: 0.2339 contrastive_loss: 5.2611 nll_loss: 0.0012 
2023-11-01 18:27:15.624 | INFO     | __main__:train:314 - Epoch: [150][800/1251]	 loss 4.40405	 cls_loss: 0.2384 cluster_loss: 1.2343 sup_con_loss: 0.2848 contrastive_loss: 5.2580 nll_loss: 0.0010 
2023-11-01 18:30:58.555 | INFO     | __main__:train:314 - Epoch: [150][900/1251]	 loss 4.42633	 cls_loss: 0.2680 cluster_loss: 1.2345 sup_con_loss: 0.3188 contrastive_loss: 5.2576 nll_loss: 0.0010 
2023-11-01 18:34:41.200 | INFO     | __main__:train:314 - Epoch: [150][1000/1251]	 loss 4.39911	 cls_loss: 0.2225 cluster_loss: 1.2438 sup_con_loss: 0.2652 contrastive_loss: 5.2584 nll_loss: 0.0020 
2023-11-01 18:38:23.335 | INFO     | __main__:train:314 - Epoch: [150][1100/1251]	 loss 4.46412	 cls_loss: 0.2492 cluster_loss: 1.2632 sup_con_loss: 0.3867 contrastive_loss: 5.2606 nll_loss: 0.0011 
2023-11-01 18:42:07.131 | INFO     | __main__:train:314 - Epoch: [150][1200/1251]	 loss 4.46656	 cls_loss: 0.2275 cluster_loss: 1.2829 sup_con_loss: 0.3735 contrastive_loss: 5.2641 nll_loss: 0.0006 
2023-11-01 18:43:58.236 | INFO     | __main__:train:319 - Train Epoch: 150 Avg Loss: 4.4178 
2023-11-01 18:43:58.244 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 19:03:31.383 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 150, Train ACC Unlabelled_v2: All 0.6168 | Old 0.7865 | New 0.5315
2023-11-01 19:03:31.561 | INFO     | __main__:main:205 - Train Accuracies: All 0.6168 | Old 0.7865 | New 0.5315
2023-11-01 19:03:35.556 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 19:03:51.944 | INFO     | __main__:train:314 - Epoch: [151][0/1251]	 loss 4.41787	 cls_loss: 0.2979 cluster_loss: 1.2513 sup_con_loss: 0.2248 contrastive_loss: 5.2616 nll_loss: 0.0015 
2023-11-01 19:07:35.670 | INFO     | __main__:train:314 - Epoch: [151][100/1251]	 loss 4.29941	 cls_loss: 0.2160 cluster_loss: 1.1746 sup_con_loss: 0.1279 contrastive_loss: 5.2529 nll_loss: 0.0012 
2023-11-01 19:11:19.496 | INFO     | __main__:train:314 - Epoch: [151][200/1251]	 loss 4.45840	 cls_loss: 0.2610 cluster_loss: 1.3201 sup_con_loss: 0.2380 contrastive_loss: 5.2680 nll_loss: 0.0014 
2023-11-01 19:15:03.955 | INFO     | __main__:train:314 - Epoch: [151][300/1251]	 loss 4.37934	 cls_loss: 0.2465 cluster_loss: 1.2597 sup_con_loss: 0.1553 contrastive_loss: 5.2584 nll_loss: 0.0019 
2023-11-01 19:18:47.628 | INFO     | __main__:train:314 - Epoch: [151][400/1251]	 loss 4.45602	 cls_loss: 0.2550 cluster_loss: 1.2749 sup_con_loss: 0.3368 contrastive_loss: 5.2599 nll_loss: 0.0013 
2023-11-01 19:22:30.626 | INFO     | __main__:train:314 - Epoch: [151][500/1251]	 loss 4.47447	 cls_loss: 0.2608 cluster_loss: 1.2677 sup_con_loss: 0.3964 contrastive_loss: 5.2606 nll_loss: 0.0011 
2023-11-01 19:26:14.171 | INFO     | __main__:train:314 - Epoch: [151][600/1251]	 loss 4.46288	 cls_loss: 0.3401 cluster_loss: 1.2965 sup_con_loss: 0.2218 contrastive_loss: 5.2647 nll_loss: 0.0014 
2023-11-01 19:30:01.364 | INFO     | __main__:train:314 - Epoch: [151][700/1251]	 loss 4.48351	 cls_loss: 0.2273 cluster_loss: 1.3058 sup_con_loss: 0.3843 contrastive_loss: 5.2617 nll_loss: 0.0006 
2023-11-01 19:33:47.747 | INFO     | __main__:train:314 - Epoch: [151][800/1251]	 loss 4.41704	 cls_loss: 0.2461 cluster_loss: 1.2917 sup_con_loss: 0.1988 contrastive_loss: 5.2622 nll_loss: 0.0013 
2023-11-01 19:37:34.167 | INFO     | __main__:train:314 - Epoch: [151][900/1251]	 loss 4.41978	 cls_loss: 0.2763 cluster_loss: 1.2587 sup_con_loss: 0.2423 contrastive_loss: 5.2592 nll_loss: 0.0017 
2023-11-01 19:41:20.312 | INFO     | __main__:train:314 - Epoch: [151][1000/1251]	 loss 4.34577	 cls_loss: 0.2488 cluster_loss: 1.1745 sup_con_loss: 0.2246 contrastive_loss: 5.2545 nll_loss: 0.0012 
2023-11-01 19:45:03.176 | INFO     | __main__:train:314 - Epoch: [151][1100/1251]	 loss 4.37774	 cls_loss: 0.2872 cluster_loss: 1.2068 sup_con_loss: 0.2150 contrastive_loss: 5.2566 nll_loss: 0.0008 
2023-11-01 19:48:45.043 | INFO     | __main__:train:314 - Epoch: [151][1200/1251]	 loss 4.36876	 cls_loss: 0.2432 cluster_loss: 1.2195 sup_con_loss: 0.2076 contrastive_loss: 5.2577 nll_loss: 0.0007 
2023-11-01 19:50:36.187 | INFO     | __main__:train:319 - Train Epoch: 151 Avg Loss: 4.4160 
2023-11-01 19:50:36.193 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 20:09:22.429 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 151, Train ACC Unlabelled_v2: All 0.6170 | Old 0.7861 | New 0.5321
2023-11-01 20:09:22.667 | INFO     | __main__:main:205 - Train Accuracies: All 0.6170 | Old 0.7861 | New 0.5321
2023-11-01 20:09:25.454 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 20:09:39.127 | INFO     | __main__:train:314 - Epoch: [152][0/1251]	 loss 4.38225	 cls_loss: 0.2354 cluster_loss: 1.2446 sup_con_loss: 0.2019 contrastive_loss: 5.2600 nll_loss: 0.0012 
2023-11-01 20:13:23.176 | INFO     | __main__:train:314 - Epoch: [152][100/1251]	 loss 4.38392	 cls_loss: 0.2699 cluster_loss: 1.2325 sup_con_loss: 0.1921 contrastive_loss: 5.2613 nll_loss: 0.0012 
2023-11-01 20:17:07.534 | INFO     | __main__:train:314 - Epoch: [152][200/1251]	 loss 4.48003	 cls_loss: 0.2787 cluster_loss: 1.2514 sup_con_loss: 0.4281 contrastive_loss: 5.2579 nll_loss: 0.0017 
2023-11-01 20:20:50.004 | INFO     | __main__:train:314 - Epoch: [152][300/1251]	 loss 4.45580	 cls_loss: 0.2453 cluster_loss: 1.2848 sup_con_loss: 0.3265 contrastive_loss: 5.2607 nll_loss: 0.0011 
2023-11-01 20:24:32.655 | INFO     | __main__:train:314 - Epoch: [152][400/1251]	 loss 4.38798	 cls_loss: 0.2578 cluster_loss: 1.2415 sup_con_loss: 0.2094 contrastive_loss: 5.2560 nll_loss: 0.0011 
2023-11-01 20:28:16.223 | INFO     | __main__:train:314 - Epoch: [152][500/1251]	 loss 4.41825	 cls_loss: 0.2384 cluster_loss: 1.2482 sup_con_loss: 0.3007 contrastive_loss: 5.2577 nll_loss: 0.0007 
2023-11-01 20:31:58.951 | INFO     | __main__:train:314 - Epoch: [152][600/1251]	 loss 4.37355	 cls_loss: 0.2737 cluster_loss: 1.1922 sup_con_loss: 0.2380 contrastive_loss: 5.2573 nll_loss: 0.0023 
2023-11-01 20:35:42.855 | INFO     | __main__:train:314 - Epoch: [152][700/1251]	 loss 4.40531	 cls_loss: 0.2856 cluster_loss: 1.2548 sup_con_loss: 0.2033 contrastive_loss: 5.2574 nll_loss: 0.0012 
2023-11-01 20:39:29.035 | INFO     | __main__:train:314 - Epoch: [152][800/1251]	 loss 4.42746	 cls_loss: 0.2696 cluster_loss: 1.2571 sup_con_loss: 0.2753 contrastive_loss: 5.2583 nll_loss: 0.0017 
2023-11-01 20:43:14.097 | INFO     | __main__:train:314 - Epoch: [152][900/1251]	 loss 4.42624	 cls_loss: 0.2414 cluster_loss: 1.2466 sup_con_loss: 0.3196 contrastive_loss: 5.2595 nll_loss: 0.0009 
2023-11-01 20:46:58.169 | INFO     | __main__:train:314 - Epoch: [152][1000/1251]	 loss 4.43342	 cls_loss: 0.2307 cluster_loss: 1.2311 sup_con_loss: 0.3809 contrastive_loss: 5.2574 nll_loss: 0.0019 
2023-11-01 20:50:42.246 | INFO     | __main__:train:314 - Epoch: [152][1100/1251]	 loss 4.38932	 cls_loss: 0.2560 cluster_loss: 1.2128 sup_con_loss: 0.2705 contrastive_loss: 5.2550 nll_loss: 0.0010 
2023-11-01 20:54:25.047 | INFO     | __main__:train:314 - Epoch: [152][1200/1251]	 loss 4.37571	 cls_loss: 0.2700 cluster_loss: 1.2175 sup_con_loss: 0.2081 contrastive_loss: 5.2557 nll_loss: 0.0008 
2023-11-01 20:56:16.069 | INFO     | __main__:train:319 - Train Epoch: 152 Avg Loss: 4.4137 
2023-11-01 20:56:16.077 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 21:15:34.592 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 152, Train ACC Unlabelled_v2: All 0.6178 | Old 0.7872 | New 0.5326
2023-11-01 21:15:34.630 | INFO     | __main__:main:205 - Train Accuracies: All 0.6178 | Old 0.7872 | New 0.5326
2023-11-01 21:15:38.982 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 21:15:54.713 | INFO     | __main__:train:314 - Epoch: [153][0/1251]	 loss 4.40509	 cls_loss: 0.2546 cluster_loss: 1.2429 sup_con_loss: 0.2521 contrastive_loss: 5.2596 nll_loss: 0.0012 
2023-11-01 21:19:40.319 | INFO     | __main__:train:314 - Epoch: [153][100/1251]	 loss 4.38435	 cls_loss: 0.2311 cluster_loss: 1.2023 sup_con_loss: 0.2947 contrastive_loss: 5.2569 nll_loss: 0.0019 
2023-11-01 21:23:23.741 | INFO     | __main__:train:314 - Epoch: [153][200/1251]	 loss 4.41284	 cls_loss: 0.2221 cluster_loss: 1.2430 sup_con_loss: 0.3201 contrastive_loss: 5.2530 nll_loss: 0.0007 
2023-11-01 21:27:11.074 | INFO     | __main__:train:314 - Epoch: [153][300/1251]	 loss 4.33287	 cls_loss: 0.2346 cluster_loss: 1.1759 sup_con_loss: 0.2031 contrastive_loss: 5.2531 nll_loss: 0.0008 
2023-11-01 21:30:54.429 | INFO     | __main__:train:314 - Epoch: [153][400/1251]	 loss 4.35294	 cls_loss: 0.2772 cluster_loss: 1.1857 sup_con_loss: 0.1946 contrastive_loss: 5.2561 nll_loss: 0.0006 
2023-11-01 21:34:38.425 | INFO     | __main__:train:314 - Epoch: [153][500/1251]	 loss 4.43173	 cls_loss: 0.2578 cluster_loss: 1.2289 sup_con_loss: 0.3529 contrastive_loss: 5.2583 nll_loss: 0.0013 
2023-11-01 21:38:23.014 | INFO     | __main__:train:314 - Epoch: [153][600/1251]	 loss 4.34493	 cls_loss: 0.2487 cluster_loss: 1.1766 sup_con_loss: 0.2172 contrastive_loss: 5.2547 nll_loss: 0.0015 
2023-11-01 21:42:10.762 | INFO     | __main__:train:314 - Epoch: [153][700/1251]	 loss 4.40879	 cls_loss: 0.2183 cluster_loss: 1.2531 sup_con_loss: 0.2785 contrastive_loss: 5.2591 nll_loss: 0.0019 
2023-11-01 21:45:55.068 | INFO     | __main__:train:314 - Epoch: [153][800/1251]	 loss 4.38109	 cls_loss: 0.2701 cluster_loss: 1.2205 sup_con_loss: 0.2139 contrastive_loss: 5.2578 nll_loss: 0.0008 
2023-11-01 21:49:38.020 | INFO     | __main__:train:314 - Epoch: [153][900/1251]	 loss 4.40032	 cls_loss: 0.3089 cluster_loss: 1.2386 sup_con_loss: 0.1949 contrastive_loss: 5.2572 nll_loss: 0.0017 
2023-11-01 21:53:21.436 | INFO     | __main__:train:314 - Epoch: [153][1000/1251]	 loss 4.42285	 cls_loss: 0.2467 cluster_loss: 1.2509 sup_con_loss: 0.2998 contrastive_loss: 5.2578 nll_loss: 0.0009 
2023-11-01 21:57:05.065 | INFO     | __main__:train:314 - Epoch: [153][1100/1251]	 loss 4.41379	 cls_loss: 0.2572 cluster_loss: 1.2192 sup_con_loss: 0.3262 contrastive_loss: 5.2561 nll_loss: 0.0007 
2023-11-01 22:00:48.596 | INFO     | __main__:train:314 - Epoch: [153][1200/1251]	 loss 4.45943	 cls_loss: 0.2202 cluster_loss: 1.2523 sup_con_loss: 0.4276 contrastive_loss: 5.2572 nll_loss: 0.0016 
2023-11-01 22:02:40.070 | INFO     | __main__:train:319 - Train Epoch: 153 Avg Loss: 4.4102 
2023-11-01 22:02:40.079 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 22:21:30.583 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 153, Train ACC Unlabelled_v2: All 0.6180 | Old 0.7882 | New 0.5325
2023-11-01 22:21:30.801 | INFO     | __main__:main:205 - Train Accuracies: All 0.6180 | Old 0.7882 | New 0.5325
2023-11-01 22:21:33.473 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 22:21:47.190 | INFO     | __main__:train:314 - Epoch: [154][0/1251]	 loss 4.38017	 cls_loss: 0.2404 cluster_loss: 1.2300 sup_con_loss: 0.2264 contrastive_loss: 5.2553 nll_loss: 0.0013 
2023-11-01 22:25:33.356 | INFO     | __main__:train:314 - Epoch: [154][100/1251]	 loss 4.42588	 cls_loss: 0.2775 cluster_loss: 1.2500 sup_con_loss: 0.2716 contrastive_loss: 5.2622 nll_loss: 0.0008 
2023-11-01 22:29:18.176 | INFO     | __main__:train:314 - Epoch: [154][200/1251]	 loss 4.38152	 cls_loss: 0.2244 cluster_loss: 1.2361 sup_con_loss: 0.2316 contrastive_loss: 5.2573 nll_loss: 0.0012 
2023-11-01 22:33:02.864 | INFO     | __main__:train:314 - Epoch: [154][300/1251]	 loss 4.34948	 cls_loss: 0.2581 cluster_loss: 1.1763 sup_con_loss: 0.2158 contrastive_loss: 5.2588 nll_loss: 0.0008 
2023-11-01 22:36:47.434 | INFO     | __main__:train:314 - Epoch: [154][400/1251]	 loss 4.35822	 cls_loss: 0.2776 cluster_loss: 1.1726 sup_con_loss: 0.2333 contrastive_loss: 5.2552 nll_loss: 0.0013 
2023-11-01 22:40:31.938 | INFO     | __main__:train:314 - Epoch: [154][500/1251]	 loss 4.33071	 cls_loss: 0.2408 cluster_loss: 1.1817 sup_con_loss: 0.1731 contrastive_loss: 5.2543 nll_loss: 0.0025 
2023-11-01 22:44:17.474 | INFO     | __main__:train:314 - Epoch: [154][600/1251]	 loss 4.38155	 cls_loss: 0.2579 cluster_loss: 1.2057 sup_con_loss: 0.2577 contrastive_loss: 5.2553 nll_loss: 0.0014 
2023-11-01 22:48:02.200 | INFO     | __main__:train:314 - Epoch: [154][700/1251]	 loss 4.42283	 cls_loss: 0.2319 cluster_loss: 1.2390 sup_con_loss: 0.3370 contrastive_loss: 5.2562 nll_loss: 0.0019 
2023-11-01 22:51:45.378 | INFO     | __main__:train:314 - Epoch: [154][800/1251]	 loss 4.40474	 cls_loss: 0.2311 cluster_loss: 1.2588 sup_con_loss: 0.2443 contrastive_loss: 5.2598 nll_loss: 0.0013 
2023-11-01 22:55:27.618 | INFO     | __main__:train:314 - Epoch: [154][900/1251]	 loss 4.34017	 cls_loss: 0.2312 cluster_loss: 1.1606 sup_con_loss: 0.2567 contrastive_loss: 5.2516 nll_loss: 0.0015 
2023-11-01 22:59:10.353 | INFO     | __main__:train:314 - Epoch: [154][1000/1251]	 loss 4.46418	 cls_loss: 0.2540 cluster_loss: 1.2595 sup_con_loss: 0.3895 contrastive_loss: 5.2595 nll_loss: 0.0016 
2023-11-01 23:02:53.881 | INFO     | __main__:train:314 - Epoch: [154][1100/1251]	 loss 4.42736	 cls_loss: 0.3039 cluster_loss: 1.2497 sup_con_loss: 0.2468 contrastive_loss: 5.2634 nll_loss: 0.0012 
2023-11-01 23:06:40.240 | INFO     | __main__:train:314 - Epoch: [154][1200/1251]	 loss 4.36214	 cls_loss: 0.2308 cluster_loss: 1.2055 sup_con_loss: 0.2212 contrastive_loss: 5.2604 nll_loss: 0.0011 
2023-11-01 23:08:31.503 | INFO     | __main__:train:319 - Train Epoch: 154 Avg Loss: 4.4057 
2023-11-01 23:08:31.510 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-01 23:27:55.503 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 154, Train ACC Unlabelled_v2: All 0.6188 | Old 0.7879 | New 0.5339
2023-11-01 23:27:55.703 | INFO     | __main__:main:205 - Train Accuracies: All 0.6188 | Old 0.7879 | New 0.5339
2023-11-01 23:27:58.551 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-01 23:28:14.492 | INFO     | __main__:train:314 - Epoch: [155][0/1251]	 loss 4.41361	 cls_loss: 0.2682 cluster_loss: 1.2352 sup_con_loss: 0.2850 contrastive_loss: 5.2562 nll_loss: 0.0006 
2023-11-01 23:31:59.561 | INFO     | __main__:train:314 - Epoch: [155][100/1251]	 loss 4.37808	 cls_loss: 0.2640 cluster_loss: 1.2150 sup_con_loss: 0.2217 contrastive_loss: 5.2576 nll_loss: 0.0008 
2023-11-01 23:35:43.212 | INFO     | __main__:train:314 - Epoch: [155][200/1251]	 loss 4.41602	 cls_loss: 0.2262 cluster_loss: 1.2490 sup_con_loss: 0.3058 contrastive_loss: 5.2566 nll_loss: 0.0013 
2023-11-01 23:39:27.192 | INFO     | __main__:train:314 - Epoch: [155][300/1251]	 loss 4.45427	 cls_loss: 0.2705 cluster_loss: 1.2703 sup_con_loss: 0.3234 contrastive_loss: 5.2611 nll_loss: 0.0010 
2023-11-01 23:43:10.027 | INFO     | __main__:train:314 - Epoch: [155][400/1251]	 loss 4.37543	 cls_loss: 0.2165 cluster_loss: 1.1943 sup_con_loss: 0.3077 contrastive_loss: 5.2536 nll_loss: 0.0008 
2023-11-01 23:46:53.876 | INFO     | __main__:train:314 - Epoch: [155][500/1251]	 loss 4.38930	 cls_loss: 0.2604 cluster_loss: 1.1989 sup_con_loss: 0.2888 contrastive_loss: 5.2573 nll_loss: 0.0005 
2023-11-01 23:50:40.478 | INFO     | __main__:train:314 - Epoch: [155][600/1251]	 loss 4.43125	 cls_loss: 0.2300 cluster_loss: 1.2284 sup_con_loss: 0.3864 contrastive_loss: 5.2550 nll_loss: 0.0013 
2023-11-01 23:54:25.678 | INFO     | __main__:train:314 - Epoch: [155][700/1251]	 loss 4.35971	 cls_loss: 0.2469 cluster_loss: 1.1805 sup_con_loss: 0.2538 contrastive_loss: 5.2556 nll_loss: 0.0010 
2023-11-01 23:58:09.381 | INFO     | __main__:train:314 - Epoch: [155][800/1251]	 loss 4.36027	 cls_loss: 0.2606 cluster_loss: 1.1978 sup_con_loss: 0.2038 contrastive_loss: 5.2582 nll_loss: 0.0013 
2023-11-02 00:01:53.112 | INFO     | __main__:train:314 - Epoch: [155][900/1251]	 loss 4.40937	 cls_loss: 0.2139 cluster_loss: 1.2701 sup_con_loss: 0.2526 contrastive_loss: 5.2612 nll_loss: 0.0008 
2023-11-02 00:05:36.319 | INFO     | __main__:train:314 - Epoch: [155][1000/1251]	 loss 4.49391	 cls_loss: 0.2262 cluster_loss: 1.3139 sup_con_loss: 0.4004 contrastive_loss: 5.2608 nll_loss: 0.0011 
2023-11-02 00:09:21.903 | INFO     | __main__:train:314 - Epoch: [155][1100/1251]	 loss 4.31816	 cls_loss: 0.2137 cluster_loss: 1.2004 sup_con_loss: 0.1374 contrastive_loss: 5.2529 nll_loss: 0.0007 
2023-11-02 00:13:06.534 | INFO     | __main__:train:314 - Epoch: [155][1200/1251]	 loss 4.43210	 cls_loss: 0.2225 cluster_loss: 1.2380 sup_con_loss: 0.3768 contrastive_loss: 5.2564 nll_loss: 0.0010 
2023-11-02 00:14:58.260 | INFO     | __main__:train:319 - Train Epoch: 155 Avg Loss: 4.4057 
2023-11-02 00:14:58.263 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 00:33:02.632 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 155, Train ACC Unlabelled_v2: All 0.6188 | Old 0.7879 | New 0.5337
2023-11-02 00:33:02.680 | INFO     | __main__:main:205 - Train Accuracies: All 0.6188 | Old 0.7879 | New 0.5337
2023-11-02 00:33:05.253 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 00:33:20.238 | INFO     | __main__:train:314 - Epoch: [156][0/1251]	 loss 4.40604	 cls_loss: 0.2114 cluster_loss: 1.2589 sup_con_loss: 0.2698 contrastive_loss: 5.2582 nll_loss: 0.0015 
2023-11-02 00:37:06.610 | INFO     | __main__:train:314 - Epoch: [156][100/1251]	 loss 4.42833	 cls_loss: 0.2221 cluster_loss: 1.2633 sup_con_loss: 0.3199 contrastive_loss: 5.2568 nll_loss: 0.0006 
2023-11-02 00:40:50.861 | INFO     | __main__:train:314 - Epoch: [156][200/1251]	 loss 4.43838	 cls_loss: 0.2267 cluster_loss: 1.2567 sup_con_loss: 0.3522 contrastive_loss: 5.2578 nll_loss: 0.0013 
2023-11-02 00:44:35.221 | INFO     | __main__:train:314 - Epoch: [156][300/1251]	 loss 4.41219	 cls_loss: 0.2290 cluster_loss: 1.2441 sup_con_loss: 0.2910 contrastive_loss: 5.2627 nll_loss: 0.0008 
2023-11-02 00:48:18.718 | INFO     | __main__:train:314 - Epoch: [156][400/1251]	 loss 4.41228	 cls_loss: 0.2245 cluster_loss: 1.2309 sup_con_loss: 0.3324 contrastive_loss: 5.2558 nll_loss: 0.0010 
2023-11-02 00:52:03.109 | INFO     | __main__:train:314 - Epoch: [156][500/1251]	 loss 4.41802	 cls_loss: 0.2535 cluster_loss: 1.2041 sup_con_loss: 0.3725 contrastive_loss: 5.2541 nll_loss: 0.0011 
2023-11-02 00:55:46.532 | INFO     | __main__:train:314 - Epoch: [156][600/1251]	 loss 4.51370	 cls_loss: 0.2810 cluster_loss: 1.2979 sup_con_loss: 0.4361 contrastive_loss: 5.2578 nll_loss: 0.0015 
2023-11-02 00:59:30.778 | INFO     | __main__:train:314 - Epoch: [156][700/1251]	 loss 4.44341	 cls_loss: 0.2529 cluster_loss: 1.2666 sup_con_loss: 0.3205 contrastive_loss: 5.2587 nll_loss: 0.0013 
2023-11-02 01:03:15.417 | INFO     | __main__:train:314 - Epoch: [156][800/1251]	 loss 4.33614	 cls_loss: 0.2243 cluster_loss: 1.1656 sup_con_loss: 0.2384 contrastive_loss: 5.2543 nll_loss: 0.0013 
2023-11-02 01:06:59.118 | INFO     | __main__:train:314 - Epoch: [156][900/1251]	 loss 4.35120	 cls_loss: 0.2602 cluster_loss: 1.2040 sup_con_loss: 0.1734 contrastive_loss: 5.2553 nll_loss: 0.0009 
2023-11-02 01:10:44.798 | INFO     | __main__:train:314 - Epoch: [156][1000/1251]	 loss 4.38853	 cls_loss: 0.2317 cluster_loss: 1.2229 sup_con_loss: 0.2677 contrastive_loss: 5.2583 nll_loss: 0.0010 
2023-11-02 01:14:32.271 | INFO     | __main__:train:314 - Epoch: [156][1100/1251]	 loss 4.38770	 cls_loss: 0.2415 cluster_loss: 1.2457 sup_con_loss: 0.2118 contrastive_loss: 5.2587 nll_loss: 0.0012 
2023-11-02 01:18:16.221 | INFO     | __main__:train:314 - Epoch: [156][1200/1251]	 loss 4.38418	 cls_loss: 0.2343 cluster_loss: 1.2302 sup_con_loss: 0.2334 contrastive_loss: 5.2608 nll_loss: 0.0014 
2023-11-02 01:20:09.042 | INFO     | __main__:train:319 - Train Epoch: 156 Avg Loss: 4.4016 
2023-11-02 01:20:09.045 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 01:38:08.509 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 156, Train ACC Unlabelled_v2: All 0.6188 | Old 0.7875 | New 0.5340
2023-11-02 01:38:08.721 | INFO     | __main__:main:205 - Train Accuracies: All 0.6188 | Old 0.7875 | New 0.5340
2023-11-02 01:38:12.028 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 01:38:25.713 | INFO     | __main__:train:314 - Epoch: [157][0/1251]	 loss 4.35908	 cls_loss: 0.2155 cluster_loss: 1.1999 sup_con_loss: 0.2461 contrastive_loss: 5.2567 nll_loss: 0.0007 
2023-11-02 01:42:09.928 | INFO     | __main__:train:314 - Epoch: [157][100/1251]	 loss 4.32944	 cls_loss: 0.2356 cluster_loss: 1.1793 sup_con_loss: 0.1828 contrastive_loss: 5.2543 nll_loss: 0.0011 
2023-11-02 01:45:54.643 | INFO     | __main__:train:314 - Epoch: [157][200/1251]	 loss 4.42153	 cls_loss: 0.2495 cluster_loss: 1.2538 sup_con_loss: 0.2841 contrastive_loss: 5.2602 nll_loss: 0.0006 
2023-11-02 01:49:37.814 | INFO     | __main__:train:314 - Epoch: [157][300/1251]	 loss 4.36294	 cls_loss: 0.2451 cluster_loss: 1.2300 sup_con_loss: 0.1658 contrastive_loss: 5.2591 nll_loss: 0.0012 
2023-11-02 01:53:23.403 | INFO     | __main__:train:314 - Epoch: [157][400/1251]	 loss 4.42924	 cls_loss: 0.2583 cluster_loss: 1.2420 sup_con_loss: 0.3172 contrastive_loss: 5.2610 nll_loss: 0.0009 
2023-11-02 01:57:08.432 | INFO     | __main__:train:314 - Epoch: [157][500/1251]	 loss 4.39160	 cls_loss: 0.2457 cluster_loss: 1.2267 sup_con_loss: 0.2531 contrastive_loss: 5.2593 nll_loss: 0.0012 
2023-11-02 02:00:52.888 | INFO     | __main__:train:314 - Epoch: [157][600/1251]	 loss 4.35997	 cls_loss: 0.2164 cluster_loss: 1.1926 sup_con_loss: 0.2648 contrastive_loss: 5.2550 nll_loss: 0.0006 
2023-11-02 02:04:37.184 | INFO     | __main__:train:314 - Epoch: [157][700/1251]	 loss 4.40694	 cls_loss: 0.2382 cluster_loss: 1.2528 sup_con_loss: 0.2581 contrastive_loss: 5.2584 nll_loss: 0.0010 
2023-11-02 02:08:21.803 | INFO     | __main__:train:314 - Epoch: [157][800/1251]	 loss 4.38745	 cls_loss: 0.2238 cluster_loss: 1.2052 sup_con_loss: 0.3130 contrastive_loss: 5.2541 nll_loss: 0.0010 
2023-11-02 02:12:06.092 | INFO     | __main__:train:314 - Epoch: [157][900/1251]	 loss 4.41150	 cls_loss: 0.2735 cluster_loss: 1.2436 sup_con_loss: 0.2553 contrastive_loss: 5.2573 nll_loss: 0.0008 
2023-11-02 02:15:52.860 | INFO     | __main__:train:314 - Epoch: [157][1000/1251]	 loss 4.41046	 cls_loss: 0.2386 cluster_loss: 1.2420 sup_con_loss: 0.2875 contrastive_loss: 5.2583 nll_loss: 0.0011 
2023-11-02 02:19:37.927 | INFO     | __main__:train:314 - Epoch: [157][1100/1251]	 loss 4.35012	 cls_loss: 0.2187 cluster_loss: 1.2142 sup_con_loss: 0.1920 contrastive_loss: 5.2562 nll_loss: 0.0006 
2023-11-02 02:23:22.814 | INFO     | __main__:train:314 - Epoch: [157][1200/1251]	 loss 4.45315	 cls_loss: 0.2478 cluster_loss: 1.2838 sup_con_loss: 0.3138 contrastive_loss: 5.2640 nll_loss: 0.0005 
2023-11-02 02:25:14.737 | INFO     | __main__:train:319 - Train Epoch: 157 Avg Loss: 4.4009 
2023-11-02 02:25:14.741 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 02:46:12.752 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 157, Train ACC Unlabelled_v2: All 0.6193 | Old 0.7893 | New 0.5339
2023-11-02 02:46:12.958 | INFO     | __main__:main:205 - Train Accuracies: All 0.6193 | Old 0.7893 | New 0.5339
2023-11-02 02:46:16.348 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 02:46:32.253 | INFO     | __main__:train:314 - Epoch: [158][0/1251]	 loss 4.42461	 cls_loss: 0.2805 cluster_loss: 1.1960 sup_con_loss: 0.3796 contrastive_loss: 5.2547 nll_loss: 0.0007 
2023-11-02 02:50:16.554 | INFO     | __main__:train:314 - Epoch: [158][100/1251]	 loss 4.38169	 cls_loss: 0.2247 cluster_loss: 1.2022 sup_con_loss: 0.3024 contrastive_loss: 5.2533 nll_loss: 0.0011 
2023-11-02 02:53:59.888 | INFO     | __main__:train:314 - Epoch: [158][200/1251]	 loss 4.42582	 cls_loss: 0.2266 cluster_loss: 1.2573 sup_con_loss: 0.2983 contrastive_loss: 5.2664 nll_loss: 0.0017 
2023-11-02 02:57:45.266 | INFO     | __main__:train:314 - Epoch: [158][300/1251]	 loss 4.33120	 cls_loss: 0.2421 cluster_loss: 1.1695 sup_con_loss: 0.2024 contrastive_loss: 5.2519 nll_loss: 0.0017 
2023-11-02 03:01:30.013 | INFO     | __main__:train:314 - Epoch: [158][400/1251]	 loss 4.29226	 cls_loss: 0.2367 cluster_loss: 1.1611 sup_con_loss: 0.1158 contrastive_loss: 5.2519 nll_loss: 0.0005 
2023-11-02 03:05:14.179 | INFO     | __main__:train:314 - Epoch: [158][500/1251]	 loss 4.44458	 cls_loss: 0.2621 cluster_loss: 1.2322 sup_con_loss: 0.3786 contrastive_loss: 5.2580 nll_loss: 0.0017 
2023-11-02 03:08:58.070 | INFO     | __main__:train:314 - Epoch: [158][600/1251]	 loss 4.36571	 cls_loss: 0.2371 cluster_loss: 1.2049 sup_con_loss: 0.2359 contrastive_loss: 5.2552 nll_loss: 0.0011 
2023-11-02 03:12:42.584 | INFO     | __main__:train:314 - Epoch: [158][700/1251]	 loss 4.40021	 cls_loss: 0.2425 cluster_loss: 1.2265 sup_con_loss: 0.2832 contrastive_loss: 5.2577 nll_loss: 0.0015 
2023-11-02 03:16:29.778 | INFO     | __main__:train:314 - Epoch: [158][800/1251]	 loss 4.42443	 cls_loss: 0.2758 cluster_loss: 1.2343 sup_con_loss: 0.3086 contrastive_loss: 5.2564 nll_loss: 0.0009 
2023-11-02 03:20:14.086 | INFO     | __main__:train:314 - Epoch: [158][900/1251]	 loss 4.39812	 cls_loss: 0.2398 cluster_loss: 1.2382 sup_con_loss: 0.2555 contrastive_loss: 5.2606 nll_loss: 0.0006 
2023-11-02 03:23:57.734 | INFO     | __main__:train:314 - Epoch: [158][1000/1251]	 loss 4.37608	 cls_loss: 0.2217 cluster_loss: 1.1989 sup_con_loss: 0.2938 contrastive_loss: 5.2545 nll_loss: 0.0009 
2023-11-02 03:27:42.405 | INFO     | __main__:train:314 - Epoch: [158][1100/1251]	 loss 4.43366	 cls_loss: 0.2657 cluster_loss: 1.2354 sup_con_loss: 0.3331 contrastive_loss: 5.2618 nll_loss: 0.0009 
2023-11-02 03:31:29.454 | INFO     | __main__:train:314 - Epoch: [158][1200/1251]	 loss 4.45717	 cls_loss: 0.2810 cluster_loss: 1.2674 sup_con_loss: 0.3239 contrastive_loss: 5.2627 nll_loss: 0.0009 
2023-11-02 03:33:20.927 | INFO     | __main__:train:319 - Train Epoch: 158 Avg Loss: 4.3996 
2023-11-02 03:33:20.935 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 03:50:41.687 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 158, Train ACC Unlabelled_v2: All 0.6199 | Old 0.7893 | New 0.5348
2023-11-02 03:50:41.918 | INFO     | __main__:main:205 - Train Accuracies: All 0.6199 | Old 0.7893 | New 0.5348
2023-11-02 03:50:45.500 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 03:50:59.062 | INFO     | __main__:train:314 - Epoch: [159][0/1251]	 loss 4.40424	 cls_loss: 0.2127 cluster_loss: 1.2279 sup_con_loss: 0.3259 contrastive_loss: 5.2559 nll_loss: 0.0013 
2023-11-02 03:54:43.596 | INFO     | __main__:train:314 - Epoch: [159][100/1251]	 loss 4.46546	 cls_loss: 0.3467 cluster_loss: 1.2479 sup_con_loss: 0.3320 contrastive_loss: 5.2553 nll_loss: 0.0008 
2023-11-02 03:58:27.595 | INFO     | __main__:train:314 - Epoch: [159][200/1251]	 loss 4.41325	 cls_loss: 0.2815 cluster_loss: 1.2386 sup_con_loss: 0.2579 contrastive_loss: 5.2591 nll_loss: 0.0010 
2023-11-02 04:02:11.901 | INFO     | __main__:train:314 - Epoch: [159][300/1251]	 loss 4.41539	 cls_loss: 0.2742 cluster_loss: 1.2089 sup_con_loss: 0.3291 contrastive_loss: 5.2580 nll_loss: 0.0008 
2023-11-02 04:05:57.403 | INFO     | __main__:train:314 - Epoch: [159][400/1251]	 loss 4.39512	 cls_loss: 0.2270 cluster_loss: 1.2099 sup_con_loss: 0.3217 contrastive_loss: 5.2553 nll_loss: 0.0007 
2023-11-02 04:09:40.885 | INFO     | __main__:train:314 - Epoch: [159][500/1251]	 loss 4.38052	 cls_loss: 0.2098 cluster_loss: 1.2365 sup_con_loss: 0.2441 contrastive_loss: 5.2569 nll_loss: 0.0010 
2023-11-02 04:13:24.135 | INFO     | __main__:train:314 - Epoch: [159][600/1251]	 loss 4.38294	 cls_loss: 0.2762 cluster_loss: 1.2037 sup_con_loss: 0.2434 contrastive_loss: 5.2579 nll_loss: 0.0011 
2023-11-02 04:17:10.029 | INFO     | __main__:train:314 - Epoch: [159][700/1251]	 loss 4.41698	 cls_loss: 0.2277 cluster_loss: 1.2296 sup_con_loss: 0.3451 contrastive_loss: 5.2559 nll_loss: 0.0009 
2023-11-02 04:20:54.712 | INFO     | __main__:train:314 - Epoch: [159][800/1251]	 loss 4.41202	 cls_loss: 0.2269 cluster_loss: 1.2356 sup_con_loss: 0.3199 contrastive_loss: 5.2560 nll_loss: 0.0012 
2023-11-02 04:24:39.515 | INFO     | __main__:train:314 - Epoch: [159][900/1251]	 loss 4.47965	 cls_loss: 0.2807 cluster_loss: 1.2531 sup_con_loss: 0.4258 contrastive_loss: 5.2570 nll_loss: 0.0008 
2023-11-02 04:28:24.311 | INFO     | __main__:train:314 - Epoch: [159][1000/1251]	 loss 4.42008	 cls_loss: 0.2693 cluster_loss: 1.2517 sup_con_loss: 0.2641 contrastive_loss: 5.2591 nll_loss: 0.0013 
2023-11-02 04:32:07.535 | INFO     | __main__:train:314 - Epoch: [159][1100/1251]	 loss 4.42759	 cls_loss: 0.2367 cluster_loss: 1.2501 sup_con_loss: 0.3282 contrastive_loss: 5.2563 nll_loss: 0.0007 
2023-11-02 04:35:54.406 | INFO     | __main__:train:314 - Epoch: [159][1200/1251]	 loss 4.36333	 cls_loss: 0.2241 cluster_loss: 1.2070 sup_con_loss: 0.2426 contrastive_loss: 5.2531 nll_loss: 0.0009 
2023-11-02 04:37:45.936 | INFO     | __main__:train:319 - Train Epoch: 159 Avg Loss: 4.3948 
2023-11-02 04:37:45.942 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 04:55:06.864 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 159, Train ACC Unlabelled_v2: All 0.6200 | Old 0.7894 | New 0.5349
2023-11-02 04:55:07.052 | INFO     | __main__:main:205 - Train Accuracies: All 0.6200 | Old 0.7894 | New 0.5349
2023-11-02 04:55:10.791 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 04:55:26.924 | INFO     | __main__:train:314 - Epoch: [160][0/1251]	 loss 4.37778	 cls_loss: 0.2481 cluster_loss: 1.2069 sup_con_loss: 0.2556 contrastive_loss: 5.2555 nll_loss: 0.0009 
2023-11-02 04:59:12.486 | INFO     | __main__:train:314 - Epoch: [160][100/1251]	 loss 4.38049	 cls_loss: 0.2244 cluster_loss: 1.2348 sup_con_loss: 0.2329 contrastive_loss: 5.2571 nll_loss: 0.0007 
2023-11-02 05:02:58.017 | INFO     | __main__:train:314 - Epoch: [160][200/1251]	 loss 4.43456	 cls_loss: 0.2201 cluster_loss: 1.2352 sup_con_loss: 0.3948 contrastive_loss: 5.2546 nll_loss: 0.0009 
2023-11-02 05:06:41.277 | INFO     | __main__:train:314 - Epoch: [160][300/1251]	 loss 4.39286	 cls_loss: 0.2178 cluster_loss: 1.2297 sup_con_loss: 0.2896 contrastive_loss: 5.2541 nll_loss: 0.0008 
2023-11-02 05:10:26.215 | INFO     | __main__:train:314 - Epoch: [160][400/1251]	 loss 4.39815	 cls_loss: 0.2428 cluster_loss: 1.2231 sup_con_loss: 0.2885 contrastive_loss: 5.2559 nll_loss: 0.0009 
2023-11-02 05:14:10.959 | INFO     | __main__:train:314 - Epoch: [160][500/1251]	 loss 4.40213	 cls_loss: 0.2120 cluster_loss: 1.2184 sup_con_loss: 0.3389 contrastive_loss: 5.2561 nll_loss: 0.0008 
2023-11-02 05:17:56.388 | INFO     | __main__:train:314 - Epoch: [160][600/1251]	 loss 4.39792	 cls_loss: 0.2498 cluster_loss: 1.2311 sup_con_loss: 0.2671 contrastive_loss: 5.2556 nll_loss: 0.0007 
2023-11-02 05:21:39.677 | INFO     | __main__:train:314 - Epoch: [160][700/1251]	 loss 4.45308	 cls_loss: 0.2501 cluster_loss: 1.2601 sup_con_loss: 0.3677 contrastive_loss: 5.2568 nll_loss: 0.0008 
2023-11-02 05:25:25.487 | INFO     | __main__:train:314 - Epoch: [160][800/1251]	 loss 4.35234	 cls_loss: 0.2205 cluster_loss: 1.1992 sup_con_loss: 0.2265 contrastive_loss: 5.2543 nll_loss: 0.0011 
2023-11-02 05:29:15.631 | INFO     | __main__:train:314 - Epoch: [160][900/1251]	 loss 4.40765	 cls_loss: 0.2170 cluster_loss: 1.2508 sup_con_loss: 0.2882 contrastive_loss: 5.2566 nll_loss: 0.0011 
2023-11-02 05:32:59.938 | INFO     | __main__:train:314 - Epoch: [160][1000/1251]	 loss 4.36692	 cls_loss: 0.2392 cluster_loss: 1.1761 sup_con_loss: 0.2945 contrastive_loss: 5.2532 nll_loss: 0.0010 
2023-11-02 05:36:44.356 | INFO     | __main__:train:314 - Epoch: [160][1100/1251]	 loss 4.33908	 cls_loss: 0.2070 cluster_loss: 1.1809 sup_con_loss: 0.2358 contrastive_loss: 5.2549 nll_loss: 0.0008 
2023-11-02 05:40:28.728 | INFO     | __main__:train:314 - Epoch: [160][1200/1251]	 loss 4.40910	 cls_loss: 0.2170 cluster_loss: 1.2521 sup_con_loss: 0.2836 contrastive_loss: 5.2597 nll_loss: 0.0012 
2023-11-02 05:42:20.210 | INFO     | __main__:train:319 - Train Epoch: 160 Avg Loss: 4.3924 
2023-11-02 05:42:20.219 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 05:59:43.949 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 160, Train ACC Unlabelled_v2: All 0.6197 | Old 0.7889 | New 0.5346
2023-11-02 05:59:43.972 | INFO     | __main__:main:205 - Train Accuracies: All 0.6197 | Old 0.7889 | New 0.5346
2023-11-02 05:59:47.139 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 06:00:01.440 | INFO     | __main__:train:314 - Epoch: [161][0/1251]	 loss 4.33734	 cls_loss: 0.2079 cluster_loss: 1.1884 sup_con_loss: 0.2139 contrastive_loss: 5.2564 nll_loss: 0.0006 
2023-11-02 06:03:45.911 | INFO     | __main__:train:314 - Epoch: [161][100/1251]	 loss 4.42063	 cls_loss: 0.2421 cluster_loss: 1.2328 sup_con_loss: 0.3360 contrastive_loss: 5.2549 nll_loss: 0.0013 
2023-11-02 06:07:29.757 | INFO     | __main__:train:314 - Epoch: [161][200/1251]	 loss 4.37536	 cls_loss: 0.2300 cluster_loss: 1.2053 sup_con_loss: 0.2707 contrastive_loss: 5.2557 nll_loss: 0.0005 
2023-11-02 06:11:13.940 | INFO     | __main__:train:314 - Epoch: [161][300/1251]	 loss 4.39638	 cls_loss: 0.2332 cluster_loss: 1.2278 sup_con_loss: 0.2818 contrastive_loss: 5.2559 nll_loss: 0.0017 
2023-11-02 06:15:00.545 | INFO     | __main__:train:314 - Epoch: [161][400/1251]	 loss 4.37670	 cls_loss: 0.2372 cluster_loss: 1.2028 sup_con_loss: 0.2723 contrastive_loss: 5.2539 nll_loss: 0.0015 
2023-11-02 06:18:44.888 | INFO     | __main__:train:314 - Epoch: [161][500/1251]	 loss 4.38425	 cls_loss: 0.2242 cluster_loss: 1.2084 sup_con_loss: 0.2985 contrastive_loss: 5.2539 nll_loss: 0.0008 
2023-11-02 06:22:28.968 | INFO     | __main__:train:314 - Epoch: [161][600/1251]	 loss 4.40770	 cls_loss: 0.2244 cluster_loss: 1.2247 sup_con_loss: 0.3329 contrastive_loss: 5.2545 nll_loss: 0.0012 
2023-11-02 06:26:13.168 | INFO     | __main__:train:314 - Epoch: [161][700/1251]	 loss 4.46050	 cls_loss: 0.2362 cluster_loss: 1.2726 sup_con_loss: 0.3758 contrastive_loss: 5.2583 nll_loss: 0.0011 
2023-11-02 06:29:56.747 | INFO     | __main__:train:314 - Epoch: [161][800/1251]	 loss 4.36681	 cls_loss: 0.2268 cluster_loss: 1.1960 sup_con_loss: 0.2644 contrastive_loss: 5.2557 nll_loss: 0.0013 
2023-11-02 06:33:41.708 | INFO     | __main__:train:314 - Epoch: [161][900/1251]	 loss 4.42876	 cls_loss: 0.2524 cluster_loss: 1.2686 sup_con_loss: 0.2722 contrastive_loss: 5.2602 nll_loss: 0.0014 
2023-11-02 06:37:26.543 | INFO     | __main__:train:314 - Epoch: [161][1000/1251]	 loss 4.37116	 cls_loss: 0.2206 cluster_loss: 1.2100 sup_con_loss: 0.2580 contrastive_loss: 5.2558 nll_loss: 0.0009 
2023-11-02 06:41:10.976 | INFO     | __main__:train:314 - Epoch: [161][1100/1251]	 loss 4.46917	 cls_loss: 0.2388 cluster_loss: 1.2669 sup_con_loss: 0.4085 contrastive_loss: 5.2594 nll_loss: 0.0005 
2023-11-02 06:44:54.727 | INFO     | __main__:train:314 - Epoch: [161][1200/1251]	 loss 4.40067	 cls_loss: 0.2405 cluster_loss: 1.2390 sup_con_loss: 0.2595 contrastive_loss: 5.2611 nll_loss: 0.0007 
2023-11-02 06:46:47.693 | INFO     | __main__:train:319 - Train Epoch: 161 Avg Loss: 4.3923 
2023-11-02 06:46:47.699 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 07:04:05.325 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 161, Train ACC Unlabelled_v2: All 0.6205 | Old 0.7902 | New 0.5353
2023-11-02 07:04:05.499 | INFO     | __main__:main:205 - Train Accuracies: All 0.6205 | Old 0.7902 | New 0.5353
2023-11-02 07:04:09.833 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 07:04:23.429 | INFO     | __main__:train:314 - Epoch: [162][0/1251]	 loss 4.43915	 cls_loss: 0.2409 cluster_loss: 1.2632 sup_con_loss: 0.3230 contrastive_loss: 5.2607 nll_loss: 0.0012 
2023-11-02 07:08:08.631 | INFO     | __main__:train:314 - Epoch: [162][100/1251]	 loss 4.39310	 cls_loss: 0.2480 cluster_loss: 1.2553 sup_con_loss: 0.2021 contrastive_loss: 5.2598 nll_loss: 0.0007 
2023-11-02 07:11:54.230 | INFO     | __main__:train:314 - Epoch: [162][200/1251]	 loss 4.38010	 cls_loss: 0.2377 cluster_loss: 1.2211 sup_con_loss: 0.2424 contrastive_loss: 5.2579 nll_loss: 0.0007 
2023-11-02 07:15:39.088 | INFO     | __main__:train:314 - Epoch: [162][300/1251]	 loss 4.44087	 cls_loss: 0.2265 cluster_loss: 1.2611 sup_con_loss: 0.3558 contrastive_loss: 5.2561 nll_loss: 0.0010 
2023-11-02 07:19:23.644 | INFO     | __main__:train:314 - Epoch: [162][400/1251]	 loss 4.45803	 cls_loss: 0.2609 cluster_loss: 1.2670 sup_con_loss: 0.3524 contrastive_loss: 5.2591 nll_loss: 0.0014 
2023-11-02 07:23:09.583 | INFO     | __main__:train:314 - Epoch: [162][500/1251]	 loss 4.36720	 cls_loss: 0.2512 cluster_loss: 1.1918 sup_con_loss: 0.2504 contrastive_loss: 5.2557 nll_loss: 0.0008 
2023-11-02 07:26:55.437 | INFO     | __main__:train:314 - Epoch: [162][600/1251]	 loss 4.39840	 cls_loss: 0.2242 cluster_loss: 1.2094 sup_con_loss: 0.3356 contrastive_loss: 5.2543 nll_loss: 0.0011 
2023-11-02 07:30:39.057 | INFO     | __main__:train:314 - Epoch: [162][700/1251]	 loss 4.39593	 cls_loss: 0.2488 cluster_loss: 1.2234 sup_con_loss: 0.2668 contrastive_loss: 5.2594 nll_loss: 0.0017 
2023-11-02 07:34:23.437 | INFO     | __main__:train:314 - Epoch: [162][800/1251]	 loss 4.41790	 cls_loss: 0.2448 cluster_loss: 1.2214 sup_con_loss: 0.3416 contrastive_loss: 5.2573 nll_loss: 0.0015 
2023-11-02 07:38:06.467 | INFO     | __main__:train:314 - Epoch: [162][900/1251]	 loss 4.38577	 cls_loss: 0.2269 cluster_loss: 1.2272 sup_con_loss: 0.2591 contrastive_loss: 5.2568 nll_loss: 0.0011 
2023-11-02 07:41:51.933 | INFO     | __main__:train:314 - Epoch: [162][1000/1251]	 loss 4.43155	 cls_loss: 0.2561 cluster_loss: 1.2359 sup_con_loss: 0.3426 contrastive_loss: 5.2586 nll_loss: 0.0006 
2023-11-02 07:45:37.426 | INFO     | __main__:train:314 - Epoch: [162][1100/1251]	 loss 4.33262	 cls_loss: 0.2439 cluster_loss: 1.1762 sup_con_loss: 0.1892 contrastive_loss: 5.2538 nll_loss: 0.0015 
2023-11-02 07:49:19.983 | INFO     | __main__:train:314 - Epoch: [162][1200/1251]	 loss 4.36298	 cls_loss: 0.2128 cluster_loss: 1.2173 sup_con_loss: 0.2240 contrastive_loss: 5.2584 nll_loss: 0.0009 
2023-11-02 07:51:11.998 | INFO     | __main__:train:319 - Train Epoch: 162 Avg Loss: 4.3889 
2023-11-02 07:51:12.008 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 08:08:34.583 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 162, Train ACC Unlabelled_v2: All 0.6202 | Old 0.7903 | New 0.5347
2023-11-02 08:08:34.740 | INFO     | __main__:main:205 - Train Accuracies: All 0.6202 | Old 0.7903 | New 0.5347
2023-11-02 08:08:37.988 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 08:08:52.635 | INFO     | __main__:train:314 - Epoch: [163][0/1251]	 loss 4.38631	 cls_loss: 0.2076 cluster_loss: 1.2261 sup_con_loss: 0.2888 contrastive_loss: 5.2536 nll_loss: 0.0008 
2023-11-02 08:12:37.932 | INFO     | __main__:train:314 - Epoch: [163][100/1251]	 loss 4.35549	 cls_loss: 0.2207 cluster_loss: 1.2173 sup_con_loss: 0.1973 contrastive_loss: 5.2575 nll_loss: 0.0006 
2023-11-02 08:16:21.643 | INFO     | __main__:train:314 - Epoch: [163][200/1251]	 loss 4.41153	 cls_loss: 0.2313 cluster_loss: 1.2326 sup_con_loss: 0.3174 contrastive_loss: 5.2581 nll_loss: 0.0005 
2023-11-02 08:20:06.345 | INFO     | __main__:train:314 - Epoch: [163][300/1251]	 loss 4.33716	 cls_loss: 0.2422 cluster_loss: 1.1776 sup_con_loss: 0.1985 contrastive_loss: 5.2561 nll_loss: 0.0011 
2023-11-02 08:23:52.154 | INFO     | __main__:train:314 - Epoch: [163][400/1251]	 loss 4.37993	 cls_loss: 0.1973 cluster_loss: 1.2278 sup_con_loss: 0.2756 contrastive_loss: 5.2546 nll_loss: 0.0008 
2023-11-02 08:27:37.305 | INFO     | __main__:train:314 - Epoch: [163][500/1251]	 loss 4.44662	 cls_loss: 0.2394 cluster_loss: 1.2839 sup_con_loss: 0.3062 contrastive_loss: 5.2619 nll_loss: 0.0009 
2023-11-02 08:31:24.353 | INFO     | __main__:train:314 - Epoch: [163][600/1251]	 loss 4.42902	 cls_loss: 0.2072 cluster_loss: 1.2632 sup_con_loss: 0.3295 contrastive_loss: 5.2606 nll_loss: 0.0007 
2023-11-02 08:35:09.806 | INFO     | __main__:train:314 - Epoch: [163][700/1251]	 loss 4.38660	 cls_loss: 0.2171 cluster_loss: 1.2160 sup_con_loss: 0.2960 contrastive_loss: 5.2542 nll_loss: 0.0014 
2023-11-02 08:38:55.587 | INFO     | __main__:train:314 - Epoch: [163][800/1251]	 loss 4.39724	 cls_loss: 0.2479 cluster_loss: 1.2152 sup_con_loss: 0.2950 contrastive_loss: 5.2559 nll_loss: 0.0010 
2023-11-02 08:42:40.998 | INFO     | __main__:train:314 - Epoch: [163][900/1251]	 loss 4.44254	 cls_loss: 0.2418 cluster_loss: 1.2421 sup_con_loss: 0.3778 contrastive_loss: 5.2569 nll_loss: 0.0014 
2023-11-02 08:46:27.979 | INFO     | __main__:train:314 - Epoch: [163][1000/1251]	 loss 4.35289	 cls_loss: 0.1971 cluster_loss: 1.2423 sup_con_loss: 0.1628 contrastive_loss: 5.2593 nll_loss: 0.0009 
2023-11-02 08:50:13.033 | INFO     | __main__:train:314 - Epoch: [163][1100/1251]	 loss 4.47929	 cls_loss: 0.2469 cluster_loss: 1.2855 sup_con_loss: 0.3915 contrastive_loss: 5.2608 nll_loss: 0.0008 
2023-11-02 08:53:58.990 | INFO     | __main__:train:314 - Epoch: [163][1200/1251]	 loss 4.37873	 cls_loss: 0.2291 cluster_loss: 1.2143 sup_con_loss: 0.2635 contrastive_loss: 5.2554 nll_loss: 0.0010 
2023-11-02 08:55:51.333 | INFO     | __main__:train:319 - Train Epoch: 163 Avg Loss: 4.3861 
2023-11-02 08:55:51.387 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 09:13:21.477 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 163, Train ACC Unlabelled_v2: All 0.6203 | Old 0.7909 | New 0.5346
2023-11-02 09:13:21.655 | INFO     | __main__:main:205 - Train Accuracies: All 0.6203 | Old 0.7909 | New 0.5346
2023-11-02 09:13:25.259 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 09:13:38.656 | INFO     | __main__:train:314 - Epoch: [164][0/1251]	 loss 4.36150	 cls_loss: 0.2068 cluster_loss: 1.2074 sup_con_loss: 0.2476 contrastive_loss: 5.2561 nll_loss: 0.0012 
2023-11-02 09:17:24.065 | INFO     | __main__:train:314 - Epoch: [164][100/1251]	 loss 4.39575	 cls_loss: 0.2118 cluster_loss: 1.2375 sup_con_loss: 0.2789 contrastive_loss: 5.2583 nll_loss: 0.0017 
2023-11-02 09:21:09.665 | INFO     | __main__:train:314 - Epoch: [164][200/1251]	 loss 4.35586	 cls_loss: 0.2318 cluster_loss: 1.2221 sup_con_loss: 0.1704 contrastive_loss: 5.2609 nll_loss: 0.0011 
2023-11-02 09:24:53.993 | INFO     | __main__:train:314 - Epoch: [164][300/1251]	 loss 4.38371	 cls_loss: 0.2230 cluster_loss: 1.1952 sup_con_loss: 0.3225 contrastive_loss: 5.2539 nll_loss: 0.0009 
2023-11-02 09:28:40.756 | INFO     | __main__:train:314 - Epoch: [164][400/1251]	 loss 4.37923	 cls_loss: 0.2753 cluster_loss: 1.2476 sup_con_loss: 0.1497 contrastive_loss: 5.2598 nll_loss: 0.0007 
2023-11-02 09:32:27.884 | INFO     | __main__:train:314 - Epoch: [164][500/1251]	 loss 4.46028	 cls_loss: 0.2362 cluster_loss: 1.2463 sup_con_loss: 0.4319 contrastive_loss: 5.2545 nll_loss: 0.0009 
2023-11-02 09:36:16.480 | INFO     | __main__:train:314 - Epoch: [164][600/1251]	 loss 4.38428	 cls_loss: 0.2288 cluster_loss: 1.2502 sup_con_loss: 0.2133 contrastive_loss: 5.2555 nll_loss: 0.0009 
2023-11-02 09:40:02.535 | INFO     | __main__:train:314 - Epoch: [164][700/1251]	 loss 4.43520	 cls_loss: 0.2477 cluster_loss: 1.2700 sup_con_loss: 0.2924 contrastive_loss: 5.2607 nll_loss: 0.0012 
2023-11-02 09:43:49.992 | INFO     | __main__:train:314 - Epoch: [164][800/1251]	 loss 4.39336	 cls_loss: 0.2494 cluster_loss: 1.2075 sup_con_loss: 0.2962 contrastive_loss: 5.2566 nll_loss: 0.0007 
2023-11-02 09:47:37.700 | INFO     | __main__:train:314 - Epoch: [164][900/1251]	 loss 4.48625	 cls_loss: 0.2292 cluster_loss: 1.2966 sup_con_loss: 0.4054 contrastive_loss: 5.2622 nll_loss: 0.0009 
2023-11-02 09:51:26.218 | INFO     | __main__:train:314 - Epoch: [164][1000/1251]	 loss 4.37534	 cls_loss: 0.2209 cluster_loss: 1.2177 sup_con_loss: 0.2593 contrastive_loss: 5.2537 nll_loss: 0.0008 
2023-11-02 09:55:14.412 | INFO     | __main__:train:314 - Epoch: [164][1100/1251]	 loss 4.40759	 cls_loss: 0.2403 cluster_loss: 1.2270 sup_con_loss: 0.3112 contrastive_loss: 5.2555 nll_loss: 0.0009 
2023-11-02 09:58:59.755 | INFO     | __main__:train:314 - Epoch: [164][1200/1251]	 loss 4.36986	 cls_loss: 0.2097 cluster_loss: 1.2331 sup_con_loss: 0.2142 contrastive_loss: 5.2602 nll_loss: 0.0009 
2023-11-02 10:00:52.288 | INFO     | __main__:train:319 - Train Epoch: 164 Avg Loss: 4.3865 
2023-11-02 10:00:52.295 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 10:18:56.047 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 164, Train ACC Unlabelled_v2: All 0.6206 | Old 0.7910 | New 0.5349
2023-11-02 10:18:56.231 | INFO     | __main__:main:205 - Train Accuracies: All 0.6206 | Old 0.7910 | New 0.5349
2023-11-02 10:18:59.893 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 10:19:13.623 | INFO     | __main__:train:314 - Epoch: [165][0/1251]	 loss 4.37735	 cls_loss: 0.2271 cluster_loss: 1.2051 sup_con_loss: 0.2775 contrastive_loss: 5.2561 nll_loss: 0.0010 
2023-11-02 10:22:59.112 | INFO     | __main__:train:314 - Epoch: [165][100/1251]	 loss 4.45584	 cls_loss: 0.2246 cluster_loss: 1.2234 sup_con_loss: 0.4746 contrastive_loss: 5.2538 nll_loss: 0.0010 
2023-11-02 10:26:45.083 | INFO     | __main__:train:314 - Epoch: [165][200/1251]	 loss 4.43031	 cls_loss: 0.2157 cluster_loss: 1.2589 sup_con_loss: 0.3368 contrastive_loss: 5.2570 nll_loss: 0.0016 
2023-11-02 10:30:35.909 | INFO     | __main__:train:314 - Epoch: [165][300/1251]	 loss 4.39459	 cls_loss: 0.2370 cluster_loss: 1.2206 sup_con_loss: 0.2922 contrastive_loss: 5.2542 nll_loss: 0.0007 
2023-11-02 10:34:22.123 | INFO     | __main__:train:314 - Epoch: [165][400/1251]	 loss 4.36502	 cls_loss: 0.2249 cluster_loss: 1.2096 sup_con_loss: 0.2369 contrastive_loss: 5.2549 nll_loss: 0.0014 
2023-11-02 10:38:08.048 | INFO     | __main__:train:314 - Epoch: [165][500/1251]	 loss 4.33166	 cls_loss: 0.2128 cluster_loss: 1.1975 sup_con_loss: 0.1791 contrastive_loss: 5.2530 nll_loss: 0.0016 
2023-11-02 10:41:57.068 | INFO     | __main__:train:314 - Epoch: [165][600/1251]	 loss 4.35758	 cls_loss: 0.2237 cluster_loss: 1.2075 sup_con_loss: 0.2183 contrastive_loss: 5.2557 nll_loss: 0.0018 
2023-11-02 10:45:46.511 | INFO     | __main__:train:314 - Epoch: [165][700/1251]	 loss 4.38477	 cls_loss: 0.2254 cluster_loss: 1.2226 sup_con_loss: 0.2668 contrastive_loss: 5.2566 nll_loss: 0.0010 
2023-11-02 10:49:32.396 | INFO     | __main__:train:314 - Epoch: [165][800/1251]	 loss 4.41928	 cls_loss: 0.2451 cluster_loss: 1.2124 sup_con_loss: 0.3673 contrastive_loss: 5.2548 nll_loss: 0.0013 
2023-11-02 10:53:17.973 | INFO     | __main__:train:314 - Epoch: [165][900/1251]	 loss 4.38497	 cls_loss: 0.2248 cluster_loss: 1.2209 sup_con_loss: 0.2769 contrastive_loss: 5.2538 nll_loss: 0.0009 
2023-11-02 10:57:06.534 | INFO     | __main__:train:314 - Epoch: [165][1000/1251]	 loss 4.38421	 cls_loss: 0.2105 cluster_loss: 1.2133 sup_con_loss: 0.2972 contrastive_loss: 5.2560 nll_loss: 0.0015 
2023-11-02 11:00:53.899 | INFO     | __main__:train:314 - Epoch: [165][1100/1251]	 loss 4.37967	 cls_loss: 0.2230 cluster_loss: 1.2322 sup_con_loss: 0.2302 contrastive_loss: 5.2609 nll_loss: 0.0005 
2023-11-02 11:04:41.983 | INFO     | __main__:train:314 - Epoch: [165][1200/1251]	 loss 4.33325	 cls_loss: 0.2191 cluster_loss: 1.1726 sup_con_loss: 0.2273 contrastive_loss: 5.2527 nll_loss: 0.0006 
2023-11-02 11:06:36.008 | INFO     | __main__:train:319 - Train Epoch: 165 Avg Loss: 4.3824 
2023-11-02 11:06:36.015 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 11:26:01.749 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 165, Train ACC Unlabelled_v2: All 0.6213 | Old 0.7905 | New 0.5363
2023-11-02 11:26:01.999 | INFO     | __main__:main:205 - Train Accuracies: All 0.6213 | Old 0.7905 | New 0.5363
2023-11-02 11:26:06.259 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 11:26:21.230 | INFO     | __main__:train:314 - Epoch: [166][0/1251]	 loss 4.38400	 cls_loss: 0.2467 cluster_loss: 1.2083 sup_con_loss: 0.2667 contrastive_loss: 5.2577 nll_loss: 0.0015 
2023-11-02 11:30:06.674 | INFO     | __main__:train:314 - Epoch: [166][100/1251]	 loss 4.35682	 cls_loss: 0.2299 cluster_loss: 1.2112 sup_con_loss: 0.2013 contrastive_loss: 5.2579 nll_loss: 0.0010 
2023-11-02 11:33:53.114 | INFO     | __main__:train:314 - Epoch: [166][200/1251]	 loss 4.41669	 cls_loss: 0.2131 cluster_loss: 1.2539 sup_con_loss: 0.3143 contrastive_loss: 5.2555 nll_loss: 0.0010 
2023-11-02 11:37:40.120 | INFO     | __main__:train:314 - Epoch: [166][300/1251]	 loss 4.38918	 cls_loss: 0.2392 cluster_loss: 1.2102 sup_con_loss: 0.2834 contrastive_loss: 5.2589 nll_loss: 0.0013 
2023-11-02 11:41:26.378 | INFO     | __main__:train:314 - Epoch: [166][400/1251]	 loss 4.43275	 cls_loss: 0.2468 cluster_loss: 1.2556 sup_con_loss: 0.3117 contrastive_loss: 5.2618 nll_loss: 0.0010 
2023-11-02 11:45:10.789 | INFO     | __main__:train:314 - Epoch: [166][500/1251]	 loss 4.30067	 cls_loss: 0.2231 cluster_loss: 1.1485 sup_con_loss: 0.1731 contrastive_loss: 5.2535 nll_loss: 0.0007 
2023-11-02 11:49:02.531 | INFO     | __main__:train:314 - Epoch: [166][600/1251]	 loss 4.38742	 cls_loss: 0.2331 cluster_loss: 1.2080 sup_con_loss: 0.2987 contrastive_loss: 5.2544 nll_loss: 0.0007 
2023-11-02 11:52:49.119 | INFO     | __main__:train:314 - Epoch: [166][700/1251]	 loss 4.45548	 cls_loss: 0.2496 cluster_loss: 1.2462 sup_con_loss: 0.3937 contrastive_loss: 5.2602 nll_loss: 0.0012 
2023-11-02 11:56:36.705 | INFO     | __main__:train:314 - Epoch: [166][800/1251]	 loss 4.43651	 cls_loss: 0.2313 cluster_loss: 1.2304 sup_con_loss: 0.3980 contrastive_loss: 5.2551 nll_loss: 0.0007 
2023-11-02 12:00:33.697 | INFO     | __main__:train:314 - Epoch: [166][900/1251]	 loss 4.41614	 cls_loss: 0.2532 cluster_loss: 1.2479 sup_con_loss: 0.2742 contrastive_loss: 5.2607 nll_loss: 0.0010 
2023-11-02 12:04:19.445 | INFO     | __main__:train:314 - Epoch: [166][1000/1251]	 loss 4.44704	 cls_loss: 0.2158 cluster_loss: 1.2315 sup_con_loss: 0.4457 contrastive_loss: 5.2522 nll_loss: 0.0011 
2023-11-02 12:08:08.698 | INFO     | __main__:train:314 - Epoch: [166][1100/1251]	 loss 4.36393	 cls_loss: 0.2174 cluster_loss: 1.2230 sup_con_loss: 0.2161 contrastive_loss: 5.2566 nll_loss: 0.0005 
2023-11-02 12:11:53.752 | INFO     | __main__:train:314 - Epoch: [166][1200/1251]	 loss 4.38751	 cls_loss: 0.2131 cluster_loss: 1.2187 sup_con_loss: 0.3021 contrastive_loss: 5.2531 nll_loss: 0.0005 
2023-11-02 12:13:46.347 | INFO     | __main__:train:319 - Train Epoch: 166 Avg Loss: 4.3827 
2023-11-02 12:13:46.354 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 12:32:54.133 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 166, Train ACC Unlabelled_v2: All 0.6213 | Old 0.7921 | New 0.5355
2023-11-02 12:32:54.360 | INFO     | __main__:main:205 - Train Accuracies: All 0.6213 | Old 0.7921 | New 0.5355
2023-11-02 12:32:57.560 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 12:33:12.136 | INFO     | __main__:train:314 - Epoch: [167][0/1251]	 loss 4.48017	 cls_loss: 0.2464 cluster_loss: 1.2456 sup_con_loss: 0.4802 contrastive_loss: 5.2544 nll_loss: 0.0009 
2023-11-02 12:37:01.053 | INFO     | __main__:train:314 - Epoch: [167][100/1251]	 loss 4.31941	 cls_loss: 0.2205 cluster_loss: 1.1919 sup_con_loss: 0.1444 contrastive_loss: 5.2556 nll_loss: 0.0008 
2023-11-02 12:40:48.876 | INFO     | __main__:train:314 - Epoch: [167][200/1251]	 loss 4.40239	 cls_loss: 0.2320 cluster_loss: 1.2353 sup_con_loss: 0.2899 contrastive_loss: 5.2550 nll_loss: 0.0010 
2023-11-02 12:44:36.265 | INFO     | __main__:train:314 - Epoch: [167][300/1251]	 loss 4.37566	 cls_loss: 0.2174 cluster_loss: 1.1864 sup_con_loss: 0.3199 contrastive_loss: 5.2544 nll_loss: 0.0012 
2023-11-02 12:48:23.447 | INFO     | __main__:train:314 - Epoch: [167][400/1251]	 loss 4.35132	 cls_loss: 0.2335 cluster_loss: 1.1578 sup_con_loss: 0.2955 contrastive_loss: 5.2510 nll_loss: 0.0004 
2023-11-02 12:52:11.202 | INFO     | __main__:train:314 - Epoch: [167][500/1251]	 loss 4.40658	 cls_loss: 0.2388 cluster_loss: 1.2084 sup_con_loss: 0.3485 contrastive_loss: 5.2540 nll_loss: 0.0005 
2023-11-02 12:55:58.697 | INFO     | __main__:train:314 - Epoch: [167][600/1251]	 loss 4.34822	 cls_loss: 0.2045 cluster_loss: 1.1839 sup_con_loss: 0.2611 contrastive_loss: 5.2529 nll_loss: 0.0014 
2023-11-02 12:59:47.429 | INFO     | __main__:train:314 - Epoch: [167][700/1251]	 loss 4.36335	 cls_loss: 0.2236 cluster_loss: 1.2036 sup_con_loss: 0.2484 contrastive_loss: 5.2538 nll_loss: 0.0008 
2023-11-02 13:03:34.001 | INFO     | __main__:train:314 - Epoch: [167][800/1251]	 loss 4.37800	 cls_loss: 0.2416 cluster_loss: 1.1969 sup_con_loss: 0.2876 contrastive_loss: 5.2519 nll_loss: 0.0011 
2023-11-02 13:07:20.342 | INFO     | __main__:train:314 - Epoch: [167][900/1251]	 loss 4.39444	 cls_loss: 0.2441 cluster_loss: 1.2183 sup_con_loss: 0.2869 contrastive_loss: 5.2550 nll_loss: 0.0009 
2023-11-02 13:11:07.285 | INFO     | __main__:train:314 - Epoch: [167][1000/1251]	 loss 4.44129	 cls_loss: 0.2009 cluster_loss: 1.2801 sup_con_loss: 0.3409 contrastive_loss: 5.2589 nll_loss: 0.0013 
2023-11-02 13:14:54.065 | INFO     | __main__:train:314 - Epoch: [167][1100/1251]	 loss 4.37307	 cls_loss: 0.2249 cluster_loss: 1.2215 sup_con_loss: 0.2362 contrastive_loss: 5.2569 nll_loss: 0.0007 
2023-11-02 13:18:42.330 | INFO     | __main__:train:314 - Epoch: [167][1200/1251]	 loss 4.35885	 cls_loss: 0.2410 cluster_loss: 1.1761 sup_con_loss: 0.2714 contrastive_loss: 5.2520 nll_loss: 0.0012 
2023-11-02 13:20:34.691 | INFO     | __main__:train:319 - Train Epoch: 167 Avg Loss: 4.3789 
2023-11-02 13:20:34.697 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 13:38:43.852 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 167, Train ACC Unlabelled_v2: All 0.6213 | Old 0.7924 | New 0.5353
2023-11-02 13:38:44.060 | INFO     | __main__:main:205 - Train Accuracies: All 0.6213 | Old 0.7924 | New 0.5353
2023-11-02 13:38:49.295 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 13:39:03.789 | INFO     | __main__:train:314 - Epoch: [168][0/1251]	 loss 4.36789	 cls_loss: 0.2331 cluster_loss: 1.1947 sup_con_loss: 0.2658 contrastive_loss: 5.2545 nll_loss: 0.0013 
2023-11-02 13:42:50.571 | INFO     | __main__:train:314 - Epoch: [168][100/1251]	 loss 4.36573	 cls_loss: 0.2446 cluster_loss: 1.2182 sup_con_loss: 0.2031 contrastive_loss: 5.2561 nll_loss: 0.0007 
2023-11-02 13:46:36.239 | INFO     | __main__:train:314 - Epoch: [168][200/1251]	 loss 4.36046	 cls_loss: 0.2295 cluster_loss: 1.2005 sup_con_loss: 0.2389 contrastive_loss: 5.2543 nll_loss: 0.0009 
2023-11-02 13:50:20.248 | INFO     | __main__:train:314 - Epoch: [168][300/1251]	 loss 4.48342	 cls_loss: 0.2114 cluster_loss: 1.2824 sup_con_loss: 0.4516 contrastive_loss: 5.2566 nll_loss: 0.0010 
2023-11-02 13:54:04.887 | INFO     | __main__:train:314 - Epoch: [168][400/1251]	 loss 4.36757	 cls_loss: 0.2141 cluster_loss: 1.2107 sup_con_loss: 0.2532 contrastive_loss: 5.2551 nll_loss: 0.0012 
2023-11-02 13:57:54.429 | INFO     | __main__:train:314 - Epoch: [168][500/1251]	 loss 4.41789	 cls_loss: 0.2387 cluster_loss: 1.2297 sup_con_loss: 0.3360 contrastive_loss: 5.2559 nll_loss: 0.0011 
2023-11-02 14:01:42.750 | INFO     | __main__:train:314 - Epoch: [168][600/1251]	 loss 4.35679	 cls_loss: 0.2098 cluster_loss: 1.2348 sup_con_loss: 0.1794 contrastive_loss: 5.2571 nll_loss: 0.0009 
2023-11-02 14:06:08.077 | INFO     | __main__:train:314 - Epoch: [168][700/1251]	 loss 4.34366	 cls_loss: 0.2580 cluster_loss: 1.1497 sup_con_loss: 0.2592 contrastive_loss: 5.2526 nll_loss: 0.0011 
2023-11-02 14:09:52.972 | INFO     | __main__:train:314 - Epoch: [168][800/1251]	 loss 4.34620	 cls_loss: 0.2250 cluster_loss: 1.1854 sup_con_loss: 0.2249 contrastive_loss: 5.2576 nll_loss: 0.0009 
2023-11-02 14:13:37.835 | INFO     | __main__:train:314 - Epoch: [168][900/1251]	 loss 4.31602	 cls_loss: 0.2063 cluster_loss: 1.1527 sup_con_loss: 0.2249 contrastive_loss: 5.2531 nll_loss: 0.0014 
2023-11-02 14:17:23.502 | INFO     | __main__:train:314 - Epoch: [168][1000/1251]	 loss 4.45167	 cls_loss: 0.2234 cluster_loss: 1.2550 sup_con_loss: 0.3980 contrastive_loss: 5.2571 nll_loss: 0.0013 
2023-11-02 14:21:08.142 | INFO     | __main__:train:314 - Epoch: [168][1100/1251]	 loss 4.38674	 cls_loss: 0.2171 cluster_loss: 1.2105 sup_con_loss: 0.3122 contrastive_loss: 5.2524 nll_loss: 0.0006 
2023-11-02 14:24:51.506 | INFO     | __main__:train:314 - Epoch: [168][1200/1251]	 loss 4.40952	 cls_loss: 0.2169 cluster_loss: 1.2501 sup_con_loss: 0.2919 contrastive_loss: 5.2588 nll_loss: 0.0007 
2023-11-02 14:26:44.577 | INFO     | __main__:train:319 - Train Epoch: 168 Avg Loss: 4.3761 
2023-11-02 14:26:44.583 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 14:46:26.433 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 168, Train ACC Unlabelled_v2: All 0.6217 | Old 0.7915 | New 0.5363
2023-11-02 14:46:26.678 | INFO     | __main__:main:205 - Train Accuracies: All 0.6217 | Old 0.7915 | New 0.5363
2023-11-02 14:46:30.083 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 14:46:45.564 | INFO     | __main__:train:314 - Epoch: [169][0/1251]	 loss 4.38663	 cls_loss: 0.2520 cluster_loss: 1.2075 sup_con_loss: 0.2762 contrastive_loss: 5.2548 nll_loss: 0.0013 
2023-11-02 14:50:30.506 | INFO     | __main__:train:314 - Epoch: [169][100/1251]	 loss 4.32238	 cls_loss: 0.1971 cluster_loss: 1.1931 sup_con_loss: 0.1783 contrastive_loss: 5.2534 nll_loss: 0.0008 
2023-11-02 14:54:15.620 | INFO     | __main__:train:314 - Epoch: [169][200/1251]	 loss 4.38611	 cls_loss: 0.2140 cluster_loss: 1.2244 sup_con_loss: 0.2826 contrastive_loss: 5.2549 nll_loss: 0.0008 
2023-11-02 14:57:58.933 | INFO     | __main__:train:314 - Epoch: [169][300/1251]	 loss 4.37925	 cls_loss: 0.2212 cluster_loss: 1.2235 sup_con_loss: 0.2593 contrastive_loss: 5.2540 nll_loss: 0.0007 
2023-11-02 15:01:44.920 | INFO     | __main__:train:314 - Epoch: [169][400/1251]	 loss 4.40765	 cls_loss: 0.2380 cluster_loss: 1.2240 sup_con_loss: 0.3204 contrastive_loss: 5.2551 nll_loss: 0.0008 
2023-11-02 15:05:31.819 | INFO     | __main__:train:314 - Epoch: [169][500/1251]	 loss 4.35014	 cls_loss: 0.2054 cluster_loss: 1.2131 sup_con_loss: 0.2016 contrastive_loss: 5.2586 nll_loss: 0.0011 
2023-11-02 15:09:18.506 | INFO     | __main__:train:314 - Epoch: [169][600/1251]	 loss 4.31662	 cls_loss: 0.2162 cluster_loss: 1.1982 sup_con_loss: 0.1341 contrastive_loss: 5.2527 nll_loss: 0.0009 
2023-11-02 15:13:04.028 | INFO     | __main__:train:314 - Epoch: [169][700/1251]	 loss 4.35976	 cls_loss: 0.2486 cluster_loss: 1.1450 sup_con_loss: 0.3216 contrastive_loss: 5.2537 nll_loss: 0.0011 
2023-11-02 15:16:49.044 | INFO     | __main__:train:314 - Epoch: [169][800/1251]	 loss 4.39384	 cls_loss: 0.2510 cluster_loss: 1.1850 sup_con_loss: 0.3405 contrastive_loss: 5.2549 nll_loss: 0.0008 
2023-11-02 15:20:33.915 | INFO     | __main__:train:314 - Epoch: [169][900/1251]	 loss 4.41232	 cls_loss: 0.2010 cluster_loss: 1.2886 sup_con_loss: 0.2391 contrastive_loss: 5.2619 nll_loss: 0.0004 
2023-11-02 15:24:22.961 | INFO     | __main__:train:314 - Epoch: [169][1000/1251]	 loss 4.45079	 cls_loss: 0.2345 cluster_loss: 1.2743 sup_con_loss: 0.3482 contrastive_loss: 5.2582 nll_loss: 0.0007 
2023-11-02 15:28:06.722 | INFO     | __main__:train:314 - Epoch: [169][1100/1251]	 loss 4.37437	 cls_loss: 0.2451 cluster_loss: 1.2413 sup_con_loss: 0.1770 contrastive_loss: 5.2600 nll_loss: 0.0007 
2023-11-02 15:31:52.280 | INFO     | __main__:train:314 - Epoch: [169][1200/1251]	 loss 4.37029	 cls_loss: 0.2119 cluster_loss: 1.1999 sup_con_loss: 0.2846 contrastive_loss: 5.2544 nll_loss: 0.0013 
2023-11-02 15:33:44.178 | INFO     | __main__:train:319 - Train Epoch: 169 Avg Loss: 4.3760 
2023-11-02 15:33:44.205 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 15:53:57.117 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 169, Train ACC Unlabelled_v2: All 0.6219 | Old 0.7930 | New 0.5359
2023-11-02 15:53:58.176 | INFO     | __main__:main:205 - Train Accuracies: All 0.6219 | Old 0.7930 | New 0.5359
2023-11-02 15:54:04.473 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 15:54:18.756 | INFO     | __main__:train:314 - Epoch: [170][0/1251]	 loss 4.39460	 cls_loss: 0.2083 cluster_loss: 1.2393 sup_con_loss: 0.2807 contrastive_loss: 5.2569 nll_loss: 0.0009 
2023-11-02 15:58:02.632 | INFO     | __main__:train:314 - Epoch: [170][100/1251]	 loss 4.40564	 cls_loss: 0.2132 cluster_loss: 1.2436 sup_con_loss: 0.3019 contrastive_loss: 5.2555 nll_loss: 0.0010 
2023-11-02 16:01:47.921 | INFO     | __main__:train:314 - Epoch: [170][200/1251]	 loss 4.34883	 cls_loss: 0.2380 cluster_loss: 1.1587 sup_con_loss: 0.2767 contrastive_loss: 5.2535 nll_loss: 0.0008 
2023-11-02 16:05:31.666 | INFO     | __main__:train:314 - Epoch: [170][300/1251]	 loss 4.32182	 cls_loss: 0.2241 cluster_loss: 1.1767 sup_con_loss: 0.1835 contrastive_loss: 5.2514 nll_loss: 0.0009 
2023-11-02 16:09:18.708 | INFO     | __main__:train:314 - Epoch: [170][400/1251]	 loss 4.37499	 cls_loss: 0.2322 cluster_loss: 1.1840 sup_con_loss: 0.3086 contrastive_loss: 5.2542 nll_loss: 0.0009 
2023-11-02 16:13:13.420 | INFO     | __main__:train:314 - Epoch: [170][500/1251]	 loss 4.46169	 cls_loss: 0.2162 cluster_loss: 1.2559 sup_con_loss: 0.4332 contrastive_loss: 5.2572 nll_loss: 0.0008 
2023-11-02 16:16:58.200 | INFO     | __main__:train:314 - Epoch: [170][600/1251]	 loss 4.35871	 cls_loss: 0.2092 cluster_loss: 1.1845 sup_con_loss: 0.2831 contrastive_loss: 5.2540 nll_loss: 0.0014 
2023-11-02 16:20:46.077 | INFO     | __main__:train:314 - Epoch: [170][700/1251]	 loss 4.38942	 cls_loss: 0.2449 cluster_loss: 1.1888 sup_con_loss: 0.3302 contrastive_loss: 5.2530 nll_loss: 0.0010 
2023-11-02 16:24:46.978 | INFO     | __main__:train:314 - Epoch: [170][800/1251]	 loss 4.41649	 cls_loss: 0.2231 cluster_loss: 1.2372 sup_con_loss: 0.3294 contrastive_loss: 5.2588 nll_loss: 0.0007 
2023-11-02 16:28:35.765 | INFO     | __main__:train:314 - Epoch: [170][900/1251]	 loss 4.38109	 cls_loss: 0.2251 cluster_loss: 1.2222 sup_con_loss: 0.2616 contrastive_loss: 5.2548 nll_loss: 0.0007 
2023-11-02 16:32:20.433 | INFO     | __main__:train:314 - Epoch: [170][1000/1251]	 loss 4.36713	 cls_loss: 0.2160 cluster_loss: 1.1849 sup_con_loss: 0.3021 contrastive_loss: 5.2525 nll_loss: 0.0015 
2023-11-02 16:36:06.102 | INFO     | __main__:train:314 - Epoch: [170][1100/1251]	 loss 4.37239	 cls_loss: 0.2204 cluster_loss: 1.2486 sup_con_loss: 0.1841 contrastive_loss: 5.2597 nll_loss: 0.0005 
2023-11-02 16:39:51.871 | INFO     | __main__:train:314 - Epoch: [170][1200/1251]	 loss 4.37529	 cls_loss: 0.2273 cluster_loss: 1.2069 sup_con_loss: 0.2725 contrastive_loss: 5.2540 nll_loss: 0.0008 
2023-11-02 16:41:43.353 | INFO     | __main__:train:319 - Train Epoch: 170 Avg Loss: 4.3749 
2023-11-02 16:41:43.356 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 17:04:26.236 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 170, Train ACC Unlabelled_v2: All 0.6223 | Old 0.7909 | New 0.5375
2023-11-02 17:04:26.470 | INFO     | __main__:main:205 - Train Accuracies: All 0.6223 | Old 0.7909 | New 0.5375
2023-11-02 17:04:29.611 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 17:04:47.214 | INFO     | __main__:train:314 - Epoch: [171][0/1251]	 loss 4.39504	 cls_loss: 0.2550 cluster_loss: 1.2164 sup_con_loss: 0.2814 contrastive_loss: 5.2542 nll_loss: 0.0014 
2023-11-02 17:08:41.791 | INFO     | __main__:train:314 - Epoch: [171][100/1251]	 loss 4.33613	 cls_loss: 0.2112 cluster_loss: 1.1697 sup_con_loss: 0.2507 contrastive_loss: 5.2516 nll_loss: 0.0006 
2023-11-02 17:12:37.807 | INFO     | __main__:train:314 - Epoch: [171][200/1251]	 loss 4.41364	 cls_loss: 0.2259 cluster_loss: 1.2371 sup_con_loss: 0.3246 contrastive_loss: 5.2555 nll_loss: 0.0008 
2023-11-02 17:16:27.167 | INFO     | __main__:train:314 - Epoch: [171][300/1251]	 loss 4.34009	 cls_loss: 0.2181 cluster_loss: 1.1749 sup_con_loss: 0.2433 contrastive_loss: 5.2523 nll_loss: 0.0009 
2023-11-02 17:20:15.286 | INFO     | __main__:train:314 - Epoch: [171][400/1251]	 loss 4.39542	 cls_loss: 0.2094 cluster_loss: 1.2169 sup_con_loss: 0.3288 contrastive_loss: 5.2548 nll_loss: 0.0004 
2023-11-02 17:24:01.970 | INFO     | __main__:train:314 - Epoch: [171][500/1251]	 loss 4.39334	 cls_loss: 0.2160 cluster_loss: 1.2015 sup_con_loss: 0.3478 contrastive_loss: 5.2526 nll_loss: 0.0008 
2023-11-02 17:27:53.835 | INFO     | __main__:train:314 - Epoch: [171][600/1251]	 loss 4.30541	 cls_loss: 0.2081 cluster_loss: 1.1488 sup_con_loss: 0.2082 contrastive_loss: 5.2498 nll_loss: 0.0006 
2023-11-02 17:31:43.260 | INFO     | __main__:train:314 - Epoch: [171][700/1251]	 loss 4.35535	 cls_loss: 0.2236 cluster_loss: 1.1892 sup_con_loss: 0.2508 contrastive_loss: 5.2539 nll_loss: 0.0013 
2023-11-02 17:35:27.841 | INFO     | __main__:train:314 - Epoch: [171][800/1251]	 loss 4.36166	 cls_loss: 0.2537 cluster_loss: 1.1878 sup_con_loss: 0.2430 contrastive_loss: 5.2533 nll_loss: 0.0010 
2023-11-02 17:39:15.448 | INFO     | __main__:train:314 - Epoch: [171][900/1251]	 loss 4.38277	 cls_loss: 0.2110 cluster_loss: 1.1992 sup_con_loss: 0.3240 contrastive_loss: 5.2546 nll_loss: 0.0005 
2023-11-02 17:43:08.897 | INFO     | __main__:train:314 - Epoch: [171][1000/1251]	 loss 4.29877	 cls_loss: 0.2628 cluster_loss: 1.1322 sup_con_loss: 0.1632 contrastive_loss: 5.2509 nll_loss: 0.0007 
2023-11-02 17:47:06.637 | INFO     | __main__:train:314 - Epoch: [171][1100/1251]	 loss 4.37724	 cls_loss: 0.2209 cluster_loss: 1.1982 sup_con_loss: 0.2997 contrastive_loss: 5.2543 nll_loss: 0.0009 
2023-11-02 17:51:18.295 | INFO     | __main__:train:314 - Epoch: [171][1200/1251]	 loss 4.41977	 cls_loss: 0.2649 cluster_loss: 1.2344 sup_con_loss: 0.3014 contrastive_loss: 5.2590 nll_loss: 0.0009 
2023-11-02 17:53:11.632 | INFO     | __main__:train:319 - Train Epoch: 171 Avg Loss: 4.3730 
2023-11-02 17:53:11.648 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 18:18:14.842 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 171, Train ACC Unlabelled_v2: All 0.6225 | Old 0.7921 | New 0.5372
2023-11-02 18:18:15.134 | INFO     | __main__:main:205 - Train Accuracies: All 0.6225 | Old 0.7921 | New 0.5372
2023-11-02 18:18:19.161 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 18:18:41.880 | INFO     | __main__:train:314 - Epoch: [172][0/1251]	 loss 4.37373	 cls_loss: 0.2422 cluster_loss: 1.2108 sup_con_loss: 0.2449 contrastive_loss: 5.2545 nll_loss: 0.0008 
2023-11-02 18:25:06.398 | INFO     | __main__:train:314 - Epoch: [172][100/1251]	 loss 4.34151	 cls_loss: 0.2389 cluster_loss: 1.1545 sup_con_loss: 0.2619 contrastive_loss: 5.2534 nll_loss: 0.0011 
2023-11-02 18:28:53.731 | INFO     | __main__:train:314 - Epoch: [172][200/1251]	 loss 4.34878	 cls_loss: 0.1954 cluster_loss: 1.1833 sup_con_loss: 0.2751 contrastive_loss: 5.2523 nll_loss: 0.0010 
2023-11-02 18:32:45.813 | INFO     | __main__:train:314 - Epoch: [172][300/1251]	 loss 4.38053	 cls_loss: 0.2053 cluster_loss: 1.2039 sup_con_loss: 0.3117 contrastive_loss: 5.2552 nll_loss: 0.0012 
2023-11-02 18:36:32.513 | INFO     | __main__:train:314 - Epoch: [172][400/1251]	 loss 4.41749	 cls_loss: 0.2321 cluster_loss: 1.2250 sup_con_loss: 0.3532 contrastive_loss: 5.2544 nll_loss: 0.0010 
2023-11-02 18:40:19.041 | INFO     | __main__:train:314 - Epoch: [172][500/1251]	 loss 4.30913	 cls_loss: 0.2054 cluster_loss: 1.1722 sup_con_loss: 0.1722 contrastive_loss: 5.2527 nll_loss: 0.0009 
2023-11-02 18:44:04.075 | INFO     | __main__:train:314 - Epoch: [172][600/1251]	 loss 4.31074	 cls_loss: 0.2284 cluster_loss: 1.1613 sup_con_loss: 0.1715 contrastive_loss: 5.2540 nll_loss: 0.0008 
2023-11-02 18:47:51.633 | INFO     | __main__:train:314 - Epoch: [172][700/1251]	 loss 4.31664	 cls_loss: 0.2061 cluster_loss: 1.1458 sup_con_loss: 0.2433 contrastive_loss: 5.2527 nll_loss: 0.0004 
2023-11-02 18:51:40.959 | INFO     | __main__:train:314 - Epoch: [172][800/1251]	 loss 4.32577	 cls_loss: 0.1852 cluster_loss: 1.1992 sup_con_loss: 0.1817 contrastive_loss: 5.2571 nll_loss: 0.0008 
2023-11-02 18:55:32.327 | INFO     | __main__:train:314 - Epoch: [172][900/1251]	 loss 4.35407	 cls_loss: 0.2467 cluster_loss: 1.1552 sup_con_loss: 0.2942 contrastive_loss: 5.2512 nll_loss: 0.0006 
2023-11-02 18:59:20.247 | INFO     | __main__:train:314 - Epoch: [172][1000/1251]	 loss 4.36770	 cls_loss: 0.2117 cluster_loss: 1.2097 sup_con_loss: 0.2577 contrastive_loss: 5.2562 nll_loss: 0.0005 
2023-11-02 19:03:12.640 | INFO     | __main__:train:314 - Epoch: [172][1100/1251]	 loss 4.33551	 cls_loss: 0.2351 cluster_loss: 1.1942 sup_con_loss: 0.1736 contrastive_loss: 5.2548 nll_loss: 0.0006 
2023-11-02 19:07:00.745 | INFO     | __main__:train:314 - Epoch: [172][1200/1251]	 loss 4.37460	 cls_loss: 0.2222 cluster_loss: 1.1875 sup_con_loss: 0.3082 contrastive_loss: 5.2552 nll_loss: 0.0013 
2023-11-02 19:08:55.096 | INFO     | __main__:train:319 - Train Epoch: 172 Avg Loss: 4.3705 
2023-11-02 19:08:55.167 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 19:31:50.498 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 172, Train ACC Unlabelled_v2: All 0.6226 | Old 0.7924 | New 0.5373
2023-11-02 19:31:50.748 | INFO     | __main__:main:205 - Train Accuracies: All 0.6226 | Old 0.7924 | New 0.5373
2023-11-02 19:31:53.744 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 19:32:12.622 | INFO     | __main__:train:314 - Epoch: [173][0/1251]	 loss 4.38001	 cls_loss: 0.2175 cluster_loss: 1.2128 sup_con_loss: 0.2757 contrastive_loss: 5.2594 nll_loss: 0.0005 
2023-11-02 19:35:59.104 | INFO     | __main__:train:314 - Epoch: [173][100/1251]	 loss 4.40654	 cls_loss: 0.2171 cluster_loss: 1.2445 sup_con_loss: 0.2952 contrastive_loss: 5.2578 nll_loss: 0.0008 
2023-11-02 19:39:50.282 | INFO     | __main__:train:314 - Epoch: [173][200/1251]	 loss 4.34231	 cls_loss: 0.2035 cluster_loss: 1.2005 sup_con_loss: 0.2147 contrastive_loss: 5.2541 nll_loss: 0.0004 
2023-11-02 19:43:39.839 | INFO     | __main__:train:314 - Epoch: [173][300/1251]	 loss 4.35436	 cls_loss: 0.2230 cluster_loss: 1.2064 sup_con_loss: 0.2179 contrastive_loss: 5.2537 nll_loss: 0.0010 
2023-11-02 19:47:27.804 | INFO     | __main__:train:314 - Epoch: [173][400/1251]	 loss 4.31759	 cls_loss: 0.2106 cluster_loss: 1.1691 sup_con_loss: 0.1969 contrastive_loss: 5.2532 nll_loss: 0.0005 
2023-11-02 19:51:20.737 | INFO     | __main__:train:314 - Epoch: [173][500/1251]	 loss 4.37341	 cls_loss: 0.2076 cluster_loss: 1.2159 sup_con_loss: 0.2635 contrastive_loss: 5.2567 nll_loss: 0.0013 
2023-11-02 19:55:05.473 | INFO     | __main__:train:314 - Epoch: [173][600/1251]	 loss 4.36499	 cls_loss: 0.2127 cluster_loss: 1.2021 sup_con_loss: 0.2656 contrastive_loss: 5.2549 nll_loss: 0.0005 
2023-11-02 19:58:55.001 | INFO     | __main__:train:314 - Epoch: [173][700/1251]	 loss 4.39834	 cls_loss: 0.2502 cluster_loss: 1.2340 sup_con_loss: 0.2610 contrastive_loss: 5.2562 nll_loss: 0.0008 
2023-11-02 20:02:41.808 | INFO     | __main__:train:314 - Epoch: [173][800/1251]	 loss 4.33531	 cls_loss: 0.2246 cluster_loss: 1.1973 sup_con_loss: 0.1744 contrastive_loss: 5.2559 nll_loss: 0.0011 
2023-11-02 20:06:29.276 | INFO     | __main__:train:314 - Epoch: [173][900/1251]	 loss 4.39361	 cls_loss: 0.2181 cluster_loss: 1.1898 sup_con_loss: 0.3688 contrastive_loss: 5.2529 nll_loss: 0.0004 
2023-11-02 20:10:18.830 | INFO     | __main__:train:314 - Epoch: [173][1000/1251]	 loss 4.34769	 cls_loss: 0.2309 cluster_loss: 1.1635 sup_con_loss: 0.2766 contrastive_loss: 5.2505 nll_loss: 0.0010 
2023-11-02 20:14:04.729 | INFO     | __main__:train:314 - Epoch: [173][1100/1251]	 loss 4.44693	 cls_loss: 0.1998 cluster_loss: 1.2602 sup_con_loss: 0.4060 contrastive_loss: 5.2537 nll_loss: 0.0008 
2023-11-02 20:17:49.787 | INFO     | __main__:train:314 - Epoch: [173][1200/1251]	 loss 4.37619	 cls_loss: 0.2195 cluster_loss: 1.2180 sup_con_loss: 0.2514 contrastive_loss: 5.2598 nll_loss: 0.0008 
2023-11-02 20:19:41.804 | INFO     | __main__:train:319 - Train Epoch: 173 Avg Loss: 4.3689 
2023-11-02 20:19:41.819 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 20:39:57.698 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 173, Train ACC Unlabelled_v2: All 0.6227 | Old 0.7929 | New 0.5371
2023-11-02 20:39:57.876 | INFO     | __main__:main:205 - Train Accuracies: All 0.6227 | Old 0.7929 | New 0.5371
2023-11-02 20:40:01.899 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 20:40:16.389 | INFO     | __main__:train:314 - Epoch: [174][0/1251]	 loss 4.28542	 cls_loss: 0.2038 cluster_loss: 1.1452 sup_con_loss: 0.1592 contrastive_loss: 5.2511 nll_loss: 0.0008 
2023-11-02 20:44:02.565 | INFO     | __main__:train:314 - Epoch: [174][100/1251]	 loss 4.39057	 cls_loss: 0.2055 cluster_loss: 1.2037 sup_con_loss: 0.3481 contrastive_loss: 5.2522 nll_loss: 0.0004 
2023-11-02 20:47:47.579 | INFO     | __main__:train:314 - Epoch: [174][200/1251]	 loss 4.32388	 cls_loss: 0.2099 cluster_loss: 1.1690 sup_con_loss: 0.2155 contrastive_loss: 5.2531 nll_loss: 0.0006 
2023-11-02 20:51:33.503 | INFO     | __main__:train:314 - Epoch: [174][300/1251]	 loss 4.33700	 cls_loss: 0.2645 cluster_loss: 1.1778 sup_con_loss: 0.1755 contrastive_loss: 5.2556 nll_loss: 0.0013 
2023-11-02 20:55:18.371 | INFO     | __main__:train:314 - Epoch: [174][400/1251]	 loss 4.35797	 cls_loss: 0.2274 cluster_loss: 1.1835 sup_con_loss: 0.2639 contrastive_loss: 5.2549 nll_loss: 0.0010 
2023-11-02 20:59:02.802 | INFO     | __main__:train:314 - Epoch: [174][500/1251]	 loss 4.33642	 cls_loss: 0.2017 cluster_loss: 1.1957 sup_con_loss: 0.2072 contrastive_loss: 5.2547 nll_loss: 0.0006 
2023-11-02 21:02:47.887 | INFO     | __main__:train:314 - Epoch: [174][600/1251]	 loss 4.33856	 cls_loss: 0.2040 cluster_loss: 1.1694 sup_con_loss: 0.2547 contrastive_loss: 5.2570 nll_loss: 0.0009 
2023-11-02 21:06:32.241 | INFO     | __main__:train:314 - Epoch: [174][700/1251]	 loss 4.38141	 cls_loss: 0.2089 cluster_loss: 1.2135 sup_con_loss: 0.2938 contrastive_loss: 5.2557 nll_loss: 0.0005 
2023-11-02 21:10:16.785 | INFO     | __main__:train:314 - Epoch: [174][800/1251]	 loss 4.35611	 cls_loss: 0.2214 cluster_loss: 1.1717 sup_con_loss: 0.2919 contrastive_loss: 5.2525 nll_loss: 0.0008 
2023-11-02 21:14:03.492 | INFO     | __main__:train:314 - Epoch: [174][900/1251]	 loss 4.38584	 cls_loss: 0.2283 cluster_loss: 1.2150 sup_con_loss: 0.2786 contrastive_loss: 5.2580 nll_loss: 0.0010 
2023-11-02 21:17:48.420 | INFO     | __main__:train:314 - Epoch: [174][1000/1251]	 loss 4.39892	 cls_loss: 0.2076 cluster_loss: 1.2134 sup_con_loss: 0.3482 contrastive_loss: 5.2535 nll_loss: 0.0009 
2023-11-02 21:21:31.221 | INFO     | __main__:train:314 - Epoch: [174][1100/1251]	 loss 4.29327	 cls_loss: 0.2113 cluster_loss: 1.1418 sup_con_loss: 0.1786 contrastive_loss: 5.2517 nll_loss: 0.0010 
2023-11-02 21:25:14.199 | INFO     | __main__:train:314 - Epoch: [174][1200/1251]	 loss 4.38622	 cls_loss: 0.1891 cluster_loss: 1.1901 sup_con_loss: 0.3801 contrastive_loss: 5.2504 nll_loss: 0.0006 
2023-11-02 21:27:05.702 | INFO     | __main__:train:319 - Train Epoch: 174 Avg Loss: 4.3686 
2023-11-02 21:27:05.710 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 21:45:32.090 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 174, Train ACC Unlabelled_v2: All 0.6225 | Old 0.7925 | New 0.5371
2023-11-02 21:45:32.332 | INFO     | __main__:main:205 - Train Accuracies: All 0.6225 | Old 0.7925 | New 0.5371
2023-11-02 21:45:35.849 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 21:45:48.382 | INFO     | __main__:train:314 - Epoch: [175][0/1251]	 loss 4.46410	 cls_loss: 0.2310 cluster_loss: 1.2635 sup_con_loss: 0.4111 contrastive_loss: 5.2572 nll_loss: 0.0009 
2023-11-02 21:49:32.401 | INFO     | __main__:train:314 - Epoch: [175][100/1251]	 loss 4.37010	 cls_loss: 0.2435 cluster_loss: 1.1997 sup_con_loss: 0.2572 contrastive_loss: 5.2525 nll_loss: 0.0009 
2023-11-02 21:53:19.551 | INFO     | __main__:train:314 - Epoch: [175][200/1251]	 loss 4.37569	 cls_loss: 0.2297 cluster_loss: 1.2128 sup_con_loss: 0.2617 contrastive_loss: 5.2534 nll_loss: 0.0007 
2023-11-02 21:57:03.842 | INFO     | __main__:train:314 - Epoch: [175][300/1251]	 loss 4.30242	 cls_loss: 0.2084 cluster_loss: 1.1355 sup_con_loss: 0.2228 contrastive_loss: 5.2504 nll_loss: 0.0006 
2023-11-02 22:00:47.829 | INFO     | __main__:train:314 - Epoch: [175][400/1251]	 loss 4.40810	 cls_loss: 0.2098 cluster_loss: 1.2244 sup_con_loss: 0.3441 contrastive_loss: 5.2578 nll_loss: 0.0008 
2023-11-02 22:04:34.683 | INFO     | __main__:train:314 - Epoch: [175][500/1251]	 loss 4.38519	 cls_loss: 0.2193 cluster_loss: 1.2343 sup_con_loss: 0.2555 contrastive_loss: 5.2553 nll_loss: 0.0008 
2023-11-02 22:08:19.017 | INFO     | __main__:train:314 - Epoch: [175][600/1251]	 loss 4.34628	 cls_loss: 0.2009 cluster_loss: 1.1845 sup_con_loss: 0.2582 contrastive_loss: 5.2534 nll_loss: 0.0010 
2023-11-02 22:12:04.259 | INFO     | __main__:train:314 - Epoch: [175][700/1251]	 loss 4.35926	 cls_loss: 0.2203 cluster_loss: 1.1889 sup_con_loss: 0.2676 contrastive_loss: 5.2538 nll_loss: 0.0008 
2023-11-02 22:15:47.593 | INFO     | __main__:train:314 - Epoch: [175][800/1251]	 loss 4.34442	 cls_loss: 0.2123 cluster_loss: 1.1910 sup_con_loss: 0.2246 contrastive_loss: 5.2558 nll_loss: 0.0011 
2023-11-02 22:19:31.709 | INFO     | __main__:train:314 - Epoch: [175][900/1251]	 loss 4.36310	 cls_loss: 0.2340 cluster_loss: 1.1813 sup_con_loss: 0.2805 contrastive_loss: 5.2526 nll_loss: 0.0010 
2023-11-02 22:23:16.503 | INFO     | __main__:train:314 - Epoch: [175][1000/1251]	 loss 4.33280	 cls_loss: 0.2293 cluster_loss: 1.1574 sup_con_loss: 0.2446 contrastive_loss: 5.2523 nll_loss: 0.0006 
2023-11-02 22:26:59.561 | INFO     | __main__:train:314 - Epoch: [175][1100/1251]	 loss 4.34654	 cls_loss: 0.2052 cluster_loss: 1.2007 sup_con_loss: 0.2198 contrastive_loss: 5.2564 nll_loss: 0.0007 
2023-11-02 22:30:44.374 | INFO     | __main__:train:314 - Epoch: [175][1200/1251]	 loss 4.33313	 cls_loss: 0.2148 cluster_loss: 1.1906 sup_con_loss: 0.1879 contrastive_loss: 5.2576 nll_loss: 0.0008 
2023-11-02 22:32:35.602 | INFO     | __main__:train:319 - Train Epoch: 175 Avg Loss: 4.3694 
2023-11-02 22:32:35.611 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 22:51:01.221 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 175, Train ACC Unlabelled_v2: All 0.6228 | Old 0.7931 | New 0.5372
2023-11-02 22:51:01.515 | INFO     | __main__:main:205 - Train Accuracies: All 0.6228 | Old 0.7931 | New 0.5372
2023-11-02 22:51:04.882 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 22:51:20.972 | INFO     | __main__:train:314 - Epoch: [176][0/1251]	 loss 4.33108	 cls_loss: 0.2278 cluster_loss: 1.1824 sup_con_loss: 0.1931 contrastive_loss: 5.2528 nll_loss: 0.0009 
2023-11-02 22:55:04.862 | INFO     | __main__:train:314 - Epoch: [176][100/1251]	 loss 4.43628	 cls_loss: 0.2185 cluster_loss: 1.2670 sup_con_loss: 0.3418 contrastive_loss: 5.2553 nll_loss: 0.0007 
2023-11-02 22:58:47.703 | INFO     | __main__:train:314 - Epoch: [176][200/1251]	 loss 4.41000	 cls_loss: 0.2269 cluster_loss: 1.2276 sup_con_loss: 0.3292 contrastive_loss: 5.2568 nll_loss: 0.0005 
2023-11-02 23:02:32.365 | INFO     | __main__:train:314 - Epoch: [176][300/1251]	 loss 4.42785	 cls_loss: 0.2273 cluster_loss: 1.2651 sup_con_loss: 0.3062 contrastive_loss: 5.2591 nll_loss: 0.0004 
2023-11-02 23:06:18.592 | INFO     | __main__:train:314 - Epoch: [176][400/1251]	 loss 4.41243	 cls_loss: 0.2039 cluster_loss: 1.2305 sup_con_loss: 0.3550 contrastive_loss: 5.2560 nll_loss: 0.0006 
2023-11-02 23:10:04.352 | INFO     | __main__:train:314 - Epoch: [176][500/1251]	 loss 4.37663	 cls_loss: 0.2288 cluster_loss: 1.2159 sup_con_loss: 0.2575 contrastive_loss: 5.2550 nll_loss: 0.0004 
2023-11-02 23:13:50.906 | INFO     | __main__:train:314 - Epoch: [176][600/1251]	 loss 4.35488	 cls_loss: 0.2164 cluster_loss: 1.2224 sup_con_loss: 0.1862 contrastive_loss: 5.2590 nll_loss: 0.0011 
2023-11-02 23:17:44.506 | INFO     | __main__:train:314 - Epoch: [176][700/1251]	 loss 4.35056	 cls_loss: 0.2137 cluster_loss: 1.1895 sup_con_loss: 0.2471 contrastive_loss: 5.2543 nll_loss: 0.0008 
2023-11-02 23:21:32.319 | INFO     | __main__:train:314 - Epoch: [176][800/1251]	 loss 4.31289	 cls_loss: 0.2456 cluster_loss: 1.1423 sup_con_loss: 0.2003 contrastive_loss: 5.2517 nll_loss: 0.0008 
2023-11-02 23:25:18.885 | INFO     | __main__:train:314 - Epoch: [176][900/1251]	 loss 4.43593	 cls_loss: 0.2041 cluster_loss: 1.2560 sup_con_loss: 0.3739 contrastive_loss: 5.2559 nll_loss: 0.0009 
2023-11-02 23:29:03.219 | INFO     | __main__:train:314 - Epoch: [176][1000/1251]	 loss 4.39242	 cls_loss: 0.2233 cluster_loss: 1.2269 sup_con_loss: 0.2822 contrastive_loss: 5.2572 nll_loss: 0.0008 
2023-11-02 23:32:48.070 | INFO     | __main__:train:314 - Epoch: [176][1100/1251]	 loss 4.35292	 cls_loss: 0.2063 cluster_loss: 1.1588 sup_con_loss: 0.3211 contrastive_loss: 5.2531 nll_loss: 0.0006 
2023-11-02 23:36:32.042 | INFO     | __main__:train:314 - Epoch: [176][1200/1251]	 loss 4.42548	 cls_loss: 0.2168 cluster_loss: 1.2776 sup_con_loss: 0.2818 contrastive_loss: 5.2612 nll_loss: 0.0007 
2023-11-02 23:38:22.895 | INFO     | __main__:train:319 - Train Epoch: 176 Avg Loss: 4.3673 
2023-11-02 23:38:22.903 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-02 23:57:52.537 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 176, Train ACC Unlabelled_v2: All 0.6231 | Old 0.7929 | New 0.5377
2023-11-02 23:57:52.733 | INFO     | __main__:main:205 - Train Accuracies: All 0.6231 | Old 0.7929 | New 0.5377
2023-11-02 23:57:56.288 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-02 23:58:10.566 | INFO     | __main__:train:314 - Epoch: [177][0/1251]	 loss 4.38590	 cls_loss: 0.2106 cluster_loss: 1.2184 sup_con_loss: 0.2965 contrastive_loss: 5.2548 nll_loss: 0.0008 
2023-11-03 00:01:53.473 | INFO     | __main__:train:314 - Epoch: [177][100/1251]	 loss 4.30435	 cls_loss: 0.2256 cluster_loss: 1.1402 sup_con_loss: 0.2001 contrastive_loss: 5.2513 nll_loss: 0.0009 
2023-11-03 00:05:41.217 | INFO     | __main__:train:314 - Epoch: [177][200/1251]	 loss 4.40420	 cls_loss: 0.2245 cluster_loss: 1.2183 sup_con_loss: 0.3378 contrastive_loss: 5.2531 nll_loss: 0.0010 
2023-11-03 00:09:26.957 | INFO     | __main__:train:314 - Epoch: [177][300/1251]	 loss 4.36515	 cls_loss: 0.2328 cluster_loss: 1.1631 sup_con_loss: 0.3199 contrastive_loss: 5.2529 nll_loss: 0.0013 
2023-11-03 00:13:10.816 | INFO     | __main__:train:314 - Epoch: [177][400/1251]	 loss 4.38996	 cls_loss: 0.2044 cluster_loss: 1.2381 sup_con_loss: 0.2734 contrastive_loss: 5.2571 nll_loss: 0.0008 
2023-11-03 00:16:55.120 | INFO     | __main__:train:314 - Epoch: [177][500/1251]	 loss 4.39307	 cls_loss: 0.2306 cluster_loss: 1.2197 sup_con_loss: 0.2975 contrastive_loss: 5.2534 nll_loss: 0.0007 
2023-11-03 00:20:38.783 | INFO     | __main__:train:314 - Epoch: [177][600/1251]	 loss 4.37455	 cls_loss: 0.2132 cluster_loss: 1.2336 sup_con_loss: 0.2283 contrastive_loss: 5.2580 nll_loss: 0.0004 
2023-11-03 00:24:22.406 | INFO     | __main__:train:314 - Epoch: [177][700/1251]	 loss 4.39896	 cls_loss: 0.2400 cluster_loss: 1.2033 sup_con_loss: 0.3297 contrastive_loss: 5.2566 nll_loss: 0.0006 
2023-11-03 00:28:07.978 | INFO     | __main__:train:314 - Epoch: [177][800/1251]	 loss 4.33673	 cls_loss: 0.2020 cluster_loss: 1.1761 sup_con_loss: 0.2492 contrastive_loss: 5.2521 nll_loss: 0.0005 
2023-11-03 00:31:52.820 | INFO     | __main__:train:314 - Epoch: [177][900/1251]	 loss 4.35825	 cls_loss: 0.2109 cluster_loss: 1.2221 sup_con_loss: 0.2118 contrastive_loss: 5.2543 nll_loss: 0.0006 
2023-11-03 00:35:37.001 | INFO     | __main__:train:314 - Epoch: [177][1000/1251]	 loss 4.37276	 cls_loss: 0.2030 cluster_loss: 1.2001 sup_con_loss: 0.3048 contrastive_loss: 5.2525 nll_loss: 0.0009 
2023-11-03 00:39:24.860 | INFO     | __main__:train:314 - Epoch: [177][1100/1251]	 loss 4.33689	 cls_loss: 0.2112 cluster_loss: 1.1742 sup_con_loss: 0.2440 contrastive_loss: 5.2517 nll_loss: 0.0007 
2023-11-03 00:43:14.415 | INFO     | __main__:train:314 - Epoch: [177][1200/1251]	 loss 4.32059	 cls_loss: 0.2249 cluster_loss: 1.1815 sup_con_loss: 0.1658 contrastive_loss: 5.2543 nll_loss: 0.0006 
2023-11-03 00:45:09.375 | INFO     | __main__:train:319 - Train Epoch: 177 Avg Loss: 4.3655 
2023-11-03 00:45:09.379 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 01:03:41.070 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 177, Train ACC Unlabelled_v2: All 0.6233 | Old 0.7938 | New 0.5376
2023-11-03 01:03:41.309 | INFO     | __main__:main:205 - Train Accuracies: All 0.6233 | Old 0.7938 | New 0.5376
2023-11-03 01:03:45.826 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 01:04:12.484 | INFO     | __main__:train:314 - Epoch: [178][0/1251]	 loss 4.31630	 cls_loss: 0.2059 cluster_loss: 1.1770 sup_con_loss: 0.1785 contrastive_loss: 5.2547 nll_loss: 0.0011 
2023-11-03 01:07:57.693 | INFO     | __main__:train:314 - Epoch: [178][100/1251]	 loss 4.36112	 cls_loss: 0.2116 cluster_loss: 1.1886 sup_con_loss: 0.2795 contrastive_loss: 5.2549 nll_loss: 0.0010 
2023-11-03 01:11:41.715 | INFO     | __main__:train:314 - Epoch: [178][200/1251]	 loss 4.34744	 cls_loss: 0.2073 cluster_loss: 1.1554 sup_con_loss: 0.3132 contrastive_loss: 5.2510 nll_loss: 0.0011 
2023-11-03 01:15:33.473 | INFO     | __main__:train:314 - Epoch: [178][300/1251]	 loss 4.36542	 cls_loss: 0.2180 cluster_loss: 1.2030 sup_con_loss: 0.2595 contrastive_loss: 5.2542 nll_loss: 0.0011 
2023-11-03 01:19:19.112 | INFO     | __main__:train:314 - Epoch: [178][400/1251]	 loss 4.34212	 cls_loss: 0.1978 cluster_loss: 1.1868 sup_con_loss: 0.2408 contrastive_loss: 5.2559 nll_loss: 0.0009 
2023-11-03 01:23:03.439 | INFO     | __main__:train:314 - Epoch: [178][500/1251]	 loss 4.41686	 cls_loss: 0.2037 cluster_loss: 1.2331 sup_con_loss: 0.3628 contrastive_loss: 5.2559 nll_loss: 0.0007 
2023-11-03 01:26:48.059 | INFO     | __main__:train:314 - Epoch: [178][600/1251]	 loss 4.35211	 cls_loss: 0.2411 cluster_loss: 1.2001 sup_con_loss: 0.1989 contrastive_loss: 5.2574 nll_loss: 0.0007 
2023-11-03 01:30:35.516 | INFO     | __main__:train:314 - Epoch: [178][700/1251]	 loss 4.40123	 cls_loss: 0.2325 cluster_loss: 1.2075 sup_con_loss: 0.3377 contrastive_loss: 5.2548 nll_loss: 0.0011 
2023-11-03 01:34:20.340 | INFO     | __main__:train:314 - Epoch: [178][800/1251]	 loss 4.36376	 cls_loss: 0.2108 cluster_loss: 1.1777 sup_con_loss: 0.3127 contrastive_loss: 5.2521 nll_loss: 0.0012 
2023-11-03 01:38:04.887 | INFO     | __main__:train:314 - Epoch: [178][900/1251]	 loss 4.39549	 cls_loss: 0.2139 cluster_loss: 1.2361 sup_con_loss: 0.2857 contrastive_loss: 5.2564 nll_loss: 0.0005 
2023-11-03 01:41:48.471 | INFO     | __main__:train:314 - Epoch: [178][1000/1251]	 loss 4.30929	 cls_loss: 0.1991 cluster_loss: 1.1411 sup_con_loss: 0.2401 contrastive_loss: 5.2508 nll_loss: 0.0008 
2023-11-03 01:45:31.874 | INFO     | __main__:train:314 - Epoch: [178][1100/1251]	 loss 4.35378	 cls_loss: 0.2297 cluster_loss: 1.1747 sup_con_loss: 0.2679 contrastive_loss: 5.2538 nll_loss: 0.0011 
2023-11-03 01:49:15.735 | INFO     | __main__:train:314 - Epoch: [178][1200/1251]	 loss 4.29852	 cls_loss: 0.2012 cluster_loss: 1.1662 sup_con_loss: 0.1562 contrastive_loss: 5.2533 nll_loss: 0.0008 
2023-11-03 01:51:07.651 | INFO     | __main__:train:319 - Train Epoch: 178 Avg Loss: 4.3652 
2023-11-03 01:51:07.654 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 02:10:00.748 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 178, Train ACC Unlabelled_v2: All 0.6232 | Old 0.7941 | New 0.5373
2023-11-03 02:10:01.073 | INFO     | __main__:main:205 - Train Accuracies: All 0.6232 | Old 0.7941 | New 0.5373
2023-11-03 02:10:04.216 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 02:10:18.284 | INFO     | __main__:train:314 - Epoch: [179][0/1251]	 loss 4.32429	 cls_loss: 0.2513 cluster_loss: 1.1451 sup_con_loss: 0.2170 contrastive_loss: 5.2532 nll_loss: 0.0014 
2023-11-03 02:14:03.299 | INFO     | __main__:train:314 - Epoch: [179][100/1251]	 loss 4.34275	 cls_loss: 0.2346 cluster_loss: 1.1715 sup_con_loss: 0.2370 contrastive_loss: 5.2547 nll_loss: 0.0007 
2023-11-03 02:17:47.654 | INFO     | __main__:train:314 - Epoch: [179][200/1251]	 loss 4.35890	 cls_loss: 0.2194 cluster_loss: 1.1814 sup_con_loss: 0.2819 contrastive_loss: 5.2536 nll_loss: 0.0007 
2023-11-03 02:21:30.722 | INFO     | __main__:train:314 - Epoch: [179][300/1251]	 loss 4.35042	 cls_loss: 0.2191 cluster_loss: 1.2028 sup_con_loss: 0.2153 contrastive_loss: 5.2540 nll_loss: 0.0014 
2023-11-03 02:25:15.597 | INFO     | __main__:train:314 - Epoch: [179][400/1251]	 loss 4.36577	 cls_loss: 0.2083 cluster_loss: 1.1905 sup_con_loss: 0.3000 contrastive_loss: 5.2514 nll_loss: 0.0006 
2023-11-03 02:29:02.318 | INFO     | __main__:train:314 - Epoch: [179][500/1251]	 loss 4.35304	 cls_loss: 0.2059 cluster_loss: 1.1786 sup_con_loss: 0.2829 contrastive_loss: 5.2535 nll_loss: 0.0011 
2023-11-03 02:32:45.857 | INFO     | __main__:train:314 - Epoch: [179][600/1251]	 loss 4.36849	 cls_loss: 0.2325 cluster_loss: 1.1710 sup_con_loss: 0.3153 contrastive_loss: 5.2530 nll_loss: 0.0011 
2023-11-03 02:36:32.079 | INFO     | __main__:train:314 - Epoch: [179][700/1251]	 loss 4.34842	 cls_loss: 0.2198 cluster_loss: 1.1890 sup_con_loss: 0.2376 contrastive_loss: 5.2532 nll_loss: 0.0009 
2023-11-03 02:40:15.726 | INFO     | __main__:train:314 - Epoch: [179][800/1251]	 loss 4.35777	 cls_loss: 0.2136 cluster_loss: 1.2046 sup_con_loss: 0.2359 contrastive_loss: 5.2560 nll_loss: 0.0011 
2023-11-03 02:44:08.217 | INFO     | __main__:train:314 - Epoch: [179][900/1251]	 loss 4.37241	 cls_loss: 0.2268 cluster_loss: 1.2054 sup_con_loss: 0.2674 contrastive_loss: 5.2537 nll_loss: 0.0010 
2023-11-03 02:47:54.423 | INFO     | __main__:train:314 - Epoch: [179][1000/1251]	 loss 4.30551	 cls_loss: 0.2011 cluster_loss: 1.1652 sup_con_loss: 0.1773 contrastive_loss: 5.2540 nll_loss: 0.0006 
2023-11-03 02:51:40.398 | INFO     | __main__:train:314 - Epoch: [179][1100/1251]	 loss 4.36925	 cls_loss: 0.2533 cluster_loss: 1.1680 sup_con_loss: 0.3033 contrastive_loss: 5.2524 nll_loss: 0.0011 
2023-11-03 02:55:24.700 | INFO     | __main__:train:314 - Epoch: [179][1200/1251]	 loss 4.33495	 cls_loss: 0.1900 cluster_loss: 1.2096 sup_con_loss: 0.1868 contrastive_loss: 5.2548 nll_loss: 0.0012 
2023-11-03 02:57:17.254 | INFO     | __main__:train:319 - Train Epoch: 179 Avg Loss: 4.3614 
2023-11-03 02:57:17.319 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 03:15:22.547 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 179, Train ACC Unlabelled_v2: All 0.6231 | Old 0.7941 | New 0.5372
2023-11-03 03:15:22.753 | INFO     | __main__:main:205 - Train Accuracies: All 0.6231 | Old 0.7941 | New 0.5372
2023-11-03 03:15:26.374 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 03:15:39.335 | INFO     | __main__:train:314 - Epoch: [180][0/1251]	 loss 4.32388	 cls_loss: 0.2217 cluster_loss: 1.1502 sup_con_loss: 0.2416 contrastive_loss: 5.2515 nll_loss: 0.0007 
2023-11-03 03:19:28.887 | INFO     | __main__:train:314 - Epoch: [180][100/1251]	 loss 4.35412	 cls_loss: 0.2143 cluster_loss: 1.1810 sup_con_loss: 0.2729 contrastive_loss: 5.2545 nll_loss: 0.0006 
2023-11-03 03:23:13.613 | INFO     | __main__:train:314 - Epoch: [180][200/1251]	 loss 4.34381	 cls_loss: 0.1855 cluster_loss: 1.1871 sup_con_loss: 0.2598 contrastive_loss: 5.2548 nll_loss: 0.0007 
2023-11-03 03:27:11.292 | INFO     | __main__:train:314 - Epoch: [180][300/1251]	 loss 4.35015	 cls_loss: 0.2369 cluster_loss: 1.1897 sup_con_loss: 0.2191 contrastive_loss: 5.2557 nll_loss: 0.0010 
2023-11-03 03:30:58.554 | INFO     | __main__:train:314 - Epoch: [180][400/1251]	 loss 4.31875	 cls_loss: 0.2148 cluster_loss: 1.1671 sup_con_loss: 0.1996 contrastive_loss: 5.2524 nll_loss: 0.0010 
2023-11-03 03:34:43.593 | INFO     | __main__:train:314 - Epoch: [180][500/1251]	 loss 4.37514	 cls_loss: 0.2422 cluster_loss: 1.2049 sup_con_loss: 0.2578 contrastive_loss: 5.2552 nll_loss: 0.0011 
2023-11-03 03:38:29.106 | INFO     | __main__:train:314 - Epoch: [180][600/1251]	 loss 4.37325	 cls_loss: 0.2243 cluster_loss: 1.1957 sup_con_loss: 0.2916 contrastive_loss: 5.2532 nll_loss: 0.0009 
2023-11-03 03:42:15.812 | INFO     | __main__:train:314 - Epoch: [180][700/1251]	 loss 4.41998	 cls_loss: 0.2182 cluster_loss: 1.2129 sup_con_loss: 0.4003 contrastive_loss: 5.2531 nll_loss: 0.0006 
2023-11-03 03:46:02.421 | INFO     | __main__:train:314 - Epoch: [180][800/1251]	 loss 4.35431	 cls_loss: 0.2068 cluster_loss: 1.1874 sup_con_loss: 0.2693 contrastive_loss: 5.2537 nll_loss: 0.0010 
2023-11-03 03:49:48.692 | INFO     | __main__:train:314 - Epoch: [180][900/1251]	 loss 4.37717	 cls_loss: 0.2127 cluster_loss: 1.1840 sup_con_loss: 0.3380 contrastive_loss: 5.2525 nll_loss: 0.0007 
2023-11-03 03:53:32.705 | INFO     | __main__:train:314 - Epoch: [180][1000/1251]	 loss 4.35707	 cls_loss: 0.2366 cluster_loss: 1.2008 sup_con_loss: 0.2253 contrastive_loss: 5.2522 nll_loss: 0.0009 
2023-11-03 03:57:16.839 | INFO     | __main__:train:314 - Epoch: [180][1100/1251]	 loss 4.36163	 cls_loss: 0.2350 cluster_loss: 1.2106 sup_con_loss: 0.2207 contrastive_loss: 5.2527 nll_loss: 0.0010 
2023-11-03 04:01:02.713 | INFO     | __main__:train:314 - Epoch: [180][1200/1251]	 loss 4.33511	 cls_loss: 0.1980 cluster_loss: 1.1835 sup_con_loss: 0.2323 contrastive_loss: 5.2532 nll_loss: 0.0007 
2023-11-03 04:02:54.244 | INFO     | __main__:train:319 - Train Epoch: 180 Avg Loss: 4.3621 
2023-11-03 04:02:54.249 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 04:20:41.161 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 180, Train ACC Unlabelled_v2: All 0.6234 | Old 0.7940 | New 0.5376
2023-11-03 04:20:41.420 | INFO     | __main__:main:205 - Train Accuracies: All 0.6234 | Old 0.7940 | New 0.5376
2023-11-03 04:20:44.308 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 04:20:57.826 | INFO     | __main__:train:314 - Epoch: [181][0/1251]	 loss 4.37203	 cls_loss: 0.2046 cluster_loss: 1.2055 sup_con_loss: 0.2870 contrastive_loss: 5.2547 nll_loss: 0.0008 
2023-11-03 04:24:43.129 | INFO     | __main__:train:314 - Epoch: [181][100/1251]	 loss 4.33059	 cls_loss: 0.2009 cluster_loss: 1.1674 sup_con_loss: 0.2452 contrastive_loss: 5.2539 nll_loss: 0.0007 
2023-11-03 04:28:26.322 | INFO     | __main__:train:314 - Epoch: [181][200/1251]	 loss 4.36104	 cls_loss: 0.2367 cluster_loss: 1.1996 sup_con_loss: 0.2344 contrastive_loss: 5.2546 nll_loss: 0.0010 
2023-11-03 04:32:11.310 | INFO     | __main__:train:314 - Epoch: [181][300/1251]	 loss 4.36911	 cls_loss: 0.2340 cluster_loss: 1.1838 sup_con_loss: 0.2946 contrastive_loss: 5.2522 nll_loss: 0.0007 
2023-11-03 04:35:54.783 | INFO     | __main__:train:314 - Epoch: [181][400/1251]	 loss 4.37258	 cls_loss: 0.1971 cluster_loss: 1.1911 sup_con_loss: 0.3232 contrastive_loss: 5.2544 nll_loss: 0.0009 
2023-11-03 04:39:42.333 | INFO     | __main__:train:314 - Epoch: [181][500/1251]	 loss 4.38880	 cls_loss: 0.2482 cluster_loss: 1.2241 sup_con_loss: 0.2475 contrastive_loss: 5.2599 nll_loss: 0.0008 
2023-11-03 04:43:25.631 | INFO     | __main__:train:314 - Epoch: [181][600/1251]	 loss 4.41801	 cls_loss: 0.2097 cluster_loss: 1.2396 sup_con_loss: 0.3378 contrastive_loss: 5.2617 nll_loss: 0.0006 
2023-11-03 04:47:09.287 | INFO     | __main__:train:314 - Epoch: [181][700/1251]	 loss 4.34422	 cls_loss: 0.2021 cluster_loss: 1.1786 sup_con_loss: 0.2670 contrastive_loss: 5.2514 nll_loss: 0.0005 
2023-11-03 04:50:53.984 | INFO     | __main__:train:314 - Epoch: [181][800/1251]	 loss 4.33211	 cls_loss: 0.2033 cluster_loss: 1.1889 sup_con_loss: 0.2066 contrastive_loss: 5.2528 nll_loss: 0.0015 
2023-11-03 04:54:38.245 | INFO     | __main__:train:314 - Epoch: [181][900/1251]	 loss 4.36305	 cls_loss: 0.1951 cluster_loss: 1.2148 sup_con_loss: 0.2484 contrastive_loss: 5.2577 nll_loss: 0.0006 
2023-11-03 04:58:22.335 | INFO     | __main__:train:314 - Epoch: [181][1000/1251]	 loss 4.32280	 cls_loss: 0.1982 cluster_loss: 1.1390 sup_con_loss: 0.2824 contrastive_loss: 5.2510 nll_loss: 0.0011 
2023-11-03 05:02:05.800 | INFO     | __main__:train:314 - Epoch: [181][1100/1251]	 loss 4.28478	 cls_loss: 0.1894 cluster_loss: 1.1526 sup_con_loss: 0.1557 contrastive_loss: 5.2527 nll_loss: 0.0005 
2023-11-03 05:05:49.923 | INFO     | __main__:train:314 - Epoch: [181][1200/1251]	 loss 4.35225	 cls_loss: 0.2144 cluster_loss: 1.1925 sup_con_loss: 0.2479 contrastive_loss: 5.2531 nll_loss: 0.0008 
2023-11-03 05:07:41.419 | INFO     | __main__:train:319 - Train Epoch: 181 Avg Loss: 4.3623 
2023-11-03 05:07:41.427 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 05:25:09.405 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 181, Train ACC Unlabelled_v2: All 0.6236 | Old 0.7947 | New 0.5376
2023-11-03 05:25:09.677 | INFO     | __main__:main:205 - Train Accuracies: All 0.6236 | Old 0.7947 | New 0.5376
2023-11-03 05:25:13.187 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 05:25:25.887 | INFO     | __main__:train:314 - Epoch: [182][0/1251]	 loss 4.39931	 cls_loss: 0.2052 cluster_loss: 1.2506 sup_con_loss: 0.2705 contrastive_loss: 5.2598 nll_loss: 0.0011 
2023-11-03 05:29:09.816 | INFO     | __main__:train:314 - Epoch: [182][100/1251]	 loss 4.36212	 cls_loss: 0.1945 cluster_loss: 1.1816 sup_con_loss: 0.3136 contrastive_loss: 5.2540 nll_loss: 0.0011 
2023-11-03 05:32:55.233 | INFO     | __main__:train:314 - Epoch: [182][200/1251]	 loss 4.36917	 cls_loss: 0.2310 cluster_loss: 1.2066 sup_con_loss: 0.2469 contrastive_loss: 5.2575 nll_loss: 0.0003 
2023-11-03 05:36:40.688 | INFO     | __main__:train:314 - Epoch: [182][300/1251]	 loss 4.32840	 cls_loss: 0.2055 cluster_loss: 1.1851 sup_con_loss: 0.2034 contrastive_loss: 5.2522 nll_loss: 0.0010 
2023-11-03 05:40:26.249 | INFO     | __main__:train:314 - Epoch: [182][400/1251]	 loss 4.35966	 cls_loss: 0.2013 cluster_loss: 1.2011 sup_con_loss: 0.2669 contrastive_loss: 5.2531 nll_loss: 0.0006 
2023-11-03 05:44:10.776 | INFO     | __main__:train:314 - Epoch: [182][500/1251]	 loss 4.34474	 cls_loss: 0.2012 cluster_loss: 1.1733 sup_con_loss: 0.2799 contrastive_loss: 5.2511 nll_loss: 0.0005 
2023-11-03 05:47:54.979 | INFO     | __main__:train:314 - Epoch: [182][600/1251]	 loss 4.34360	 cls_loss: 0.2211 cluster_loss: 1.1664 sup_con_loss: 0.2635 contrastive_loss: 5.2535 nll_loss: 0.0011 
2023-11-03 05:51:39.947 | INFO     | __main__:train:314 - Epoch: [182][700/1251]	 loss 4.34498	 cls_loss: 0.2213 cluster_loss: 1.1757 sup_con_loss: 0.2459 contrastive_loss: 5.2560 nll_loss: 0.0009 
2023-11-03 05:55:25.001 | INFO     | __main__:train:314 - Epoch: [182][800/1251]	 loss 4.37675	 cls_loss: 0.2068 cluster_loss: 1.2067 sup_con_loss: 0.2977 contrastive_loss: 5.2543 nll_loss: 0.0005 
2023-11-03 05:59:09.994 | INFO     | __main__:train:314 - Epoch: [182][900/1251]	 loss 4.31711	 cls_loss: 0.1987 cluster_loss: 1.1679 sup_con_loss: 0.2082 contrastive_loss: 5.2538 nll_loss: 0.0006 
2023-11-03 06:02:57.960 | INFO     | __main__:train:314 - Epoch: [182][1000/1251]	 loss 4.43334	 cls_loss: 0.2449 cluster_loss: 1.2471 sup_con_loss: 0.3392 contrastive_loss: 5.2580 nll_loss: 0.0005 
2023-11-03 06:06:42.366 | INFO     | __main__:train:314 - Epoch: [182][1100/1251]	 loss 4.35623	 cls_loss: 0.2020 cluster_loss: 1.2007 sup_con_loss: 0.2514 contrastive_loss: 5.2564 nll_loss: 0.0005 
2023-11-03 06:10:25.820 | INFO     | __main__:train:314 - Epoch: [182][1200/1251]	 loss 4.36867	 cls_loss: 0.2051 cluster_loss: 1.2003 sup_con_loss: 0.2914 contrastive_loss: 5.2527 nll_loss: 0.0005 
2023-11-03 06:12:18.032 | INFO     | __main__:train:319 - Train Epoch: 182 Avg Loss: 4.3603 
2023-11-03 06:12:18.040 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 06:29:49.223 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 182, Train ACC Unlabelled_v2: All 0.6237 | Old 0.7942 | New 0.5379
2023-11-03 06:29:49.465 | INFO     | __main__:main:205 - Train Accuracies: All 0.6237 | Old 0.7942 | New 0.5379
2023-11-03 06:29:52.636 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 06:30:06.732 | INFO     | __main__:train:314 - Epoch: [183][0/1251]	 loss 4.31744	 cls_loss: 0.2164 cluster_loss: 1.1783 sup_con_loss: 0.1731 contrastive_loss: 5.2534 nll_loss: 0.0005 
2023-11-03 06:33:51.779 | INFO     | __main__:train:314 - Epoch: [183][100/1251]	 loss 4.34367	 cls_loss: 0.2210 cluster_loss: 1.1839 sup_con_loss: 0.2317 contrastive_loss: 5.2540 nll_loss: 0.0006 
2023-11-03 06:37:36.034 | INFO     | __main__:train:314 - Epoch: [183][200/1251]	 loss 4.35244	 cls_loss: 0.2436 cluster_loss: 1.1913 sup_con_loss: 0.2166 contrastive_loss: 5.2560 nll_loss: 0.0006 
2023-11-03 06:41:20.102 | INFO     | __main__:train:314 - Epoch: [183][300/1251]	 loss 4.39180	 cls_loss: 0.2111 cluster_loss: 1.2324 sup_con_loss: 0.2871 contrastive_loss: 5.2550 nll_loss: 0.0007 
2023-11-03 06:45:03.528 | INFO     | __main__:train:314 - Epoch: [183][400/1251]	 loss 4.32825	 cls_loss: 0.2058 cluster_loss: 1.1853 sup_con_loss: 0.2015 contrastive_loss: 5.2530 nll_loss: 0.0008 
2023-11-03 06:48:50.362 | INFO     | __main__:train:314 - Epoch: [183][500/1251]	 loss 4.36743	 cls_loss: 0.2196 cluster_loss: 1.1894 sup_con_loss: 0.2944 contrastive_loss: 5.2515 nll_loss: 0.0009 
2023-11-03 06:52:34.066 | INFO     | __main__:train:314 - Epoch: [183][600/1251]	 loss 4.35022	 cls_loss: 0.2245 cluster_loss: 1.1929 sup_con_loss: 0.2252 contrastive_loss: 5.2555 nll_loss: 0.0014 
2023-11-03 06:56:18.076 | INFO     | __main__:train:314 - Epoch: [183][700/1251]	 loss 4.39276	 cls_loss: 0.2006 cluster_loss: 1.1969 sup_con_loss: 0.3724 contrastive_loss: 5.2513 nll_loss: 0.0008 
2023-11-03 07:00:02.552 | INFO     | __main__:train:314 - Epoch: [183][800/1251]	 loss 4.34357	 cls_loss: 0.2265 cluster_loss: 1.1589 sup_con_loss: 0.2711 contrastive_loss: 5.2542 nll_loss: 0.0009 
2023-11-03 07:03:48.266 | INFO     | __main__:train:314 - Epoch: [183][900/1251]	 loss 4.30022	 cls_loss: 0.2085 cluster_loss: 1.1533 sup_con_loss: 0.1793 contrastive_loss: 5.2527 nll_loss: 0.0006 
2023-11-03 07:07:35.811 | INFO     | __main__:train:314 - Epoch: [183][1000/1251]	 loss 4.40091	 cls_loss: 0.2143 cluster_loss: 1.2166 sup_con_loss: 0.3406 contrastive_loss: 5.2544 nll_loss: 0.0006 
2023-11-03 07:11:19.102 | INFO     | __main__:train:314 - Epoch: [183][1100/1251]	 loss 4.35058	 cls_loss: 0.2172 cluster_loss: 1.2040 sup_con_loss: 0.2101 contrastive_loss: 5.2582 nll_loss: 0.0006 
2023-11-03 07:15:06.233 | INFO     | __main__:train:314 - Epoch: [183][1200/1251]	 loss 4.35880	 cls_loss: 0.2255 cluster_loss: 1.1709 sup_con_loss: 0.2914 contrastive_loss: 5.2552 nll_loss: 0.0009 
2023-11-03 07:16:57.614 | INFO     | __main__:train:319 - Train Epoch: 183 Avg Loss: 4.3597 
2023-11-03 07:16:57.625 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 07:34:36.491 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 183, Train ACC Unlabelled_v2: All 0.6236 | Old 0.7949 | New 0.5375
2023-11-03 07:34:36.693 | INFO     | __main__:main:205 - Train Accuracies: All 0.6236 | Old 0.7949 | New 0.5375
2023-11-03 07:34:40.384 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 07:34:57.118 | INFO     | __main__:train:314 - Epoch: [184][0/1251]	 loss 4.38084	 cls_loss: 0.2107 cluster_loss: 1.2120 sup_con_loss: 0.2960 contrastive_loss: 5.2542 nll_loss: 0.0005 
2023-11-03 07:38:47.037 | INFO     | __main__:train:314 - Epoch: [184][100/1251]	 loss 4.37094	 cls_loss: 0.2255 cluster_loss: 1.1997 sup_con_loss: 0.2734 contrastive_loss: 5.2551 nll_loss: 0.0007 
2023-11-03 07:42:31.284 | INFO     | __main__:train:314 - Epoch: [184][200/1251]	 loss 4.39309	 cls_loss: 0.2072 cluster_loss: 1.2047 sup_con_loss: 0.3511 contrastive_loss: 5.2524 nll_loss: 0.0006 
2023-11-03 07:46:16.679 | INFO     | __main__:train:314 - Epoch: [184][300/1251]	 loss 4.32481	 cls_loss: 0.2205 cluster_loss: 1.1588 sup_con_loss: 0.2304 contrastive_loss: 5.2507 nll_loss: 0.0009 
2023-11-03 07:50:02.111 | INFO     | __main__:train:314 - Epoch: [184][400/1251]	 loss 4.34143	 cls_loss: 0.2058 cluster_loss: 1.1716 sup_con_loss: 0.2640 contrastive_loss: 5.2534 nll_loss: 0.0008 
2023-11-03 07:53:48.341 | INFO     | __main__:train:314 - Epoch: [184][500/1251]	 loss 4.34572	 cls_loss: 0.2036 cluster_loss: 1.1705 sup_con_loss: 0.2840 contrastive_loss: 5.2520 nll_loss: 0.0005 
2023-11-03 07:57:34.086 | INFO     | __main__:train:314 - Epoch: [184][600/1251]	 loss 4.36898	 cls_loss: 0.2126 cluster_loss: 1.1975 sup_con_loss: 0.2910 contrastive_loss: 5.2518 nll_loss: 0.0007 
2023-11-03 08:01:18.715 | INFO     | __main__:train:314 - Epoch: [184][700/1251]	 loss 4.38361	 cls_loss: 0.2063 cluster_loss: 1.2338 sup_con_loss: 0.2592 contrastive_loss: 5.2582 nll_loss: 0.0009 
2023-11-03 08:05:03.788 | INFO     | __main__:train:314 - Epoch: [184][800/1251]	 loss 4.32184	 cls_loss: 0.1981 cluster_loss: 1.1982 sup_con_loss: 0.1662 contrastive_loss: 5.2534 nll_loss: 0.0008 
2023-11-03 08:08:47.764 | INFO     | __main__:train:314 - Epoch: [184][900/1251]	 loss 4.34615	 cls_loss: 0.2073 cluster_loss: 1.1866 sup_con_loss: 0.2497 contrastive_loss: 5.2523 nll_loss: 0.0010 
2023-11-03 08:12:32.068 | INFO     | __main__:train:314 - Epoch: [184][1000/1251]	 loss 4.33914	 cls_loss: 0.2049 cluster_loss: 1.1770 sup_con_loss: 0.2511 contrastive_loss: 5.2517 nll_loss: 0.0009 
2023-11-03 08:16:15.662 | INFO     | __main__:train:314 - Epoch: [184][1100/1251]	 loss 4.35217	 cls_loss: 0.2105 cluster_loss: 1.1644 sup_con_loss: 0.3037 contrastive_loss: 5.2533 nll_loss: 0.0007 
2023-11-03 08:19:59.159 | INFO     | __main__:train:314 - Epoch: [184][1200/1251]	 loss 4.41555	 cls_loss: 0.2161 cluster_loss: 1.2241 sup_con_loss: 0.3646 contrastive_loss: 5.2540 nll_loss: 0.0015 
2023-11-03 08:21:51.741 | INFO     | __main__:train:319 - Train Epoch: 184 Avg Loss: 4.3582 
2023-11-03 08:21:51.750 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 08:39:32.096 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 184, Train ACC Unlabelled_v2: All 0.6235 | Old 0.7942 | New 0.5377
2023-11-03 08:39:32.329 | INFO     | __main__:main:205 - Train Accuracies: All 0.6235 | Old 0.7942 | New 0.5377
2023-11-03 08:39:35.305 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 08:39:50.454 | INFO     | __main__:train:314 - Epoch: [185][0/1251]	 loss 4.38993	 cls_loss: 0.2398 cluster_loss: 1.1975 sup_con_loss: 0.3194 contrastive_loss: 5.2533 nll_loss: 0.0012 
2023-11-03 08:43:37.545 | INFO     | __main__:train:314 - Epoch: [185][100/1251]	 loss 4.35551	 cls_loss: 0.2028 cluster_loss: 1.1917 sup_con_loss: 0.2718 contrastive_loss: 5.2526 nll_loss: 0.0006 
2023-11-03 08:47:30.187 | INFO     | __main__:train:314 - Epoch: [185][200/1251]	 loss 4.37512	 cls_loss: 0.2083 cluster_loss: 1.1864 sup_con_loss: 0.3317 contrastive_loss: 5.2531 nll_loss: 0.0005 
2023-11-03 08:51:15.965 | INFO     | __main__:train:314 - Epoch: [185][300/1251]	 loss 4.36528	 cls_loss: 0.2302 cluster_loss: 1.1883 sup_con_loss: 0.2775 contrastive_loss: 5.2533 nll_loss: 0.0005 
2023-11-03 08:55:00.624 | INFO     | __main__:train:314 - Epoch: [185][400/1251]	 loss 4.37727	 cls_loss: 0.1958 cluster_loss: 1.2135 sup_con_loss: 0.2988 contrastive_loss: 5.2527 nll_loss: 0.0011 
2023-11-03 08:58:45.714 | INFO     | __main__:train:314 - Epoch: [185][500/1251]	 loss 4.34546	 cls_loss: 0.2194 cluster_loss: 1.1963 sup_con_loss: 0.2140 contrastive_loss: 5.2538 nll_loss: 0.0012 
2023-11-03 09:02:31.300 | INFO     | __main__:train:314 - Epoch: [185][600/1251]	 loss 4.34248	 cls_loss: 0.2274 cluster_loss: 1.1915 sup_con_loss: 0.2107 contrastive_loss: 5.2523 nll_loss: 0.0007 
2023-11-03 09:06:17.082 | INFO     | __main__:train:314 - Epoch: [185][700/1251]	 loss 4.33970	 cls_loss: 0.2183 cluster_loss: 1.1594 sup_con_loss: 0.2691 contrastive_loss: 5.2528 nll_loss: 0.0011 
2023-11-03 09:10:02.448 | INFO     | __main__:train:314 - Epoch: [185][800/1251]	 loss 4.41727	 cls_loss: 0.2068 cluster_loss: 1.2394 sup_con_loss: 0.3492 contrastive_loss: 5.2559 nll_loss: 0.0007 
2023-11-03 09:13:46.639 | INFO     | __main__:train:314 - Epoch: [185][900/1251]	 loss 4.32018	 cls_loss: 0.2352 cluster_loss: 1.1598 sup_con_loss: 0.1952 contrastive_loss: 5.2539 nll_loss: 0.0006 
2023-11-03 09:17:30.086 | INFO     | __main__:train:314 - Epoch: [185][1000/1251]	 loss 4.34304	 cls_loss: 0.2126 cluster_loss: 1.1960 sup_con_loss: 0.2183 contrastive_loss: 5.2526 nll_loss: 0.0006 
2023-11-03 09:21:14.944 | INFO     | __main__:train:314 - Epoch: [185][1100/1251]	 loss 4.34135	 cls_loss: 0.2155 cluster_loss: 1.1620 sup_con_loss: 0.2779 contrastive_loss: 5.2499 nll_loss: 0.0009 
2023-11-03 09:24:58.937 | INFO     | __main__:train:314 - Epoch: [185][1200/1251]	 loss 4.35884	 cls_loss: 0.2056 cluster_loss: 1.1884 sup_con_loss: 0.2869 contrastive_loss: 5.2515 nll_loss: 0.0005 
2023-11-03 09:26:50.640 | INFO     | __main__:train:319 - Train Epoch: 185 Avg Loss: 4.3599 
2023-11-03 09:26:50.645 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 09:44:31.048 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 185, Train ACC Unlabelled_v2: All 0.6238 | Old 0.7941 | New 0.5382
2023-11-03 09:44:31.246 | INFO     | __main__:main:205 - Train Accuracies: All 0.6238 | Old 0.7941 | New 0.5382
2023-11-03 09:44:34.976 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 09:44:51.832 | INFO     | __main__:train:314 - Epoch: [186][0/1251]	 loss 4.32865	 cls_loss: 0.2127 cluster_loss: 1.1919 sup_con_loss: 0.1843 contrastive_loss: 5.2528 nll_loss: 0.0006 
2023-11-03 09:48:37.836 | INFO     | __main__:train:314 - Epoch: [186][100/1251]	 loss 4.35547	 cls_loss: 0.2001 cluster_loss: 1.2108 sup_con_loss: 0.2278 contrastive_loss: 5.2582 nll_loss: 0.0009 
2023-11-03 09:52:22.928 | INFO     | __main__:train:314 - Epoch: [186][200/1251]	 loss 4.39591	 cls_loss: 0.2053 cluster_loss: 1.2088 sup_con_loss: 0.3542 contrastive_loss: 5.2521 nll_loss: 0.0005 
2023-11-03 09:56:06.255 | INFO     | __main__:train:314 - Epoch: [186][300/1251]	 loss 4.31180	 cls_loss: 0.2031 cluster_loss: 1.1659 sup_con_loss: 0.1969 contrastive_loss: 5.2514 nll_loss: 0.0006 
2023-11-03 09:59:51.646 | INFO     | __main__:train:314 - Epoch: [186][400/1251]	 loss 4.29950	 cls_loss: 0.2203 cluster_loss: 1.1432 sup_con_loss: 0.1832 contrastive_loss: 5.2526 nll_loss: 0.0010 
2023-11-03 10:03:34.960 | INFO     | __main__:train:314 - Epoch: [186][500/1251]	 loss 4.32263	 cls_loss: 0.2026 cluster_loss: 1.1408 sup_con_loss: 0.2746 contrastive_loss: 5.2509 nll_loss: 0.0010 
2023-11-03 10:07:20.208 | INFO     | __main__:train:314 - Epoch: [186][600/1251]	 loss 4.35701	 cls_loss: 0.2026 cluster_loss: 1.1690 sup_con_loss: 0.3174 contrastive_loss: 5.2528 nll_loss: 0.0009 
2023-11-03 10:11:05.803 | INFO     | __main__:train:314 - Epoch: [186][700/1251]	 loss 4.40075	 cls_loss: 0.2328 cluster_loss: 1.2238 sup_con_loss: 0.3052 contrastive_loss: 5.2554 nll_loss: 0.0009 
2023-11-03 10:14:50.722 | INFO     | __main__:train:314 - Epoch: [186][800/1251]	 loss 4.37767	 cls_loss: 0.1954 cluster_loss: 1.2176 sup_con_loss: 0.2847 contrastive_loss: 5.2568 nll_loss: 0.0013 
2023-11-03 10:18:35.582 | INFO     | __main__:train:314 - Epoch: [186][900/1251]	 loss 4.36291	 cls_loss: 0.2145 cluster_loss: 1.1902 sup_con_loss: 0.2809 contrastive_loss: 5.2540 nll_loss: 0.0008 
2023-11-03 10:22:19.791 | INFO     | __main__:train:314 - Epoch: [186][1000/1251]	 loss 4.34105	 cls_loss: 0.2026 cluster_loss: 1.2017 sup_con_loss: 0.2079 contrastive_loss: 5.2545 nll_loss: 0.0008 
2023-11-03 10:26:06.680 | INFO     | __main__:train:314 - Epoch: [186][1100/1251]	 loss 4.33355	 cls_loss: 0.2055 cluster_loss: 1.1735 sup_con_loss: 0.2355 contrastive_loss: 5.2550 nll_loss: 0.0007 
2023-11-03 10:29:49.540 | INFO     | __main__:train:314 - Epoch: [186][1200/1251]	 loss 4.33415	 cls_loss: 0.2230 cluster_loss: 1.1920 sup_con_loss: 0.1785 contrastive_loss: 5.2578 nll_loss: 0.0013 
2023-11-03 10:31:41.023 | INFO     | __main__:train:319 - Train Epoch: 186 Avg Loss: 4.3583 
2023-11-03 10:31:41.030 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 10:50:24.217 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 186, Train ACC Unlabelled_v2: All 0.6239 | Old 0.7943 | New 0.5383
2023-11-03 10:50:24.414 | INFO     | __main__:main:205 - Train Accuracies: All 0.6239 | Old 0.7943 | New 0.5383
2023-11-03 10:50:28.680 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 10:50:45.126 | INFO     | __main__:train:314 - Epoch: [187][0/1251]	 loss 4.32637	 cls_loss: 0.2043 cluster_loss: 1.1534 sup_con_loss: 0.2607 contrastive_loss: 5.2511 nll_loss: 0.0006 
2023-11-03 10:54:29.104 | INFO     | __main__:train:314 - Epoch: [187][100/1251]	 loss 4.40402	 cls_loss: 0.2150 cluster_loss: 1.2064 sup_con_loss: 0.3646 contrastive_loss: 5.2559 nll_loss: 0.0007 
2023-11-03 10:58:14.630 | INFO     | __main__:train:314 - Epoch: [187][200/1251]	 loss 4.43972	 cls_loss: 0.2231 cluster_loss: 1.2270 sup_con_loss: 0.4251 contrastive_loss: 5.2534 nll_loss: 0.0006 
2023-11-03 11:01:58.003 | INFO     | __main__:train:314 - Epoch: [187][300/1251]	 loss 4.36449	 cls_loss: 0.1975 cluster_loss: 1.2002 sup_con_loss: 0.2861 contrastive_loss: 5.2529 nll_loss: 0.0007 
2023-11-03 11:05:44.730 | INFO     | __main__:train:314 - Epoch: [187][400/1251]	 loss 4.34010	 cls_loss: 0.2373 cluster_loss: 1.2019 sup_con_loss: 0.1684 contrastive_loss: 5.2559 nll_loss: 0.0005 
2023-11-03 11:09:30.009 | INFO     | __main__:train:314 - Epoch: [187][500/1251]	 loss 4.33827	 cls_loss: 0.2010 cluster_loss: 1.2036 sup_con_loss: 0.1998 contrastive_loss: 5.2534 nll_loss: 0.0009 
2023-11-03 11:13:15.952 | INFO     | __main__:train:314 - Epoch: [187][600/1251]	 loss 4.36989	 cls_loss: 0.2162 cluster_loss: 1.2058 sup_con_loss: 0.2741 contrastive_loss: 5.2519 nll_loss: 0.0008 
2023-11-03 11:17:03.825 | INFO     | __main__:train:314 - Epoch: [187][700/1251]	 loss 4.33031	 cls_loss: 0.1998 cluster_loss: 1.1578 sup_con_loss: 0.2672 contrastive_loss: 5.2518 nll_loss: 0.0006 
2023-11-03 11:20:47.667 | INFO     | __main__:train:314 - Epoch: [187][800/1251]	 loss 4.33646	 cls_loss: 0.2249 cluster_loss: 1.1503 sup_con_loss: 0.2755 contrastive_loss: 5.2511 nll_loss: 0.0004 
2023-11-03 11:24:34.149 | INFO     | __main__:train:314 - Epoch: [187][900/1251]	 loss 4.37339	 cls_loss: 0.2258 cluster_loss: 1.1852 sup_con_loss: 0.3120 contrastive_loss: 5.2526 nll_loss: 0.0006 
2023-11-03 11:28:19.823 | INFO     | __main__:train:314 - Epoch: [187][1000/1251]	 loss 4.36832	 cls_loss: 0.2002 cluster_loss: 1.1929 sup_con_loss: 0.3104 contrastive_loss: 5.2517 nll_loss: 0.0007 
2023-11-03 11:32:04.585 | INFO     | __main__:train:314 - Epoch: [187][1100/1251]	 loss 4.28339	 cls_loss: 0.2003 cluster_loss: 1.1299 sup_con_loss: 0.1852 contrastive_loss: 5.2514 nll_loss: 0.0007 
2023-11-03 11:35:52.579 | INFO     | __main__:train:314 - Epoch: [187][1200/1251]	 loss 4.38224	 cls_loss: 0.2143 cluster_loss: 1.2553 sup_con_loss: 0.2071 contrastive_loss: 5.2583 nll_loss: 0.0009 
2023-11-03 11:37:44.734 | INFO     | __main__:train:319 - Train Epoch: 187 Avg Loss: 4.3579 
2023-11-03 11:37:44.744 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 11:58:01.250 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 187, Train ACC Unlabelled_v2: All 0.6239 | Old 0.7947 | New 0.5380
2023-11-03 11:58:01.578 | INFO     | __main__:main:205 - Train Accuracies: All 0.6239 | Old 0.7947 | New 0.5380
2023-11-03 11:58:05.617 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 11:58:20.784 | INFO     | __main__:train:314 - Epoch: [188][0/1251]	 loss 4.36763	 cls_loss: 0.2164 cluster_loss: 1.2011 sup_con_loss: 0.2710 contrastive_loss: 5.2543 nll_loss: 0.0010 
2023-11-03 12:02:10.748 | INFO     | __main__:train:314 - Epoch: [188][100/1251]	 loss 4.36365	 cls_loss: 0.2117 cluster_loss: 1.1749 sup_con_loss: 0.3185 contrastive_loss: 5.2519 nll_loss: 0.0006 
2023-11-03 12:05:56.599 | INFO     | __main__:train:314 - Epoch: [188][200/1251]	 loss 4.37190	 cls_loss: 0.2010 cluster_loss: 1.2303 sup_con_loss: 0.2355 contrastive_loss: 5.2599 nll_loss: 0.0005 
2023-11-03 12:09:41.214 | INFO     | __main__:train:314 - Epoch: [188][300/1251]	 loss 4.42195	 cls_loss: 0.2252 cluster_loss: 1.2331 sup_con_loss: 0.3586 contrastive_loss: 5.2551 nll_loss: 0.0003 
2023-11-03 12:13:24.642 | INFO     | __main__:train:314 - Epoch: [188][400/1251]	 loss 4.35786	 cls_loss: 0.2254 cluster_loss: 1.2066 sup_con_loss: 0.2214 contrastive_loss: 5.2561 nll_loss: 0.0007 
2023-11-03 12:17:08.971 | INFO     | __main__:train:314 - Epoch: [188][500/1251]	 loss 4.32086	 cls_loss: 0.2095 cluster_loss: 1.1771 sup_con_loss: 0.1926 contrastive_loss: 5.2526 nll_loss: 0.0008 
2023-11-03 12:20:53.041 | INFO     | __main__:train:314 - Epoch: [188][600/1251]	 loss 4.36647	 cls_loss: 0.2016 cluster_loss: 1.2036 sup_con_loss: 0.2797 contrastive_loss: 5.2539 nll_loss: 0.0006 
2023-11-03 12:24:35.926 | INFO     | __main__:train:314 - Epoch: [188][700/1251]	 loss 4.32801	 cls_loss: 0.2352 cluster_loss: 1.1536 sup_con_loss: 0.2335 contrastive_loss: 5.2518 nll_loss: 0.0005 
2023-11-03 12:28:21.028 | INFO     | __main__:train:314 - Epoch: [188][800/1251]	 loss 4.31638	 cls_loss: 0.2123 cluster_loss: 1.1801 sup_con_loss: 0.1644 contrastive_loss: 5.2561 nll_loss: 0.0010 
2023-11-03 12:32:06.294 | INFO     | __main__:train:314 - Epoch: [188][900/1251]	 loss 4.39184	 cls_loss: 0.2179 cluster_loss: 1.2132 sup_con_loss: 0.3126 contrastive_loss: 5.2568 nll_loss: 0.0007 
2023-11-03 12:35:50.436 | INFO     | __main__:train:314 - Epoch: [188][1000/1251]	 loss 4.43767	 cls_loss: 0.2199 cluster_loss: 1.2377 sup_con_loss: 0.3999 contrastive_loss: 5.2546 nll_loss: 0.0008 
2023-11-03 12:39:34.850 | INFO     | __main__:train:314 - Epoch: [188][1100/1251]	 loss 4.35236	 cls_loss: 0.2135 cluster_loss: 1.2065 sup_con_loss: 0.2257 contrastive_loss: 5.2523 nll_loss: 0.0005 
2023-11-03 12:43:20.452 | INFO     | __main__:train:314 - Epoch: [188][1200/1251]	 loss 4.32508	 cls_loss: 0.2061 cluster_loss: 1.1694 sup_con_loss: 0.2271 contrastive_loss: 5.2499 nll_loss: 0.0009 
2023-11-03 12:45:14.100 | INFO     | __main__:train:319 - Train Epoch: 188 Avg Loss: 4.3565 
2023-11-03 12:45:14.326 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 13:04:28.454 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 188, Train ACC Unlabelled_v2: All 0.6240 | Old 0.7947 | New 0.5382
2023-11-03 13:04:29.599 | INFO     | __main__:main:205 - Train Accuracies: All 0.6240 | Old 0.7947 | New 0.5382
2023-11-03 13:04:35.309 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 13:04:53.008 | INFO     | __main__:train:314 - Epoch: [189][0/1251]	 loss 4.33390	 cls_loss: 0.2120 cluster_loss: 1.1965 sup_con_loss: 0.1881 contrastive_loss: 5.2541 nll_loss: 0.0010 
2023-11-03 13:08:37.483 | INFO     | __main__:train:314 - Epoch: [189][100/1251]	 loss 4.33556	 cls_loss: 0.1901 cluster_loss: 1.1999 sup_con_loss: 0.2062 contrastive_loss: 5.2553 nll_loss: 0.0010 
2023-11-03 13:12:24.609 | INFO     | __main__:train:314 - Epoch: [189][200/1251]	 loss 4.36594	 cls_loss: 0.2234 cluster_loss: 1.1999 sup_con_loss: 0.2645 contrastive_loss: 5.2527 nll_loss: 0.0010 
2023-11-03 13:16:08.905 | INFO     | __main__:train:314 - Epoch: [189][300/1251]	 loss 4.32180	 cls_loss: 0.2111 cluster_loss: 1.1685 sup_con_loss: 0.2063 contrastive_loss: 5.2547 nll_loss: 0.0007 
2023-11-03 13:19:56.055 | INFO     | __main__:train:314 - Epoch: [189][400/1251]	 loss 4.38064	 cls_loss: 0.2160 cluster_loss: 1.2003 sup_con_loss: 0.3126 contrastive_loss: 5.2532 nll_loss: 0.0008 
2023-11-03 13:23:40.479 | INFO     | __main__:train:314 - Epoch: [189][500/1251]	 loss 4.34245	 cls_loss: 0.2123 cluster_loss: 1.1717 sup_con_loss: 0.2619 contrastive_loss: 5.2528 nll_loss: 0.0006 
2023-11-03 13:27:27.481 | INFO     | __main__:train:314 - Epoch: [189][600/1251]	 loss 4.32548	 cls_loss: 0.2032 cluster_loss: 1.1765 sup_con_loss: 0.2111 contrastive_loss: 5.2535 nll_loss: 0.0010 
2023-11-03 13:31:12.943 | INFO     | __main__:train:314 - Epoch: [189][700/1251]	 loss 4.31411	 cls_loss: 0.2080 cluster_loss: 1.1689 sup_con_loss: 0.1923 contrastive_loss: 5.2513 nll_loss: 0.0009 
2023-11-03 13:34:59.596 | INFO     | __main__:train:314 - Epoch: [189][800/1251]	 loss 4.34059	 cls_loss: 0.2193 cluster_loss: 1.1675 sup_con_loss: 0.2592 contrastive_loss: 5.2519 nll_loss: 0.0005 
2023-11-03 13:38:45.399 | INFO     | __main__:train:314 - Epoch: [189][900/1251]	 loss 4.35872	 cls_loss: 0.1999 cluster_loss: 1.2029 sup_con_loss: 0.2612 contrastive_loss: 5.2534 nll_loss: 0.0007 
2023-11-03 13:42:30.740 | INFO     | __main__:train:314 - Epoch: [189][1000/1251]	 loss 4.33535	 cls_loss: 0.2054 cluster_loss: 1.1910 sup_con_loss: 0.2061 contrastive_loss: 5.2559 nll_loss: 0.0008 
2023-11-03 13:46:14.797 | INFO     | __main__:train:314 - Epoch: [189][1100/1251]	 loss 4.34285	 cls_loss: 0.2267 cluster_loss: 1.1900 sup_con_loss: 0.2130 contrastive_loss: 5.2539 nll_loss: 0.0005 
2023-11-03 13:50:03.523 | INFO     | __main__:train:314 - Epoch: [189][1200/1251]	 loss 4.32794	 cls_loss: 0.1984 cluster_loss: 1.1536 sup_con_loss: 0.2738 contrastive_loss: 5.2494 nll_loss: 0.0007 
2023-11-03 13:51:56.856 | INFO     | __main__:train:319 - Train Epoch: 189 Avg Loss: 4.3553 
2023-11-03 13:51:56.867 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 14:12:17.267 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 189, Train ACC Unlabelled_v2: All 0.6239 | Old 0.7945 | New 0.5382
2023-11-03 14:12:17.755 | INFO     | __main__:main:205 - Train Accuracies: All 0.6239 | Old 0.7945 | New 0.5382
2023-11-03 14:12:21.308 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 14:12:44.122 | INFO     | __main__:train:314 - Epoch: [190][0/1251]	 loss 4.35198	 cls_loss: 0.2033 cluster_loss: 1.1823 sup_con_loss: 0.2764 contrastive_loss: 5.2539 nll_loss: 0.0006 
2023-11-03 14:16:38.682 | INFO     | __main__:train:314 - Epoch: [190][100/1251]	 loss 4.41330	 cls_loss: 0.2241 cluster_loss: 1.2024 sup_con_loss: 0.3959 contrastive_loss: 5.2524 nll_loss: 0.0007 
2023-11-03 14:20:23.353 | INFO     | __main__:train:314 - Epoch: [190][200/1251]	 loss 4.31966	 cls_loss: 0.1983 cluster_loss: 1.1848 sup_con_loss: 0.1799 contrastive_loss: 5.2563 nll_loss: 0.0006 
2023-11-03 14:24:12.709 | INFO     | __main__:train:314 - Epoch: [190][300/1251]	 loss 4.32086	 cls_loss: 0.1944 cluster_loss: 1.1611 sup_con_loss: 0.2398 contrastive_loss: 5.2516 nll_loss: 0.0006 
2023-11-03 14:27:59.125 | INFO     | __main__:train:314 - Epoch: [190][400/1251]	 loss 4.30038	 cls_loss: 0.2080 cluster_loss: 1.1316 sup_con_loss: 0.2252 contrastive_loss: 5.2501 nll_loss: 0.0006 
2023-11-03 14:31:46.674 | INFO     | __main__:train:314 - Epoch: [190][500/1251]	 loss 4.33603	 cls_loss: 0.2056 cluster_loss: 1.1595 sup_con_loss: 0.2751 contrastive_loss: 5.2513 nll_loss: 0.0008 
2023-11-03 14:35:36.139 | INFO     | __main__:train:314 - Epoch: [190][600/1251]	 loss 4.32810	 cls_loss: 0.2217 cluster_loss: 1.1491 sup_con_loss: 0.2566 contrastive_loss: 5.2507 nll_loss: 0.0009 
2023-11-03 14:39:26.208 | INFO     | __main__:train:314 - Epoch: [190][700/1251]	 loss 4.35571	 cls_loss: 0.2145 cluster_loss: 1.1649 sup_con_loss: 0.3122 contrastive_loss: 5.2515 nll_loss: 0.0007 
2023-11-03 14:43:16.236 | INFO     | __main__:train:314 - Epoch: [190][800/1251]	 loss 4.35556	 cls_loss: 0.2336 cluster_loss: 1.1897 sup_con_loss: 0.2359 contrastive_loss: 5.2565 nll_loss: 0.0013 
2023-11-03 14:47:01.177 | INFO     | __main__:train:314 - Epoch: [190][900/1251]	 loss 4.40840	 cls_loss: 0.1948 cluster_loss: 1.2129 sup_con_loss: 0.3912 contrastive_loss: 5.2529 nll_loss: 0.0005 
2023-11-03 14:50:49.200 | INFO     | __main__:train:314 - Epoch: [190][1000/1251]	 loss 4.34225	 cls_loss: 0.2336 cluster_loss: 1.1965 sup_con_loss: 0.1948 contrastive_loss: 5.2524 nll_loss: 0.0005 
2023-11-03 14:54:35.399 | INFO     | __main__:train:314 - Epoch: [190][1100/1251]	 loss 4.37741	 cls_loss: 0.2277 cluster_loss: 1.2270 sup_con_loss: 0.2368 contrastive_loss: 5.2560 nll_loss: 0.0009 
2023-11-03 14:58:26.239 | INFO     | __main__:train:314 - Epoch: [190][1200/1251]	 loss 4.34723	 cls_loss: 0.2117 cluster_loss: 1.1733 sup_con_loss: 0.2723 contrastive_loss: 5.2533 nll_loss: 0.0006 
2023-11-03 15:00:21.119 | INFO     | __main__:train:319 - Train Epoch: 190 Avg Loss: 4.3541 
2023-11-03 15:00:21.122 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 15:25:42.745 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 190, Train ACC Unlabelled_v2: All 0.6240 | Old 0.7945 | New 0.5383
2023-11-03 15:25:43.089 | INFO     | __main__:main:205 - Train Accuracies: All 0.6240 | Old 0.7945 | New 0.5383
2023-11-03 15:25:48.303 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 15:26:22.258 | INFO     | __main__:train:314 - Epoch: [191][0/1251]	 loss 4.41112	 cls_loss: 0.2081 cluster_loss: 1.2424 sup_con_loss: 0.3222 contrastive_loss: 5.2573 nll_loss: 0.0007 
2023-11-03 15:30:10.422 | INFO     | __main__:train:314 - Epoch: [191][100/1251]	 loss 4.34264	 cls_loss: 0.2096 cluster_loss: 1.1752 sup_con_loss: 0.2534 contrastive_loss: 5.2550 nll_loss: 0.0010 
2023-11-03 15:33:59.476 | INFO     | __main__:train:314 - Epoch: [191][200/1251]	 loss 4.31397	 cls_loss: 0.2151 cluster_loss: 1.1844 sup_con_loss: 0.1458 contrastive_loss: 5.2568 nll_loss: 0.0009 
2023-11-03 15:37:50.841 | INFO     | __main__:train:314 - Epoch: [191][300/1251]	 loss 4.36820	 cls_loss: 0.1965 cluster_loss: 1.2128 sup_con_loss: 0.2749 contrastive_loss: 5.2529 nll_loss: 0.0005 
2023-11-03 15:41:42.795 | INFO     | __main__:train:314 - Epoch: [191][400/1251]	 loss 4.39370	 cls_loss: 0.2218 cluster_loss: 1.2277 sup_con_loss: 0.2821 contrastive_loss: 5.2594 nll_loss: 0.0007 
2023-11-03 15:45:32.277 | INFO     | __main__:train:314 - Epoch: [191][500/1251]	 loss 4.38327	 cls_loss: 0.2177 cluster_loss: 1.2148 sup_con_loss: 0.2869 contrastive_loss: 5.2555 nll_loss: 0.0010 
2023-11-03 15:49:18.806 | INFO     | __main__:train:314 - Epoch: [191][600/1251]	 loss 4.36368	 cls_loss: 0.2250 cluster_loss: 1.1740 sup_con_loss: 0.2996 contrastive_loss: 5.2558 nll_loss: 0.0007 
2023-11-03 15:53:06.968 | INFO     | __main__:train:314 - Epoch: [191][700/1251]	 loss 4.35786	 cls_loss: 0.2047 cluster_loss: 1.1689 sup_con_loss: 0.3207 contrastive_loss: 5.2514 nll_loss: 0.0008 
2023-11-03 15:56:52.991 | INFO     | __main__:train:314 - Epoch: [191][800/1251]	 loss 4.41443	 cls_loss: 0.2170 cluster_loss: 1.2217 sup_con_loss: 0.3670 contrastive_loss: 5.2542 nll_loss: 0.0007 
2023-11-03 16:00:45.029 | INFO     | __main__:train:314 - Epoch: [191][900/1251]	 loss 4.35871	 cls_loss: 0.2100 cluster_loss: 1.1836 sup_con_loss: 0.2913 contrastive_loss: 5.2513 nll_loss: 0.0006 
2023-11-03 16:04:39.172 | INFO     | __main__:train:314 - Epoch: [191][1000/1251]	 loss 4.36526	 cls_loss: 0.2523 cluster_loss: 1.1920 sup_con_loss: 0.2472 contrastive_loss: 5.2541 nll_loss: 0.0005 
2023-11-03 16:08:25.839 | INFO     | __main__:train:314 - Epoch: [191][1100/1251]	 loss 4.38834	 cls_loss: 0.2251 cluster_loss: 1.2334 sup_con_loss: 0.2610 contrastive_loss: 5.2551 nll_loss: 0.0007 
2023-11-03 16:12:16.380 | INFO     | __main__:train:314 - Epoch: [191][1200/1251]	 loss 4.36674	 cls_loss: 0.2339 cluster_loss: 1.2139 sup_con_loss: 0.2246 contrastive_loss: 5.2560 nll_loss: 0.0008 
2023-11-03 16:14:10.439 | INFO     | __main__:train:319 - Train Epoch: 191 Avg Loss: 4.3562 
2023-11-03 16:14:10.446 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 16:41:15.626 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 191, Train ACC Unlabelled_v2: All 0.6241 | Old 0.7949 | New 0.5382
2023-11-03 16:41:15.907 | INFO     | __main__:main:205 - Train Accuracies: All 0.6241 | Old 0.7949 | New 0.5382
2023-11-03 16:41:22.512 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 16:41:40.774 | INFO     | __main__:train:314 - Epoch: [192][0/1251]	 loss 4.32808	 cls_loss: 0.2303 cluster_loss: 1.1483 sup_con_loss: 0.2507 contrastive_loss: 5.2500 nll_loss: 0.0009 
2023-11-03 16:45:29.935 | INFO     | __main__:train:314 - Epoch: [192][100/1251]	 loss 4.34828	 cls_loss: 0.2107 cluster_loss: 1.1865 sup_con_loss: 0.2527 contrastive_loss: 5.2523 nll_loss: 0.0008 
2023-11-03 16:49:22.983 | INFO     | __main__:train:314 - Epoch: [192][200/1251]	 loss 4.35491	 cls_loss: 0.2227 cluster_loss: 1.1831 sup_con_loss: 0.2680 contrastive_loss: 5.2511 nll_loss: 0.0009 
2023-11-03 16:53:11.953 | INFO     | __main__:train:314 - Epoch: [192][300/1251]	 loss 4.34570	 cls_loss: 0.2097 cluster_loss: 1.1713 sup_con_loss: 0.2787 contrastive_loss: 5.2506 nll_loss: 0.0005 
2023-11-03 16:57:01.740 | INFO     | __main__:train:314 - Epoch: [192][400/1251]	 loss 4.31464	 cls_loss: 0.2191 cluster_loss: 1.1569 sup_con_loss: 0.2030 contrastive_loss: 5.2525 nll_loss: 0.0008 
2023-11-03 17:00:48.389 | INFO     | __main__:train:314 - Epoch: [192][500/1251]	 loss 4.35568	 cls_loss: 0.2006 cluster_loss: 1.1844 sup_con_loss: 0.2890 contrastive_loss: 5.2519 nll_loss: 0.0008 
2023-11-03 17:04:53.213 | INFO     | __main__:train:314 - Epoch: [192][600/1251]	 loss 4.33456	 cls_loss: 0.2152 cluster_loss: 1.1549 sup_con_loss: 0.2694 contrastive_loss: 5.2514 nll_loss: 0.0009 
2023-11-03 17:08:44.420 | INFO     | __main__:train:314 - Epoch: [192][700/1251]	 loss 4.36826	 cls_loss: 0.2054 cluster_loss: 1.2057 sup_con_loss: 0.2834 contrastive_loss: 5.2507 nll_loss: 0.0005 
2023-11-03 17:12:31.544 | INFO     | __main__:train:314 - Epoch: [192][800/1251]	 loss 4.39378	 cls_loss: 0.2098 cluster_loss: 1.2131 sup_con_loss: 0.3351 contrastive_loss: 5.2522 nll_loss: 0.0006 
2023-11-03 17:16:19.518 | INFO     | __main__:train:314 - Epoch: [192][900/1251]	 loss 4.34224	 cls_loss: 0.1999 cluster_loss: 1.1697 sup_con_loss: 0.2781 contrastive_loss: 5.2527 nll_loss: 0.0004 
2023-11-03 17:20:09.858 | INFO     | __main__:train:314 - Epoch: [192][1000/1251]	 loss 4.34325	 cls_loss: 0.2039 cluster_loss: 1.1539 sup_con_loss: 0.3091 contrastive_loss: 5.2505 nll_loss: 0.0009 
2023-11-03 17:23:59.349 | INFO     | __main__:train:314 - Epoch: [192][1100/1251]	 loss 4.41103	 cls_loss: 0.2224 cluster_loss: 1.2227 sup_con_loss: 0.3465 contrastive_loss: 5.2563 nll_loss: 0.0006 
2023-11-03 17:28:35.465 | INFO     | __main__:train:314 - Epoch: [192][1200/1251]	 loss 4.34785	 cls_loss: 0.2219 cluster_loss: 1.1699 sup_con_loss: 0.2704 contrastive_loss: 5.2530 nll_loss: 0.0007 
2023-11-03 17:30:28.064 | INFO     | __main__:train:319 - Train Epoch: 192 Avg Loss: 4.3553 
2023-11-03 17:30:28.108 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 17:54:00.668 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 192, Train ACC Unlabelled_v2: All 0.6240 | Old 0.7939 | New 0.5386
2023-11-03 17:54:01.444 | INFO     | __main__:main:205 - Train Accuracies: All 0.6240 | Old 0.7939 | New 0.5386
2023-11-03 17:54:06.416 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 17:54:21.739 | INFO     | __main__:train:314 - Epoch: [193][0/1251]	 loss 4.38988	 cls_loss: 0.2050 cluster_loss: 1.2040 sup_con_loss: 0.3436 contrastive_loss: 5.2536 nll_loss: 0.0004 
2023-11-03 17:58:14.672 | INFO     | __main__:train:314 - Epoch: [193][100/1251]	 loss 4.29984	 cls_loss: 0.2025 cluster_loss: 1.1370 sup_con_loss: 0.2169 contrastive_loss: 5.2510 nll_loss: 0.0009 
2023-11-03 18:02:04.531 | INFO     | __main__:train:314 - Epoch: [193][200/1251]	 loss 4.32624	 cls_loss: 0.2073 cluster_loss: 1.1723 sup_con_loss: 0.2214 contrastive_loss: 5.2513 nll_loss: 0.0008 
2023-11-03 18:05:56.663 | INFO     | __main__:train:314 - Epoch: [193][300/1251]	 loss 4.33224	 cls_loss: 0.2028 cluster_loss: 1.1735 sup_con_loss: 0.2388 contrastive_loss: 5.2528 nll_loss: 0.0006 
2023-11-03 18:09:48.811 | INFO     | __main__:train:314 - Epoch: [193][400/1251]	 loss 4.37208	 cls_loss: 0.1943 cluster_loss: 1.1991 sup_con_loss: 0.3118 contrastive_loss: 5.2536 nll_loss: 0.0007 
2023-11-03 18:13:34.628 | INFO     | __main__:train:314 - Epoch: [193][500/1251]	 loss 4.37887	 cls_loss: 0.2140 cluster_loss: 1.1923 sup_con_loss: 0.3239 contrastive_loss: 5.2528 nll_loss: 0.0012 
2023-11-03 18:17:22.406 | INFO     | __main__:train:314 - Epoch: [193][600/1251]	 loss 4.31834	 cls_loss: 0.1987 cluster_loss: 1.1561 sup_con_loss: 0.2355 contrastive_loss: 5.2531 nll_loss: 0.0004 
2023-11-03 18:21:08.492 | INFO     | __main__:train:314 - Epoch: [193][700/1251]	 loss 4.30759	 cls_loss: 0.2146 cluster_loss: 1.1541 sup_con_loss: 0.1930 contrastive_loss: 5.2526 nll_loss: 0.0005 
2023-11-03 18:24:57.614 | INFO     | __main__:train:314 - Epoch: [193][800/1251]	 loss 4.34575	 cls_loss: 0.2114 cluster_loss: 1.1890 sup_con_loss: 0.2363 contrastive_loss: 5.2546 nll_loss: 0.0007 
2023-11-03 18:28:42.063 | INFO     | __main__:train:314 - Epoch: [193][900/1251]	 loss 4.34327	 cls_loss: 0.2053 cluster_loss: 1.1631 sup_con_loss: 0.2884 contrastive_loss: 5.2524 nll_loss: 0.0004 
2023-11-03 18:32:28.193 | INFO     | __main__:train:314 - Epoch: [193][1000/1251]	 loss 4.38926	 cls_loss: 0.2311 cluster_loss: 1.2263 sup_con_loss: 0.2664 contrastive_loss: 5.2578 nll_loss: 0.0004 
2023-11-03 18:36:14.447 | INFO     | __main__:train:314 - Epoch: [193][1100/1251]	 loss 4.36710	 cls_loss: 0.2133 cluster_loss: 1.2124 sup_con_loss: 0.2499 contrastive_loss: 5.2554 nll_loss: 0.0009 
2023-11-03 18:40:02.963 | INFO     | __main__:train:314 - Epoch: [193][1200/1251]	 loss 4.34477	 cls_loss: 0.2227 cluster_loss: 1.1573 sup_con_loss: 0.2867 contrastive_loss: 5.2509 nll_loss: 0.0011 
2023-11-03 18:41:54.819 | INFO     | __main__:train:319 - Train Epoch: 193 Avg Loss: 4.3553 
2023-11-03 18:41:54.841 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 19:03:33.435 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 193, Train ACC Unlabelled_v2: All 0.6241 | Old 0.7948 | New 0.5383
2023-11-03 19:03:33.660 | INFO     | __main__:main:205 - Train Accuracies: All 0.6241 | Old 0.7948 | New 0.5383
2023-11-03 19:03:37.148 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 19:03:51.168 | INFO     | __main__:train:314 - Epoch: [194][0/1251]	 loss 4.30962	 cls_loss: 0.2071 cluster_loss: 1.1602 sup_con_loss: 0.1886 contrastive_loss: 5.2562 nll_loss: 0.0005 
2023-11-03 19:07:37.605 | INFO     | __main__:train:314 - Epoch: [194][100/1251]	 loss 4.46389	 cls_loss: 0.2060 cluster_loss: 1.2734 sup_con_loss: 0.4171 contrastive_loss: 5.2578 nll_loss: 0.0005 
2023-11-03 19:11:24.908 | INFO     | __main__:train:314 - Epoch: [194][200/1251]	 loss 4.33090	 cls_loss: 0.2115 cluster_loss: 1.1667 sup_con_loss: 0.2392 contrastive_loss: 5.2520 nll_loss: 0.0010 
2023-11-03 19:15:09.957 | INFO     | __main__:train:314 - Epoch: [194][300/1251]	 loss 4.31473	 cls_loss: 0.2114 cluster_loss: 1.1500 sup_con_loss: 0.2269 contrastive_loss: 5.2508 nll_loss: 0.0008 
2023-11-03 19:18:55.247 | INFO     | __main__:train:314 - Epoch: [194][400/1251]	 loss 4.36270	 cls_loss: 0.2092 cluster_loss: 1.1758 sup_con_loss: 0.3187 contrastive_loss: 5.2503 nll_loss: 0.0009 
2023-11-03 19:22:42.087 | INFO     | __main__:train:314 - Epoch: [194][500/1251]	 loss 4.40987	 cls_loss: 0.2146 cluster_loss: 1.2243 sup_con_loss: 0.3531 contrastive_loss: 5.2535 nll_loss: 0.0006 
2023-11-03 19:26:25.922 | INFO     | __main__:train:314 - Epoch: [194][600/1251]	 loss 4.29441	 cls_loss: 0.2261 cluster_loss: 1.1384 sup_con_loss: 0.1765 contrastive_loss: 5.2504 nll_loss: 0.0008 
2023-11-03 19:30:11.893 | INFO     | __main__:train:314 - Epoch: [194][700/1251]	 loss 4.34684	 cls_loss: 0.2034 cluster_loss: 1.1958 sup_con_loss: 0.2413 contrastive_loss: 5.2511 nll_loss: 0.0007 
2023-11-03 19:33:57.284 | INFO     | __main__:train:314 - Epoch: [194][800/1251]	 loss 4.30917	 cls_loss: 0.2212 cluster_loss: 1.1596 sup_con_loss: 0.1825 contrastive_loss: 5.2513 nll_loss: 0.0008 
2023-11-03 19:37:41.671 | INFO     | __main__:train:314 - Epoch: [194][900/1251]	 loss 4.35125	 cls_loss: 0.2171 cluster_loss: 1.1968 sup_con_loss: 0.2362 contrastive_loss: 5.2522 nll_loss: 0.0008 
2023-11-03 19:41:27.148 | INFO     | __main__:train:314 - Epoch: [194][1000/1251]	 loss 4.36832	 cls_loss: 0.2026 cluster_loss: 1.2102 sup_con_loss: 0.2694 contrastive_loss: 5.2553 nll_loss: 0.0005 
2023-11-03 19:45:11.123 | INFO     | __main__:train:314 - Epoch: [194][1100/1251]	 loss 4.36450	 cls_loss: 0.1951 cluster_loss: 1.1912 sup_con_loss: 0.3072 contrastive_loss: 5.2517 nll_loss: 0.0008 
2023-11-03 19:48:57.254 | INFO     | __main__:train:314 - Epoch: [194][1200/1251]	 loss 4.35399	 cls_loss: 0.2177 cluster_loss: 1.1585 sup_con_loss: 0.3130 contrastive_loss: 5.2530 nll_loss: 0.0008 
2023-11-03 19:50:49.796 | INFO     | __main__:train:319 - Train Epoch: 194 Avg Loss: 4.3551 
2023-11-03 19:50:49.805 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 20:11:57.799 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 194, Train ACC Unlabelled_v2: All 0.6240 | Old 0.7943 | New 0.5384
2023-11-03 20:11:58.168 | INFO     | __main__:main:205 - Train Accuracies: All 0.6240 | Old 0.7943 | New 0.5384
2023-11-03 20:12:01.265 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 20:12:17.393 | INFO     | __main__:train:314 - Epoch: [195][0/1251]	 loss 4.34407	 cls_loss: 0.1999 cluster_loss: 1.1956 sup_con_loss: 0.2291 contrastive_loss: 5.2549 nll_loss: 0.0011 
2023-11-03 20:16:05.457 | INFO     | __main__:train:314 - Epoch: [195][100/1251]	 loss 4.35295	 cls_loss: 0.2213 cluster_loss: 1.2003 sup_con_loss: 0.2295 contrastive_loss: 5.2531 nll_loss: 0.0005 
2023-11-03 20:19:51.669 | INFO     | __main__:train:314 - Epoch: [195][200/1251]	 loss 4.37525	 cls_loss: 0.2400 cluster_loss: 1.2070 sup_con_loss: 0.2533 contrastive_loss: 5.2575 nll_loss: 0.0006 
2023-11-03 20:23:38.713 | INFO     | __main__:train:314 - Epoch: [195][300/1251]	 loss 4.32736	 cls_loss: 0.1983 cluster_loss: 1.1652 sup_con_loss: 0.2489 contrastive_loss: 5.2506 nll_loss: 0.0006 
2023-11-03 20:27:25.606 | INFO     | __main__:train:314 - Epoch: [195][400/1251]	 loss 4.35651	 cls_loss: 0.2027 cluster_loss: 1.1957 sup_con_loss: 0.2608 contrastive_loss: 5.2553 nll_loss: 0.0011 
2023-11-03 20:31:13.750 | INFO     | __main__:train:314 - Epoch: [195][500/1251]	 loss 4.42699	 cls_loss: 0.2199 cluster_loss: 1.2336 sup_con_loss: 0.3729 contrastive_loss: 5.2568 nll_loss: 0.0007 
2023-11-03 20:35:03.491 | INFO     | __main__:train:314 - Epoch: [195][600/1251]	 loss 4.29670	 cls_loss: 0.2258 cluster_loss: 1.1370 sup_con_loss: 0.1818 contrastive_loss: 5.2526 nll_loss: 0.0008 
2023-11-03 20:38:53.942 | INFO     | __main__:train:314 - Epoch: [195][700/1251]	 loss 4.36355	 cls_loss: 0.2243 cluster_loss: 1.2084 sup_con_loss: 0.2325 contrastive_loss: 5.2574 nll_loss: 0.0009 
2023-11-03 20:42:41.697 | INFO     | __main__:train:314 - Epoch: [195][800/1251]	 loss 4.32905	 cls_loss: 0.2464 cluster_loss: 1.1716 sup_con_loss: 0.1906 contrastive_loss: 5.2521 nll_loss: 0.0007 
2023-11-03 20:46:32.178 | INFO     | __main__:train:314 - Epoch: [195][900/1251]	 loss 4.35886	 cls_loss: 0.1982 cluster_loss: 1.1914 sup_con_loss: 0.2838 contrastive_loss: 5.2540 nll_loss: 0.0007 
2023-11-03 20:50:20.227 | INFO     | __main__:train:314 - Epoch: [195][1000/1251]	 loss 4.34564	 cls_loss: 0.1930 cluster_loss: 1.1747 sup_con_loss: 0.2885 contrastive_loss: 5.2507 nll_loss: 0.0006 
2023-11-03 20:54:06.927 | INFO     | __main__:train:314 - Epoch: [195][1100/1251]	 loss 4.36809	 cls_loss: 0.1995 cluster_loss: 1.1921 sup_con_loss: 0.3074 contrastive_loss: 5.2535 nll_loss: 0.0011 
2023-11-03 20:57:58.760 | INFO     | __main__:train:314 - Epoch: [195][1200/1251]	 loss 4.38366	 cls_loss: 0.2264 cluster_loss: 1.1941 sup_con_loss: 0.3190 contrastive_loss: 5.2551 nll_loss: 0.0008 
2023-11-03 20:59:50.832 | INFO     | __main__:train:319 - Train Epoch: 195 Avg Loss: 4.3563 
2023-11-03 20:59:50.840 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 21:22:58.173 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 195, Train ACC Unlabelled_v2: All 0.6240 | Old 0.7949 | New 0.5381
2023-11-03 21:22:58.442 | INFO     | __main__:main:205 - Train Accuracies: All 0.6240 | Old 0.7949 | New 0.5381
2023-11-03 21:23:02.859 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 21:23:18.511 | INFO     | __main__:train:314 - Epoch: [196][0/1251]	 loss 4.36121	 cls_loss: 0.2220 cluster_loss: 1.1832 sup_con_loss: 0.2855 contrastive_loss: 5.2517 nll_loss: 0.0009 
2023-11-03 21:27:02.336 | INFO     | __main__:train:314 - Epoch: [196][100/1251]	 loss 4.38416	 cls_loss: 0.2092 cluster_loss: 1.1860 sup_con_loss: 0.3529 contrastive_loss: 5.2549 nll_loss: 0.0008 
2023-11-03 21:30:50.071 | INFO     | __main__:train:314 - Epoch: [196][200/1251]	 loss 4.33453	 cls_loss: 0.2125 cluster_loss: 1.1476 sup_con_loss: 0.2852 contrastive_loss: 5.2517 nll_loss: 0.0008 
2023-11-03 21:34:36.351 | INFO     | __main__:train:314 - Epoch: [196][300/1251]	 loss 4.39829	 cls_loss: 0.1909 cluster_loss: 1.2030 sup_con_loss: 0.3850 contrastive_loss: 5.2523 nll_loss: 0.0008 
2023-11-03 21:38:24.591 | INFO     | __main__:train:314 - Epoch: [196][400/1251]	 loss 4.34160	 cls_loss: 0.2092 cluster_loss: 1.1700 sup_con_loss: 0.2651 contrastive_loss: 5.2530 nll_loss: 0.0006 
2023-11-03 21:42:16.183 | INFO     | __main__:train:314 - Epoch: [196][500/1251]	 loss 4.32499	 cls_loss: 0.2356 cluster_loss: 1.1603 sup_con_loss: 0.2067 contrastive_loss: 5.2538 nll_loss: 0.0010 
2023-11-03 21:46:00.972 | INFO     | __main__:train:314 - Epoch: [196][600/1251]	 loss 4.33156	 cls_loss: 0.2060 cluster_loss: 1.1489 sup_con_loss: 0.2783 contrastive_loss: 5.2535 nll_loss: 0.0004 
2023-11-03 21:49:45.608 | INFO     | __main__:train:314 - Epoch: [196][700/1251]	 loss 4.39397	 cls_loss: 0.2263 cluster_loss: 1.2119 sup_con_loss: 0.3185 contrastive_loss: 5.2540 nll_loss: 0.0004 
2023-11-03 21:53:29.912 | INFO     | __main__:train:314 - Epoch: [196][800/1251]	 loss 4.29291	 cls_loss: 0.2083 cluster_loss: 1.1513 sup_con_loss: 0.1623 contrastive_loss: 5.2527 nll_loss: 0.0006 
2023-11-03 21:57:14.482 | INFO     | __main__:train:314 - Epoch: [196][900/1251]	 loss 4.37189	 cls_loss: 0.2049 cluster_loss: 1.2069 sup_con_loss: 0.2830 contrastive_loss: 5.2551 nll_loss: 0.0008 
2023-11-03 22:00:59.064 | INFO     | __main__:train:314 - Epoch: [196][1000/1251]	 loss 4.37634	 cls_loss: 0.2402 cluster_loss: 1.2217 sup_con_loss: 0.2314 contrastive_loss: 5.2560 nll_loss: 0.0008 
2023-11-03 22:04:45.132 | INFO     | __main__:train:314 - Epoch: [196][1100/1251]	 loss 4.36579	 cls_loss: 0.2087 cluster_loss: 1.1987 sup_con_loss: 0.2821 contrastive_loss: 5.2523 nll_loss: 0.0008 
2023-11-03 22:08:31.108 | INFO     | __main__:train:314 - Epoch: [196][1200/1251]	 loss 4.36852	 cls_loss: 0.2099 cluster_loss: 1.1820 sup_con_loss: 0.3180 contrastive_loss: 5.2532 nll_loss: 0.0009 
2023-11-03 22:10:23.107 | INFO     | __main__:train:319 - Train Epoch: 196 Avg Loss: 4.3556 
2023-11-03 22:10:23.116 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 22:29:04.089 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 196, Train ACC Unlabelled_v2: All 0.6242 | Old 0.7945 | New 0.5386
2023-11-03 22:29:04.385 | INFO     | __main__:main:205 - Train Accuracies: All 0.6242 | Old 0.7945 | New 0.5386
2023-11-03 22:29:08.343 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 22:29:23.375 | INFO     | __main__:train:314 - Epoch: [197][0/1251]	 loss 4.32029	 cls_loss: 0.1979 cluster_loss: 1.1787 sup_con_loss: 0.1994 contrastive_loss: 5.2529 nll_loss: 0.0007 
2023-11-03 22:33:18.143 | INFO     | __main__:train:314 - Epoch: [197][100/1251]	 loss 4.37349	 cls_loss: 0.2113 cluster_loss: 1.1852 sup_con_loss: 0.3290 contrastive_loss: 5.2514 nll_loss: 0.0006 
2023-11-03 22:37:04.459 | INFO     | __main__:train:314 - Epoch: [197][200/1251]	 loss 4.32552	 cls_loss: 0.1985 cluster_loss: 1.1693 sup_con_loss: 0.2317 contrastive_loss: 5.2520 nll_loss: 0.0011 
2023-11-03 22:40:49.759 | INFO     | __main__:train:314 - Epoch: [197][300/1251]	 loss 4.31346	 cls_loss: 0.2009 cluster_loss: 1.1361 sup_con_loss: 0.2595 contrastive_loss: 5.2511 nll_loss: 0.0007 
2023-11-03 22:44:36.260 | INFO     | __main__:train:314 - Epoch: [197][400/1251]	 loss 4.33309	 cls_loss: 0.2064 cluster_loss: 1.1985 sup_con_loss: 0.1877 contrastive_loss: 5.2544 nll_loss: 0.0007 
2023-11-03 22:48:21.915 | INFO     | __main__:train:314 - Epoch: [197][500/1251]	 loss 4.41301	 cls_loss: 0.2061 cluster_loss: 1.2242 sup_con_loss: 0.3669 contrastive_loss: 5.2556 nll_loss: 0.0006 
2023-11-03 22:52:05.944 | INFO     | __main__:train:314 - Epoch: [197][600/1251]	 loss 4.32213	 cls_loss: 0.2028 cluster_loss: 1.1668 sup_con_loss: 0.2238 contrastive_loss: 5.2510 nll_loss: 0.0012 
2023-11-03 22:55:51.280 | INFO     | __main__:train:314 - Epoch: [197][700/1251]	 loss 4.35393	 cls_loss: 0.2261 cluster_loss: 1.1802 sup_con_loss: 0.2638 contrastive_loss: 5.2526 nll_loss: 0.0012 
2023-11-03 22:59:35.765 | INFO     | __main__:train:314 - Epoch: [197][800/1251]	 loss 4.27334	 cls_loss: 0.1993 cluster_loss: 1.1287 sup_con_loss: 0.1594 contrastive_loss: 5.2513 nll_loss: 0.0008 
2023-11-03 23:03:18.978 | INFO     | __main__:train:314 - Epoch: [197][900/1251]	 loss 4.40252	 cls_loss: 0.2166 cluster_loss: 1.1939 sup_con_loss: 0.3890 contrastive_loss: 5.2524 nll_loss: 0.0005 
2023-11-03 23:07:04.363 | INFO     | __main__:train:314 - Epoch: [197][1000/1251]	 loss 4.39734	 cls_loss: 0.2143 cluster_loss: 1.2230 sup_con_loss: 0.3206 contrastive_loss: 5.2534 nll_loss: 0.0005 
2023-11-03 23:10:48.201 | INFO     | __main__:train:314 - Epoch: [197][1100/1251]	 loss 4.36502	 cls_loss: 0.2052 cluster_loss: 1.2092 sup_con_loss: 0.2598 contrastive_loss: 5.2546 nll_loss: 0.0008 
2023-11-03 23:14:33.234 | INFO     | __main__:train:314 - Epoch: [197][1200/1251]	 loss 4.43874	 cls_loss: 0.1923 cluster_loss: 1.2158 sup_con_loss: 0.4761 contrastive_loss: 5.2516 nll_loss: 0.0010 
2023-11-03 23:16:26.090 | INFO     | __main__:train:319 - Train Epoch: 197 Avg Loss: 4.3548 
2023-11-03 23:16:26.098 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-03 23:35:17.845 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 197, Train ACC Unlabelled_v2: All 0.6241 | Old 0.7941 | New 0.5386
2023-11-03 23:35:18.045 | INFO     | __main__:main:205 - Train Accuracies: All 0.6241 | Old 0.7941 | New 0.5386
2023-11-03 23:35:21.769 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-03 23:35:36.716 | INFO     | __main__:train:314 - Epoch: [198][0/1251]	 loss 4.37239	 cls_loss: 0.1970 cluster_loss: 1.2056 sup_con_loss: 0.2962 contrastive_loss: 5.2545 nll_loss: 0.0007 
2023-11-03 23:39:23.140 | INFO     | __main__:train:314 - Epoch: [198][100/1251]	 loss 4.38258	 cls_loss: 0.1898 cluster_loss: 1.2102 sup_con_loss: 0.3249 contrastive_loss: 5.2538 nll_loss: 0.0008 
2023-11-03 23:43:06.734 | INFO     | __main__:train:314 - Epoch: [198][200/1251]	 loss 4.38718	 cls_loss: 0.2061 cluster_loss: 1.2227 sup_con_loss: 0.2960 contrastive_loss: 5.2558 nll_loss: 0.0004 
2023-11-03 23:46:51.622 | INFO     | __main__:train:314 - Epoch: [198][300/1251]	 loss 4.29666	 cls_loss: 0.2130 cluster_loss: 1.1433 sup_con_loss: 0.1873 contrastive_loss: 5.2501 nll_loss: 0.0009 
2023-11-03 23:50:36.383 | INFO     | __main__:train:314 - Epoch: [198][400/1251]	 loss 4.31752	 cls_loss: 0.1893 cluster_loss: 1.1663 sup_con_loss: 0.2244 contrastive_loss: 5.2521 nll_loss: 0.0008 
2023-11-03 23:54:21.174 | INFO     | __main__:train:314 - Epoch: [198][500/1251]	 loss 4.38382	 cls_loss: 0.2110 cluster_loss: 1.1886 sup_con_loss: 0.3553 contrastive_loss: 5.2493 nll_loss: 0.0010 
2023-11-03 23:58:06.390 | INFO     | __main__:train:314 - Epoch: [198][600/1251]	 loss 4.32687	 cls_loss: 0.2016 cluster_loss: 1.1869 sup_con_loss: 0.1981 contrastive_loss: 5.2537 nll_loss: 0.0006 
2023-11-04 00:01:52.697 | INFO     | __main__:train:314 - Epoch: [198][700/1251]	 loss 4.35682	 cls_loss: 0.2247 cluster_loss: 1.1618 sup_con_loss: 0.3114 contrastive_loss: 5.2515 nll_loss: 0.0005 
2023-11-04 00:05:36.515 | INFO     | __main__:train:314 - Epoch: [198][800/1251]	 loss 4.32797	 cls_loss: 0.1942 cluster_loss: 1.1906 sup_con_loss: 0.2029 contrastive_loss: 5.2528 nll_loss: 0.0007 
2023-11-04 00:09:20.336 | INFO     | __main__:train:314 - Epoch: [198][900/1251]	 loss 4.35865	 cls_loss: 0.2183 cluster_loss: 1.1839 sup_con_loss: 0.2807 contrastive_loss: 5.2514 nll_loss: 0.0010 
2023-11-04 00:13:04.346 | INFO     | __main__:train:314 - Epoch: [198][1000/1251]	 loss 4.34134	 cls_loss: 0.2007 cluster_loss: 1.2013 sup_con_loss: 0.2102 contrastive_loss: 5.2553 nll_loss: 0.0007 
2023-11-04 00:16:47.567 | INFO     | __main__:train:314 - Epoch: [198][1100/1251]	 loss 4.29907	 cls_loss: 0.2045 cluster_loss: 1.1505 sup_con_loss: 0.1870 contrastive_loss: 5.2516 nll_loss: 0.0007 
2023-11-04 00:20:33.142 | INFO     | __main__:train:314 - Epoch: [198][1200/1251]	 loss 4.33617	 cls_loss: 0.2112 cluster_loss: 1.1707 sup_con_loss: 0.2479 contrastive_loss: 5.2522 nll_loss: 0.0006 
2023-11-04 00:22:24.721 | INFO     | __main__:train:319 - Train Epoch: 198 Avg Loss: 4.3538 
2023-11-04 00:22:24.747 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-04 00:44:43.827 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 198, Train ACC Unlabelled_v2: All 0.6242 | Old 0.7947 | New 0.5385
2023-11-04 00:44:43.871 | INFO     | __main__:main:205 - Train Accuracies: All 0.6242 | Old 0.7947 | New 0.5385
2023-11-04 00:44:48.362 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
2023-11-04 00:45:07.389 | INFO     | __main__:train:314 - Epoch: [199][0/1251]	 loss 4.32090	 cls_loss: 0.2368 cluster_loss: 1.1534 sup_con_loss: 0.2087 contrastive_loss: 5.2531 nll_loss: 0.0008 
2023-11-04 00:48:58.826 | INFO     | __main__:train:314 - Epoch: [199][100/1251]	 loss 4.38894	 cls_loss: 0.2095 cluster_loss: 1.1917 sup_con_loss: 0.3549 contrastive_loss: 5.2555 nll_loss: 0.0007 
2023-11-04 00:52:44.360 | INFO     | __main__:train:314 - Epoch: [199][200/1251]	 loss 4.42339	 cls_loss: 0.2093 cluster_loss: 1.2367 sup_con_loss: 0.3705 contrastive_loss: 5.2555 nll_loss: 0.0005 
2023-11-04 00:56:28.747 | INFO     | __main__:train:314 - Epoch: [199][300/1251]	 loss 4.32087	 cls_loss: 0.2037 cluster_loss: 1.1544 sup_con_loss: 0.2438 contrastive_loss: 5.2512 nll_loss: 0.0006 
2023-11-04 01:00:27.749 | INFO     | __main__:train:314 - Epoch: [199][400/1251]	 loss 4.37522	 cls_loss: 0.2120 cluster_loss: 1.1845 sup_con_loss: 0.3349 contrastive_loss: 5.2511 nll_loss: 0.0006 
2023-11-04 01:04:12.253 | INFO     | __main__:train:314 - Epoch: [199][500/1251]	 loss 4.35492	 cls_loss: 0.2135 cluster_loss: 1.1780 sup_con_loss: 0.2897 contrastive_loss: 5.2503 nll_loss: 0.0004 
2023-11-04 01:07:55.285 | INFO     | __main__:train:314 - Epoch: [199][600/1251]	 loss 4.31428	 cls_loss: 0.2036 cluster_loss: 1.1628 sup_con_loss: 0.2098 contrastive_loss: 5.2513 nll_loss: 0.0004 
2023-11-04 01:11:39.730 | INFO     | __main__:train:314 - Epoch: [199][700/1251]	 loss 4.34996	 cls_loss: 0.2021 cluster_loss: 1.2037 sup_con_loss: 0.2327 contrastive_loss: 5.2540 nll_loss: 0.0003 
2023-11-04 01:15:25.503 | INFO     | __main__:train:314 - Epoch: [199][800/1251]	 loss 4.39001	 cls_loss: 0.2268 cluster_loss: 1.2181 sup_con_loss: 0.2899 contrastive_loss: 5.2566 nll_loss: 0.0006 
2023-11-04 01:19:11.730 | INFO     | __main__:train:314 - Epoch: [199][900/1251]	 loss 4.36405	 cls_loss: 0.2251 cluster_loss: 1.1434 sup_con_loss: 0.3673 contrastive_loss: 5.2505 nll_loss: 0.0007 
2023-11-04 01:22:55.175 | INFO     | __main__:train:314 - Epoch: [199][1000/1251]	 loss 4.29971	 cls_loss: 0.2022 cluster_loss: 1.1754 sup_con_loss: 0.1368 contrastive_loss: 5.2558 nll_loss: 0.0007 
2023-11-04 01:26:40.186 | INFO     | __main__:train:314 - Epoch: [199][1100/1251]	 loss 4.33962	 cls_loss: 0.2104 cluster_loss: 1.1663 sup_con_loss: 0.2639 contrastive_loss: 5.2537 nll_loss: 0.0007 
2023-11-04 01:30:24.401 | INFO     | __main__:train:314 - Epoch: [199][1200/1251]	 loss 4.32535	 cls_loss: 0.1993 cluster_loss: 1.1591 sup_con_loss: 0.2521 contrastive_loss: 5.2514 nll_loss: 0.0006 
2023-11-04 01:32:15.970 | INFO     | __main__:train:319 - Train Epoch: 199 Avg Loss: 4.3537 
2023-11-04 01:32:15.978 | INFO     | __main__:main:198 - Testing on unlabelled examples in the training data...
2023-11-04 01:49:51.432 | INFO     | util.cluster_and_log_utils:log_accs_from_preds:180 - Epoch 199, Train ACC Unlabelled_v2: All 0.6241 | Old 0.7949 | New 0.5382
2023-11-04 01:49:51.610 | INFO     | __main__:main:205 - Train Accuracies: All 0.6241 | Old 0.7949 | New 0.5382
2023-11-04 01:49:55.800 | INFO     | __main__:main:215 - model saved to dev_outputs/simgcd/log/imagenet1k_simgcd_(25.10.2023_|_52.465)/checkpoints/model.pt.
